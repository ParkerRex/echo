<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
.cursor/
  rules/
    api-client-usage.mdc
    architecture.mdc
    cursor_rules.mdc
    fastapi.mdc
    memory_bank.mdc
    sb-create-database-functions.mdc
    sb-create-migration.mdc
    sb-create-rls-policies.mdc
    self_improve.mdc
.doing/
  tasks.md
apps/
  core/
    api/
      endpoints/
        __init__.py
        jobs_endpoints.py
        video_processing_endpoints.py
      schemas/
        user_schemas.py
        video_processing_schemas.py
      endpoints.py
    app/
      db/
        engine.py
        schemas.py
    bin/
      clean_test_files.sh
      codegen_models.sh
      codegen_pydantic_supabase.sh
      dev.sh
      format.sh
      lint.sh
      setup.sh
      test.sh
      typecheck.sh
    core/
      exceptions.py
    lib/
      ai/
        __init__.py
        ai_client_factory.py
        base_adapter.py
        gemini_adapter.py
      auth/
        supabase_auth.py
      cache/
        __init__.py
        redis_cache.py
        redis.py
      database/
        __init__.py
        connection.py
      messaging/
        __init__.py
        email.py
      publishing/
        publishing_interface.py
        youtube_adapter.py
      storage/
        __init__.py
        file_storage.py
      utils/
        ffmpeg_utils.py
        file_utils.py
        subtitle_utils.py
      __init__.py
    models/
      __init__.py
      chat_model.py
      enums.py
      user_model.py
      video_job_model.py
      video_metadata_model.py
      video_model.py
    operations/
      __init__.py
      chat_repository.py
      transaction_repo.py
      user_repository.py
      video_job_repository.py
      video_metadata_repository.py
      video_repository.py
    services/
      __init__.py
      ai_service.py
      auth_service.py
      chat_service.py
      job_service.py
      metadata_service.py
      user_service.py
      video_processing_service.py
    tests/
      api/
        __init__.py
        test_jobs_api.py
      integration/
        api/
          test_job_status_retrieval.py
          test_video_upload_flow.py
        conftest.py
        test_video_processing_api.py
      operations/
        __init__.py
        test_video_job_repository.py
      services/
        __init__.py
        test_job_service.py
      unit/
        lib/
          ai/
            __init__.py
            test_ai_client_factory.py
            test_gemini_adapter.py
          auth/
            __init__.py
            test_supabase_auth.py
          cache/
            __init__.py
            test_redis_cache.py
          publishing/
            test_youtube_adapter.py
          storage/
            __init__.py
            test_file_storage.py
          utils/
            __init__.py
            test_ffmpeg_utils.py
            test_file_utils.py
            test_subtitle_utils.py
        operations/
          __init__.py
          test_video_job_repository.py
          test_video_metadata_repository.py
          test_video_repository.py
        services/
          test_user_service.py
          test_video_processing_service.py
      conftest.py
      test_api.py
      test_architecture.py
    .env.production
    .gitignore
    .python-version
    main.py
    package.json
    pyproject.toml
    README.md
  web/
    app/
      components/
        form/
          select-field.tsx
          submit-button.tsx
          text-field.tsx
        home/
          hero.tsx
        shared/
          container.tsx
          navbar.tsx
        ui/
          accordion.tsx
          alert-dialog.tsx
          alert.tsx
          aspect-ratio.tsx
          avatar.tsx
          badge.tsx
          breadcrumb.tsx
          button.tsx
          calendar.tsx
          card.tsx
          carousel.tsx
          chart.tsx
          checkbox.tsx
          collapsible.tsx
          combo-box.tsx
          command.tsx
          context-menu.tsx
          date-picker.tsx
          dialog.tsx
          drawer.tsx
          dropdown-menu.tsx
          dropzone.test.tsx
          dropzone.tsx
          form.tsx
          hover-card.tsx
          input-otp.tsx
          input.tsx
          label.tsx
          menubar.tsx
          navigation-menu.tsx
          pagination.tsx
          popover.tsx
          progress-steps.tsx
          progress.tsx
          radio-group.tsx
          resizable.tsx
          scroll-area.tsx
          select.tsx
          separator.tsx
          sheet.tsx
          sidebar.tsx
          skeleton.tsx
          slider.tsx
          sonner.tsx
          switch.tsx
          table.tsx
          tabs.tsx
          textarea.tsx
          toast.tsx
          toaster.tsx
          toggle-group.tsx
          toggle.tsx
          tooltip.tsx
          use-toast.tsx
        video/
          content-editor.tsx
          processing-dashboard.tsx
          processing-steps.ts
          thumbnail-gallery.tsx
          title-selector.tsx
          video-detail.tsx
          video-progress-card.tsx
          VideoList.tsx
          VideoListItem.tsx
          VideoUploadDropzone.tsx
        auth.tsx
        button-link.tsx
        default-catch-boundary.tsx
        GoogleLoginButton.tsx
        layout.tsx
        login.tsx
        navigation.tsx
        not-found.tsx
        post-error.tsx
        ProtectedLayout.tsx
        user-error.tsx
        user-menu.tsx
      lib/
        api.ts
        date.ts
        form.ts
        types.gen.ts
        types.ts
        use-mobile.ts
        useAppWebSocket.ts
        useAuth.ts
        useDebounce.ts
        useJobStatus.ts
        useJobStatusManager.ts
        useMutation.ts
        utils.ts
      routes/
        auth/
          callback.tsx
        __root.tsx
        _authed.jobs.$jobId.tsx
        _authed.tsx
        _pathlessLayout.tsx
        $videoId.tsx
        dashboard.tsx
        index.tsx
        login.tsx
        logout.tsx
        profile.tsx
        settings.tsx
        sign-in.tsx
        signup.tsx
      services/
        auth.api.ts
        auth.schema.ts
        gcs-content.ts
        queries.ts
      api.ts
      client.tsx
      env.ts
      globals.css
      router.tsx
      routeTree.gen.ts
      ssr.tsx
      types.ts
    .env.development
    .env.production
    .gitignore
    app.config.ts
    biome.json
    components.json
    package.json
    postcss.config.mjs
    README.md
    tailwind.config.ts
    tsconfig.json
packages/
  supabase/
    clients/
      browser.ts
      ssr.ts
    migrations/
      20250514044259_create_videos_table.sql
      README.md
    mutations/
      index.ts
    .gitignore
    config.toml
    index.ts
    package.json
.cursorignore
.dockerignore
.gitignore
.python-version
.repomixignore
echo.code-workspace
package.json
pnpm-workspace.yaml
README.md
repomix.config.json
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".cursor/rules/api-client-usage.mdc">
---
description: 
globs: 
alwaysApply: false
---
---
description: 
globs: 
alwaysApply: true
---
# Cursor Rules for API Client Usage

## API Call Organization

1. **Client Import**
   - Import the API client from the centralized location
   ```typescript
   import { api } from "~/api";
   ```

2. **Query Structure**
   - Use the appropriate method for the HTTP verb
   - First parameter is the HTTP method, second is the endpoint path
   ```typescript
   // GET request
   const { data } = api.useQuery("get", "/api/v1/resource");
   
   // POST request
   const mutation = api.useMutation("post", "/api/v1/resource");
   mutation.mutate(payload);
   ```

3. **Endpoint Patterns**
   - All endpoints should use `/api/v1/` prefix
   - Use resource-focused naming: `/api/v1/users`, `/api/v1/products`

## Data Handling

1. **Type Safety**
   - Define response and request types for all API calls
   ```typescript
   type HelloResponse = { message: string };
   const { data } = api.useQuery<HelloResponse>("get", "/api/v1/hello");
   ```

2. **Loading States**
   - Always handle loading states in UI components
   ```typescript
   const { data, isLoading, error } = api.useQuery("get", "/api/v1/resource");
   if (isLoading) return <LoadingSpinner />;
   if (error) return <ErrorMessage error={error} />;
   ```

3. **Error Handling**
   - Check for errors in all API calls
   - Use appropriate error boundaries

## Query Options

1. **Caching and Refetching**
   - Configure cache time and stale time based on data volatility
   ```typescript
   const { data } = api.useQuery("get", "/api/v1/resource", {
     staleTime: 60000, // 1 minute
     cacheTime: 300000, // 5 minutes
   });
   ```

2. **Query Dependencies**
   - Use the enabled option for dependent queries
   ```typescript
   const { data: user } = api.useQuery("get", "/api/v1/user");
   const { data: userPosts } = api.useQuery("get", `/api/v1/posts?userId=${user?.id}`, {
     enabled: !!user?.id,
   });
   ```

## Component Integration

1. **Data Fetching Location**
   - Fetch data at the route component level when possible
   - Pass data down to child components as props

2. **Mutation Patterns**
   - Handle optimistic updates when appropriate
   - Invalidate related queries after successful mutations
   ```typescript
   const mutation = api.useMutation("post", "/api/v1/resource", {
     onSuccess: () => {
       api.queryClient.invalidateQueries(["get", "/api/v1/resource"]);
     },
   });
   ```
</file>

<file path=".cursor/rules/architecture.mdc">
---
description: 
globs: 
alwaysApply: false
---
---
description: 
globs: 
alwaysApply: true
---
# Cursor Rules for AI-Driven Backend Service

This document outlines the rules and guidelines for maintaining code quality and architectural integrity in this project.

## Code Organization Rules

1. **Layered Architecture Adherence**

   - Keep code within its appropriate layer:
     - `api/` – HTTP interfaces only
     - `services/` – Business logic only
     - `operations/` – Data access only
     - `models/` – Data models only
     - `lib/` – Infrastructure components only

2. **Domain Separation**

   - Organize code by domain within each layer (`auth`, `user`, etc.)
   - File naming should reflect both domain and purpose (e.g., `auth_service.py`)

3. **Import Order**

   ```python
   # 1. Standard library imports
   import os
   from typing import Optional, List

   # 2. Third-party imports
   from fastapi import Depends, HTTPException
   from sqlalchemy.orm import Session

   # 3. Internal imports - by layer, alphabetical
   from api.schemas import UserResponse
   from lib.database import get_db_session
   from models.user import User
   from operations.user import UserRepository
   ```

## Coding Style Rules

1. **Type Annotations**

   - All function parameters and return values must have type hints
   - Complex types should use `typing` module (List, Dict, Optional, etc.)

2. **Function Structure**

   - Single responsibility principle for all functions
   - Document complex functions with docstrings

3. **Error Handling**
   - API layer: Return proper HTTP exceptions
   - Service layer: Business-specific exceptions
   - Operations layer: Database-specific errors
   - Use try/except blocks at appropriate layer boundaries

## Layer-Specific Rules

1. **API Layer**

   - Routes should be minimal and delegate to services
   - All endpoint parameters should be validated with Pydantic
   - Response models must be defined for all endpoints
   - Authentication/authorization handled via FastAPI dependencies

2. **Service Layer**

   - No direct database access; use repositories
   - Implement domain-specific business rules
   - Transaction boundaries should be defined here
   - Return domain objects, not ORM models

3. **Operations Layer**

   - Implement repository pattern
   - Methods should focus on CRUD operations
   - No business logic
   - Handle query optimization

4. **Models Layer**

   - ORM models should be minimal and reflect database schema
   - Avoid business logic in models
   - Use appropriate SQLAlchemy types and constraints

5. **Infrastructure/Lib Layer**
   - Components should be stateless where possible
   - Use dependency injection pattern
   - Implement singleton pattern for expensive resources
   - Provide clear interfaces

## Dependency Injection Rules

1. **Dependency Chain**

   - Follow dependency direction: API → Service → Operations → Models
   - Never reference a higher layer from a lower layer

2. **Dependency Functions**
   - Name dependency functions as `get_*`
   - Implement proper error handling
   - Follow FastAPI's dependency pattern

## Testing Rules

1. **Test Coverage**

   - Minimum 80% code coverage
   - Unit tests for all service functions
   - Integration tests for API endpoints

2. **Test Structure**
   - Use fixtures for test setup
   - Use mocks for external dependencies
   - Test both success and error paths

## Documentation Rules

1. **Code Documentation**

   - Every module should have a module-level docstring
   - Complex functions require docstrings
   - Public functions must have parameter and return documentation

2. **API Documentation**
   - All endpoints must have descriptions
   - Use FastAPI's response_model attribute
   - Include example requests/responses

## Security Rules

1. **Input Validation**

   - All user inputs must be validated with Pydantic schemas
   - Implement additional validation for security-sensitive fields

2. **Authentication**

   - All non-public endpoints must require authentication
   - JWT token validation required for authenticated endpoints

3. **Error Messages**
   - No sensitive data in error messages
   - Consistent error format across API

## Performance Rules

1. **Database Access**

   - Use query optimization techniques
   - Implement caching for frequently accessed data
   - Set appropriate indexes on frequently queried columns

2. **Async Operations**
   - Use async endpoints for I/O-bound operations
</file>

<file path=".cursor/rules/cursor_rules.mdc">
---
description: 
globs: 
alwaysApply: false
---
---
description: Guidelines for creating and maintaining Cursor rules to ensure consistency and effectiveness.
globs: .cursor/rules/*.mdc
alwaysApply: true
---

- **Required Rule Structure:**
  ```markdown
  ---
  description: Clear, one-line description of what the rule enforces
  globs: path/to/files/*.ext, other/path/**/*
  alwaysApply: boolean
  ---

  - **Main Points in Bold**
    - Sub-points with details
    - Examples and explanations
  ```

- **File References:**
  - Use `[filename](mdc:path/to/file)` ([filename](mdc:filename)) to reference files
  - Example: [prisma.mdc](mdc:.cursor/rules/prisma.mdc) for rule references
  - Example: [schema.prisma](mdc:prisma/schema.prisma) for code references

- **Code Examples:**
  - Use language-specific code blocks
  ```typescript
  // ✅ DO: Show good examples
  const goodExample = true;
  
  // ❌ DON'T: Show anti-patterns
  const badExample = false;
  ```

- **Rule Content Guidelines:**
  - Start with high-level overview
  - Include specific, actionable requirements
  - Show examples of correct implementation
  - Reference existing code when possible
  - Keep rules DRY by referencing other rules

- **Rule Maintenance:**
  - Update rules when new patterns emerge
  - Add examples from actual codebase
  - Remove outdated patterns
  - Cross-reference related rules

- **Best Practices:**
  - Use bullet points for clarity
  - Keep descriptions concise
  - Include both DO and DON'T examples
  - Reference actual code over theoretical examples
  - Use consistent formatting across rules
</file>

<file path=".cursor/rules/fastapi.mdc">
---
description: 
globs: 
alwaysApply: false
---
You are an expert in Python, FastAPI, and scalable API development.
  
Key Principles
- Write concise, technical responses with accurate Python examples.
- Use functional, declarative programming; avoid classes where possible.
- Prefer iteration and modularization over code duplication.
- Use descriptive variable names with auxiliary verbs (e.g., is_active, has_permission).
- Use lowercase with underscores for directories and files (e.g., routers/user_routes.py).
- Favor named exports for routes and utility functions.
- Use the Receive an Object, Return an Object (RORO) pattern.
  
Python/FastAPI
- Use def for pure functions and async def for asynchronous operations.
- Use type hints for all function signatures. Prefer Pydantic models over raw dictionaries for input validation.
- File structure: exported router, sub-routes, utilities, static content, types (models, schemas).
- Avoid unnecessary curly braces in conditional statements.
- For single-line statements in conditionals, omit curly braces.
- Use concise, one-line syntax for simple conditional statements (e.g., if condition: do_something()).
  
Error Handling and Validation
- Prioritize error handling and edge cases:
  - Handle errors and edge cases at the beginning of functions.
  - Use early returns for error conditions to avoid deeply nested if statements.
  - Place the happy path last in the function for improved readability.
  - Avoid unnecessary else statements; use the if-return pattern instead.
  - Use guard clauses to handle preconditions and invalid states early.
  - Implement proper error logging and user-friendly error messages.
  - Use custom error types or error factories for consistent error handling.
  
Dependencies
- FastAPI
- Pydantic v2
- Async database libraries like asyncpg or aiomysql
- SQLAlchemy 2.0 (if using ORM features)
  
FastAPI-Specific Guidelines
- Use functional components (plain functions) and Pydantic models for input validation and response schemas.
- Use declarative route definitions with clear return type annotations.
- Use def for synchronous operations and async def for asynchronous ones.
- Minimize @app.on_event("startup") and @app.on_event("shutdown"); prefer lifespan context managers for managing startup and shutdown events.
- Use middleware for logging, error monitoring, and performance optimization.
- Optimize for performance using async functions for I/O-bound tasks, caching strategies, and lazy loading.
- Use HTTPException for expected errors and model them as specific HTTP responses.
- Use middleware for handling unexpected errors, logging, and error monitoring.
- Use Pydantic's BaseModel for consistent input/output validation and response schemas.
  
Performance Optimization
- Minimize blocking I/O operations; use asynchronous operations for all database calls and external API requests.
- Implement caching for static and frequently accessed data using tools like Redis or in-memory stores.
- Optimize data serialization and deserialization with Pydantic.
- Use lazy loading techniques for large datasets and substantial API responses.
  
Key Conventions
1. Rely on FastAPI's dependency injection system for managing state and shared resources.
2. Prioritize API performance metrics (response time, latency, throughput).
3. Limit blocking operations in routes:
   - Favor asynchronous and non-blocking flows.
   - Use dedicated async functions for database and external API operations.
   - Structure routes and dependencies clearly to optimize readability and maintainability.
  
Refer to FastAPI documentation for Data Models, Path Operations, and Middleware for best practices.
</file>

<file path=".cursor/rules/memory_bank.mdc">
---
description: 
globs: 
alwaysApply: false
---
---
description: Describes Cline's Memory Bank system, its structure, and workflows for maintaining project knowledge across sessions.
author: https://github.com/nickbaumann98
version: 1.0
tags: ["memory-bank", "knowledge-base", "core-behavior", "documentation-protocol"]
globs: ["memory-bank/**/*.md", "*"]
---
# Cline's Memory Bank

I am Cline, an expert software engineer with a unique characteristic: my memory resets completely between sessions. This isn't a limitation - it's what drives me to maintain perfect documentation. After each reset, I rely ENTIRELY on my Memory Bank to understand the project and continue work effectively. I MUST read ALL memory bank files at the start of EVERY task - this is not optional.

## Memory Bank Structure

The Memory Bank consists of core files and optional context files, all in Markdown format. Files build upon each other in a clear hierarchy:

```mermaid
flowchart TD
    PB[projectbrief.md] --> PC[productContext.md]
    PB --> SP[systemPatterns.md]
    PB --> TC[techContext.md]
    
    PC --> AC[activeContext.md]
    SP --> AC
    TC --> AC
    
    AC --> P[tasks.md]
```

### Core Files (Required)
1. `projectbrief.md`
   - Foundation document that shapes all other files
   - Created at project start if it doesn't exist
   - Defines core requirements and goals
   - Source of truth for project scope

2. `productContext.md`
   - Why this project exists
   - Problems it solves
   - How it should work
   - User experience goals

3. `activeContext.md`
   - Current work focus
   - Recent changes
   - Next steps
   - Active decisions and considerations
   - Important patterns and preferences
   - Learnings and project insights

4. `systemPatterns.md`
   - System architecture
   - Key technical decisions
   - Design patterns in use
   - Component relationships
   - Critical implementation paths

5. `techContext.md`
   - Technologies used
   - Development setup
   - Technical constraints
   - Dependencies
   - Tool usage patterns

6. `tasks.md`
   - What works
   - What's left to build
   - Current status
   - Known issues
   - Evolution of project decisions

### Additional Context
Create additional files/folders within .ai_docs/ when they help organize:
- Complex feature documentation
- Integration specifications
- API documentation
- Testing strategies
- Deployment procedures

## Core Workflows

### Plan Mode
```mermaid
flowchart TD
    Start[Start] --> ReadFiles[Read Memory Bank]
    ReadFiles --> CheckFiles{Files Complete?}
    
    CheckFiles -->|No| Plan[Create Plan]
    Plan --> Document[Document in Chat]
    
    CheckFiles -->|Yes| Verify[Verify Context]
    Verify --> Strategy[Develop Strategy]
    Strategy --> Present[Present Approach]
```

### Act Mode
```mermaid
flowchart TD
    Start[Start] --> Context[Check Memory Bank]
    Context --> Update[Update Documentation]
    Update --> Execute[Execute Task]
    Execute --> Document[Document Changes]
```

## Documentation Updates

Memory Bank updates occur when:
1. Discovering new project patterns
2. After implementing significant changes
3. When user requests with **update memory bank** (MUST review ALL files)
4. When context needs clarification

```mermaid
flowchart TD
    Start[Update Process]
    
    subgraph Process
        P1[Review ALL Files]
        P2[Document Current State]
        P3[Clarify Next Steps]
        P4[Document Insights & Patterns]
        
        P1 --> P2 --> P3 --> P4
    end
    
    Start --> Process
```

Note: When triggered by **update memory bank**, I MUST review every memory bank file, even if some don't require updates. Focus particularly on activeContext.md and tasks.md as they track current state.

REMEMBER: After every memory reset, I begin completely fresh. The Memory Bank is my only link to previous work. It must be maintained with precision and clarity, as my effectiveness depends entirely on its accuracy.
</file>

<file path=".cursor/rules/sb-create-database-functions.mdc">
---
description: Guidelines for writing Supabase database functions
globs: 
alwaysApply: false
---

# Database: Create functions

You're a Supabase Postgres expert in writing database functions. Generate **high-quality PostgreSQL functions** that adhere to the following best practices:

## General Guidelines

1. **Default to `SECURITY INVOKER`:**

   - Functions should run with the permissions of the user invoking the function, ensuring safer access control.
   - Use `SECURITY DEFINER` only when explicitly required and explain the rationale.

2. **Set the `search_path` Configuration Parameter:**

   - Always set `search_path` to an empty string (`set search_path = '';`).
   - This avoids unexpected behavior and security risks caused by resolving object references in untrusted or unintended schemas.
   - Use fully qualified names (e.g., `schema_name.table_name`) for all database objects referenced within the function.

3. **Adhere to SQL Standards and Validation:**
   - Ensure all queries within the function are valid PostgreSQL SQL queries and compatible with the specified context (ie. Supabase).

## Best Practices

1. **Minimize Side Effects:**

   - Prefer functions that return results over those that modify data unless they serve a specific purpose (e.g., triggers).

2. **Use Explicit Typing:**

   - Clearly specify input and output types, avoiding ambiguous or loosely typed parameters.

3. **Default to Immutable or Stable Functions:**

   - Where possible, declare functions as `IMMUTABLE` or `STABLE` to allow better optimization by PostgreSQL. Use `VOLATILE` only if the function modifies data or has side effects.

4. **Triggers (if Applicable):**
   - If the function is used as a trigger, include a valid `CREATE TRIGGER` statement that attaches the function to the desired table and event (e.g., `BEFORE INSERT`).

## Example Templates

### Simple Function with `SECURITY INVOKER`

```sql
create or replace function my_schema.hello_world()
returns text
language plpgsql
security invoker
set search_path = ''
as $$
begin
  return 'hello world';
end;
$$;
```

### Function with Parameters and Fully Qualified Object Names

```sql
create or replace function public.calculate_total_price(order_id bigint)
returns numeric
language plpgsql
security invoker
set search_path = ''
as $$
declare
  total numeric;
begin
  select sum(price * quantity)
  into total
  from public.order_items
  where order_id = calculate_total_price.order_id;

  return total;
end;
$$;
```

### Function as a Trigger

```sql
create or replace function my_schema.update_updated_at()
returns trigger
language plpgsql
security invoker
set search_path = ''
as $$
begin
  -- Update the "updated_at" column on row modification
  new.updated_at := now();
  return new;
end;
$$;

create trigger update_updated_at_trigger
before update on my_schema.my_table
for each row
execute function my_schema.update_updated_at();
```

### Function with Error Handling

```sql
create or replace function my_schema.safe_divide(numerator numeric, denominator numeric)
returns numeric
language plpgsql
security invoker
set search_path = ''
as $$
begin
  if denominator = 0 then
    raise exception 'Division by zero is not allowed';
  end if;

  return numerator / denominator;
end;
$$;
```

### Immutable Function for Better Optimization

```sql
create or replace function my_schema.full_name(first_name text, last_name text)
returns text
language sql
security invoker
set search_path = ''
immutable
as $$
  select first_name || ' ' || last_name;
$$;
```
</file>

<file path=".cursor/rules/sb-create-migration.mdc">
---
description: Guidelines for writing Postgres migrations
globs: 
alwaysApply: false
---

# Database: Create migration

You are a Postgres Expert who loves creating secure database schemas.

This project uses the migrations provided by the Supabase CLI.

## Creating a migration file

Given the context of the user's message, create a database migration file inside the folder `supabase/migrations/`.

The file MUST following this naming convention:

The file MUST be named in the format `YYYYMMDDHHmmss_short_description.sql` with proper casing for months, minutes, and seconds in UTC time:

1. `YYYY` - Four digits for the year (e.g., `2024`).
2. `MM` - Two digits for the month (01 to 12).
3. `DD` - Two digits for the day of the month (01 to 31).
4. `HH` - Two digits for the hour in 24-hour format (00 to 23).
5. `mm` - Two digits for the minute (00 to 59).
6. `ss` - Two digits for the second (00 to 59).
7. Add an appropriate description for the migration.

For example:

```
20240906123045_create_profiles.sql
```

## SQL Guidelines

Write Postgres-compatible SQL code for Supabase migration files that:

- Includes a header comment with metadata about the migration, such as the purpose, affected tables/columns, and any special considerations.
- Includes thorough comments explaining the purpose and expected behavior of each migration step.
- Write all SQL in lowercase.
- Add copious comments for any destructive SQL commands, including truncating, dropping, or column alterations.
- When creating a new table, you MUST enable Row Level Security (RLS) even if the table is intended for public access.
- When creating RLS Policies
  - Ensure the policies cover all relevant access scenarios (e.g. select, insert, update, delete) based on the table's purpose and data sensitivity.
  - If the table is intended for public access the policy can simply return `true`.
  - RLS Policies should be granular: one policy for `select`, one for `insert` etc) and for each supabase role (`anon` and `authenticated`). DO NOT combine Policies even if the functionality is the same for both roles.
  - Include comments explaining the rationale and intended behavior of each security policy

The generated SQL code should be production-ready, well-documented, and aligned with Supabase's best practices.
</file>

<file path=".cursor/rules/sb-create-rls-policies.mdc">
---
description: Guidelines for writing Postgres Row Level Security policies
globs: 
alwaysApply: false
---

# Database: Create RLS policies

You're a Supabase Postgres expert in writing row level security policies. Your purpose is to generate a policy with the constraints given by the user. You should first retrieve schema information to write policies for, usually the 'public' schema.

The output should use the following instructions:

- The generated SQL must be valid SQL.
- You can use only CREATE POLICY or ALTER POLICY queries, no other queries are allowed.
- Always use double apostrophe in SQL strings (eg. 'Night''s watch')
- You can add short explanations to your messages.
- The result should be a valid markdown. The SQL code should be wrapped in ``` (including sql language tag).
- Always use "auth.uid()" instead of "current_user".
- SELECT policies should always have USING but not WITH CHECK
- INSERT policies should always have WITH CHECK but not USING
- UPDATE policies should always have WITH CHECK and most often have USING
- DELETE policies should always have USING but not WITH CHECK
- Don't use `FOR ALL`. Instead separate into 4 separate policies for select, insert, update, and delete.
- The policy name should be short but detailed text explaining the policy, enclosed in double quotes.
- Always put explanations as separate text. Never use inline SQL comments.
- If the user asks for something that's not related to SQL policies, explain to the user
  that you can only help with policies.
- Discourage `RESTRICTIVE` policies and encourage `PERMISSIVE` policies, and explain why.

The output should look like this:

```sql
CREATE POLICY "My descriptive policy." ON books FOR INSERT to authenticated USING ( (select auth.uid()) = author_id ) WITH ( true );
```

Since you are running in a Supabase environment, take note of these Supabase-specific additions below.

## Authenticated and unauthenticated roles

Supabase maps every request to one of the roles:

- `anon`: an unauthenticated request (the user is not logged in)
- `authenticated`: an authenticated request (the user is logged in)

These are actually [Postgres Roles](mdc:docs/guides/database/postgres/roles). You can use these roles within your Policies using the `TO` clause:

```sql
create policy "Profiles are viewable by everyone"
on profiles
for select
to authenticated, anon
using ( true );

-- OR

create policy "Public profiles are viewable only by authenticated users"
on profiles
for select
to authenticated
using ( true );
```

Note that `for ...` must be added after the table but before the roles. `to ...` must be added after `for ...`:

### Incorrect

```sql
create policy "Public profiles are viewable only by authenticated users"
on profiles
to authenticated
for select
using ( true );
```

### Correct

```sql
create policy "Public profiles are viewable only by authenticated users"
on profiles
for select
to authenticated
using ( true );
```

## Multiple operations

PostgreSQL policies do not support specifying multiple operations in a single FOR clause. You need to create separate policies for each operation.

### Incorrect

```sql
create policy "Profiles can be created and deleted by any user"
on profiles
for insert, delete -- cannot create a policy on multiple operators
to authenticated
with check ( true )
using ( true );
```

### Correct

```sql
create policy "Profiles can be created by any user"
on profiles
for insert
to authenticated
with check ( true );

create policy "Profiles can be deleted by any user"
on profiles
for delete
to authenticated
using ( true );
```

## Helper functions

Supabase provides some helper functions that make it easier to write Policies.

### `auth.uid()`

Returns the ID of the user making the request.

### `auth.jwt()`

Returns the JWT of the user making the request. Anything that you store in the user's `raw_app_meta_data` column or the `raw_user_meta_data` column will be accessible using this function. It's important to know the distinction between these two:

- `raw_user_meta_data` - can be updated by the authenticated user using the `supabase.auth.update()` function. It is not a good place to store authorization data.
- `raw_app_meta_data` - cannot be updated by the user, so it's a good place to store authorization data.

The `auth.jwt()` function is extremely versatile. For example, if you store some team data inside `app_metadata`, you can use it to determine whether a particular user belongs to a team. For example, if this was an array of IDs:

```sql
create policy "User is in team"
on my_table
to authenticated
using ( team_id in (select auth.jwt() -> 'app_metadata' -> 'teams'));
```

### MFA

The `auth.jwt()` function can be used to check for [Multi-Factor Authentication](mdc:docs/guides/auth/auth-mfa#enforce-rules-for-mfa-logins). For example, you could restrict a user from updating their profile unless they have at least 2 levels of authentication (Assurance Level 2):

```sql
create policy "Restrict updates."
on profiles
as restrictive
for update
to authenticated using (
  (select auth.jwt()->>'aal') = 'aal2'
);
```

## RLS performance recommendations

Every authorization system has an impact on performance. While row level security is powerful, the performance impact is important to keep in mind. This is especially true for queries that scan every row in a table - like many `select` operations, including those using limit, offset, and ordering.

Based on a series of [tests](mdc:https:/github.com/GaryAustin1/RLS-Performance), we have a few recommendations for RLS:

### Add indexes

Make sure you've added [indexes](mdc:docs/guides/database/postgres/indexes) on any columns used within the Policies which are not already indexed (or primary keys). For a Policy like this:

```sql
create policy "Users can access their own records" on test_table
to authenticated
using ( (select auth.uid()) = user_id );
```

You can add an index like:

```sql
create index userid
on test_table
using btree (user_id);
```

### Call functions with `select`

You can use `select` statement to improve policies that use functions. For example, instead of this:

```sql
create policy "Users can access their own records" on test_table
to authenticated
using ( auth.uid() = user_id );
```

You can do:

```sql
create policy "Users can access their own records" on test_table
to authenticated
using ( (select auth.uid()) = user_id );
```

This method works well for JWT functions like `auth.uid()` and `auth.jwt()` as well as `security definer` Functions. Wrapping the function causes an `initPlan` to be run by the Postgres optimizer, which allows it to "cache" the results per-statement, rather than calling the function on each row.

Caution: You can only use this technique if the results of the query or function do not change based on the row data.

### Minimize joins

You can often rewrite your Policies to avoid joins between the source and the target table. Instead, try to organize your policy to fetch all the relevant data from the target table into an array or set, then you can use an `IN` or `ANY` operation in your filter.

For example, this is an example of a slow policy which joins the source `test_table` to the target `team_user`:

```sql
create policy "Users can access records belonging to their teams" on test_table
to authenticated
using (
  (select auth.uid()) in (
    select user_id
    from team_user
    where team_user.team_id = team_id -- joins to the source "test_table.team_id"
  )
);
```

We can rewrite this to avoid this join, and instead select the filter criteria into a set:

```sql
create policy "Users can access records belonging to their teams" on test_table
to authenticated
using (
  team_id in (
    select team_id
    from team_user
    where user_id = (select auth.uid()) -- no join
  )
);
```

### Specify roles in your policies

Always use the Role of inside your policies, specified by the `TO` operator. For example, instead of this query:

```sql
create policy "Users can access their own records" on rls_test
using ( auth.uid() = user_id );
```

Use:

```sql
create policy "Users can access their own records" on rls_test
to authenticated
using ( (select auth.uid()) = user_id );
```

This prevents the policy `( (select auth.uid()) = user_id )` from running for any `anon` users, since the execution stops at the `to authenticated` step.
</file>

<file path=".cursor/rules/self_improve.mdc">
---
description: Guidelines for continuously improving Cursor rules based on emerging code patterns and best practices.
globs: **/*
alwaysApply: true
---

- **Rule Improvement Triggers:**
  - New code patterns not covered by existing rules
  - Repeated similar implementations across files
  - Common error patterns that could be prevented
  - New libraries or tools being used consistently
  - Emerging best practices in the codebase

- **Analysis Process:**
  - Compare new code with existing rules
  - Identify patterns that should be standardized
  - Look for references to external documentation
  - Check for consistent error handling patterns
  - Monitor test patterns and coverage

- **Rule Updates:**
  - **Add New Rules When:**
    - A new technology/pattern is used in 3+ files
    - Common bugs could be prevented by a rule
    - Code reviews repeatedly mention the same feedback
    - New security or performance patterns emerge

  - **Modify Existing Rules When:**
    - Better examples exist in the codebase
    - Additional edge cases are discovered
    - Related rules have been updated
    - Implementation details have changed

- **Example Pattern Recognition:**
  ```typescript
  // If you see repeated patterns like:
  const data = await prisma.user.findMany({
    select: { id: true, email: true },
    where: { status: 'ACTIVE' }
  });
  
  // Consider adding to [prisma.mdc](mdc:.cursor/rules/prisma.mdc):
  // - Standard select fields
  // - Common where conditions
  // - Performance optimization patterns
  ```

- **Rule Quality Checks:**
  - Rules should be actionable and specific
  - Examples should come from actual code
  - References should be up to date
  - Patterns should be consistently enforced

- **Continuous Improvement:**
  - Monitor code review comments
  - Track common development questions
  - Update rules after major refactors
  - Add links to relevant documentation
  - Cross-reference related rules

- **Rule Deprecation:**
  - Mark outdated patterns as deprecated
  - Remove rules that no longer apply
  - Update references to deprecated rules
  - Document migration paths for old patterns

- **Documentation Updates:**
  - Keep examples synchronized with code
  - Update references to external docs
  - Maintain links between related rules
  - Document breaking changes
Follow [cursor_rules.mdc](mdc:.cursor/rules/cursor_rules.mdc) for proper rule formatting and structure.
</file>

<file path=".doing/tasks.md">
## Full Task List: Database, Backend, and Frontend Synchronization for End-to-End Type Safety

**Objective:** To establish a robust and type-safe data flow from the Supabase database through the Python backend (SQLAlchemy ORM models, Pydantic API Schemas) to the TypeScript frontend types. This involves restructuring the database, regenerating/refining models, and updating the respective layers of the application.

**Core Problem Addressed:** The current database schema (based on the single `videos` table in the old migration) is insufficient and needs to be expanded to properly represent `videos`, `video_jobs`, and `video_metadata` as distinct but related entities.

**Key Tools & Libraries:**
*   Supabase CLI (for migrations)
*   `sqlacodegen` (for generating SQLAlchemy ORM models from the database)
*   `supabase-pydantic` (for generating Pydantic models directly from the Supabase schema)
*   `pydantic-to-typescript` (for generating TypeScript types from Pydantic API schemas)

---

**Phase 1: Database Schema Definition & Migration**

* - [x] **Task 1.1: Finalize Table Structures (Conceptual)**
    *   **Objective:** Confirm the columns, types, relationships, and constraints for `videos`, `video_jobs`, and `video_metadata` tables.
    *   **Details:**
        *   **`public.videos` Table:**
            *   `id`: `SERIAL PRIMARY KEY` (Auto-incrementing integer, maps to `VideoModel.id`)
            *   `uploader_user_id`: `UUID REFERENCES auth.users(id) ON DELETE CASCADE NOT NULL` (Links to Supabase auth user)
            *   `original_filename`: `TEXT NOT NULL`
            *   `storage_path`: `TEXT NOT NULL UNIQUE` (Path to the original video, e.g., in GCS)
            *   `content_type`: `TEXT NOT NULL` (e.g., "video/mp4")
            *   `size_bytes`: `BIGINT NOT NULL`
            *   `created_at`: `TIMESTAMPTZ DEFAULT timezone('utc'::text, now()) NOT NULL`
            *   `updated_at`: `TIMESTAMPTZ DEFAULT timezone('utc'::text, now()) NOT NULL`
        *   **`public.video_jobs` Table:**
            *   `id`: `SERIAL PRIMARY KEY` (Maps to `VideoJobModel.id`)
            *   `video_id`: `INTEGER REFERENCES public.videos(id) ON DELETE CASCADE NOT NULL` (Foreign key to `videos` table)
            *   `status`: `public.processing_status_enum NOT NULL DEFAULT 'PENDING'` (PostgreSQL ENUM type: `('PENDING', 'PROCESSING', 'COMPLETED', 'FAILED')`)
            *   `processing_stages`: `JSONB NULL` (Stores progress, e.g., `{"transcription": "done", "metadata_extraction": "pending"}`)
            *   `error_message`: `TEXT NULL`
            *   `created_at`: `TIMESTAMPTZ DEFAULT timezone('utc'::text, now()) NOT NULL`
            *   `updated_at`: `TIMESTAMPTZ DEFAULT timezone('utc'::text, now()) NOT NULL`
        *   **`public.video_metadata` Table:**
            *   `id`: `SERIAL PRIMARY KEY` (Maps to `VideoMetadataModel.id`)
            *   `job_id`: `INTEGER REFERENCES public.video_jobs(id) ON DELETE CASCADE NOT NULL UNIQUE` (One-to-one with `video_jobs`)
            *   `title`: `TEXT NULL`
            *   `description`: `TEXT NULL`
            *   `tags`: `TEXT[] NULL` (Array of text for tags)
            *   `transcript_text`: `TEXT NULL`
            *   `transcript_file_url`: `TEXT NULL` (URL to stored transcript file)
            *   `subtitle_files_urls`: `JSONB NULL` (e.g., `{"vtt": "url_to_vtt", "srt": "url_to_srt"}`)
            *   `thumbnail_file_url`: `TEXT NULL` (URL to stored thumbnail)
            *   `extracted_video_duration_seconds`: `FLOAT NULL`
            *   `extracted_video_resolution`: `TEXT NULL` (e.g., "1920x1080")
            *   `extracted_video_format`: `TEXT NULL` (e.g., "mp4")
            *   `show_notes_text`: `TEXT NULL`
            *   `created_at`: `TIMESTAMPTZ DEFAULT timezone('utc'::text, now()) NOT NULL`
            *   `updated_at`: `TIMESTAMPTZ DEFAULT timezone('utc'::text, now()) NOT NULL`

* - [x] **Task 1.2: Create/Update SQL Migration File**
    *   **Objective:** Write the SQL to create these tables, define the `processing_status_enum` type, set up RLS policies, and create `updated_at` triggers.
    *   **File to Modify:** `packages/supabase/migrations/20250514044259_create_videos_table.sql`
        *   *(Note: In a production workflow with existing data, you would create a new additive migration. For a development reset, modifying the existing one is acceptable if you intend to reset the DB.)*
    *   **Action:** Replace the entire content of this file with the following SQL. This SQL includes the enum, tables, triggers, RLS, and comments as per best practices.

        ```sql
        -- Migration: Setup video processing tables (videos, video_jobs, video_metadata)
        -- Original Timestamp: 20250514044259 (retained for filename consistency if modifying)
        -- Purpose: Defines the core data structure for the video processing pipeline,
        -- including tables for video uploads, processing jobs, and generated metadata,
        -- along with appropriate RLS policies for user data isolation and an enum for job status.

        BEGIN;

        -- 0. Create ENUM type for processing_status if it doesn't exist
        -- This ensures the type is available before being used in table definitions.
        DO $$
        BEGIN
            IF NOT EXISTS (SELECT 1 FROM pg_type WHERE typname = 'processing_status_enum') THEN
                CREATE TYPE public.processing_status_enum AS ENUM ('PENDING', 'PROCESSING', 'COMPLETED', 'FAILED');
            END IF;
        END$$;

        -- 1. Create the 'videos' table
        -- Stores core information about uploaded video files.
        CREATE TABLE IF NOT EXISTS public.videos (
            id SERIAL PRIMARY KEY,
            uploader_user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE NOT NULL,
            original_filename TEXT NOT NULL,
            storage_path TEXT NOT NULL UNIQUE,
            content_type TEXT NOT NULL,
            size_bytes BIGINT NOT NULL,
            created_at TIMESTAMPTZ DEFAULT timezone('utc'::text, now()) NOT NULL,
            updated_at TIMESTAMPTZ DEFAULT timezone('utc'::text, now()) NOT NULL
        );

        COMMENT ON TABLE public.videos IS 'Stores information about originally uploaded video files.';
        COMMENT ON COLUMN public.videos.id IS 'Unique identifier for the video entry.';
        COMMENT ON COLUMN public.videos.uploader_user_id IS 'Foreign key to auth.users, identifying the uploader.';
        COMMENT ON COLUMN public.videos.original_filename IS 'The original name of the uploaded video file.';
        COMMENT ON COLUMN public.videos.storage_path IS 'Unique path where the original video is stored (e.g., GCS path).';
        COMMENT ON COLUMN public.videos.content_type IS 'MIME type of the video (e.g., video/mp4).';
        COMMENT ON COLUMN public.videos.size_bytes IS 'Size of the original video file in bytes.';
        COMMENT ON COLUMN public.videos.created_at IS 'Timestamp of when the video record was created.';
        COMMENT ON COLUMN public.videos.updated_at IS 'Timestamp of when the video record was last updated.';

        -- Generic Trigger function for updated_at columns
        -- This function can be reused for multiple tables.
        CREATE OR REPLACE FUNCTION public.update_updated_at_column()
        RETURNS TRIGGER LANGUAGE plpgsql SECURITY INVOKER SET search_path = '' AS $$
        BEGIN
            NEW.updated_at = timezone('utc'::text, now());
            RETURN NEW;
        END;
        $$;

        -- Trigger for 'videos' table to automatically update 'updated_at'
        DROP TRIGGER IF EXISTS trig_update_videos_updated_at ON public.videos;
        CREATE TRIGGER trig_update_videos_updated_at
        BEFORE UPDATE ON public.videos
        FOR EACH ROW EXECUTE FUNCTION public.update_updated_at_column();

        -- RLS for 'videos' table
        ALTER TABLE public.videos ENABLE ROW LEVEL SECURITY;

        -- Policy: Users can select their own videos.
        DROP POLICY IF EXISTS "Users can select their own videos" ON public.videos;
        CREATE POLICY "Users can select their own videos" ON public.videos
        FOR SELECT TO authenticated USING ((SELECT auth.uid()) = uploader_user_id);

        -- Policy: Users can insert videos for themselves.
        DROP POLICY IF EXISTS "Users can insert their own videos" ON public.videos;
        CREATE POLICY "Users can insert their own videos" ON public.videos
        FOR INSERT TO authenticated WITH CHECK ((SELECT auth.uid()) = uploader_user_id);

        -- Policy: Users can update their own videos.
        DROP POLICY IF EXISTS "Users can update their own videos" ON public.videos;
        CREATE POLICY "Users can update their own videos" ON public.videos
        FOR UPDATE TO authenticated USING ((SELECT auth.uid()) = uploader_user_id) WITH CHECK ((SELECT auth.uid()) = uploader_user_id);

        -- Policy: Users can delete their own videos.
        DROP POLICY IF EXISTS "Users can delete their own videos" ON public.videos;
        CREATE POLICY "Users can delete their own videos" ON public.videos
        FOR DELETE TO authenticated USING ((SELECT auth.uid()) = uploader_user_id);

        -- Index for faster RLS checks and queries on uploader_user_id
        CREATE INDEX IF NOT EXISTS idx_videos_uploader_user_id ON public.videos(uploader_user_id);

        -- 2. Create the 'video_jobs' table
        -- Tracks the status and progress of video processing tasks.
        CREATE TABLE IF NOT EXISTS public.video_jobs (
            id SERIAL PRIMARY KEY,
            video_id INTEGER REFERENCES public.videos(id) ON DELETE CASCADE NOT NULL,
            status public.processing_status_enum NOT NULL DEFAULT 'PENDING',
            processing_stages JSONB NULL,
            error_message TEXT NULL,
            created_at TIMESTAMPTZ DEFAULT timezone('utc'::text, now()) NOT NULL,
            updated_at TIMESTAMPTZ DEFAULT timezone('utc'::text, now()) NOT NULL
        );

        COMMENT ON TABLE public.video_jobs IS 'Tracks each processing attempt or workflow for a video.';
        COMMENT ON COLUMN public.video_jobs.id IS 'Unique identifier for the video processing job.';
        COMMENT ON COLUMN public.video_jobs.video_id IS 'Foreign key referencing the associated video in public.videos.';
        COMMENT ON COLUMN public.video_jobs.status IS 'Current status of the job using the processing_status_enum type.';
        COMMENT ON COLUMN public.video_jobs.processing_stages IS 'JSONB field to store detailed progress of various processing stages.';
        COMMENT ON COLUMN public.video_jobs.error_message IS 'Stores any error message if the job failed.';
        COMMENT ON COLUMN public.video_jobs.created_at IS 'Timestamp of when the job record was created.';
        COMMENT ON COLUMN public.video_jobs.updated_at IS 'Timestamp of when the job record was last updated.';

        -- Trigger for 'video_jobs' table
        DROP TRIGGER IF EXISTS trig_update_video_jobs_updated_at ON public.video_jobs;
        CREATE TRIGGER trig_update_video_jobs_updated_at
        BEFORE UPDATE ON public.video_jobs
        FOR EACH ROW EXECUTE FUNCTION public.update_updated_at_column();

        -- RLS for 'video_jobs' table
        ALTER TABLE public.video_jobs ENABLE ROW LEVEL SECURITY;

        -- Policy: Users can select jobs related to their own videos.
        DROP POLICY IF EXISTS "Users can select jobs for their videos" ON public.video_jobs;
        CREATE POLICY "Users can select jobs for their videos" ON public.video_jobs
        FOR SELECT TO authenticated USING (
            EXISTS (SELECT 1 FROM public.videos v WHERE v.id = video_jobs.video_id AND v.uploader_user_id = (SELECT auth.uid()))
        );

        -- Policy: Users can insert jobs for their own videos.
        DROP POLICY IF EXISTS "Users can insert jobs for their videos" ON public.video_jobs;
        CREATE POLICY "Users can insert jobs for their videos" ON public.video_jobs
        FOR INSERT TO authenticated WITH CHECK (
            EXISTS (SELECT 1 FROM public.videos v WHERE v.id = video_jobs.video_id AND v.uploader_user_id = (SELECT auth.uid()))
        );

        -- Policy: Users can update jobs related to their own videos.
        DROP POLICY IF EXISTS "Users can update jobs for their videos" ON public.video_jobs;
        CREATE POLICY "Users can update jobs for their videos" ON public.video_jobs
        FOR UPDATE TO authenticated USING (
             EXISTS (SELECT 1 FROM public.videos v WHERE v.id = video_jobs.video_id AND v.uploader_user_id = (SELECT auth.uid()))
        ) WITH CHECK (
            EXISTS (SELECT 1 FROM public.videos v WHERE v.id = video_jobs.video_id AND v.uploader_user_id = (SELECT auth.uid()))
        );

        -- Policy: Users can delete jobs related to their own videos.
        DROP POLICY IF EXISTS "Users can delete jobs for their videos" ON public.video_jobs;
        CREATE POLICY "Users can delete jobs for their videos" ON public.video_jobs
        FOR DELETE TO authenticated USING (
            EXISTS (SELECT 1 FROM public.videos v WHERE v.id = video_jobs.video_id AND v.uploader_user_id = (SELECT auth.uid()))
        );

        -- Indexes for foreign keys and frequently queried columns
        CREATE INDEX IF NOT EXISTS idx_video_jobs_video_id ON public.video_jobs(video_id);
        CREATE INDEX IF NOT EXISTS idx_video_jobs_status ON public.video_jobs(status);

        -- 3. Create the 'video_metadata' table
        -- Stores metadata extracted or generated during video processing.
        CREATE TABLE IF NOT EXISTS public.video_metadata (
            id SERIAL PRIMARY KEY,
            job_id INTEGER REFERENCES public.video_jobs(id) ON DELETE CASCADE NOT NULL UNIQUE,
            title TEXT NULL,
            description TEXT NULL,
            tags TEXT[] NULL,
            transcript_text TEXT NULL,
            transcript_file_url TEXT NULL,
            subtitle_files_urls JSONB NULL,
            thumbnail_file_url TEXT NULL,
            extracted_video_duration_seconds FLOAT NULL,
            extracted_video_resolution TEXT NULL,
            extracted_video_format TEXT NULL,
            show_notes_text TEXT NULL,
            created_at TIMESTAMPTZ DEFAULT timezone('utc'::text, now()) NOT NULL,
            updated_at TIMESTAMPTZ DEFAULT timezone('utc'::text, now()) NOT NULL
        );

        COMMENT ON TABLE public.video_metadata IS 'Stores metadata extracted or generated from a successfully completed video job.';
        COMMENT ON COLUMN public.video_metadata.id IS 'Unique identifier for the video metadata entry.';
        COMMENT ON COLUMN public.video_metadata.job_id IS 'Foreign key referencing the video_jobs table (one-to-one relationship).';
        COMMENT ON COLUMN public.video_metadata.title IS 'Generated or user-provided title of the video.';
        COMMENT ON COLUMN public.video_metadata.description IS 'Generated or user-provided description of the video.';
        COMMENT ON COLUMN public.video_metadata.tags IS 'Array of tags associated with the video.';
        COMMENT ON COLUMN public.video_metadata.transcript_text IS 'Full text transcript of the video.';
        COMMENT ON COLUMN public.video_metadata.transcript_file_url IS 'URL to the stored transcript file (e.g., in GCS).';
        COMMENT ON COLUMN public.video_metadata.subtitle_files_urls IS 'JSONB object storing URLs to various subtitle formats (e.g., {"vtt": "url", "srt": "url"}).';
        COMMENT ON COLUMN public.video_metadata.thumbnail_file_url IS 'URL to the stored thumbnail image.';
        COMMENT ON COLUMN public.video_metadata.extracted_video_duration_seconds IS 'Duration of the video in seconds, extracted by FFmpeg.';
        COMMENT ON COLUMN public.video_metadata.extracted_video_resolution IS 'Resolution of the video (e.g., "1920x1080").';
        COMMENT ON COLUMN public.video_metadata.extracted_video_format IS 'Format of the video (e.g., "mp4").';
        COMMENT ON COLUMN public.video_metadata.show_notes_text IS 'Generated or user-provided show notes or detailed summary.';
        COMMENT ON COLUMN public.video_metadata.created_at IS 'Timestamp of when the metadata record was created.';
        COMMENT ON COLUMN public.video_metadata.updated_at IS 'Timestamp of when the metadata record was last updated.';

        -- Trigger for 'video_metadata' table
        DROP TRIGGER IF EXISTS trig_update_video_metadata_updated_at ON public.video_metadata;
        CREATE TRIGGER trig_update_video_metadata_updated_at
        BEFORE UPDATE ON public.video_metadata
        FOR EACH ROW EXECUTE FUNCTION public.update_updated_at_column();

        -- RLS for 'video_metadata' table
        ALTER TABLE public.video_metadata ENABLE ROW LEVEL SECURITY;

        -- Policy: Users can select metadata for jobs related to their own videos.
        DROP POLICY IF EXISTS "Users can select metadata for their video jobs" ON public.video_metadata;
        CREATE POLICY "Users can select metadata for their video jobs" ON public.video_metadata
        FOR SELECT TO authenticated USING (
            EXISTS (
                SELECT 1
                FROM public.video_jobs vj
                JOIN public.videos v ON vj.video_id = v.id
                WHERE vj.id = video_metadata.job_id AND v.uploader_user_id = (SELECT auth.uid())
            )
        );

        -- Policy: Users can insert metadata for jobs related to their own videos.
        DROP POLICY IF EXISTS "Users can insert metadata for their video jobs" ON public.video_metadata;
        CREATE POLICY "Users can insert metadata for their video jobs" ON public.video_metadata
        FOR INSERT TO authenticated WITH CHECK (
            EXISTS (
                SELECT 1
                FROM public.video_jobs vj
                JOIN public.videos v ON vj.video_id = v.id
                WHERE vj.id = video_metadata.job_id AND v.uploader_user_id = (SELECT auth.uid())
            )
        );

        -- Policy: Users can update metadata for jobs related to their own videos.
        DROP POLICY IF EXISTS "Users can update metadata for their video jobs" ON public.video_metadata;
        CREATE POLICY "Users can update metadata for their video jobs" ON public.video_metadata
        FOR UPDATE TO authenticated USING (
            EXISTS (
                SELECT 1
                FROM public.video_jobs vj
                JOIN public.videos v ON vj.video_id = v.id
                WHERE vj.id = video_metadata.job_id AND v.uploader_user_id = (SELECT auth.uid())
            )
        ) WITH CHECK (
            EXISTS (
                SELECT 1
                FROM public.video_jobs vj
                JOIN public.videos v ON vj.video_id = v.id
                WHERE vj.id = video_metadata.job_id AND v.uploader_user_id = (SELECT auth.uid())
            )
        );

        -- Policy: Users can delete metadata for jobs related to their own videos.
        DROP POLICY IF EXISTS "Users can delete metadata for their video jobs" ON public.video_metadata;
        CREATE POLICY "Users can delete metadata for their video jobs" ON public.video_metadata
        FOR DELETE TO authenticated USING (
            EXISTS (
                SELECT 1
                FROM public.video_jobs vj
                JOIN public.videos v ON vj.video_id = v.id
                WHERE vj.id = video_metadata.job_id AND v.uploader_user_id = (SELECT auth.uid())
            )
        );

        -- Index for the foreign key job_id
        CREATE INDEX IF NOT EXISTS idx_video_metadata_job_id ON public.video_metadata(job_id);

        COMMIT;
        ```

* - [x] **Task 1.3: Apply Database Changes**
    *   **Objective:** Update your local Supabase instance with the new schema.
    *   **Commands (from project root):**
        1.  Ensure Supabase local development environment is running: `pnpm db:start` (if not already running).
        2.  Reset the database to apply the modified migration cleanly: `pnpm db:reset`
            *   *(This command will wipe any existing local data and re-apply all migrations from scratch. This is suitable for this major schema change in a development environment. For production, you'd use `supabase db push` or a more controlled migration strategy.)*
    *   **Verification:**
        *   Open Supabase Studio (usually at `http://localhost:54323`).
        *   Navigate to the `Table Editor` section.
        *   Verify that `videos`, `video_jobs`, and `video_metadata` tables exist in the `public` schema with the correct columns, types, primary keys, and foreign key relationships.
        *   Verify that RLS is enabled for each table (look for the shield icon).
        *   Check the "Policies" tab for each table to ensure the defined RLS policies are present.
        *   In the `SQL Editor`, run `SELECT enum_range(NULL::public.processing_status_enum);` to verify the `processing_status_enum` type exists and has the correct values: `(PENDING,PROCESSING,COMPLETED,FAILED)`.

---

**Phase 2: Python Backend Code Generation & Model Alignment**

* - [x] **Task 2.1: Update Python Dependencies (If Necessary)**
    *   **Objective:** Ensure `pyproject.toml` includes `supabase-pydantic` and other necessary tools, then install/update dependencies.
    *   **File:** `apps/core/pyproject.toml`
    *   **Action:** Verify that `supabase-pydantic~=0.19.1` (or the version you intend to use) is listed under `[project.dependencies]` or `[project.optional-dependencies.dev]`. Also ensure `sqlacodegen` is present for ORM model generation.
    *   **Command (from project root, then `cd apps/core`):**
        ```bash
        cd apps/core
        # Ensure your Python virtual environment is active
        # (e.g., source .venv/bin/activate or however you manage it)
        uv pip install -e ".[dev]" # Installs package in editable mode with dev dependencies
        ```
    *   **Verification:** The command completes successfully. If `uv.lock` is modified, commit it.

* - [ ] **Task 2.2: Generate SQLAlchemy ORM Models**
    *   **Objective:** Create initial SQLAlchemy ORM model definitions based on the new database schema.
    *   **Command (from project root):** `pnpm codegen:db-orm-models`
        *   This script (`apps/core/bin/codegen_models.sh`) runs `sqlacodegen` and outputs to `apps/core/app/db/models.py`.
    *   **Verification & Manual Adjustments:**
        1.  Open the generated file: `apps/core/app/db/models.py`.
        2.  It should contain classes like `Videos`, `VideoJobs`, `VideoMetadata` (names might vary slightly based on `sqlacodegen`'s inflection).
        3.  **Crucially, review and adjust relationships:** `sqlacodegen` might not perfectly infer `back_populates` or `uselist=False` for one-to-one relationships. You will likely need to manually edit this file.
            *   Example for `Videos` model:
                ```python
                # In class Videos(Base):
                #   __tablename__ = 'videos'
                #   # ... other columns
                #   jobs = relationship("VideoJobs", back_populates="video") # Ensure correct class name "VideoJobs"
                ```
            *   Example for `VideoJobs` model:
                ```python
                # In class VideoJobs(Base):
                #   __tablename__ = 'video_jobs'
                #   # ... other columns
                #   video_id = Column(Integer, ForeignKey('videos.id'), nullable=False)
                #   video = relationship("Videos", back_populates="jobs")
                #   video_metadata = relationship("VideoMetadata", back_populates="job", uselist=False, cascade="all, delete-orphan") # uselist=False for one-to-one
                ```
            *   Example for `VideoMetadata` model:
                ```python
                # In class VideoMetadata(Base):
                #   __tablename__ = 'video_metadata'
                #   # ... other columns
                #   job_id = Column(Integer, ForeignKey('video_jobs.id'), nullable=False, unique=True)
                #   job = relationship("VideoJobs", back_populates="video_metadata")
                ```
        4.  **Adjust Enum Type for `status` column:** The `status` column in the `VideoJobs` model generated by `sqlacodegen` will likely be `Column(Text,...)`. Manually change this to use your Python Enum.
            *   First, ensure your Python enum exists (Task 2.3).
            *   Then, in `apps/core/app/db/models.py` (or later in `apps/core/models/video_job_model.py` after moving), modify the `VideoJobs` class:
                ```python
                from sqlalchemy import Enum # Add Enum to sqlalchemy imports
                from apps.core.models.enums import ProcessingStatus # Path to your Python enum

                # ... inside the VideoJobs class definition ...
                # status = Column(Text, nullable=False, server_default=text("'PENDING'::processing_status_enum")) # Original from sqlacodegen (example)
                status = Column(Enum(ProcessingStatus, name="processing_status_enum", create_type=False), nullable=False, server_default='PENDING')
                # create_type=False because we defined the ENUM type in SQL already.
                # server_default='PENDING' ensures the DB default is also aligned if SQLAlchemy manages table creation (not the case here as migration does it).
                ```

* - [ ] **Task 2.3: Create/Verify Python Enum for `ProcessingStatus`**
    *   **Objective:** Ensure a Python enum exists that mirrors the `processing_status_enum` in the database.
    *   **File:** `apps/core/models/enums.py`
    *   **Action:** Create or verify the file with the following content:
        ```python
        from enum import Enum

        class ProcessingStatus(str, Enum):
            PENDING = "PENDING"
            PROCESSING = "PROCESSING"
            COMPLETED = "COMPLETED"
            FAILED = "FAILED"
        ```
    *   **Verification:** Enum values exactly match those defined in the SQL `CREATE TYPE public.processing_status_enum AS ENUM (...)`.

* - [ ] **Task 2.4: Consolidate and Refine SQLAlchemy Models into `apps/core/models/`**
    *   **Objective:** Move the generated and manually adjusted ORM model definitions from `apps/core/app/db/models.py` into your structured model files within `apps/core/models/`. This makes them the canonical ORM models for your application.
    *   **Source File:** `apps/core/app/db/models.py`
    *   **Target Files:**
        *   `apps/core/models/video_model.py` (for the `Videos` table's model)
        *   `apps/core/models/video_job_model.py` (for the `VideoJobs` table's model)
        *   `apps/core/models/video_metadata_model.py` (for the `VideoMetadata` table's model)
        *   `apps/core/models/__init__.py` (to export the models)
    *   **Action:**
        1.  For each generated model class (e.g., `Videos`, `VideoJobs`, `VideoMetadata`) in `apps/core/app/db/models.py`:
            *   Copy the class definition.
            *   Paste it into the corresponding target file (e.g., `Videos` class into `video_model.py`).
            *   Rename the class to your desired application-consistent name (e.g., `Videos` to `VideoModel`, `VideoJobs` to `VideoJobModel`, `VideoMetadata` to `VideoMetadataModel`).
            *   Adjust imports within these files. Common imports will be:
                ```python
                from sqlalchemy import Column, Integer, String, Text, ForeignKey, DateTime, JSON, Enum, Float, BigInteger # etc.
                from sqlalchemy.orm import relationship
                from sqlalchemy.sql import func # For server_default=func.now()
                from apps.core.lib.database.connection import Base # Assuming Base is defined here
                from ..enums import ProcessingStatus # For VideoJobModel, if enums.py is in the same directory
                # For relationships, use string references to avoid circular imports if models are in separate files:
                # e.g., video = relationship("VideoModel", back_populates="jobs")
                ```
            *   Ensure all relationships (`relationship(...)`) use the new class names and correctly define `back_populates`.
        2.  Update `apps/core/models/__init__.py` to export your refined models:
            ```python
            from .enums import ProcessingStatus
            from .video_model import VideoModel
            from .video_job_model import VideoJobModel
            from .video_metadata_model import VideoMetadataModel
            # Add other models like User, Chat, Message if they are part of this structure

            __all__ = [
                "ProcessingStatus",
                "VideoModel",
                "VideoJobModel",
                "VideoMetadataModel",
                # "User", "Chat", "Message"
            ]
            ```
        3.  Once confident, you can delete `apps/core/app/db/models.py` or add it to `.gitignore` as its contents are now managed within `apps/core/models/`. For this guide, assume it's moved and maintained in `apps/core/models/`.
    *   **Verification:** The models in `apps/core/models/` are correctly defined, importable, and reflect the database schema including relationships and the `ProcessingStatus` enum.

* - [ ] **Task 2.5: Generate Pydantic Models using `supabase-pydantic`**
    *   **Objective:** Create Pydantic V2 models directly from the live Supabase schema. These models can be useful for direct DB interactions or as a reference for your API schemas.
    *   **Command (from project root):** `pnpm codegen:db-pydantic-models`
        *   This script (`apps/core/bin/codegen_pydantic_supabase.sh`) runs `supabase-pydantic`.
        *   Ensure your `.env` file at the project root has `SUPABASE_URL` and `SUPABASE_SERVICE_ROLE_KEY` correctly set for `supabase-pydantic` to connect and introspect the schema.
    *   **Output File:** `apps/core/app/db_pydantic_models/supabase_models.py`
    *   **Verification:**
        *   Inspect the generated `supabase_models.py`.
        *   It should contain Pydantic classes corresponding to your tables (e.g., `Videos`, `VideoJobs`, `VideoMetadata`).
        *   Check that types are mapped correctly (e.g., `timestamptz` to `datetime.datetime`, `text[]` to `List[str]`, `jsonb` to `Dict` or `Any`, `processing_status_enum` to a Pydantic `Enum` or `Literal`).
        *   Note: `supabase-pydantic` might generate its own version of the `ProcessingStatus` enum or use `Literal`. You'll need to decide if you use this generated enum or your manually defined Python enum (`apps.core.models.enums.ProcessingStatus`) in your API schemas. Consistency is key.

---

**Phase 3: Python Backend Logic Refactoring**

* - [ ] **Task 3.1: Refactor Pydantic API Schemas**
    *   **Objective:** Update your FastAPI request/response schemas to align with the new database structure (three tables) and the refined SQLAlchemy ORM models. These API schemas will be the source for TypeScript type generation.
    *   **File:** `apps/core/api/schemas/video_processing_schemas.py`
    *   **Action:**
        1.  Review each existing schema (e.g., `VideoSchema`, `VideoJobSchema`, `VideoMetadataSchema`, `VideoSummary`, `VideoDetailsResponse`, `VideoUploadResponseSchema`, `VideoMetadataUpdateRequest`).
        2.  **Design Decision:** Your API schemas should reflect the data structures you want to expose to the client. They will be built based on your SQLAlchemy ORM models (from `apps.core.models`).
            *   Create distinct Pydantic schemas for API representation of `Video`, `VideoJob`, and `VideoMetadata`.
            *   Example: `VideoResponseSchema`, `VideoJobResponseSchema`, `VideoMetadataResponseSchema`.
            *   These schemas should include `model_config = ConfigDict(from_attributes=True)` to allow direct creation from SQLAlchemy ORM model instances.
        3.  Update schemas that combine data. For example, `VideoJobResponseSchema` might nest `VideoResponseSchema` and `VideoMetadataResponseSchema` if you want to return job details along with its related video and metadata.
            ```python
            # Example structure in apps/core/api/schemas/video_processing_schemas.py

            from datetime import datetime
            from typing import List, Optional, Any, Dict, Union # Union for processing_stages
            from pydantic import BaseModel, Field, ConfigDict
            from apps.core.models.enums import ProcessingStatus # Your canonical Python enum

            class VideoResponseSchema(BaseModel):
                id: int
                uploader_user_id: str # Assuming UUID is converted to str for API
                original_filename: str
                # storage_path: str # Potentially not exposed directly in all responses
                content_type: str
                size_bytes: int
                created_at: datetime
                updated_at: datetime
                model_config = ConfigDict(from_attributes=True)

            class VideoMetadataResponseSchema(BaseModel):
                id: int
                # job_id: int # Usually linked via VideoJobResponseSchema
                title: Optional[str] = None
                description: Optional[str] = None
                tags: Optional[List[str]] = Field(default_factory=list)
                transcript_text: Optional[str] = None # Or just URL if text is too large
                transcript_file_url: Optional[str] = None
                subtitle_files_urls: Optional[Dict[str, Any]] = Field(default_factory=dict) # e.g. {"vtt": "url", "srt": "url"}
                thumbnail_file_url: Optional[str] = None
                extracted_video_duration_seconds: Optional[float] = None
                extracted_video_resolution: Optional[str] = None
                extracted_video_format: Optional[str] = None
                show_notes_text: Optional[str] = None # Or URL
                created_at: datetime
                updated_at: datetime
                model_config = ConfigDict(from_attributes=True)

            class VideoJobResponseSchema(BaseModel):
                id: int
                video_id: int
                status: ProcessingStatus # Use your Python enum
                processing_stages: Optional[Union[List[str], Dict[str, Any]]] = None # Flexible for stages
                error_message: Optional[str] = None
                created_at: datetime
                updated_at: datetime
                video: Optional[VideoResponseSchema] = None # For nested video details
                metadata: Optional[VideoMetadataResponseSchema] = None # For nested metadata
                model_config = ConfigDict(from_attributes=True, extra="ignore") # extra='ignore' can be useful

            class VideoUploadResponseSchema(BaseModel): # For the /upload endpoint response
                job_id: int
                status: ProcessingStatus

            class VideoSummarySchema(BaseModel): # For list views
                id: int # This is VideoModel.id
                original_filename: str
                title: Optional[str] = None # From VideoMetadataModel.title via the latest job
                created_at: datetime # VideoModel.created_at
                status: Optional[ProcessingStatus] = None # VideoJobModel.status for the latest job
                thumbnail_file_url: Optional[str] = None # VideoMetadataModel.thumbnail_file_url
                model_config = ConfigDict(from_attributes=True) # If built from ORM objects with joins

            class VideoMetadataUpdateRequestSchema(BaseModel): # For updating metadata
                title: Optional[str] = None
                description: Optional[str] = None
                tags: Optional[List[str]] = None
                # Add other editable fields as needed
            ```
        4.  Ensure all schemas use `datetime.datetime` for date/time fields (Pydantic V2 standard).
        5.  The `status` field in `VideoJobResponseSchema` must use your Python enum `apps.core.models.enums.ProcessingStatus`.
    *   **Verification:** API schemas in `apps/core/api/schemas/video_processing_schemas.py` are well-defined, use correct types (especially `ProcessingStatus` and `datetime`), have `from_attributes=True` where ORM instances are returned by services, and are ready for `pydantic-to-typescript`.

* - [ ] **Task 3.2: Update Repository Layer (`apps/core/operations/`)**
    *   **Objective:** Ensure repositories use the correct SQLAlchemy ORM models (from `apps.core.models`) and query the new table structures. All repository methods should now be `async`.
    *   **Files to Update:**
        *   `apps/core/operations/video_repository.py`
        *   `apps/core/operations/video_job_repository.py`
        *   `apps/core/operations/video_metadata_repository.py`
    *   **Action:**
        1.  **Imports:** Change imports from `apps.core.app.db.models` or old model paths to `from apps.core.models import VideoModel, VideoJobModel, VideoMetadataModel, ProcessingStatus`.
        2.  **Async Methods:** Convert all synchronous methods (`def`) to asynchronous (`async def`). All database operations (`db.execute`, `db.add`, `db.commit`, `db.refresh`, `db.flush`) must be `await`ed. The `db` parameter type hint should be `AsyncSession`.
        3.  **`VideoRepository`**:
            *   `create`: Should now create a `VideoModel` instance.
            *   `get_by_id`: Should fetch `VideoModel`.
        4.  **`VideoJobRepository`**:
            *   `create`: Creates a `VideoJobModel` linking to `video_id`.
            *   `get_by_id`: Fetches `VideoJobModel`. Consider eager loading related `video` and `video_metadata` here if frequently needed together:
                ```python
                # Example in VideoJobRepository.get_by_id
                from sqlalchemy.orm import joinedload
                # ...
                stmt = (
                    select(VideoJobModel)
                    .filter(VideoJobModel.id == job_id)
                    .options(
                        joinedload(VideoJobModel.video),
                        joinedload(VideoJobModel.video_metadata)
                    )
                )
                result = await db.execute(stmt)
                return result.scalars().first()
                ```
            *   `update_status`: Updates `VideoJobModel.status` and `error_message`.
            *   `add_processing_stage`: Updates `VideoJobModel.processing_stages`.
            *   `get_by_user_id_and_statuses`: This method is crucial. It needs to join `VideoJobModel` with `VideoModel` to filter by `uploader_user_id`. Ensure it also uses eager loading for `video` and `video_metadata` if these are part of the response schema.
                ```python
                # In apps/core/operations/video_job_repository.py
                from sqlalchemy.orm import joinedload
                # ...
                @staticmethod
                async def get_by_user_id_and_statuses(
                    db: AsyncSession,
                    user_id: str, # This is VideoModel.uploader_user_id (UUID as str from Supabase)
                    statuses: Optional[List[ProcessingStatus]] = None,
                    limit: int = 100,
                    offset: int = 0,
                ) -> List[VideoJobModel]:
                    stmt = (
                        select(VideoJobModel)
                        .join(VideoModel, VideoJobModel.video_id == VideoModel.id)
                        .filter(VideoModel.uploader_user_id == user_id)
                    )
                    if statuses:
                        stmt = stmt.filter(VideoJobModel.status.in_(statuses))

                    stmt = stmt.options(
                        joinedload(VideoJobModel.video),
                        joinedload(VideoJobModel.video_metadata) # Eager load metadata
                    ).order_by(VideoJobModel.created_at.desc()).offset(offset).limit(limit)
                    
                    result = await db.execute(stmt)
                    return list(result.scalars().all())
                ```
        5.  **`VideoMetadataRepository`**:
            *   `create_or_update`: Uses `job_id` to find/create `VideoMetadataModel`.
            *   `get_by_job_id`: Fetches `VideoMetadataModel`.
        6.  **Dependency Injection for Repositories:** Ensure repository getter functions (e.g., `get_video_repository`) are updated if necessary, though if they are simple type hints or class instantiations, they might not need changes beyond what FastAPI handles for `Depends`.
    *   **Verification:** Repository methods are `async`, use `AsyncSession`, align with the new ORM models, and database queries are correct for the new schema. Eager loading is implemented where appropriate.

* - [ ] **Task 3.3: Update Service Layer (`apps/core/services/`)**
    *   **Objective:** Adapt service logic to the new three-model structure and asynchronous repository methods.
    *   **Files to Update:**
        *   `apps/core/services/video_processing_service.py`
        *   `apps/core/services/job_service.py`
        *   Potentially `apps/core/services/metadata_service.py` if it interacts directly with these models/repos.
    *   **Action:**
        1.  **Async Calls:** All calls to repository methods must now be `await`ed. Service methods interacting with repos will likely become `async def`.
        2.  **`VideoProcessingService.initiate_video_processing`**:
            *   Save video file to storage (already async).
            *   `await self.video_repo.create(...)` to create `VideoModel`.
            *   `await self.job_repo.create(...)` to create `VideoJobModel`, linking it to the `VideoModel.id`.
            *   `await db.commit()` (session passed to the service method).
            *   Schedule `_execute_processing_pipeline` (which is async) in background tasks.
        3.  **`VideoProcessingService._execute_processing_pipeline`**:
            *   This method runs in a background task and should manage its own `AsyncSession`.
                ```python
                # At the beginning of _execute_processing_pipeline
                async with AsyncSessionLocal() as db_bg: # Create a new session for the background task
                    # ... rest of the logic using db_bg ...
                    await self.job_repo.get_by_id(db_bg, job_id)
                    # ...
                    await db_bg.commit()
                ```
            *   Fetch `VideoJobModel` using `await self.job_repo.get_by_id(db_bg, job_id)`.
            *   Access related `VideoModel` via `job.video` (ensure it's loaded, possibly via eager loading in `job_repo.get_by_id`).
            *   When saving metadata (title, description, transcript URL, etc.), create/update a `VideoMetadataModel` instance using `await self.metadata_repo.create_or_update(db_bg, job_id=job.id, title=...)`.
            *   Update `VideoJobModel` status and stages using `await self.job_repo.update_status(...)` and `await self.job_repo.add_processing_stage(...)`.
            *   Commit changes within the background task's session: `await db_bg.commit()`.
        4.  **`VideoProcessingService.get_job_details`**:
            *   Fetch `VideoJobModel` using `await self.job_repo.get_by_id(db, job_id)`.
            *   The eager loading in `job_repo.get_by_id` should make `job.video` and `job.video_metadata` available.
            *   Perform authorization check: `job.video.uploader_user_id == user_id`.
        5.  **`JobService.get_user_jobs_by_statuses`**:
            *   This service should now correctly call `await VideoJobRepository.get_by_user_id_and_statuses(...)`. The returned `VideoJobModel` instances should have their `video` and `video_metadata` relationships populated due to eager loading in the repository.
    *   **Verification:** Service logic correctly orchestrates `async` operations across the new models and repositories. Background tasks manage their own sessions. Data flow between services and repositories is correct.

* - [ ] **Task 3.4: Update API Endpoints (`apps/core/api/endpoints/`)**
    *   **Objective:** Ensure API endpoints use the correct Pydantic API schemas (from `apps.core.api.schemas.video_processing_schemas`) and make `async` calls to services.
    *   **Files to Update:**
        *   `apps/core/api/endpoints/video_processing_endpoints.py`
        *   `apps/core/api/endpoints/jobs_endpoints.py`
    *   **Action:**
        1.  **Async Endpoints:** All endpoint functions that call `async` service methods must be `async def`.
        2.  **Dependencies:** Ensure `db: AsyncSession = Depends(get_async_db_session)` is used for injecting asynchronous sessions.
        3.  **Response Models:** Update `response_model` in endpoint definitions to use the refactored Pydantic API schemas (e.g., `VideoJobResponseSchema`, `VideoUploadResponseSchema`, `List[VideoSummarySchema]`).
        4.  Ensure data passed to and returned from service calls matches the updated service method signatures and Pydantic API schema expectations.
        5.  For `get_my_processing_jobs` (in `jobs_endpoints.py`), it should return `List[VideoJobResponseSchema]` (or `List[VideoSummarySchema]` if a summary is preferred for lists). The service `get_user_jobs_by_statuses` returns `List[VideoJobModel]`. FastAPI will convert these ORM models to the Pydantic response model using `from_attributes=True`.
        6.  For `upload_video` (in `video_processing_endpoints.py`), the response `VideoUploadResponseSchema` should contain `job_id` and initial `status` from the created `VideoJobModel`.
        7.  For `get_job_details` (in `video_processing_endpoints.py`), the response `VideoJobResponseSchema` should be populated from the `VideoJobModel` returned by the service, including its nested `video` and `metadata` if applicable due to eager loading.
    *   **Verification:** API endpoints are correctly typed with `async def`, use `AsyncSession`, use the correct Pydantic API response schemas, and function correctly with the refactored services. Test with a tool like Postman or by running frontend against it.

---

**Phase 4: TypeScript Type Generation & Frontend Alignment**

* - [ ] **Task 4.1: Generate TypeScript Types**
    *   **Objective:** Create up-to-date TypeScript interfaces for the frontend based on the Pydantic API schemas.
    *   **Command (from project root):** `pnpm codegen:api-types`
    *   **Script to Verify/Update (in root `package.json`):**
        ```jsonc
        // In root package.json under "scripts"
        "codegen:api-types": "cd apps/core && uv run pydantic-to-typescript --module apps.core.api.schemas.video_processing_schemas --output ../../apps/web/app/types/api.ts --json2ts-cmd ../../apps/web/node_modules/.bin/json2ts && cd ../..",
        ```
        *   Ensure `--module` points to `apps.core.api.schemas.video_processing_schemas` (where your final API Pydantic schemas are defined).
        *   Ensure `--output` points to `apps/web/app/types/api.ts`.
    *   **Verification:** Open `apps/web/app/types/api.ts`. It should contain TypeScript interfaces like `VideoJobResponseSchema`, `VideoResponseSchema`, `VideoMetadataResponseSchema`, `ProcessingStatus` (as a TypeScript enum or literal union type), etc., matching your Pydantic API schema definitions.

* - [ ] **Task 4.2: Update Frontend Code**
    *   **Objective:** Ensure frontend components, hooks, and API calls use the new TypeScript types and expect data in the new structure.
    *   **Key Files/Areas to Update:**
        *   **API Client Functions:** `apps/web/app/lib/api.ts` - Update fetch functions to use new request/response types.
        *   **WebSocket Handling:** `apps/web/app/hooks/useAppWebSocket.ts` and `apps/web/app/hooks/useJobStatusManager.ts` - If WebSocket message structures for job updates change, update the types and handling logic. The `WebSocketJobUpdate` type in `useJobStatusManager.ts` will be critical.
        *   **Video Components:**
            *   `apps/web/app/components/video/ProcessingDashboard.tsx`
            *   `apps/web/app/components/video/VideoList.tsx` & `VideoListItem.tsx` (will likely use `VideoSummarySchema`)
            *   `apps/web/app/components/video/VideoDetail.tsx` (route `/video/$videoId`, will use `VideoJobResponseSchema` or a similar detailed type)
            *   `apps/web/app/components/video/VideoUploadDropzone.tsx` (ensure it aligns with any changes to upload API responses)
        *   **Route Components:** Any routes in `apps/web/app/routes/` that display or interact with video/job data.
        *   **TanStack Query Hooks:** Review `useQuery` and `useMutation` calls to ensure query keys and expected data types match the new API responses.
    *   **Action:**
        1.  Update type imports in frontend files to use the types from `~/types/api` (or the correct relative path to `api.ts`).
        2.  Adjust data access patterns. For example, if `VideoSummarySchema` is now used for lists, ensure components expect this structure. If `VideoJobResponseSchema` now nests `video` and `metadata` objects, update components to access data like `job.video.original_filename` or `job.metadata.title`.
        3.  Pay close attention to how `processing_stages` and `status` are handled and displayed.
    *   **Verification:** Frontend compiles without TypeScript errors. Data fetched from the backend is correctly displayed. UI interactions related to video/job data work as expected.

---

**Phase 5: Testing**

* - [ ] **Task 5.1: Update Backend Unit & Integration Tests**
    *   **Objective:** Ensure all backend tests pass with the new schema, asynchronous logic, and model structures.
    *   **Files to Update:** All test files in `apps/core/tests/`.
        *   `apps/core/tests/unit/operations/`: Update repository tests for async methods and new model interactions.
        *   `apps/core/tests/unit/services/`: Update service tests for async calls and new data structures.
        *   `apps/core/tests/api/`: Update API integration tests to expect new request/response structures and test async endpoints.
        *   `apps/core/tests/integration/conftest.py` (or `apps/core/tests/conftest.py`): Update fixtures to create and populate the new `videos`, `video_jobs`, `video_metadata` tables correctly for integration tests. Ensure async session fixtures are used.
    *   **Command (from project root):** `pnpm api:test` (or `cd apps/core && pytest`)
    *   **Verification:** All backend tests pass. Coverage is maintained or improved.

* - [ ] **Task 5.2: Frontend Testing (if applicable)**
    *   **Objective:** Ensure frontend tests (unit, integration, E2E) pass with the new types and UI changes.
    *   **Action:** Update any frontend tests in `apps/web/` that interact with video/job data or components displaying this data.
    *   **Verification:** Frontend tests pass.

---

This detailed roadmap should guide you through the process of achieving end-to-end type safety and aligning your database, backend, and frontend. Remember to tackle one phase and task at a time, verifying each step before moving to the next. Good luck!
</file>

<file path="apps/core/api/endpoints/__init__.py">
from apps.core.api.endpoints.video_processing_endpoints import router as router
</file>

<file path="apps/core/api/endpoints/jobs_endpoints.py">
from typing import List, Optional

from fastapi import APIRouter, Depends, Query
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm import Session

from apps.core.api.schemas.video_processing_schemas import VideoJobSchema
from apps.core.lib.auth.supabase_auth import AuthenticatedUser, get_current_user
from apps.core.lib.database.connection import get_async_db_session, get_db_session
from apps.core.models.enums import ProcessingStatus
from apps.core.services.job_service import get_user_jobs_by_statuses

# Placeholder for the service function we will create in Task 3.X.2
# from apps.core.services.job_service import get_user_jobs_by_statuses

router = APIRouter()


@router.get(
    "/",
    response_model=List[VideoJobSchema],
    summary="Get User's Processing Jobs",
    description="Retrieve a list of video processing jobs for the authenticated user, filtered by status.",
)
async def get_my_processing_jobs(
    *,  # Enforces keyword-only arguments for clarity
    db: AsyncSession = Depends(get_async_db_session),
    current_user: AuthenticatedUser = Depends(get_current_user),
    status: Optional[List[ProcessingStatus]] = Query(
        default=None,  # Default to None, meaning all non-terminal if not specified by service
        description="Filter jobs by status (e.g., PENDING, PROCESSING). If not provided, by default PENDING and PROCESSING jobs are returned.",
        example=[ProcessingStatus.PENDING, ProcessingStatus.PROCESSING],
    ),
):
    """
    Retrieves video processing jobs for the current authenticated user.

    Allows filtering by one or more job statuses.
    If no statuses are provided, the service layer will return PENDING and PROCESSING jobs.
    The user_id passed to the service layer will be current_user.id (string UUID from Supabase).
    """
    # Call the service layer function.
    # Note: get_user_jobs_by_statuses is async, so we await it.
    # The underlying repository call is synchronous for now.
    jobs = await get_user_jobs_by_statuses(
        db=db,
        user_id=current_user.id,  # Pass the string ID from AuthenticatedUser
        statuses=status,
    )
    return jobs


# Future job-related endpoints will be added here
</file>

<file path="apps/core/api/endpoints/video_processing_endpoints.py">
"""
API endpoints for video processing functionality.

This module defines FastAPI routes for video upload, processing, and status retrieval.
It provides a clean RESTful interface for the video processing pipeline, handling
authentication, request validation, response formatting, and error handling.

The endpoints handle:
- Video file uploads with validation
- Asynchronous video processing via background tasks
- Status checking for ongoing and completed jobs
- Authorization to ensure users only access their own data

All business logic is delegated to the VideoProcessingService, with this module
focusing solely on HTTP concerns.
"""

from fastapi import APIRouter, BackgroundTasks, Depends, File, HTTPException, UploadFile
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm import Session

from apps.core.api.schemas.video_processing_schemas import (
    VideoJobSchema,
    VideoUploadResponseSchema,
)
from apps.core.core.config import settings
from apps.core.lib.ai.ai_client_factory import get_ai_adapter
from apps.core.lib.auth.supabase_auth import AuthenticatedUser, get_current_user
from apps.core.lib.database.connection import get_async_db_session, get_db_session
from apps.core.lib.storage.file_storage import FileStorageService
from apps.core.lib.utils.ffmpeg_utils import FfmpegUtils
from apps.core.lib.utils.file_utils import FileUtils
from apps.core.lib.utils.subtitle_utils import SubtitleUtils
from apps.core.operations.video_job_repository import (
    VideoJobRepository,
    get_video_job_repository,
)
from apps.core.operations.video_metadata_repository import VideoMetadataRepository
from apps.core.operations.video_repository import VideoRepository, get_video_repository
from apps.core.services.video_processing_service import VideoProcessingService

router = APIRouter()


async def get_video_processing_service(
    # Repositories are now injected via their async getters
    video_repo: VideoRepository = Depends(get_video_repository),
    job_repo: VideoJobRepository = Depends(get_video_job_repository),
    # VideoMetadataRepository uses static methods, so no instance needed for them directly
    # However, VideoProcessingService expects an instance. We can pass a dummy or refactor service.
    # For now, let's assume VideoProcessingService can handle VideoMetadataRepository methods being called statically if needed
    # or we can instantiate it if it has a simple __init__.
    # VideoMetadataRepository has no __init__, its methods are static.
    # The service VideoProcessingService instantiates it as `metadata_repo: VideoMetadataRepository`. Let's keep that for now.
    # If VideoProcessingService directly calls VideoMetadataRepository.create_or_update (which it does), that's fine.
    storage_service: FileStorageService = Depends(
        FileStorageService
    ),  # Assuming FileStorageService can be Depended on directly or has a getter
    ai_adapter_instance=Depends(
        get_ai_adapter
    ),  # Renamed to avoid conflict, uses existing getter
    ffmpeg_utils_instance: FfmpegUtils = Depends(
        FfmpegUtils
    ),  # Assuming FfmpegUtils can be Depended on
    subtitle_utils_instance: SubtitleUtils = Depends(
        SubtitleUtils
    ),  # Assuming SubtitleUtils can be Depended on
    file_utils_instance: FileUtils = Depends(
        FileUtils
    ),  # Assuming FileUtils can be Depended on
) -> VideoProcessingService:
    # Dependency injection for the service and its dependencies
    return VideoProcessingService(
        video_repo=video_repo,  # Injected async repo
        job_repo=job_repo,  # Injected async repo
        metadata_repo=VideoMetadataRepository(),  # Instantiated as before (static methods)
        storage=storage_service,
        ai_adapter=ai_adapter_instance,
        ffmpeg_utils=ffmpeg_utils_instance,
        subtitle_utils=subtitle_utils_instance,
        file_utils=file_utils_instance,
    )


@router.post(
    "/upload",
    response_model=VideoUploadResponseSchema,
    summary="Upload a video and initiate processing",
)
async def upload_video(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...),
    current_user: AuthenticatedUser = Depends(get_current_user),
    db: AsyncSession = Depends(get_async_db_session),
    service: VideoProcessingService = Depends(get_video_processing_service),
):
    """
    Upload a video file and initiate the processing pipeline.

    This endpoint allows users to upload a video file, which is then processed to:
    - Extract metadata (duration, resolution, format)
    - Generate a transcript
    - Create AI-generated title, description, and tags
    - Generate subtitle files (VTT and SRT formats)
    - Extract a thumbnail image

    The processing occurs asynchronously in the background, and clients can
    check the processing status using the returned job_id.

    Returns:
        VideoUploadResponseSchema: Contains the job_id and initial PENDING status

    Raises:
        400: If the uploaded file is not a video or is missing metadata
        401: If the user is not authenticated
    """
    if not file.content_type or not file.content_type.startswith("video/"):
        raise HTTPException(status_code=400, detail="File must be a video")
    if not file.filename or not file.content_type:
        raise HTTPException(status_code=400, detail="Missing file metadata")
    video_content = await file.read()
    job = await service.initiate_video_processing(
        db=db,
        original_filename=file.filename,
        video_content=video_content,
        content_type=file.content_type,
        uploader_user_id=current_user.id,
        background_tasks=background_tasks,
    )
    return VideoUploadResponseSchema(job_id=job.id, status=job.status)


@router.get(
    "/jobs/{job_id}",
    response_model=VideoJobSchema,
    summary="Get video processing job details",
)
async def get_job_details(
    job_id: int,
    current_user: AuthenticatedUser = Depends(get_current_user),
    db: AsyncSession = Depends(get_async_db_session),
    service: VideoProcessingService = Depends(get_video_processing_service),
):
    """
    Retrieve details and status of a video processing job.

    This endpoint allows users to check the status of a video processing job and retrieve
    all associated metadata. It includes authorization checks to ensure users can only
    access their own video processing jobs.

    The response includes:
    - Job status (PENDING, PROCESSING, COMPLETED, FAILED)
    - Processing stages information
    - Error messages (if any)
    - Video metadata (title, description, tags, etc.)
    - Generated asset URLs (transcript, subtitles, thumbnail)
    - Technical metadata (duration, resolution, format)

    Path Parameters:
        job_id (int): The ID of the video processing job to retrieve

    Returns:
        VideoJobSchema: Complete job information with nested video and metadata

    Raises:
        401: If the user is not authenticated
        403/404: If the job doesn't exist or belongs to another user
    """
    job = await service.get_job_details(db=db, job_id=job_id, user_id=current_user.id)
    return job
</file>

<file path="apps/core/api/schemas/user_schemas.py">
from datetime import datetime
from typing import Any, Dict, List, Optional
from uuid import UUID

from pydantic import BaseModel, ConfigDict, EmailStr


# User schemas
class UserBase(BaseModel):
    username: str
    email: EmailStr
    full_name: Optional[str] = None


class UserCreate(UserBase):
    password: str


class UserUpdate(BaseModel):
    username: Optional[str] = None
    email: Optional[EmailStr] = None
    full_name: Optional[str] = None
    password: Optional[str] = None


class UserResponse(UserBase):
    id: int
    is_active: bool

    model_config = ConfigDict(from_attributes=True)


# Auth schemas
class Token(BaseModel):
    access_token: str
    token_type: str


class TokenData(BaseModel):
    username: Optional[str] = None


class LoginRequest(BaseModel):
    username: str
    password: str


class HelloResponse(BaseModel):
    message: str


# Chat schemas
class MessageBase(BaseModel):
    content: str
    is_from_ai: bool = False


class MessageCreate(MessageBase):
    chat_id: int


class MessageResponse(MessageBase):
    id: int
    chat_id: int
    created_at: datetime

    model_config = ConfigDict(from_attributes=True)


class ChatBase(BaseModel):
    title: Optional[str] = None


class ChatCreate(ChatBase):
    pass


class ChatUpdate(ChatBase):
    title: Optional[str] = None


class ChatResponse(ChatBase):
    id: int
    created_at: datetime
    updated_at: datetime

    model_config = ConfigDict(from_attributes=True)


class ChatDetailResponse(ChatResponse):
    messages: List[MessageResponse] = []

    model_config = ConfigDict(from_attributes=True)


# Streaming Chat schemas
class ClientAttachment(BaseModel):
    name: str
    contentType: str
    url: str


class ToolInvocation(BaseModel):
    toolCallId: str
    toolName: str
    args: Dict[str, Any]
    result: Dict[str, Any]


class ClientMessage(BaseModel):
    role: str
    content: str
    experimental_attachments: Optional[List[ClientAttachment]] = None
    toolInvocations: Optional[List[ToolInvocation]] = None


class ChatRequest(BaseModel):
    messages: List[ClientMessage]
    chat_id: UUID


class StreamingMessageCreate(BaseModel):
    content: str
    chat_id: UUID
    protocol: str = "data"
</file>

<file path="apps/core/api/schemas/video_processing_schemas.py">
"""
Pydantic schemas for video processing API requests and responses.

This module defines the data models used for API input validation and response
serialization in the video processing API endpoints. These schemas provide a
contract between the backend services and API clients, ensuring type safety
and proper documentation.

The schemas are designed to map cleanly to the database models while providing
appropriate defaults, validation rules, and documentation for the API layer.
"""

from datetime import datetime
from typing import Any, Dict, List, Optional, Union

from pydantic import BaseModel, ConfigDict, Field

from apps.core.models.enums import ProcessingStatus

# --- API Client Specific Schemas ---


class ApiErrorDetail(BaseModel):
    """Individual error detail, often part of a list in ApiErrorResponse."""

    loc: Optional[List[Union[str, int]]] = Field(
        default=None, description="Location of the error (e.g., field path)"
    )
    msg: str = Field(..., description="Error message")
    type: str = Field(..., description="Type of error (e.g., 'value_error')")
    ctx: Optional[Dict[str, Any]] = Field(
        default=None, description="Additional context for the error"
    )


class ApiErrorResponse(BaseModel):
    """Standard error response structure for API errors."""

    detail: Union[str, List[ApiErrorDetail]] = Field(
        ..., description="Error message or list of error details"
    )


class SignedUploadUrlRequest(BaseModel):
    """Request schema for obtaining a signed URL for video upload."""

    filename: str = Field(..., description="Original filename of the video.")
    contentType: str = Field(
        ..., alias="content_type", description="MIME type of the video file."
    )
    # Using alias for contentType to match frontend usage, backend might prefer content_type

    model_config = ConfigDict(populate_by_name=True)


class SignedUploadUrlResponse(BaseModel):
    """Response schema after requesting a signed URL."""

    uploadUrl: str = Field(
        ..., alias="upload_url", description="The GCS signed URL for direct PUT upload."
    )
    videoId: str = Field(
        ...,
        alias="video_id",
        description="The unique ID assigned to this video upload attempt/record.",
    )
    # Assuming videoId is a string identifier generated for the upload process,
    # which might later be associated with an integer DB ID.

    model_config = ConfigDict(populate_by_name=True)


class UploadCompleteRequest(BaseModel):
    """Request schema to notify the backend that a direct upload is complete."""

    videoId: str = Field(
        ..., alias="video_id", description="The unique ID of the video upload."
    )
    originalFilename: str = Field(
        ...,
        alias="original_filename",
        description="Original filename of the uploaded video.",
    )
    contentType: str = Field(
        ..., alias="content_type", description="MIME type of the video file."
    )
    sizeBytes: int = Field(
        ..., alias="size_bytes", description="Size of the video file in bytes."
    )
    storagePath: Optional[str] = Field(
        default=None,
        alias="storage_path",
        description="Canonical path in GCS if known by uploader; backend may infer.",
    )
    # Aliases to match frontend camelCase, Python typically uses snake_case.

    model_config = ConfigDict(populate_by_name=True)


class VideoSummary(BaseModel):
    """Summarized video information, typically for lists."""

    id: int = Field(..., description="Unique identifier for the video.")
    original_filename: str = Field(..., description="Original filename of the video.")
    title: Optional[str] = Field(default=None, description="Title of the video.")
    created_at: Optional[datetime] = Field(
        default=None, description="Timestamp of video creation."
    )
    status: Optional[ProcessingStatus] = Field(
        default=None, description="Current processing status of the video."
    )
    thumbnail_file_url: Optional[str] = Field(
        default=None, description="URL to the video's thumbnail."
    )
    # Add other fields like duration, title if available and desired in summary

    model_config = ConfigDict(from_attributes=True)


class VideoMetadataUpdateRequest(BaseModel):
    """Request schema for updating video metadata."""

    title: Optional[str] = Field(default=None, description="New title for the video.")
    description: Optional[str] = Field(
        default=None, description="New description for the video."
    )
    tags: Optional[List[str]] = Field(
        default=None, description="New list of tags for the video."
    )
    # Add other editable metadata fields from VideoMetadataSchema as needed

    model_config = ConfigDict(extra="forbid")  # Prevent unspecified fields


# --- Existing Schemas (ensure they are compatible) ---


class VideoUploadResponseSchema(BaseModel):
    """
    Response schema for the video upload endpoint. (Existing)
    NOTE: This might be for when upload starts processing, not the signed URL itself.
    If getSignedUploadUrl returns SignedUploadUrlResponse, this might be for a different step.
    For now, keeping as is, assuming it's used by an endpoint.
    """

    job_id: int = Field(..., description="The ID of the created video processing job.")
    status: ProcessingStatus = Field(..., description="The initial status of the job.")


class VideoSchema(BaseModel):
    """Schema representing a video file in the system. (Existing)"""

    id: int
    uploader_user_id: str
    original_filename: str
    storage_path: str
    content_type: str
    size_bytes: int
    created_at: Optional[datetime] = None
    updated_at: Optional[datetime] = None

    model_config = ConfigDict(from_attributes=True)


class VideoMetadataSchema(BaseModel):
    """Schema representing metadata extracted from a processed video. (Existing)"""

    id: Optional[int] = None
    job_id: Optional[int] = None
    title: Optional[str] = None
    description: Optional[str] = None
    tags: Optional[List[str]] = Field(default_factory=list)
    transcript_text: Optional[str] = None
    transcript_file_url: Optional[str] = None
    subtitle_files_urls: Optional[Dict[str, Any]] = Field(default_factory=dict)
    thumbnail_file_url: Optional[str] = None
    extracted_video_duration_seconds: Optional[float] = None
    extracted_video_resolution: Optional[str] = None
    extracted_video_format: Optional[str] = None
    show_notes_text: Optional[str] = None
    created_at: Optional[datetime] = None
    updated_at: Optional[datetime] = None

    model_config = ConfigDict(from_attributes=True)


class VideoJobSchema(BaseModel):
    """Schema representing a video processing job. (Existing)"""

    id: int
    video_id: int
    status: ProcessingStatus
    processing_stages: Optional[Union[List[str], Dict[str, Any]]] = None
    error_message: Optional[str] = None
    created_at: Optional[datetime] = None
    updated_at: Optional[datetime] = None
    video: Optional[VideoSchema] = None
    metadata: Optional[VideoMetadataSchema] = None

    model_config = ConfigDict(from_attributes=True, extra="ignore")


class VideoDetailsResponse(
    BaseModel
):  # Renamed from VideoJobSchema for clarity if it's the primary response for video details
    """
    Comprehensive details for a specific video, including its job and metadata.
    This often mirrors VideoJobSchema if that schema is the primary source of truth.
    Alternatively, it can be a composition of VideoSchema, VideoMetadataSchema, and job details.
    Let's make it closely related to VideoJobSchema for now.
    """

    id: int = Field(
        ...,
        description="Video Job ID. If this is for Video Details, this might be Video ID with Job details nested or vice-versa",
    )  # Clarify if this ID is Video or Job
    video_id: int = Field(..., description="Associated Video ID")
    uploader_user_id: Optional[str] = Field(
        None, description="ID of the user who uploaded the video. (Derived from video)"
    )
    original_filename: Optional[str] = Field(
        None, description="Original filename from the upload. (Derived from video)"
    )

    status: ProcessingStatus = Field(
        ..., description="Current status of the processing job."
    )
    processing_stages: Optional[Union[List[str], Dict[str, Any]]] = Field(
        default=None, description="Progress information."
    )
    error_message: Optional[str] = Field(
        default=None, description="Error details if the job failed."
    )

    created_at: Optional[datetime] = Field(
        default=None, description="When the job (or video) was created."
    )
    updated_at: Optional[datetime] = Field(
        default=None, description="When the job (or video) was last updated."
    )

    # Nested video and metadata details
    video: Optional[VideoSchema] = Field(
        default=None, description="Associated video details."
    )
    metadata: Optional[VideoMetadataSchema] = Field(
        default=None, description="Associated metadata details."
    )

    model_config = ConfigDict(from_attributes=True, extra="ignore")

    # If VideoDetailsResponse is intended to be populated from a VideoJobModel that has
    # related VideoModel and VideoMetadataModel, `from_attributes=True` helps.
    # The direct fields like uploader_user_id and original_filename can be populated if
    # the ORM query for VideoJobModel also loads related VideoModel and these are exposed.
    # Otherwise, they might be better inside the nested `video: VideoSchema`.
    # For now, keeping them potentially at top level for flexibility in how backend serves it.


# Ensure all schemas intended for generation are defined above this line or imported.
# ProcessingStatus is an enum and should be handled correctly by pydantic-to-typescript.
</file>

<file path="apps/core/api/endpoints.py">
from typing import List
from uuid import UUID

from fastapi import APIRouter, Depends, HTTPException, Query, status
from fastapi.responses import StreamingResponse
from services.ai_service import AIService, get_ai_service
from services.auth_service import AuthService, get_auth_service
from services.chat_service import ChatService, get_chat_service
from services.user_service import UserService, get_user_service

from api.schemas import (
    ChatCreate,
    ChatDetailResponse,
    ChatRequest,
    ChatResponse,
    ChatUpdate,
    HelloResponse,
    LoginRequest,
    MessageCreate,
    MessageResponse,
    StreamingMessageCreate,
    Token,
    UserCreate,
    UserResponse,
)

router = APIRouter()


@router.post(
    "/users/", response_model=UserResponse, status_code=status.HTTP_201_CREATED
)
def create_user(
    user_data: UserCreate,
    auth_service: AuthService = Depends(get_auth_service),
):
    """Create a new user"""
    return auth_service.register_user(user_data.model_dump())


@router.get("/users/{user_id}", response_model=UserResponse)
def get_user_by_id(user_id: int, user_service: UserService = Depends(get_user_service)):
    """Get user by ID"""
    return user_service.get_user_profile(user_id)


@router.post("/login/", response_model=Token)
def login(
    login_data: LoginRequest,
    auth_service: AuthService = Depends(get_auth_service),
):
    """Login and get access token"""
    user = auth_service.authenticate_user(login_data.username, login_data.password)
    if not user:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Incorrect username or password",
            headers={"WWW-Authenticate": "Bearer"},
        )

    # In a real app, generate JWT token here
    access_token = f"dummy_token_for_{user['username']}"

    return {"access_token": access_token, "token_type": "bearer"}


@router.get("/hello", response_model=HelloResponse)
def hello() -> HelloResponse:
    return HelloResponse(message="Hello, World!")


# Chat endpoints
@router.get("/chats/", response_model=List[ChatResponse])
def get_chats(
    skip: int = 0,
    limit: int = 20,
    chat_service: ChatService = Depends(get_chat_service),
):
    """Get all chats"""
    return chat_service.get_chats(skip=skip, limit=limit)


@router.post(
    "/chats/", response_model=ChatDetailResponse, status_code=status.HTTP_201_CREATED
)
def create_chat(
    chat_data: ChatCreate, chat_service: ChatService = Depends(get_chat_service)
):
    """Create a new chat"""
    return chat_service.create_chat(chat_data.model_dump())


@router.get("/chats/{chat_id}", response_model=ChatDetailResponse)
def get_chat(chat_id: UUID, chat_service: ChatService = Depends(get_chat_service)):
    """Get chat by ID with messages"""
    return chat_service.get_chat(chat_id)


@router.put("/chats/{chat_id}", response_model=ChatResponse)
def update_chat(
    chat_id: UUID,
    chat_data: ChatUpdate,
    chat_service: ChatService = Depends(get_chat_service),
):
    """Update chat title"""
    return chat_service.update_chat(chat_id, chat_data.model_dump())


@router.delete("/chats/{chat_id}", status_code=status.HTTP_200_OK)
def delete_chat(chat_id: UUID, chat_service: ChatService = Depends(get_chat_service)):
    """Delete a chat"""
    return chat_service.delete_chat(chat_id)


# Message endpoints
@router.post(
    "/messages/", response_model=MessageResponse, status_code=status.HTTP_201_CREATED
)
def create_message(
    message_data: MessageCreate, chat_service: ChatService = Depends(get_chat_service)
):
    """Create a new message"""
    return chat_service.create_message(message_data.model_dump())


@router.get("/chats/{chat_id}/messages/", response_model=List[MessageResponse])
def get_chat_messages(
    chat_id: UUID,
    skip: int = 0,
    limit: int = 50,
    chat_service: ChatService = Depends(get_chat_service),
):
    """Get all messages for a chat"""
    return chat_service.get_chat_messages(chat_id, skip=skip, limit=limit)


# Streaming Chat endpoints
@router.post("/chat")
async def stream_chat(
    request: ChatRequest,
    protocol: str = Query("data"),
    ai_service: AIService = Depends(get_ai_service),
):
    """
    Stream a chat interaction using Vercel AI protocol
    This endpoint is designed to be compatible with the Vercel AI SDK
    """
    # Return an error if there are no messages or the last message is not from the user
    if not request.messages or request.messages[-1].role != "user":
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Last message must be from the user",
        )

    # Extract messages in dict format for processing
    client_messages = [msg.model_dump() for msg in request.messages]

    # For demonstration purposes, use chat ID 1
    # In a real app, you would maintain the chat ID in a session or create a new chat
    chat_id = request.chat_id

    # Create a streaming response using the AI service
    response = StreamingResponse(
        ai_service.process_chat_stream(client_messages, chat_id, protocol)
    )

    # Add the Vercel AI protocol header
    response.headers["x-vercel-ai-data-stream"] = "v1"
    return response


@router.post("/stream-message")
async def stream_message(
    message_data: StreamingMessageCreate,
    ai_service: AIService = Depends(get_ai_service),
):
    """Send a message and get a streaming AI response"""

    # Create a streaming response
    response = StreamingResponse(
        ai_service.stream_ai_response(
            message_content=message_data.content,
            chat_id=message_data.chat_id,
            protocol=message_data.protocol,
        )
    )

    # Add Vercel AI protocol header
    response.headers["x-vercel-ai-data-stream"] = "v1"
    return response
</file>

<file path="apps/core/app/db/engine.py">
import os
from functools import lru_cache

from dotenv import load_dotenv
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

# Construct the path to the root .env file
# __file__ is engine.py, so ../../.. goes from app/db/engine.py to apps/core/ to apps/ to project root
dotenv_path = os.path.join(os.path.dirname(__file__), "..", "..", "..", "..", ".env")
load_dotenv(dotenv_path=dotenv_path)

DATABASE_URL = os.getenv(
    "DATABASE_URL", "postgresql://postgres:postgres@localhost:54322/postgres"
)


@lru_cache
def get_engine():
    # Add connect_args for SQLite compatibility if you ever use SQLite for testing with this engine
    connect_args = {}
    if DATABASE_URL.startswith("sqlite"):
        connect_args = {"check_same_thread": False}
    return create_engine(DATABASE_URL, pool_pre_ping=True, connect_args=connect_args)


SessionLocal = sessionmaker(bind=get_engine(), autoflush=False, autocommit=False)
</file>

<file path="apps/core/app/db/schemas.py">
from enum import Enum
from typing import Any, Dict, List, Optional, Union

from pydantic import (  # Keep pydantic BaseModel for custom schemas
    BaseModel,
    ConfigDict,
    Field,
)

# Assuming supabase-pydantic generates models into this path and module
# The actual model names (e.g., Videos, VideoJobs, VideoMetadata) will depend on your table names
# and how supabase-pydantic names them. You'll need to inspect the generated file.
# from apps.core.app.db_pydantic_models.supabase_models import (
#     Videos as GeneratedVideoSchema,
#     VideoJobs as GeneratedVideoJobSchema,
#     VideoMetadata as GeneratedVideoMetadataSchema
# )


# Your existing ProcessingStatus enum
class ProcessingStatus(str, Enum):
    PENDING = "PENDING"
    PROCESSING = "PROCESSING"
    COMPLETED = "COMPLETED"
    FAILED = "FAILED"


# --- API Client Specific Schemas (likely remain unchanged) ---
class ApiErrorDetail(BaseModel):
    loc: Optional[List[Union[str, int]]] = Field(default=None)
    msg: str
    type: str
    ctx: Optional[Dict[str, Any]] = Field(default=None)


class ApiErrorResponse(BaseModel):
    detail: Union[str, List[ApiErrorDetail]]


class SignedUploadUrlRequest(BaseModel):
    filename: str
    content_type: str = Field(..., alias="contentType")
    model_config = ConfigDict(populate_by_name=True)


class SignedUploadUrlResponse(BaseModel):
    upload_url: str = Field(..., alias="uploadUrl")
    video_id: str = Field(..., alias="videoId")
    model_config = ConfigDict(populate_by_name=True)


class UploadCompleteRequest(BaseModel):
    video_id: str = Field(..., alias="videoId")
    original_filename: str = Field(..., alias="originalFilename")
    content_type: str = Field(..., alias="contentType")
    size_bytes: int = Field(..., alias="sizeBytes")
    storage_path: Optional[str] = Field(default=None, alias="storagePath")
    model_config = ConfigDict(populate_by_name=True)


# --- Schemas that might use or be replaced by supabase-pydantic generated models ---


# If supabase-pydantic generates a suitable `VideosSchema`, you might use it directly
# or create a specific API version like this:
class VideoSchema(BaseModel):  # This is your API representation
    id: int
    uploader_user_id: str
    original_filename: str
    storage_path: str  # This might be different from DB model if it's a URL
    content_type: str
    size_bytes: int
    created_at: Optional[str] = None
    updated_at: Optional[str] = None
    model_config = ConfigDict(from_attributes=True)  # If mapping from ORM


class VideoMetadataSchema(BaseModel):  # Your API representation
    id: Optional[int] = None
    job_id: Optional[int] = None
    title: Optional[str] = None
    description: Optional[str] = None
    tags: Optional[List[str]] = Field(default_factory=list)
    transcript_text: Optional[str] = None
    transcript_file_url: Optional[str] = None
    subtitle_files_urls: Optional[Dict[str, Any]] = Field(default_factory=dict)
    thumbnail_file_url: Optional[str] = None
    extracted_video_duration_seconds: Optional[float] = None
    extracted_video_resolution: Optional[str] = None
    extracted_video_format: Optional[str] = None
    show_notes_text: Optional[str] = None
    created_at: Optional[str] = None
    updated_at: Optional[str] = None
    model_config = ConfigDict(from_attributes=True)


class VideoJobSchema(BaseModel):  # Your API representation
    id: int
    video_id: int
    status: ProcessingStatus  # Use your enum
    processing_stages: Optional[Union[List[str], Dict[str, Any]]] = None
    error_message: Optional[str] = None
    created_at: Optional[str] = None
    updated_at: Optional[str] = None
    video: Optional[VideoSchema] = None  # Nesting your API VideoSchema
    metadata: Optional[VideoMetadataSchema] = (
        None  # Nesting your API VideoMetadataSchema
    )
    model_config = ConfigDict(from_attributes=True, extra="ignore")


class VideoUploadResponseSchema(BaseModel):
    job_id: int
    status: ProcessingStatus  # Use your enum


class VideoSummary(BaseModel):
    id: int
    original_filename: str
    title: Optional[str] = None
    created_at: Optional[str] = None
    status: Optional[ProcessingStatus] = None  # Use your enum
    thumbnail_file_url: Optional[str] = None
    model_config = ConfigDict(from_attributes=True)


class VideoMetadataUpdateRequest(BaseModel):
    title: Optional[str] = None
    description: Optional[str] = None
    tags: Optional[List[str]] = None
    model_config = ConfigDict(extra="forbid")


# VideoDetailsResponse might be identical to VideoJobSchema or a slight variation
class VideoDetailsResponse(VideoJobSchema):  # Example: inheriting if very similar
    pass
</file>

<file path="apps/core/bin/clean_test_files.sh">
#!/usr/bin/env bash
set -euo pipefail

# Get the app directory
APP_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
cd "$APP_DIR"

# Define test directories to clean
TEST_UPLOADS_DIR="$APP_DIR/output_files/uploads/test"
TEST_USER_UPLOADS_DIR="$APP_DIR/output_files/uploads/test-user-id"

# Also check for and clean the incorrect path that might have been created
INCORRECT_PATH="$(cd "$APP_DIR/.." && pwd)/output_files/uploads/test"

echo "Cleaning test files..."

# Remove files in test directory
if [ -d "$TEST_UPLOADS_DIR" ]; then
    echo "Removing files from $TEST_UPLOADS_DIR"
    rm -rf "$TEST_UPLOADS_DIR"/*
    echo "✓ Test directory cleaned"
fi

# Remove mp4 files in test-user-id directory
if [ -d "$TEST_USER_UPLOADS_DIR" ]; then
    echo "Removing mp4 files from $TEST_USER_UPLOADS_DIR"
    rm -rf "$TEST_USER_UPLOADS_DIR"/*.mp4
    echo "✓ Test user files cleaned"
fi

# Clean incorrect path if it exists
if [ -d "$INCORRECT_PATH" ]; then
    echo "Cleaning incorrect path: $INCORRECT_PATH"
    rm -rf "$INCORRECT_PATH"
    echo "✓ Incorrect path removed"
fi

# Recreate the test directory structure
mkdir -p "$TEST_UPLOADS_DIR"

echo "Test files cleanup complete!"
</file>

<file path="apps/core/bin/codegen_models.sh">
#!/usr/bin/env bash
set -euo pipefail

# Navigate to project root to find .env
PROJECT_ROOT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/../../.." && pwd)"
cd "$PROJECT_ROOT_DIR"

ENV_FILE=".env"

if [ -f "$ENV_FILE" ]; then
  set -a # automatically export all variables
  source "$ENV_FILE"
  set +a
else
  echo "Warning: .env file not found at project root. DATABASE_URL might not be set."
fi

# Check if DATABASE_URL is set, fallback to default local Supabase URL if not.
DB_URL_TO_USE="${DATABASE_URL:-postgresql://postgres:postgres@localhost:54322/postgres}"

if [ "${DATABASE_URL}" != "${DB_URL_TO_USE}" ] && [ -z "${DATABASE_URL}" ]; then
    echo "Warning: DATABASE_URL not set in .env, using default: ${DB_URL_TO_USE}"
fi

echo "Generating SQLAlchemy models from ${DB_URL_TO_USE}..."
# Ensure the output directory exists
mkdir -p "${PROJECT_ROOT_DIR}/apps/core/app/db"

# Run sqlacodegen using uv to ensure it uses the project's Python environment and dependencies
# Using the default generator which is declarative for SQLAlchemy
uv run sqlacodegen "${DB_URL_TO_USE}" --outfile "${PROJECT_ROOT_DIR}/apps/core/app/db/models.py"

echo "SQLAlchemy models generated in apps/core/app/db/models.py"
echo "Reminder: Update Pydantic schemas in apps/core/app/db/schemas.py using pydantic-sqlalchemy-2 if needed."
</file>

<file path="apps/core/bin/codegen_pydantic_supabase.sh">
#!/usr/bin/env bash
set -euo pipefail

# Navigate to project root to find .env and ensure correct relative paths
PROJECT_ROOT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/../../.." && pwd)"
cd "$PROJECT_ROOT_DIR"

ENV_FILE=".env"

if [ -f "$ENV_FILE" ]; then
  set -a # automatically export all variables
  source "$ENV_FILE"
  set +a
else
  echo "Warning: .env file not found at project root. DATABASE_URL or Supabase connection details might not be set for supabase-pydantic."
fi

# supabase-pydantic uses environment variables for connection:
# SUPABASE_URL and SUPABASE_KEY (anon or service_role)
# Or, it can use DATABASE_URL.
# Ensure your .env file has these. For schema introspection, SERVICE_ROLE_KEY is best.

OUTPUT_DIR_PYDANTIC="${PROJECT_ROOT_DIR}/apps/core/app/db_pydantic_models"
OUTPUT_FILE_PYDANTIC="${OUTPUT_DIR_PYDANTIC}/supabase_models.py"

mkdir -p "$OUTPUT_DIR_PYDANTIC"

echo "Generating Pydantic models from Supabase schema using supabase-pydantic..."
echo "Outputting to: ${OUTPUT_FILE_PYDANTIC}"

# Ensure SUPABASE_URL and a SUPABASE_KEY (preferably SUPABASE_SERVICE_ROLE_KEY) are set in .env
if [ -z "${SUPABASE_URL}" ] || [ -z "${SUPABASE_SERVICE_ROLE_KEY}" ]; then
    echo "Error: SUPABASE_URL and SUPABASE_SERVICE_ROLE_KEY must be set in the root .env file for supabase-pydantic."
    # Fallback to DATABASE_URL if the others aren't set, though supabase-pydantic prefers URL/KEY
    if [ -z "${DATABASE_URL}" ]; then
        echo "Error: Neither Supabase URL/Key nor DATABASE_URL are set. Cannot generate Pydantic models."
        exit 1
    else
        echo "Warning: Using DATABASE_URL for supabase-pydantic. URL/KEY method is preferred by the tool."
        # The tool might still pick up DATABASE_URL if others are missing.
    fi
fi

# Command for supabase-pydantic.
# It will pick up SUPABASE_URL and SUPABASE_KEY from the environment.
# Use --service-role-key flag if you want to explicitly tell it to use that key.
CMD_PYDANTIC="uv run supabase-pydantic --output \"${OUTPUT_FILE_PYDANTIC}\" --schema public --pydantic-v2"

# If you want to ensure it uses the service role key for introspection:
# CMD_PYDANTIC="uv run supabase-pydantic --output \"${OUTPUT_FILE_PYDANTIC}\" --schema public --pydantic-v2 --service-role-key"

eval "$CMD_PYDANTIC"

echo "Pydantic models from Supabase schema generated in ${OUTPUT_FILE_PYDANTIC}"
echo "Review the generated models and import them into your FastAPI schemas or services as needed."
</file>

<file path="apps/core/bin/dev.sh">
#!/usr/bin/env bash
set -euo pipefail

# Get the app directory (apps/core)
APP_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
cd "$APP_DIR"

# Set PYTHONPATH to include the project root directory (one level up from apps/core)
PROJECT_ROOT_DIR="$(cd "$APP_DIR/../.." && pwd)"
export PYTHONPATH=$PROJECT_ROOT_DIR

echo "Ensuring Python dependencies are in sync..."
uv pip sync # Assumes uv.lock is present and managed

echo "Starting FastAPI server on port 8000..."
# Run uvicorn using uv to ensure it's from the virtual environment
uv run uvicorn apps.core.main:app --reload --port 8000
</file>

<file path="apps/core/bin/format.sh">
#!/usr/bin/env bash
set -euo pipefail

uv run ruff format
</file>

<file path="apps/core/bin/lint.sh">
#!/usr/bin/env bash
set -euo pipefail

uv run ruff check --fix
</file>

<file path="apps/core/bin/setup.sh">
#!/usr/bin/env bash
set -euo pipefail

uv python install

uv sync
</file>

<file path="apps/core/bin/test.sh">
#!/usr/bin/env bash
set -euo pipefail

# Get the app directory
APP_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
cd "$APP_DIR"

# Set PYTHONPATH to include the app directory
export PYTHONPATH="$APP_DIR"

# Debug output to show PATH and PYTHONPATH
echo "Running tests with PYTHONPATH=$PYTHONPATH"

# Run pytest with uv instead of direct Python call
uv run pytest "$@"
</file>

<file path="apps/core/bin/typecheck.sh">
#!/usr/bin/env bash
set -euo pipefail

# Run mypy
echo "Running mypy..."
uv run mypy . --exclude .venv --exclude venv --exclude __pycache__ --exclude .pytest_cache

# Return success/failure status
if [ $? -eq 0 ]; then
  echo "✅ Type checking passed!"
  exit 0
else
  echo "❌ Type checking failed."
  exit 1
fi
</file>

<file path="apps/core/core/exceptions.py">
"""
Custom exception classes for the Echo Core application.

This module defines various exception types used throughout the application
to provide more specific error handling for different failure scenarios.
These exceptions help with debugging and proper error reporting to clients.

Usage:
    from apps.core.core.exceptions import VideoProcessingError, FFmpegError

    try:
        # Code that might fail with FFmpeg
        process_video_with_ffmpeg(...)
    except FFmpegError as e:
        # Handle FFmpeg-specific errors
        logger.error(f"FFmpeg processing failed: {str(e)}")
        raise VideoProcessingError("Video processing failed due to FFmpeg error") from e
"""


class PublishingError(Exception):
    """Exception raised for errors during publishing operations (e.g., YouTube upload failures)."""

    pass


class MetadataGenerationError(Exception):
    """Exception raised for errors during metadata generation operations."""

    pass


class VideoProcessingError(Exception):
    """Exception raised for errors during video processing operations."""

    pass


class FFmpegError(VideoProcessingError):
    """Exception raised for errors during FFmpeg operations."""

    pass


class AINoResponseError(VideoProcessingError):
    """Exception raised when AI services fail to provide a response."""

    pass
</file>

<file path="apps/core/lib/ai/__init__.py">
from lib.ai.ai_client_factory import get_ai_adapter
from lib.ai.base_adapter import AIAdapterInterface
from lib.ai.gemini_adapter import AINoResponseError, GeminiAdapter

__all__ = ["AIAdapterInterface", "AINoResponseError", "GeminiAdapter", "get_ai_adapter"]
</file>

<file path="apps/core/lib/ai/ai_client_factory.py">
"""
Factory for creating AI service adapters.

This module provides a factory function to get the appropriate AI adapter instance
based on the configuration settings.
"""

from typing import Optional

from lib.ai.base_adapter import AIAdapterInterface
from lib.ai.gemini_adapter import GeminiAdapter

from core.config import settings


def get_ai_adapter(settings_instance=None) -> AIAdapterInterface:
    """
    Factory function to get the appropriate AI adapter based on settings.

    Args:
        settings_instance: Optional settings instance. If not provided, uses the global settings.

    Returns:
        An instance of a class implementing AIAdapterInterface

    Raises:
        ImportError: If the required AI service library is not installed
        ValueError: If the configuration is invalid or missing
    """
    settings_obj = settings_instance or settings

    # Determine which AI provider to use based on available API keys
    # If multiple API keys are available, prioritize in this order:
    # 1. Gemini (default)
    # 2. OpenAI
    # 3. Fall back to default (Gemini)

    if settings_obj.GEMINI_API_KEY:
        return GeminiAdapter(settings_obj)

    # Future implementations can add more AI adapters here
    # elif settings_obj.OPENAI_API_KEY:
    #     return OpenAIAdapter(settings_obj)

    # Default to Gemini (will raise an error if no API key is set)
    return GeminiAdapter(settings_obj)
</file>

<file path="apps/core/lib/ai/base_adapter.py">
"""
Base adapter interface for AI service integrations.

This module defines the abstract base class that all AI service adapters must implement.
"""

from abc import ABC, abstractmethod
from typing import Any, Dict, List, Optional, Union


class AIAdapterInterface(ABC):
    """
    Abstract base class defining the interface for AI service adapters.

    All AI service implementations (e.g., Gemini, OpenAI) must inherit from this
    class and implement its methods to provide a consistent interface for the application.
    """

    @abstractmethod
    async def generate_text(self, prompt: str, context: Optional[str] = None) -> str:
        """Generate text based on a prompt and optional context."""
        pass

    @abstractmethod
    async def transcribe_audio(self, audio_file_path: str) -> str:
        """Transcribe speech from an audio file to text."""
        pass

    @abstractmethod
    async def analyze_content(self, content: str) -> Dict[str, Any]:
        """Analyze content to extract meaningful information."""
        pass

    @abstractmethod
    async def segment_transcript(
        self, transcript: str
    ) -> List[Dict[str, Union[str, float]]]:
        """Segment a transcript into meaningful chunks with timestamps."""
        pass

    @abstractmethod
    async def summarize_text(self, text: str, max_length: Optional[int] = None) -> str:
        """Generate a concise summary of the provided text."""
        pass

    # --- Additional methods required by MetadataService ---

    def generate_metadata(self, transcript: str) -> Dict[str, Any]:
        """
        Generate all metadata components from a transcript.
        Should return a dict with keys: title, description, tags, show_notes, chapters.
        """
        raise NotImplementedError

    def summarize_content(self, transcript: str, max_length: int = 500) -> str:
        """
        Summarize transcript content to a description.
        """
        raise NotImplementedError

    def generate_thumbnail_description(
        self, transcript: str, timestamp: float = 30.0
    ) -> str:
        """
        Generate a description for a thumbnail at a specific timestamp.
        """
        raise NotImplementedError

    def _generate_title_tags(self, transcript: str) -> Dict[str, str]:
        """
        Generate title and tags as a dictionary from transcript.
        Should return a dict with keys: Description, Keywords.
        """
        raise NotImplementedError
</file>

<file path="apps/core/lib/ai/gemini_adapter.py">
"""
Gemini AI service adapter implementation.

This module implements the AIAdapterInterface for Google's Gemini AI models.
"""

import asyncio
import json
import os
from concurrent.futures import ThreadPoolExecutor
from pathlib import Path
from typing import Any, Dict, List, Optional, Union

# Import Google's Generative AI library with error handling
try:
    import google.generativeai as genai
    from google.generativeai.types import content_types

    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False

from lib.ai.base_adapter import AIAdapterInterface

from core.config import settings


class GeminiAdapter(AIAdapterInterface):
    """
    Adapter for Google's Gemini AI models.
    """

    def __init__(self, settings_instance=None):
        """
        Initialize the Gemini adapter with API key from settings.

        Args:
            settings_instance: Optional settings instance. If not provided, uses the global settings.
        """
        self.settings = settings_instance or settings

        if not GEMINI_AVAILABLE:
            raise ImportError(
                "Google Generative AI library is not installed. "
                "Please install with: pip install google-generativeai"
            )

        if not self.settings.GEMINI_API_KEY:
            raise ValueError(
                "GEMINI_API_KEY must be set in settings to use GeminiAdapter"
            )

        # Configure the Gemini API
        genai.configure(api_key=self.settings.GEMINI_API_KEY)

        # Set up the default model
        self.text_model = genai.GenerativeModel("gemini-pro")
        self.vision_model = genai.GenerativeModel("gemini-pro-vision")

    async def generate_text(self, prompt: str, context: Optional[str] = None) -> str:
        """
        Generate text based on a prompt and optional context using Gemini.

        Args:
            prompt: The text prompt to generate content from
            context: Optional context to provide additional information to the AI

        Returns:
            The generated text as a string

        Raises:
            AINoResponseError: If Gemini fails to generate a response
        """
        try:
            # Combine prompt and context if context is provided
            full_prompt = f"{context}\n\n{prompt}" if context else prompt

            # Run in a thread pool to avoid blocking the event loop
            loop = asyncio.get_event_loop()
            with ThreadPoolExecutor() as pool:
                response = await loop.run_in_executor(
                    pool, lambda: self.text_model.generate_content(full_prompt)
                )

            # Check response validity
            if not response or not hasattr(response, "text"):
                raise AINoResponseError("Gemini failed to generate a response")

            return response.text

        except Exception as e:
            # Re-raise as AINoResponseError for consistent error handling
            raise AINoResponseError(
                f"Error generating text with Gemini: {str(e)}"
            ) from e

    async def transcribe_audio(self, audio_file_path: str) -> str:
        """
        Transcribe speech from an audio file to text.

        Note: As of current implementation, Gemini does not directly support audio transcription.
        This method relies on a custom implementation or may use other Google services.

        Args:
            audio_file_path: Path to the audio file to transcribe

        Returns:
            The transcribed text as a string

        Raises:
            AINoResponseError: If transcription fails
            FileNotFoundError: If the audio file does not exist
        """
        # Check if file exists
        if not os.path.exists(audio_file_path):
            raise FileNotFoundError(f"Audio file not found: {audio_file_path}")

        # Note: This is a placeholder implementation.
        # In a real implementation, this would typically use:
        # 1. Google Speech-to-Text API
        # 2. Google Cloud Speech API
        # 3. A separate transcription service

        try:
            # Placeholder for actual transcription implementation
            # In a real implementation, would call the appropriate API
            raise NotImplementedError(
                "Direct audio transcription is not supported by Gemini. "
                "Consider using Google Speech-to-Text API instead."
            )

        except Exception as e:
            raise AINoResponseError(f"Error transcribing audio: {str(e)}") from e

    async def analyze_content(self, content: str) -> Dict[str, Any]:
        """
        Analyze content to extract meaningful information using Gemini.

        Args:
            content: The text content to analyze

        Returns:
            A dictionary containing analysis results

        Raises:
            AINoResponseError: If Gemini fails to analyze the content
        """
        try:
            # Create a structured prompt for content analysis
            analysis_prompt = """
            Analyze the following content and extract meaningful information.
            Return your analysis as a valid JSON object with the following structure:
            {
                "title": "A concise, attention-grabbing title",
                "description": "A clear description summarizing the main points (150-200 words)",
                "tags": ["relevant", "tags", "for", "categorization"],
                "key_points": ["Main point 1", "Main point 2", "Main point 3"],
                "sentiment": "positive/negative/neutral"
            }
            
            Only provide the JSON object without any additional text or explanation.
            
            Content to analyze:
            
            """

            full_prompt = f"{analysis_prompt}\n{content}"

            # Run in a thread pool to avoid blocking the event loop
            loop = asyncio.get_event_loop()
            with ThreadPoolExecutor() as pool:
                response = await loop.run_in_executor(
                    pool, lambda: self.text_model.generate_content(full_prompt)
                )

            # Parse the JSON response
            result = json.loads(response.text)

            # Validate essential fields
            required_fields = ["title", "description", "tags", "key_points"]
            for field in required_fields:
                if field not in result:
                    result[field] = None

            return result

        except json.JSONDecodeError as e:
            raise AINoResponseError(f"Gemini returned malformed JSON: {str(e)}") from e
        except Exception as e:
            raise AINoResponseError(
                f"Error analyzing content with Gemini: {str(e)}"
            ) from e

    async def segment_transcript(
        self, transcript: str
    ) -> List[Dict[str, Union[str, float]]]:
        """
        Segment a transcript into meaningful chunks with timestamps.

        Args:
            transcript: The transcript text to segment

        Returns:
            A list of segment dictionaries

        Raises:
            AINoResponseError: If Gemini fails to segment the transcript
        """
        try:
            # Create a structured prompt for transcript segmentation
            segmentation_prompt = """
            Segment the following transcript into meaningful chunks with estimated timestamps.
            Return your segmentation as a valid JSON array with the following structure:
            [
                {
                    "text": "Segment text",
                    "start_time": 0.0,
                    "end_time": 10.5
                },
                {
                    "text": "Next segment text",
                    "start_time": 10.5,
                    "end_time": 20.0
                }
            ]
            
            Only provide the JSON array without any additional text or explanation.
            Assume the transcript starts at 0.0 seconds.
            Estimate reasonable timestamps based on the length of text.
            
            Transcript to segment:
            
            """

            full_prompt = f"{segmentation_prompt}\n{transcript}"

            # Run in a thread pool to avoid blocking the event loop
            loop = asyncio.get_event_loop()
            with ThreadPoolExecutor() as pool:
                response = await loop.run_in_executor(
                    pool, lambda: self.text_model.generate_content(full_prompt)
                )

            # Parse the JSON response
            segments = json.loads(response.text)

            # Validate segment structure
            for segment in segments:
                if not all(
                    key in segment for key in ["text", "start_time", "end_time"]
                ):
                    raise ValueError("Segment is missing required fields")

            return segments

        except json.JSONDecodeError as e:
            raise AINoResponseError(f"Gemini returned malformed JSON: {str(e)}") from e
        except Exception as e:
            raise AINoResponseError(
                f"Error segmenting transcript with Gemini: {str(e)}"
            ) from e

    async def summarize_text(self, text: str, max_length: Optional[int] = None) -> str:
        """
        Generate a concise summary of the provided text using Gemini.

        Args:
            text: The text to summarize
            max_length: Optional maximum length of the summary in characters

        Returns:
            The summarized text as a string

        Raises:
            AINoResponseError: If Gemini fails to summarize the text
        """
        try:
            # Create a structured prompt for summarization
            summary_prompt = "Summarize the following text in a concise manner"

            if max_length:
                summary_prompt += f" in {max_length} characters or less"

            full_prompt = f"{summary_prompt}:\n\n{text}"

            # Run in a thread pool to avoid blocking the event loop
            loop = asyncio.get_event_loop()
            with ThreadPoolExecutor() as pool:
                response = await loop.run_in_executor(
                    pool, lambda: self.text_model.generate_content(full_prompt)
                )

            # Check response validity
            if not response or not hasattr(response, "text"):
                raise AINoResponseError("Gemini failed to generate a summary")

            summary = response.text

            # Trim if necessary
            if max_length and len(summary) > max_length:
                summary = summary[:max_length]

            return summary

        except Exception as e:
            raise AINoResponseError(
                f"Error summarizing text with Gemini: {str(e)}"
            ) from e


# Custom exception for AI services
class AINoResponseError(Exception):
    """Exception raised when an AI service fails to generate a response."""

    pass
</file>

<file path="apps/core/lib/auth/supabase_auth.py">
"""
supabase_auth.py: Supabase authentication utilities for Echo backend.

- Provides AuthenticatedUser Pydantic model.
- Provides get_current_user FastAPI dependency for JWT validation.
- Designed for use in the infrastructure/lib layer.

Directory: apps/core/lib/auth/supabase_auth.py
Layer: Infrastructure/Lib
"""

from typing import Optional

from fastapi import Depends, HTTPException, status
from fastapi.security import OAuth2PasswordBearer
from jose import JWTError, jwt
from pydantic import BaseModel

from apps.core.core.config import settings

oauth2_scheme = OAuth2PasswordBearer(tokenUrl="token")


class AuthenticatedUser(BaseModel):
    id: str
    email: Optional[str] = None
    aud: Optional[str] = None


async def get_current_user(token: str = Depends(oauth2_scheme)) -> AuthenticatedUser:
    """
    FastAPI dependency to extract and validate the current user from a Supabase JWT.

    Args:
        token (str): JWT token from the Authorization header.

    Returns:
        AuthenticatedUser: The authenticated user.

    Raises:
        HTTPException: If the token is invalid or missing required claims.
    """
    credentials_exception = HTTPException(
        status_code=status.HTTP_401_UNAUTHORIZED,
        detail="Could not validate Supabase credentials",
        headers={"WWW-Authenticate": "Bearer"},
    )
    try:
        payload = jwt.decode(
            token,
            settings.SUPABASE_JWT_SECRET,
            algorithms=[settings.ALGORITHM],
            audience="authenticated",
        )
        user_id = payload.get("sub")
        email: Optional[str] = payload.get("email")
        aud: Optional[str] = payload.get("aud")
        if user_id is None:
            raise credentials_exception
        return AuthenticatedUser(id=str(user_id), email=email, aud=aud)
    except JWTError:
        raise credentials_exception
</file>

<file path="apps/core/lib/cache/__init__.py">
from lib.cache.redis import RedisClient, get_redis_client

__all__ = ["RedisClient", "get_redis_client"]
</file>

<file path="apps/core/lib/cache/redis_cache.py">
"""
RedisCache: Async Redis cache utility for Echo backend.

- Uses redis-py (asyncio) for non-blocking cache operations.
- Connects using settings from the central Settings object.
- Provides async get/set methods with TTL support.
- Designed for dependency injection and stateless usage.

Directory: apps/core/lib/cache/redis_cache.py
Layer: Infrastructure/Lib
"""

from typing import Any, Optional

import redis.asyncio as aioredis

from apps.core.core.config import settings


class RedisCache:
    """
    Async Redis cache utility for storing and retrieving values with TTL.
    """

    def __init__(self):
        self._client = aioredis.Redis(
            host=settings.REDIS_HOST,
            port=settings.REDIS_PORT,
            db=getattr(settings, "REDIS_DB", 0),
            password=getattr(settings, "REDIS_PASSWORD", None),
            decode_responses=True,
        )

    async def get(self, key: str) -> Optional[str]:
        """
        Retrieve a value from Redis by key.

        Args:
            key (str): The cache key.

        Returns:
            Optional[str]: The cached value, or None if not found.
        """
        return await self._client.get(key)

    async def set(self, key: str, value: Any, ttl_seconds: int = 3600) -> None:
        """
        Set a value in Redis with an optional TTL.

        Args:
            key (str): The cache key.
            value (Any): The value to cache (will be stringified).
            ttl_seconds (int): Time-to-live in seconds (default: 1 hour).
        """
        await self._client.set(key, str(value), ex=ttl_seconds)

    async def close(self):
        """
        Close the Redis connection.
        """
        await self._client.close()
</file>

<file path="apps/core/lib/cache/redis.py">
import json
from typing import Any, Optional, cast

import redis

from core.config import settings


class RedisClient:
    def __init__(self):
        self.redis_client = redis.Redis(
            host=settings.REDIS_HOST,
            port=settings.REDIS_PORT,
            db=settings.REDIS_DB,
            password=settings.REDIS_PASSWORD,
            decode_responses=True,
        )

    def get(self, key: str) -> Optional[Any]:
        """Get a value from Redis"""
        value = self.redis_client.get(key)
        if value:
            try:
                return json.loads(cast(str, value))
            except json.JSONDecodeError:
                return value
        return None

    def set(self, key: str, value: Any, expiry: Optional[int] = None) -> bool:
        """Set a value in Redis with optional expiry in seconds"""
        if not isinstance(value, str):
            value = json.dumps(value)

        if expiry:
            return bool(self.redis_client.setex(key, expiry, value))
        return bool(self.redis_client.set(key, value))

    def delete(self, key: str) -> bool:
        """Delete a key from Redis"""
        return bool(self.redis_client.delete(key))

    def exists(self, key: str) -> bool:
        """Check if a key exists in Redis"""
        return bool(self.redis_client.exists(key))

    def hash_get(self, hash_key: str, field: str) -> Optional[Any]:
        """Get a field from a hash in Redis"""
        value = self.redis_client.hget(hash_key, field)
        if value:
            try:
                return json.loads(cast(str, value))
            except json.JSONDecodeError:
                return value
        return None

    def hash_set(self, hash_key: str, field: str, value: Any) -> bool:
        """Set a field in a hash in Redis"""
        if not isinstance(value, str):
            value = json.dumps(value)
        return bool(self.redis_client.hset(hash_key, field, value))

    def flush(self) -> bool:
        """Clear the entire Redis database"""
        return bool(self.redis_client.flushdb())


# Singleton instance
_redis_client = None


def get_redis_client() -> RedisClient:
    """Dependency to get Redis client instance"""
    global _redis_client
    if _redis_client is None:
        _redis_client = RedisClient()
    return _redis_client
</file>

<file path="apps/core/lib/database/__init__.py">
from lib.database.connection import (
    Base,
    SessionLocal,
    create_session,
    engine,
    get_db_session,
)

__all__ = [
    "engine",
    "Base",
    "SessionLocal",
    "get_db_session",
    "create_session",
]
</file>

<file path="apps/core/lib/database/connection.py">
from typing import AsyncGenerator, Generator

from sqlalchemy import create_engine
from sqlalchemy.ext.asyncio import AsyncSession, async_sessionmaker, create_async_engine
from sqlalchemy.orm import Session, declarative_base, sessionmaker

from core.config import settings

# Create SQLAlchemy engine
# Add connect_args for SQLite compatibility
connect_args = {}
if settings.DATABASE_URL.startswith("sqlite"):
    connect_args = {"check_same_thread": False}

engine = create_engine(settings.DATABASE_URL, connect_args=connect_args)


# Async SQLAlchemy engine
async_db_url = settings.DATABASE_URL
if settings.DATABASE_URL.startswith("postgresql://"):
    async_db_url = settings.DATABASE_URL.replace(
        "postgresql://", "postgresql+asyncpg://"
    )
elif settings.DATABASE_URL.startswith(
    "sqlite:///"
):  # Assuming 'sqlite:////path/to/db.sqlite'
    async_db_url = settings.DATABASE_URL.replace("sqlite:///", "sqlite+aiosqlite:///")
elif settings.DATABASE_URL.startswith(
    "sqlite://"
):  # Assuming relative path 'sqlite://./db.sqlite'
    async_db_url = settings.DATABASE_URL.replace("sqlite://", "sqlite+aiosqlite://")


async_engine = create_async_engine(async_db_url)

# SessionLocal class
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# Async SessionLocal class
AsyncSessionLocal = async_sessionmaker(
    bind=async_engine,
    class_=AsyncSession,
    expire_on_commit=False,
    autocommit=False,  # Explicitly set for clarity, though default for AsyncSession
    autoflush=False,  # Explicitly set for clarity, though default for AsyncSession
)

# Base class for models
Base = declarative_base()


def get_db_session() -> Generator[Session, None, None]:
    """
    Dependency function to get DB session
    Usage: db: Session = Depends(get_db_session)
    """
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()


async def get_async_db_session() -> AsyncGenerator[AsyncSession, None]:
    """
    Dependency function to get an async DB session.
    Usage: db: AsyncSession = Depends(get_async_db_session)
    """
    # The type checker might complain here, but this is the standard way
    # to create an async session with SQLAlchemy.
    async_session_local_instance = AsyncSessionLocal()

    async with async_session_local_instance as session:
        try:
            yield session
        except Exception:
            await session.rollback()
            raise
        finally:
            # Closing the session is handled by the async context manager
            pass


def create_session() -> Session:
    """Create and return a new session"""
    return SessionLocal()


# It's good practice to also have an async version if needed outside FastAPI Depends
async def create_async_session() -> AsyncSession:
    """Create and return a new async session"""
    # The type checker might complain here as well.
    return AsyncSessionLocal()
</file>

<file path="apps/core/lib/messaging/__init__.py">
from lib.messaging.email import EmailService, get_email_service

__all__ = ["EmailService", "get_email_service"]
</file>

<file path="apps/core/lib/messaging/email.py">
import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from pathlib import Path
from typing import Any, Dict, List, Optional

import jinja2

from core.config import settings


class EmailService:
    def __init__(self):
        self.server = settings.SMTP_SERVER
        self.port = settings.SMTP_PORT
        self.username = settings.SMTP_USERNAME
        self.password = settings.SMTP_PASSWORD
        self.from_email = settings.EMAIL_FROM_ADDRESS

        # Template environment
        template_dir = Path(settings.EMAIL_TEMPLATES_DIR)
        self.template_env = jinja2.Environment(
            loader=jinja2.FileSystemLoader(template_dir),
            autoescape=jinja2.select_autoescape(["html", "xml"]),
        )

    def _get_connection(self):
        """Get SMTP connection"""
        connection = smtplib.SMTP(self.server, self.port)
        connection.starttls()
        if self.username and self.password:
            connection.login(self.username, self.password)
        return connection

    def send_email(
        self,
        to_email: List[str],
        subject: str,
        body: str,
        cc: Optional[List[str]] = None,
        bcc: Optional[List[str]] = None,
        is_html: bool = False,
    ) -> bool:
        """Send a simple email"""
        if not to_email:
            return False

        msg = MIMEMultipart()
        msg["From"] = self.from_email
        msg["To"] = ", ".join(to_email)
        msg["Subject"] = subject

        if cc:
            msg["Cc"] = ", ".join(cc)
        if bcc:
            msg["Bcc"] = ", ".join(bcc)

        msg.attach(MIMEText(body, "html" if is_html else "plain"))

        try:
            with self._get_connection() as server:
                all_recipients = to_email + (cc or []) + (bcc or [])
                server.send_message(msg, self.from_email, all_recipients)
            return True
        except Exception as e:
            print(f"Failed to send email: {e}")
            return False

    def send_template_email(
        self,
        to_email: List[str],
        subject: str,
        template_name: str,
        template_vars: Dict[str, Any],
        cc: Optional[List[str]] = None,
        bcc: Optional[List[str]] = None,
    ) -> bool:
        """Send an email using a template"""
        try:
            template = self.template_env.get_template(template_name)
            html_content = template.render(**template_vars)
            return self.send_email(
                to_email, subject, html_content, cc, bcc, is_html=True
            )
        except Exception as e:
            print(f"Failed to render or send template email: {e}")
            return False


# Singleton instance
_email_service = None


def get_email_service() -> EmailService:
    """Dependency to get Email service instance"""
    global _email_service
    if _email_service is None:
        _email_service = EmailService()
    return _email_service
</file>

<file path="apps/core/lib/publishing/publishing_interface.py">
"""
Publishing interface for modular video processing backend.

Defines the contract for publishing operations independent of any specific
platform implementation (YouTube, Vimeo, etc.).
"""

from abc import ABC, abstractmethod
from typing import Dict, Optional


class PublishingInterface(ABC):
    """
    Interface for video publishing operations.

    This interface defines the contract for all publishing adapter implementations,
    ensuring they provide the necessary methods for publishing videos to platforms.
    """

    @abstractmethod
    def upload_video(self, video_file: str, metadata: Dict) -> str:
        """
        Upload a video to the publishing platform.

        Args:
            video_file: Path to the video file
            metadata: Dictionary containing video metadata:
                      {
                          "title": str,
                          "description": str,
                          "tags": List[str],
                          "category_id": str,
                          ...
                      }

        Returns:
            The video ID on the platform

        Raises:
            PublishingError: If the upload fails
        """
        pass

    @abstractmethod
    def update_metadata(self, video_id: str, metadata: Dict) -> bool:
        """
        Update metadata for a video on the publishing platform.

        Args:
            video_id: ID of the video on the platform
            metadata: Dictionary containing video metadata to update

        Returns:
            True if the update succeeded, False otherwise

        Raises:
            PublishingError: If the update fails
        """
        pass

    @abstractmethod
    def get_upload_status(self, video_id: str) -> str:
        """
        Get the status of a video upload.

        Args:
            video_id: ID of the video on the platform

        Returns:
            Status of the upload (e.g., "uploading", "processing", "ready", "failed")

        Raises:
            PublishingError: If the status check fails
        """
        pass

    @abstractmethod
    def delete_video(self, video_id: str) -> bool:
        """
        Delete a video from the publishing platform.

        Args:
            video_id: ID of the video on the platform

        Returns:
            True if the deletion succeeded, False otherwise

        Raises:
            PublishingError: If the deletion fails
        """
        pass

    @abstractmethod
    def get_video_url(self, video_id: str) -> str:
        """
        Get the public URL for a video on the publishing platform.

        Args:
            video_id: ID of the video on the platform

        Returns:
            Public URL for the video

        Raises:
            PublishingError: If the URL retrieval fails
        """
        pass

    @abstractmethod
    def upload_caption(
        self, video_id: str, caption_file: str, language: str = "en"
    ) -> bool:
        """
        Upload a caption file for a video on the publishing platform.

        Args:
            video_id: ID of the video on the platform
            caption_file: Path to the caption file (VTT, SRT, etc.)
            language: Language code for the captions

        Returns:
            True if the upload succeeded, False otherwise

        Raises:
            PublishingError: If the caption upload fails
        """
        pass

    @abstractmethod
    def set_publishing_time(
        self, video_id: str, publish_at: Optional[str] = None
    ) -> bool:
        """
        Set the publishing time for a video on the platform.

        Args:
            video_id: ID of the video on the platform
            publish_at: ISO 8601 format datetime string when the video should be published,
                        or None to publish immediately

        Returns:
            True if the publishing time was set successfully, False otherwise

        Raises:
            PublishingError: If setting the publishing time fails
        """
        pass
</file>

<file path="apps/core/lib/publishing/youtube_adapter.py">
"""
YouTubeAdapter: Modular publishing adapter for YouTube integration.

Implements the publishing interface for uploading, updating, and managing videos on YouTube.
Ported from legacy video_processor/adapters/publishing/youtube.py.
"""

import http.client
import json
import logging
import os
import time
from typing import Any, Dict, List, Optional

# Google API client imports
import google.oauth2.credentials
import httplib2
from core.exceptions import PublishingError
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from googleapiclient.http import MediaFileUpload

from apps.core.lib.publishing.publishing_interface import PublishingInterface

logger = logging.getLogger(__name__)

YOUTUBE_API_SERVICE_NAME = "youtube"
YOUTUBE_API_VERSION = "v3"
RETRIABLE_EXCEPTIONS = (
    httplib2.HttpLib2Error,
    IOError,
    http.client.NotConnected,
    http.client.IncompleteRead,
    http.client.ImproperConnectionState,
    http.client.CannotSendRequest,
    http.client.CannotSendHeader,
    http.client.ResponseNotReady,
    http.client.BadStatusLine,
)
RETRIABLE_STATUS_CODES = [500, 502, 503, 504]
MAX_RETRIES = 10


class YouTubeAdapter(PublishingInterface):
    """
    YouTube adapter for publishing videos and managing metadata.
    """

    def __init__(
        self,
        client_secrets_file: str,
        oauth_token_file: str,
        scopes: Optional[List[str]] = None,
        api_service_name: str = "youtube",
        api_version: str = "v3",
    ):
        """
        Initialize the YouTube adapter.

        Args:
            client_secrets_file: Path to the client secrets file
            oauth_token_file: Path to the OAuth token file
            scopes: List of OAuth scopes (default: upload and read)
            api_service_name: YouTube API service name
            api_version: YouTube API version
        """
        self._client_secrets_file = client_secrets_file
        self._oauth_token_file = oauth_token_file
        self._scopes = scopes or [
            "https://www.googleapis.com/auth/youtube.upload",
            "https://www.googleapis.com/auth/youtube.force-ssl",
        ]
        self._api_service_name = api_service_name
        self._api_version = api_version
        self._youtube = None  # Will be set by tests or real API client in production
        self._initialize_youtube_client()

    def upload_video(self, video_file: str, metadata: Dict[str, Any]) -> str:
        """
        Upload a video to YouTube with metadata.
        """
        if not self._youtube:
            self._initialize_youtube_client()

        if not video_file or not os.path.isfile(video_file):
            raise PublishingError(f"Video file does not exist: {video_file}")

        try:
            body = {
                "snippet": {
                    "title": metadata.get("title", "Untitled Video"),
                    "description": metadata.get("description", ""),
                    "tags": metadata.get("tags", []),
                    "categoryId": metadata.get("category_id", "22"),
                },
                "status": {
                    "privacyStatus": metadata.get("privacy_status", "private"),
                    "selfDeclaredMadeForKids": metadata.get("made_for_kids", False),
                },
            }

            media = MediaFileUpload(
                video_file,
                mimetype="video/*",
                resumable=True,
                chunksize=1024 * 1024 * 5,
            )

            insert_request = self._youtube.videos().insert(
                part=",".join(body.keys()), body=body, media_body=media
            )

            video_id = self._execute_upload_with_retries(insert_request)
            logger.info(f"Video uploaded successfully with ID: {video_id}")
            return video_id

        except HttpError as e:
            error_content = json.loads(e.content.decode("utf-8"))
            error_message = error_content.get("error", {}).get("message", str(e))
            logger.error(f"HTTP error during upload: {error_message}")
            raise PublishingError(f"YouTube upload failed: {error_message}")

        except Exception as e:
            logger.error(f"Failed to upload video: {str(e)}")
            raise PublishingError(f"YouTube upload failed: {str(e)}")

    def _initialize_youtube_client(self) -> None:
        """
        Initialize the YouTube API client.
        """
        try:
            if not os.path.exists(self._oauth_token_file):
                raise PublishingError(
                    f"OAuth token file not found: {self._oauth_token_file}. "
                    "Please run the authentication flow first."
                )

            with open(self._oauth_token_file, "r") as token_file:
                token_data = json.load(token_file)

            credentials = google.oauth2.credentials.Credentials(
                token=token_data.get("token"),
                refresh_token=token_data.get("refresh_token"),
                token_uri=token_data.get(
                    "token_uri", "https://oauth2.googleapis.com/token"
                ),
                client_id=token_data.get("client_id"),
                client_secret=token_data.get("client_secret"),
                scopes=self._scopes,
            )

            self._youtube = build(
                self._api_service_name,
                self._api_version,
                credentials=credentials,
                cache_discovery=False,
            )

            logger.info("YouTube API client initialized successfully")

        except Exception as e:
            logger.error(f"Failed to initialize YouTube API client: {str(e)}")
            raise PublishingError(f"Failed to initialize YouTube API client: {str(e)}")

    def _execute_upload_with_retries(self, request):
        """
        Execute an upload request with retries for transient errors.
        """
        response = None
        error = None
        retry = 0
        video_id = None

        while response is None:
            try:
                logger.info(f"Uploading video (attempt {retry + 1}/{MAX_RETRIES})")
                status, response = request.next_chunk()

                if response is not None:
                    if "id" in response:
                        video_id = response["id"]
                        return video_id
                    else:
                        raise PublishingError(
                            f"YouTube upload failed, no video ID in response: {response}"
                        )

                if status:
                    progress = int(status.progress() * 100)
                    logger.info(f"Upload progress: {progress}%")

            except HttpError as e:
                if e.resp.status in RETRIABLE_STATUS_CODES:
                    error = (
                        f"A retriable HTTP error {e.resp.status} occurred: {e.content}"
                    )
                else:
                    raise

            except RETRIABLE_EXCEPTIONS as e:
                error = f"A retriable error occurred: {e}"

            if error is not None:
                logger.warning(error)
                retry += 1

                if retry > MAX_RETRIES:
                    logger.error("Maximum retries exceeded")
                    raise PublishingError(
                        f"YouTube upload failed after {MAX_RETRIES} retries: {error}"
                    )

                max_sleep = 2**retry
                sleep_seconds = min(max_sleep, 60)
                logger.info(f"Sleeping {sleep_seconds} seconds before retrying...")
                time.sleep(sleep_seconds)

    def update_metadata(self, video_id: str, metadata: Dict[str, Any]) -> bool:
        """
        Update metadata for an existing YouTube video.
        """
        if not self._youtube:
            self._initialize_youtube_client()

        try:
            video_response = (
                self._youtube.videos()
                .list(part="snippet,status", id=video_id)
                .execute()
            )

            if not video_response.get("items"):
                raise PublishingError(f"Video with ID {video_id} not found")

            video_item = video_response["items"][0]
            snippet = video_item["snippet"]
            status = video_item["status"]

            # Update snippet fields if provided
            if "title" in metadata:
                snippet["title"] = metadata["title"]

            if "description" in metadata:
                snippet["description"] = metadata["description"]

            if "tags" in metadata:
                snippet["tags"] = metadata["tags"]

            if "category_id" in metadata:
                snippet["categoryId"] = metadata["category_id"]

            # Update status fields if provided
            if "privacy_status" in metadata:
                status["privacyStatus"] = metadata["privacy_status"]

            if "made_for_kids" in metadata:
                status["selfDeclaredMadeForKids"] = metadata["made_for_kids"]

            update_request = self._youtube.videos().update(
                part="snippet,status",
                body={"id": video_id, "snippet": snippet, "status": status},
            )

            update_response = update_request.execute()

            logger.info(f"Video metadata updated successfully for ID: {video_id}")
            return True

        except HttpError as e:
            error_content = json.loads(e.content.decode("utf-8"))
            error_message = error_content.get("error", {}).get("message", str(e))
            logger.error(f"HTTP error during metadata update: {error_message}")
            raise PublishingError(f"YouTube metadata update failed: {error_message}")

        except Exception as e:
            logger.error(f"Failed to update video metadata: {str(e)}")
            raise PublishingError(f"YouTube metadata update failed: {str(e)}")

    def get_upload_status(self, video_id: str) -> str:
        """
        Get the upload/processing status of a YouTube video.
        """
        if not self._youtube:
            self._initialize_youtube_client()

        try:
            processing_response = (
                self._youtube.videos()
                .list(part="processingDetails,status", id=video_id)
                .execute()
            )

            if not processing_response.get("items"):
                raise PublishingError(f"Video with ID {video_id} not found")

            video_item = processing_response["items"][0]
            processing_details = video_item.get("processingDetails", {})
            status = video_item.get("status", {})

            # Check if video is being processed
            if processing_details.get("processingStatus") == "processing":
                return "processing"

            # Check if video processing failed
            if processing_details.get("processingStatus") == "failed":
                return "failed"

            # Check upload status
            upload_status = status.get("uploadStatus")
            if upload_status == "uploaded" or upload_status == "processed":
                return "ready"
            elif upload_status == "failed":
                return "failed"

            # If we can't determine status, return the raw processing status
            return processing_details.get("processingStatus", "unknown")

        except HttpError as e:
            error_content = json.loads(e.content.decode("utf-8"))
            error_message = error_content.get("error", {}).get("message", str(e))
            logger.error(f"HTTP error during status check: {error_message}")
            raise PublishingError(f"YouTube status check failed: {error_message}")

        except Exception as e:
            logger.error(f"Failed to get video status: {str(e)}")
            raise PublishingError(f"YouTube status check failed: {str(e)}")

    def delete_video(self, video_id: str) -> bool:
        """
        Delete a YouTube video.
        """
        if not self._youtube:
            self._initialize_youtube_client()

        try:
            self._youtube.videos().delete(id=video_id).execute()
            logger.info(f"Video with ID {video_id} deleted successfully")
            return True

        except HttpError as e:
            if e.resp.status == 404:
                logger.warning(
                    f"Video with ID {video_id} not found, considering deletion successful"
                )
                return True

            error_content = json.loads(e.content.decode("utf-8"))
            error_message = error_content.get("error", {}).get("message", str(e))
            logger.error(f"HTTP error during video deletion: {error_message}")
            raise PublishingError(f"YouTube video deletion failed: {error_message}")

        except Exception as e:
            logger.error(f"Failed to delete video: {str(e)}")
            raise PublishingError(f"YouTube video deletion failed: {str(e)}")

    def get_video_url(self, video_id: str) -> str:
        """
        Get the public URL for a video on the publishing platform.
        """
        if not video_id:
            raise PublishingError("Invalid video_id for YouTube URL.")
        return f"https://www.youtube.com/watch?v={video_id}"

    def upload_caption(
        self, video_id: str, caption_file: str, language: str = "en"
    ) -> bool:
        """
        Upload a caption file for a video on the publishing platform.
        """
        if not self._youtube:
            self._initialize_youtube_client()

        if not os.path.exists(caption_file):
            raise PublishingError(f"Caption file not found: {caption_file}")

        try:
            name, extension = os.path.splitext(caption_file)
            extension = extension.lower().strip(".")

            format_mapping = {
                "srt": "srt",
                "vtt": "webvtt",
                "sbv": "sbv",
                "sub": "sub",
                "ttml": "ttml",
            }

            if extension not in format_mapping:
                raise PublishingError(
                    f"Unsupported caption format: {extension}. "
                    f"Supported formats: {', '.join(format_mapping.keys())}"
                )

            caption_format = format_mapping[extension]

            caption_insert = self._youtube.captions().insert(
                part="snippet",
                body={
                    "snippet": {
                        "videoId": video_id,
                        "language": language,
                        "name": f"{language.upper()} - {os.path.basename(name)}",
                    }
                },
                media_body=MediaFileUpload(
                    caption_file, mimetype=f"text/{extension}", resumable=True
                ),
            )

            caption_response = caption_insert.execute()
            logger.info(
                f"Caption uploaded successfully for video ID {video_id} in language {language}"
            )
            return True

        except HttpError as e:
            error_content = json.loads(e.content.decode("utf-8"))
            error_message = error_content.get("error", {}).get("message", str(e))
            logger.error(f"HTTP error during caption upload: {error_message}")
            raise PublishingError(f"YouTube caption upload failed: {error_message}")

        except Exception as e:
            logger.error(f"Failed to upload caption: {str(e)}")
            raise PublishingError(f"YouTube caption upload failed: {str(e)}")

    def set_publishing_time(
        self, video_id: str, publish_at: Optional[str] = None
    ) -> bool:
        """
        Set the publishing time for a video on the platform.
        """
        if not self._youtube:
            self._initialize_youtube_client()

        try:
            video_response = (
                self._youtube.videos().list(part="status", id=video_id).execute()
            )

            if not video_response.get("items"):
                raise PublishingError(f"Video with ID {video_id} not found")

            video_item = video_response["items"][0]
            status = video_item["status"]

            if publish_at is None:
                if "publishAt" in status:
                    del status["publishAt"]
                status["privacyStatus"] = "public"
            else:
                status["privacyStatus"] = "private"
                status["publishAt"] = publish_at

            update_request = self._youtube.videos().update(
                part="status", body={"id": video_id, "status": status}
            )

            update_response = update_request.execute()

            logger.info(
                f"Publishing time for video ID {video_id} set to: {publish_at or 'immediate'}"
            )
            return True

        except HttpError as e:
            error_content = json.loads(e.content.decode("utf-8"))
            error_message = error_content.get("error", {}).get("message", str(e))
            logger.error(f"HTTP error during publishing time update: {error_message}")
            raise PublishingError(
                f"YouTube publishing time update failed: {error_message}"
            )

        except Exception as e:
            logger.error(f"Failed to set publishing time: {str(e)}")
            raise PublishingError(f"YouTube publishing time update failed: {str(e)}")


# TODO: Add dependency injection registration and configuration as needed for modular backend.
</file>

<file path="apps/core/lib/storage/__init__.py">
from lib.storage.file_storage import FileStorageService, get_file_storage_service


# Temporary stub for legacy imports
class FileStorage:
    pass


# Temporary alias for legacy import
get_file_storage = get_file_storage_service

__all__ = [
    "FileStorageService",
    "get_file_storage_service",
    "FileStorage",
    "get_file_storage",
]
</file>

<file path="apps/core/lib/storage/file_storage.py">
import asyncio
import os
import shutil
import uuid
from concurrent.futures import ThreadPoolExecutor
from pathlib import Path
from typing import Any, BinaryIO, List, Optional, Tuple, Union

from fastapi import UploadFile

# Import Google Cloud Storage dependencies with error handling
# to allow the module to load even if these aren't installed
try:
    from google.cloud import storage
    from google.oauth2 import service_account

    GCS_AVAILABLE = True
except ImportError:
    GCS_AVAILABLE = False

    # Dummy classes for type hints
    class storage:
        class Client:
            pass

    class service_account:
        class Credentials:
            @staticmethod
            def from_service_account_file(path: str) -> Any:
                pass


from core.config import settings


class FileStorageService:
    """
    A service for handling file storage operations with support for both local filesystem
    and Google Cloud Storage (GCS).
    """

    def upload_from_string(
        self,
        content: str,
        storage_path: str,
        content_type: str = "application/octet-stream",
    ) -> None:
        """
        Upload a string as a file to the configured storage backend.

        Args:
            content: The string content to upload
            storage_path: The path (relative or absolute) where the file should be stored
            content_type: The MIME type of the content (default: application/octet-stream)
        """
        if self.settings.STORAGE_BACKEND == "local":
            # Save to local filesystem
            full_path = self.local_storage_path / storage_path
            os.makedirs(os.path.dirname(full_path), exist_ok=True)
            with open(full_path, "w", encoding="utf-8") as f:
                f.write(content)
        elif self.settings.STORAGE_BACKEND == "gcs":
            if self.gcs_client is None:
                raise RuntimeError("GCS client not initialized")
            bucket = self.gcs_client.bucket(self.settings.GCS_BUCKET_NAME)
            blob = bucket.blob(storage_path)
            blob.upload_from_string(content, content_type=content_type)
        else:
            raise ValueError(
                f"Unsupported storage backend: {self.settings.STORAGE_BACKEND}"
            )

    def __init__(self, settings_instance=None):
        """
        Initialize the storage service based on configuration.

        Args:
            settings_instance: An optional Settings instance. If not provided, uses the global settings.
        """
        self.settings = settings_instance or settings

        # Set up local storage configuration
        self.local_storage_path = (
            Path(self.settings.BASE_DIR) / self.settings.LOCAL_STORAGE_PATH
        )
        os.makedirs(self.local_storage_path, exist_ok=True)

        # Set up GCS client if needed
        self.gcs_client = None
        if self.settings.STORAGE_BACKEND == "gcs":
            if not GCS_AVAILABLE:
                raise ImportError(
                    "Google Cloud Storage dependencies are not installed. "
                    "Please install with: pip install google-cloud-storage"
                )

            if self.settings.GOOGLE_APPLICATION_CREDENTIALS_PATH:
                credentials = service_account.Credentials.from_service_account_file(
                    self.settings.GOOGLE_APPLICATION_CREDENTIALS_PATH
                )
                self.gcs_client = storage.Client(
                    credentials=credentials, project=credentials.project_id
                )
            else:
                # Use default credentials from environment
                self.gcs_client = storage.Client()

            # Verify bucket exists
            if not self.settings.GCS_BUCKET_NAME:
                raise ValueError(
                    "GCS_BUCKET_NAME must be set when using GCS storage backend"
                )

    async def save_file(
        self, file_content: bytes, filename: str, subdir: Optional[str] = "uploads"
    ) -> str:
        """
        Save a file to the configured storage backend.

        Args:
            file_content: The binary content of the file
            filename: The name of the file
            subdir: Optional subdirectory for organizing storage

        Returns:
            A string representing the storage path of the saved file
        """
        # Generate a unique filename to prevent collisions
        file_extension = os.path.splitext(filename)[1]
        unique_filename = f"{uuid.uuid4()}{file_extension}"

        # Define the full path including subdirectory
        relative_path = f"{subdir}/{unique_filename}" if subdir else unique_filename

        if self.settings.STORAGE_BACKEND == "local":
            # Ensure subdirectory exists
            if subdir:
                target_dir = self.local_storage_path / subdir
                os.makedirs(target_dir, exist_ok=True)

            # Save to local filesystem
            file_path = self.local_storage_path / relative_path

            # Use async to avoid blocking on file I/O
            loop = asyncio.get_event_loop()
            with ThreadPoolExecutor() as pool:
                await loop.run_in_executor(
                    pool, lambda: self._save_local_file(file_path, file_content)
                )

            return relative_path

        elif self.settings.STORAGE_BACKEND == "gcs":
            # Upload to GCS using a thread pool to avoid blocking
            loop = asyncio.get_event_loop()
            with ThreadPoolExecutor() as pool:
                await loop.run_in_executor(
                    pool, lambda: self._upload_to_gcs(relative_path, file_content)
                )

            return f"gs://{self.settings.GCS_BUCKET_NAME}/{relative_path}"

        else:
            raise ValueError(
                f"Unsupported storage backend: {self.settings.STORAGE_BACKEND}"
            )

    async def download_file(
        self, storage_path: str, destination_local_path: str
    ) -> str:
        """
        Download a file from storage to a local path.

        Args:
            storage_path: The path where the file is stored
            destination_local_path: The local path where the file should be saved

        Returns:
            The local path where the file is downloaded
        """
        # Ensure destination directory exists
        os.makedirs(os.path.dirname(destination_local_path), exist_ok=True)

        if self.settings.STORAGE_BACKEND == "local":
            # For local storage, just copy the file
            source_path = self._get_local_path(storage_path)

            loop = asyncio.get_event_loop()
            with ThreadPoolExecutor() as pool:
                await loop.run_in_executor(
                    pool, lambda: shutil.copy2(source_path, destination_local_path)
                )

        elif self.settings.STORAGE_BACKEND == "gcs":
            # Handle GCS URI format (gs://bucket-name/path/to/file)
            bucket_name: str
            blob_name: str

            if storage_path.startswith("gs://"):
                parts = self._parse_gcs_uri(storage_path)
                bucket_name, blob_name = parts
            else:
                # Assume it's just the blob name
                bucket_name = self.settings.GCS_BUCKET_NAME or ""
                blob_name = storage_path

            loop = asyncio.get_event_loop()
            with ThreadPoolExecutor() as pool:
                await loop.run_in_executor(
                    pool,
                    lambda: self._download_from_gcs(
                        bucket_name, blob_name, destination_local_path
                    ),
                )

        else:
            raise ValueError(
                f"Unsupported storage backend: {self.settings.STORAGE_BACKEND}"
            )

        return destination_local_path

    async def get_public_url(self, storage_path: str) -> Optional[str]:
        """
        Get a public URL for accessing the file.

        Args:
            storage_path: The path where the file is stored

        Returns:
            A public URL string or None if not available
        """
        if self.settings.STORAGE_BACKEND == "local":
            # For local files, we typically don't have a public URL
            # Return a placeholder or None
            return None

        elif self.settings.STORAGE_BACKEND == "gcs":
            # Handle GCS URI format
            bucket_name: str
            blob_name: str

            if storage_path.startswith("gs://"):
                parts = self._parse_gcs_uri(storage_path)
                bucket_name, blob_name = parts
            else:
                # Assume it's just the blob name
                bucket_name = self.settings.GCS_BUCKET_NAME or ""
                blob_name = storage_path

            # Generate a public URL for GCS objects
            return f"https://storage.googleapis.com/{bucket_name}/{blob_name}"

        else:
            raise ValueError(
                f"Unsupported storage backend: {self.settings.STORAGE_BACKEND}"
            )

    def _save_local_file(self, file_path: Path, content: bytes) -> None:
        """Helper method to save content to a local file"""
        with open(file_path, "wb") as f:
            f.write(content)

    def _upload_to_gcs(self, blob_name: str, content: bytes) -> None:
        """Helper method to upload content to GCS"""
        if self.gcs_client is None:
            raise RuntimeError("GCS client not initialized")

        bucket = self.gcs_client.bucket(self.settings.GCS_BUCKET_NAME)
        blob = bucket.blob(blob_name)
        blob.upload_from_string(content)

    def _download_from_gcs(
        self, bucket_name: str, blob_name: str, destination_path: str
    ) -> None:
        """Helper method to download a file from GCS"""
        if self.gcs_client is None:
            raise RuntimeError("GCS client not initialized")

        bucket = self.gcs_client.bucket(bucket_name)
        blob = bucket.blob(blob_name)
        blob.download_to_filename(destination_path)

    def _get_local_path(self, relative_path: str) -> Path:
        """Convert a relative storage path to a full local path"""
        # Handle absolute paths that might have been stored
        if os.path.isabs(relative_path):
            return Path(relative_path)
        return self.local_storage_path / relative_path

    def _parse_gcs_uri(self, gcs_uri: str) -> Tuple[str, str]:
        """Parse a GCS URI (gs://bucket-name/path/to/file) into bucket and blob names"""
        if not gcs_uri.startswith("gs://"):
            raise ValueError(f"Invalid GCS URI: {gcs_uri}")

        # Remove 'gs://' prefix
        path = gcs_uri[5:]

        # Split into bucket and blob name
        parts = path.split("/", 1)
        if len(parts) != 2:
            raise ValueError(f"Invalid GCS URI format: {gcs_uri}")

        bucket_name, blob_name = parts
        return bucket_name, blob_name


# Singleton factory
_file_storage_service = None


def get_file_storage_service() -> FileStorageService:
    """Factory function to get the FileStorageService singleton instance"""
    global _file_storage_service
    if _file_storage_service is None:
        _file_storage_service = FileStorageService()
    return _file_storage_service
</file>

<file path="apps/core/lib/utils/ffmpeg_utils.py">
"""
FfmpegUtils: Synchronous FFmpeg utility functions for video processing.

- Provides methods for audio extraction, frame extraction, and metadata retrieval.
- Uses subprocess.run to call the ffmpeg CLI.
- Designed for use in the infrastructure/lib layer.

Directory: apps/core/lib/utils/ffmpeg_utils.py
Layer: Infrastructure/Lib
"""

import json
import subprocess
from typing import Any, Dict


class FfmpegUtils:
    """
    Utility class for common FFmpeg operations.
    All methods are synchronous and use subprocess.run.
    """

    @staticmethod
    def extract_audio_sync(video_path: str, output_audio_path: str) -> None:
        """
        Extracts audio from a video file and saves it to output_audio_path.

        Args:
            video_path (str): Path to the input video file.
            output_audio_path (str): Path to save the extracted audio file.

        Raises:
            RuntimeError: If ffmpeg fails.
        """
        cmd = [
            "ffmpeg",
            "-y",  # Overwrite output files without asking
            "-i",
            video_path,
            "-vn",  # No video
            "-acodec",
            "pcm_s16le",
            "-ar",
            "44100",
            "-ac",
            "2",
            output_audio_path,
        ]
        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        if result.returncode != 0:
            raise RuntimeError(
                f"FFmpeg audio extraction failed: {result.stderr.decode('utf-8')}"
            )

    @staticmethod
    def extract_frame_sync(
        video_path: str, timestamp_seconds: float, output_image_path: str
    ) -> None:
        """
        Extracts a single frame from a video at the specified timestamp.

        Args:
            video_path (str): Path to the input video file.
            timestamp_seconds (float): Timestamp in seconds to extract the frame.
            output_image_path (str): Path to save the extracted image.

        Raises:
            RuntimeError: If ffmpeg fails.
        """
        cmd = [
            "ffmpeg",
            "-y",
            "-ss",
            str(timestamp_seconds),
            "-i",
            video_path,
            "-frames:v",
            "1",
            output_image_path,
        ]
        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        if result.returncode != 0:
            raise RuntimeError(
                f"FFmpeg frame extraction failed: {result.stderr.decode('utf-8')}"
            )

    @staticmethod
    def get_video_metadata_sync(video_path: str) -> Dict[str, Any]:
        """
        Retrieves metadata from a video file using ffprobe.

        Args:
            video_path (str): Path to the input video file.

        Returns:
            Dict[str, Any]: Parsed metadata dictionary.

        Raises:
            RuntimeError: If ffprobe fails.
        """
        cmd = [
            "ffprobe",
            "-v",
            "error",
            "-show_entries",
            "format:stream",
            "-print_format",
            "json",
            video_path,
        ]
        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        if result.returncode != 0:
            raise RuntimeError(
                f"ffprobe metadata extraction failed: {result.stderr.decode('utf-8')}"
            )
        return json.loads(result.stdout.decode("utf-8"))
</file>

<file path="apps/core/lib/utils/file_utils.py">
"""
FileUtils: Utility functions for temporary directory management.

- Provides methods for creating and cleaning up temporary directories.
- Designed for use in the infrastructure/lib layer.

Directory: apps/core/lib/utils/file_utils.py
Layer: Infrastructure/Lib
"""

import os
import shutil
import tempfile
from typing import Optional


class FileUtils:
    """
    Utility class for temporary directory creation and cleanup.
    """

    @staticmethod
    def create_temp_dir(prefix: Optional[str] = "echo_tmp_") -> str:
        """
        Creates a temporary directory for processing.

        Args:
            prefix (Optional[str]): Prefix for the temp directory name.

        Returns:
            str: Path to the created temporary directory.
        """
        return tempfile.mkdtemp(prefix=prefix)

    @staticmethod
    def cleanup_temp_dir(dir_path: str) -> None:
        """
        Removes a temporary directory and all its contents.

        Args:
            dir_path (str): Path to the directory to remove.
        """
        if os.path.exists(dir_path):
            shutil.rmtree(dir_path)
</file>

<file path="apps/core/lib/utils/subtitle_utils.py">
"""
SubtitleUtils: Utility functions for generating VTT and SRT subtitle files.

- Provides methods to generate VTT and SRT content from transcript segments.
- Designed for use in the infrastructure/lib layer.

Directory: apps/core/lib/utils/subtitle_utils.py
Layer: Infrastructure/Lib
"""

from typing import Dict, List


class SubtitleUtils:
    """
    Utility class for generating VTT and SRT subtitle content.
    """

    @staticmethod
    def generate_vtt(transcript_segments: List[Dict]) -> str:
        """
        Generates VTT subtitle content from transcript segments.

        Args:
            transcript_segments (List[Dict]): List of segments, each with 'text', 'start_time', 'end_time'.

        Returns:
            str: VTT formatted subtitle content.
        """

        def format_timestamp(seconds: float) -> str:
            h = int(seconds // 3600)
            m = int((seconds % 3600) // 60)
            s = seconds % 60
            ms = int((s - int(s)) * 1000)
            return f"{h:02}:{m:02}:{int(s):02}.{ms:03}"

        lines = ["WEBVTT\n"]
        for seg in transcript_segments:
            start = format_timestamp(seg["start_time"])
            end = format_timestamp(seg["end_time"])
            lines.append(f"{start} --> {end}")
            lines.append(seg["text"])
            lines.append("")
        return "\n".join(lines)

    @staticmethod
    def generate_srt(transcript_segments: List[Dict]) -> str:
        """
        Generates SRT subtitle content from transcript segments.

        Args:
            transcript_segments (List[Dict]): List of segments, each with 'text', 'start_time', 'end_time'.

        Returns:
            str: SRT formatted subtitle content.
        """

        def format_timestamp(seconds: float) -> str:
            h = int(seconds // 3600)
            m = int((seconds % 3600) // 60)
            s = int(seconds % 60)
            ms = int((seconds - int(seconds)) * 1000)
            return f"{h:02}:{m:02}:{s:02},{ms:03}"

        lines = []
        for idx, seg in enumerate(transcript_segments, 1):
            start = format_timestamp(seg["start_time"])
            end = format_timestamp(seg["end_time"])
            lines.append(f"{idx}")
            lines.append(f"{start} --> {end}")
            lines.append(seg["text"])
            lines.append("")
        return "\n".join(lines)
</file>

<file path="apps/core/lib/__init__.py">
"""
Common libraries and utilities for the application.
"""

# Import and expose key components for easier access
from lib.cache import RedisClient, get_redis_client
from lib.database import Base, create_session, engine, get_db_session
from lib.messaging import EmailService, get_email_service
from lib.storage import FileStorage, get_file_storage

__all__ = [
    # Cache
    "RedisClient",
    "get_redis_client",
    # Database
    "engine",
    "Base",
    "get_db_session",
    "create_session",
    # Messaging
    "EmailService",
    "get_email_service",
    # Storage
    "FileStorage",
    "get_file_storage",
]
</file>

<file path="apps/core/models/__init__.py">
from apps.core.models.chat_model import Chat, Message
from apps.core.models.enums import ProcessingStatus
from apps.core.models.user_model import User
from apps.core.models.video_job_model import VideoJobModel
from apps.core.models.video_metadata_model import VideoMetadataModel
from apps.core.models.video_model import VideoModel

__all__ = [
    "User",
    "Chat",
    "Message",
    "VideoModel",
    "VideoJobModel",
    "VideoMetadataModel",
    "ProcessingStatus",
]
</file>

<file path="apps/core/models/chat_model.py">
import uuid

from lib.database import Base
from sqlalchemy import Column, DateTime, ForeignKey, Index, Integer, String, Text
from sqlalchemy.dialects.postgresql import UUID
from sqlalchemy.orm import relationship
from sqlalchemy.sql import func


class Chat(Base):
    __tablename__ = "chats"

    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4, index=True)
    title = Column(String(255), nullable=True)
    # Anonymous chats don't need a user_id, but we can add it later if needed
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(
        DateTime(timezone=True), onupdate=func.now(), server_default=func.now()
    )

    # Relationships
    messages = relationship(
        "Message", back_populates="chat", cascade="all, delete-orphan"
    )

    # Add index on created_at for sorting chats by date
    __table_args__ = (Index("ix_chats_created_at", created_at.desc()),)


class Message(Base):
    __tablename__ = "messages"

    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4, index=True)
    chat_id = Column(
        UUID(as_uuid=True), ForeignKey("chats.id", ondelete="CASCADE"), nullable=False
    )
    content = Column(Text, nullable=False)
    # is_from_ai: True if message is from AI, False if from user
    is_from_ai = Column(Integer, default=0, nullable=False)
    created_at = Column(DateTime(timezone=True), server_default=func.now())

    # Relationship
    chat = relationship("Chat", back_populates="messages")

    # Add indexes for query optimization
    __table_args__ = (
        Index("ix_messages_chat_id", chat_id),
        Index("ix_messages_created_at", created_at),
    )
</file>

<file path="apps/core/models/enums.py">
"""
Enumeration types used throughout the video processing system.

This module defines enumeration classes used to represent fixed sets of values
in a type-safe manner, such as processing status states. Using enums instead of
string literals improves type safety and code readability.

Usage:
    from apps.core.models.enums import ProcessingStatus

    # Create a new job with pending status
    job = VideoJobModel(status=ProcessingStatus.PENDING)

    # Check job status
    if job.status == ProcessingStatus.COMPLETED:
        print("Processing is complete!")
"""

from enum import Enum, auto


class ProcessingStatus(str, Enum):
    """
    Enumeration of possible video processing job statuses.

    This enum inherits from str to allow for easy serialization to/from databases
    and JSON, while still providing type safety and enumeration benefits.

    Attributes:
        PENDING: Job has been created but processing has not started.
        PROCESSING: Job is currently being processed.
        COMPLETED: Job has completed successfully.
        FAILED: Job processing failed with an error.
    """

    PENDING = "PENDING"
    PROCESSING = "PROCESSING"
    COMPLETED = "COMPLETED"
    FAILED = "FAILED"
</file>

<file path="apps/core/models/user_model.py">
from lib.database import Base
from sqlalchemy import Boolean, Column, DateTime, Integer, String
from sqlalchemy.sql import func


class User(Base):
    __tablename__ = "users"

    id = Column(Integer, primary_key=True, index=True)
    username = Column(String, unique=True, index=True)
    email = Column(String, unique=True, index=True)
    full_name = Column(String)
    hashed_password = Column(String)
    is_active = Column(Boolean, default=True)
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(DateTime(timezone=True), onupdate=func.now())
</file>

<file path="apps/core/models/video_job_model.py">
"""
SQLAlchemy model for video processing jobs.

This module defines the VideoJobModel class, which represents a video processing job
in the database. Each job is associated with a specific video and tracks the
processing status, stages, and any error information.

Usage:
    from apps.core.models.video_job_model import VideoJobModel
    from apps.core.models.enums import ProcessingStatus

    # Create a new video processing job
    new_job = VideoJobModel(
        video_id=1,
        status=ProcessingStatus.PENDING,
        processing_stages={"transcription": False, "metadata": False}
    )

    # Add to database
    db.add(new_job)
    db.commit()

    # Update job status
    new_job.status = ProcessingStatus.PROCESSING
    new_job.processing_stages["transcription"] = True
    db.commit()
"""

from sqlalchemy import (
    JSON,
    Column,
    DateTime,
    Enum,
    ForeignKey,
    Integer,
    String,
    Text,
    func,
)
from sqlalchemy.orm import relationship

from apps.core.lib.database.connection import Base
from apps.core.models.enums import ProcessingStatus

# Remove direct import causing circular dependency
# from apps.core.models.video_metadata_model import VideoMetadataModel


class VideoJobModel(Base):
    """
    SQLAlchemy model representing a video processing job.

    This model tracks the status and progress of a video processing task, including
    which processing stages have been completed and any errors that occurred.
    It maintains relationships with both the source video and the generated metadata.

    Attributes:
        id (int): Primary key, auto-incrementing identifier.
        video_id (int): Foreign key referencing the associated video.
        status (ProcessingStatus): Current status of the job (PENDING, PROCESSING, COMPLETED, FAILED).
        processing_stages (JSON): Dictionary tracking completion of various processing steps.
        error_message (str): Error message if processing failed, otherwise None.
        created_at (datetime): Timestamp when the job was created.
        updated_at (datetime): Timestamp when the job was last updated.
        video (relationship): Many-to-one relationship with VideoModel.
        video_metadata (relationship): One-to-one relationship with VideoMetadataModel.
    """

    __tablename__ = "video_jobs"

    id = Column(Integer, primary_key=True, autoincrement=True)
    video_id = Column(Integer, ForeignKey("videos.id"), nullable=False)
    status = Column(
        Enum(ProcessingStatus), default=ProcessingStatus.PENDING, nullable=False
    )
    processing_stages = Column(JSON, nullable=True)
    error_message = Column(Text, nullable=True)
    created_at = Column(DateTime, default=func.now(), nullable=False)
    updated_at = Column(
        DateTime, default=func.now(), onupdate=func.now(), nullable=False
    )

    # Define relationships
    video = relationship("VideoModel", back_populates="jobs")
    # Use string reference instead of direct class reference
    video_metadata = relationship(
        "VideoMetadataModel",
        back_populates="job",
        uselist=False,
        cascade="all, delete-orphan",
    )

    def __repr__(self):
        return f"<VideoJob(id={self.id}, status={self.status})>"
</file>

<file path="apps/core/models/video_metadata_model.py">
"""
SQLAlchemy model for storing video metadata information.

This module defines the VideoMetadataModel class which stores metadata extracted from
videos during processing, such as title, description, transcript, and technical details.
It also provides a ValueObject class (VideoMetadata) for simpler in-memory representation.

Usage:
    from apps.core.models.video_metadata_model import VideoMetadataModel, VideoMetadata

    # Create new video metadata
    metadata = VideoMetadataModel(
        job_id=123,
        title="My Awesome Video",
        description="This is a video about...",
        tags=["tutorial", "programming"],
        transcript_text="Full transcript text..."
    )

    # Add to database
    db.add(metadata)
    db.commit()

    # Using the value object for in-memory operations
    metadata_vo = VideoMetadata(
        title="My Video",
        description="Description",
        tags=["tag1", "tag2"]
    )
    metadata_json = metadata_vo.to_json()
"""

import json
from dataclasses import asdict, dataclass, field
from typing import Any, Dict, List

from sqlalchemy import (
    JSON,
    Column,
    DateTime,
    Float,
    ForeignKey,
    Integer,
    String,
    Text,
    func,
)
from sqlalchemy.orm import relationship

from apps.core.lib.database.connection import Base

# Remove direct import causing circular dependency
# from apps.core.models.video_job_model import VideoJobModel


class VideoMetadataModel(Base):
    """
    SQLAlchemy model representing metadata extracted from a processed video.

    This model stores all metadata extracted or generated during video processing,
    including AI-generated title and description, transcripts, subtitles, technical
    information about the video, and generated assets like thumbnails.

    Attributes:
        id (int): Primary key, auto-incrementing identifier.
        job_id (int): Foreign key referencing the processing job that created this metadata.
        title (str): AI-generated or user-provided title for the video.
        description (str): AI-generated or user-provided description.
        tags (JSON): List of keywords/tags related to the video content.
        transcript_text (str): Full text transcript of the video's audio content.
        transcript_file_url (str): URL to the stored transcript file.
        subtitle_files_urls (JSON): Dictionary mapping subtitle format to file URLs.
        thumbnail_file_url (str): URL to the generated thumbnail image.
        extracted_video_duration_seconds (float): Duration of the video in seconds.
        extracted_video_resolution (str): Resolution of the video (e.g., "1920x1080").
        extracted_video_format (str): Format/codec of the video file.
        show_notes_text (str): AI-generated or user-provided show notes/summary.
        created_at (datetime): Timestamp when the metadata was created.
        updated_at (datetime): Timestamp when the metadata was last updated.
        job (relationship): Many-to-one relationship with VideoJobModel.
    """

    __tablename__ = "video_metadata"

    id = Column(Integer, primary_key=True, autoincrement=True)
    job_id = Column(Integer, ForeignKey("video_jobs.id"), unique=True, nullable=False)
    title = Column(String, nullable=True)
    description = Column(Text, nullable=True)
    tags = Column(JSON, nullable=True)
    transcript_text = Column(Text, nullable=True)
    transcript_file_url = Column(String, nullable=True)
    subtitle_files_urls = Column(JSON, nullable=True)
    thumbnail_file_url = Column(String, nullable=True)
    extracted_video_duration_seconds = Column(Float, nullable=True)
    extracted_video_resolution = Column(String, nullable=True)
    extracted_video_format = Column(String, nullable=True)
    show_notes_text = Column(Text, nullable=True)
    created_at = Column(DateTime, default=func.now(), nullable=False)
    updated_at = Column(
        DateTime, default=func.now(), onupdate=func.now(), nullable=False
    )

    # Define relationship back to job - use string reference instead of direct class reference
    job = relationship("VideoJobModel", back_populates="video_metadata")

    def __repr__(self):
        return f"<VideoMetadata(id={self.id}, job_id={self.job_id})>"


@dataclass
class VideoMetadata:
    """
    Value object representing video metadata for in-memory operations.

    This dataclass provides a lightweight representation of video metadata
    without the ORM overhead, useful for business logic operations and
    serialization/deserialization.

    Attributes:
        title (str): Title of the video, defaults to "Untitled Video".
        description (str): Description of the video content.
        tags (List[str]): List of keywords/tags related to the video.
        show_notes (str): Notes or summary about the video content.
        chapters (List[Dict[str, Any]]): Chapter markers with timestamps.
    """

    title: str = "Untitled Video"
    description: str = ""
    tags: List[str] = field(default_factory=list)
    show_notes: str = ""
    chapters: List[Dict[str, Any]] = field(default_factory=list)

    def to_dict(self) -> Dict[str, Any]:
        """
        Convert the metadata to a dictionary.

        Returns:
            Dict[str, Any]: Dictionary representation of the metadata.
        """
        return asdict(self)

    def to_json(self) -> str:
        """
        Convert the metadata to a JSON string.

        Returns:
            str: JSON string representation of the metadata.
        """
        return json.dumps(self.to_dict(), ensure_ascii=False, indent=2)
</file>

<file path="apps/core/models/video_model.py">
"""
SQLAlchemy model for storing video file information.

This module defines the VideoModel class, which represents uploaded video files
in the database. Each video is associated with an uploader user and can have
multiple related processing jobs.

Usage:
    from apps.core.models.video_model import VideoModel

    # Create a new video entry
    new_video = VideoModel(
        uploader_user_id="user123",
        original_filename="my_video.mp4",
        storage_path="uploads/user123/my_video.mp4",
        content_type="video/mp4",
        size_bytes=1024000
    )

    # Add to database
    db.add(new_video)
    db.commit()
"""

from sqlalchemy import Column, DateTime, ForeignKey, Integer, String, func
from sqlalchemy.orm import relationship

from apps.core.lib.database.connection import Base


class VideoModel(Base):
    """
    SQLAlchemy model representing an uploaded video file.

    This model stores information about the original video file, including its
    storage location, file metadata, and the user who uploaded it. It maintains
    relationships with processing jobs and tracks creation/update timestamps.

    Attributes:
        id (int): Primary key, auto-incrementing identifier.
        uploader_user_id (str): User ID of the person who uploaded the video.
        original_filename (str): Original filename of the uploaded video.
        storage_path (str): Path where the video is stored (GCS or local filesystem).
        content_type (str): MIME type of the video file (e.g., 'video/mp4').
        size_bytes (int): Size of the video file in bytes.
        created_at (datetime): Timestamp when the entry was created.
        updated_at (datetime): Timestamp when the entry was last updated.
        jobs (relationship): One-to-many relationship with VideoJobModel.
    """

    __tablename__ = "videos"

    id = Column(Integer, primary_key=True, autoincrement=True)
    uploader_user_id = Column(String, index=True, nullable=False)
    original_filename = Column(String, nullable=False)
    storage_path = Column(String, unique=True, nullable=False)
    content_type = Column(String, nullable=False)
    size_bytes = Column(Integer, nullable=False)
    created_at = Column(DateTime, default=func.now(), nullable=False)
    updated_at = Column(
        DateTime, default=func.now(), onupdate=func.now(), nullable=False
    )

    # Define relationship to video jobs
    jobs = relationship(
        "VideoJobModel", back_populates="video", cascade="all, delete-orphan"
    )

    def __repr__(self):
        return f"<Video(id={self.id}, filename={self.original_filename})>"
</file>

<file path="apps/core/operations/__init__.py">
from apps.core.operations.chat_repository import ChatRepository, get_chat_repository
from apps.core.operations.user_repository import UserRepository, get_user_repository

__all__ = [
    "UserRepository",
    "get_user_repository",
    "ChatRepository",
    "get_chat_repository",
]
</file>

<file path="apps/core/operations/chat_repository.py">
from typing import Any, Dict, List, Optional
from uuid import UUID

from fastapi import Depends

# from lib.database import create_session # Will be replaced
from sqlalchemy import delete, desc, select, update  # Added select, delete, update
from sqlalchemy.ext.asyncio import AsyncSession  # Added AsyncSession
from sqlalchemy.orm import Session

from apps.core.lib.database.connection import (
    get_async_db_session,  # Import async session getter
)
from apps.core.models.chat_model import Chat, Message


class ChatRepository:
    def __init__(self, db: AsyncSession):  # Changed to AsyncSession
        self.db = db

    # Chat operations
    async def get_chat(self, chat_id: UUID) -> Optional[Chat]:  # async def
        result = await self.db.execute(select(Chat).filter(Chat.id == chat_id))
        return result.scalars().first()

    async def get_chats(
        self, skip: int = 0, limit: int = 20
    ) -> List[Chat]:  # async def
        result = await self.db.execute(
            select(Chat).order_by(desc(Chat.updated_at)).offset(skip).limit(limit)
        )
        return list(result.scalars().all())

    async def create_chat(self, chat_data: Dict[str, Any]) -> Chat:  # async def
        chat = Chat(**chat_data)
        self.db.add(chat)
        await self.db.commit()  # await commit
        await self.db.refresh(chat)  # await refresh
        return chat

    async def update_chat(
        self, chat_id: UUID, chat_data: Dict[str, Any]
    ) -> Optional[Chat]:  # async def
        # chat = await self.get_chat(chat_id) # Fetch first approach
        # if chat:
        #     for key, value in chat_data.items():
        #         setattr(chat, key, value)
        #     await self.db.commit()
        #     await self.db.refresh(chat)
        # return chat
        # Direct update approach (more efficient for partial updates)
        stmt = update(Chat).where(Chat.id == chat_id).values(**chat_data)
        result = await self.db.execute(stmt)
        if result.rowcount == 0:
            return None
        await self.db.commit()
        return await self.get_chat(
            chat_id
        )  # Re-fetch to get updated model with all fields

    async def delete_chat(self, chat_id: UUID) -> bool:  # async def
        stmt = delete(Chat).where(Chat.id == chat_id)
        result = await self.db.execute(stmt)
        await self.db.commit()
        return result.rowcount > 0

    # Message operations
    async def get_message(self, message_id: UUID) -> Optional[Message]:  # async def
        result = await self.db.execute(select(Message).filter(Message.id == message_id))
        return result.scalars().first()

    async def get_messages_by_chat(  # async def
        self, chat_id: UUID, skip: int = 0, limit: int = 50
    ) -> List[Message]:
        result = await self.db.execute(
            select(Message)
            .filter(Message.chat_id == chat_id)
            .order_by(Message.created_at)
            .offset(skip)
            .limit(limit)
        )
        return list(result.scalars().all())

    async def create_message(
        self, message_data: Dict[str, Any]
    ) -> Message:  # async def
        message = Message(**message_data)
        self.db.add(message)

        # Update the chat's updated_at timestamp
        # The comment "The updated_at will be automatically updated due to onupdate" implies
        # that the database might handle this. If not, an explicit update might be needed.
        # Forcing an update via ORM could be:
        chat = await self.get_chat(message_data["chat_id"])
        if chat:
            # If Chat model has a listener or if there's a DB trigger for updated_at,
            # simply adding the message and committing might be enough.
            # If we need to explicitly mark chat as dirty for ORM to update `updated_at` (if it's ORM-managed):
            # from sqlalchemy.orm.attributes import flag_modified
            # chat.some_field_to_trigger_update = chat.some_field_to_trigger_update # or flag_modified(chat, "updated_at") if it is not autogenerated by DB
            # self.db.add(chat) # Ensure chat is part of the session if it needs an update.
            pass  # Assuming DB onupdate handles Chat.updated_at, or ORM handles it on relationship changes.

        await self.db.commit()  # await commit
        await self.db.refresh(message)  # await refresh
        return message

    async def delete_message(self, message_id: UUID) -> bool:  # async def
        stmt = delete(Message).where(Message.id == message_id)
        result = await self.db.execute(stmt)
        await self.db.commit()
        return result.rowcount > 0


async def get_chat_repository(  # async def
    db: AsyncSession = Depends(get_async_db_session),  # Use get_async_db_session
) -> ChatRepository:
    return ChatRepository(db)
</file>

<file path="apps/core/operations/transaction_repo.py">
from typing import Any, Awaitable, Callable

from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm import Session


class TransactionRepository:
    def __init__(self, db: AsyncSession):
        self.db = db

    async def run_in_transaction(
        self, callback: Callable[[AsyncSession], Awaitable[Any]]
    ) -> Any:
        """
        Execute an async function within a database transaction.

        Args:
            callback: An async function that takes the async session as parameter and returns a result

        Returns:
            The result of the callback function
        """
        try:
            result = await callback(self.db)
            await self.db.commit()
            return result
        except Exception as e:
            await self.db.rollback()
            raise e
</file>

<file path="apps/core/operations/user_repository.py">
from typing import List, Optional

from fastapi import Depends
from sqlalchemy import delete, select, update  # Added select, delete, update
from sqlalchemy.ext.asyncio import AsyncSession  # Added AsyncSession

# from lib.database import create_session # Will be replaced by async version
from sqlalchemy.orm import Session

from apps.core.lib.database.connection import (
    get_async_db_session,  # Import async session getter
)
from apps.core.models.user_model import User


class UserRepository:
    def __init__(self, db: AsyncSession):  # Changed to AsyncSession
        self.db = db

    async def get_user(self, user_id: int) -> Optional[User]:  # async def
        result = await self.db.execute(select(User).filter(User.id == user_id))
        return result.scalars().first()

    async def get_user_by_email(self, email: str) -> Optional[User]:  # async def
        result = await self.db.execute(select(User).filter(User.email == email))
        return result.scalars().first()

    async def get_user_by_username(self, username: str) -> Optional[User]:  # async def
        result = await self.db.execute(select(User).filter(User.username == username))
        return result.scalars().first()

    async def get_users(
        self, skip: int = 0, limit: int = 100
    ) -> List[User]:  # async def
        result = await self.db.execute(select(User).offset(skip).limit(limit))
        return list(result.scalars().all())

    async def create_user(self, user_data: dict) -> User:  # async def
        user = User(**user_data)
        self.db.add(user)
        await self.db.commit()  # await commit
        await self.db.refresh(user)  # await refresh
        return user

    async def update_user(
        self, user_id: int, user_data: dict
    ) -> Optional[User]:  # async def
        # We need to be careful here. self.get_user is now async.
        # SQLAlchemy 2.0 style update is preferred for partial updates.
        # However, to maintain similar logic of fetch then update for now:
        user = await self.get_user(user_id)
        if user:
            for key, value in user_data.items():
                setattr(user, key, value)
            await self.db.commit()  # await commit
            await self.db.refresh(user)  # await refresh
        return user
        # Alternative using SQLAlchemy update:
        # stmt = update(User).where(User.id == user_id).values(**user_data)
        # result = await self.db.execute(stmt)
        # if result.rowcount == 0:
        #     return None
        # await self.db.commit()
        # return await self.get_user(user_id) # Re-fetch to get updated model

    async def delete_user(self, user_id: int) -> bool:  # async def
        # SQLAlchemy 2.0 style delete is preferred.
        stmt = delete(User).where(User.id == user_id)
        result = await self.db.execute(stmt)
        await self.db.commit()  # await commit
        return result.rowcount > 0
        # Old logic:
        # user = await self.get_user(user_id)
        # if user:
        #     await self.db.delete(user) # await delete
        #     await self.db.commit()
        #     return True
        # return False


async def get_user_repository(  # async def
    db: AsyncSession = Depends(get_async_db_session),  # Use get_async_db_session
) -> UserRepository:
    return UserRepository(db)
</file>

<file path="apps/core/operations/video_job_repository.py">
"""
Repository for VideoJobModel data access operations.

This module provides a repository class implementing the repository pattern for
VideoJobModel entities. It abstracts database operations for creating, retrieving,
and updating video processing jobs. The repository handles the persistence details
while keeping business logic separate, accepting a SQLAlchemy Session for all operations.

Usage:
    from sqlalchemy.orm import Session
    from apps.core.models.enums import ProcessingStatus
    from apps.core.operations.video_job_repository import VideoJobRepository

    # Create a new video processing job
    job_repo = VideoJobRepository()
    new_job = job_repo.create(
        db=db_session,
        video_id=1,
        status=ProcessingStatus.PENDING,
        processing_stages={"transcription": False}
    )

    # Update job status
    updated_job = job_repo.update_status(
        db=db_session,
        job_id=new_job.id,
        status=ProcessingStatus.PROCESSING
    )

    # Record a processing stage
    job_repo.add_processing_stage(
        db=db_session,
        job_id=new_job.id,
        stage="transcription_complete"
    )
"""

from typing import Any, List, Optional

from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm import Session, joinedload

from apps.core.models.enums import ProcessingStatus
from apps.core.models.video_job_model import VideoJobModel
from apps.core.models.video_model import VideoModel


class VideoJobRepository:
    """
    Repository for VideoJobModel data access.
    """

    @staticmethod
    async def create(
        db: AsyncSession,
        video_id: int,
        status: ProcessingStatus = ProcessingStatus.PENDING,
        processing_stages: Optional[Any] = None,
        error_message: Optional[str] = None,
    ) -> VideoJobModel:
        """
        Create and persist a new VideoJobModel.

        Args:
            db (AsyncSession): SQLAlchemy async session.
            video_id (int): Associated video ID.
            status (ProcessingStatus): Initial processing status.
            processing_stages (Optional[Any]): Initial processing stages (JSON/text).
            error_message (Optional[str]): Initial error message.

        Returns:
            VideoJobModel: The created job model.
        """
        job = VideoJobModel(
            video_id=video_id,
            status=status,
            processing_stages=processing_stages,
            error_message=error_message,
        )
        db.add(job)
        await db.flush()
        return job

    @staticmethod
    async def get_by_id(db: AsyncSession, job_id: int) -> Optional[VideoJobModel]:
        """
        Retrieve a VideoJobModel by its ID.

        Args:
            db (AsyncSession): SQLAlchemy async session.
            job_id (int): Job ID.

        Returns:
            Optional[VideoJobModel]: The job model, or None if not found.
        """
        result = await db.execute(
            select(VideoJobModel).filter(VideoJobModel.id == job_id)
        )
        return result.scalars().first()

    @staticmethod
    async def update_status(
        db: AsyncSession,
        job_id: int,
        status: ProcessingStatus,
        error_message: Optional[str] = None,
    ) -> Optional[VideoJobModel]:
        """
        Update the status (and optionally error message) of a VideoJobModel.

        Args:
            db (AsyncSession): SQLAlchemy async session.
            job_id (int): Job ID.
            status (ProcessingStatus): New status.
            error_message (Optional[str]): Error message.

        Returns:
            Optional[VideoJobModel]: The updated job model, or None if not found.
        """
        result = await db.execute(
            select(VideoJobModel).filter(VideoJobModel.id == job_id)
        )
        job = result.scalars().first()
        if job is not None:
            job.status = status  # type: ignore
            if error_message is not None:
                job.error_message = error_message  # type: ignore
            await db.flush()
        return job

    @staticmethod
    async def add_processing_stage(
        db: AsyncSession, job_id: int, stage: str
    ) -> Optional[VideoJobModel]:
        """
        Add a processing stage to the job's processing_stages list (assumes JSON/text).

        Args:
            db (AsyncSession): SQLAlchemy async session.
            job_id (int): Job ID.
            stage (str): Stage to add.

        Returns:
            Optional[VideoJobModel]: The updated job model, or None if not found.
        """
        result = await db.execute(
            select(VideoJobModel).filter(VideoJobModel.id == job_id)
        )
        job = result.scalars().first()
        if job is not None:
            # Explicitly handle None to avoid potential issues with linter and SQLAlchemy attributes
            current_processing_stages = job.processing_stages
            if current_processing_stages is None:
                stages = []
            else:
                stages = current_processing_stages

            if isinstance(stages, str):
                import json

                try:
                    stages = json.loads(stages)
                except Exception:
                    stages = []
            if not isinstance(stages, list):
                stages = []
            stages.append(stage)
            job.processing_stages = stages  # type: ignore
            await db.flush()
        return job

    @staticmethod
    async def get_by_user_id_and_statuses(
        db: AsyncSession,
        user_id: str,
        statuses: Optional[List[ProcessingStatus]] = None,
        limit: int = 100,
        offset: int = 0,
    ) -> List[VideoJobModel]:
        """
        Retrieve VideoJobModels for a specific user, filtered by statuses, with pagination.

        Args:
            db (AsyncSession): SQLAlchemy async session.
            user_id (str): The uploader_user_id (Supabase string UUID) from VideoModel.
            statuses (Optional[List[ProcessingStatus]]): List of statuses to filter by.
                                                      If None or empty, default statuses might be applied
                                                      (e.g., PENDING, PROCESSING) or no status filter.
            limit (int): Maximum number of jobs to return.
            offset (int): Number of jobs to skip for pagination.

        Returns:
            List[VideoJobModel]: A list of job models.
        """
        stmt = (
            select(VideoJobModel)
            .join(VideoModel, VideoJobModel.video_id == VideoModel.id)
            .filter(VideoModel.uploader_user_id == user_id)
        )

        if statuses:
            stmt = stmt.filter(VideoJobModel.status.in_(statuses))

        # Eager load related video and metadata to prevent N+1 queries if accessed later
        # This is useful if the VideoJobSchema nests VideoSchema and VideoMetadataSchema
        stmt = stmt.options(
            joinedload(VideoJobModel.video), joinedload(VideoJobModel.video_metadata)
        )

        stmt = (
            stmt.order_by(VideoJobModel.created_at.desc()).offset(offset).limit(limit)
        )

        result = await db.execute(stmt)
        return list(result.scalars().all())


async def get_video_job_repository() -> VideoJobRepository:
    """
    FastAPI dependency for getting a VideoJobRepository instance.
    Used for dependency injection in API endpoints.

    Returns:
        VideoJobRepository: An instance of the VideoJobRepository.
    """
    return VideoJobRepository()
</file>

<file path="apps/core/operations/video_metadata_repository.py">
"""
video_metadata_repository.py: Repository for VideoMetadataModel data access.

- Provides methods for creating/updating and retrieving VideoMetadataModel instances.
- Accepts SQLAlchemy Session as the first argument.
- No business logic; data access only.

Directory: apps/core/operations/video_metadata_repository.py
Layer: Operations
"""

from typing import Any, Optional

from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm import Session

from apps.core.models.video_metadata_model import VideoMetadataModel


class VideoMetadataRepository:
    """
    Repository for VideoMetadataModel data access.
    """

    @staticmethod
    async def create_or_update(
        db: AsyncSession, job_id: int, **kwargs: Any
    ) -> VideoMetadataModel:
        """
        Create or update a VideoMetadataModel for a given job_id.

        Args:
            db (AsyncSession): SQLAlchemy async session.
            job_id (int): Associated job ID.
            **kwargs: Fields to update or set.

        Returns:
            VideoMetadataModel: The created or updated metadata model.
        """
        result = await db.execute(
            select(VideoMetadataModel).filter(VideoMetadataModel.job_id == job_id)
        )
        metadata = result.scalars().first()

        if metadata is None:
            metadata = VideoMetadataModel(job_id=job_id, **kwargs)
            db.add(metadata)
        else:
            for key, value in kwargs.items():
                setattr(metadata, key, value)
        await db.flush()
        return metadata

    @staticmethod
    async def get_by_job_id(
        db: AsyncSession, job_id: int
    ) -> Optional[VideoMetadataModel]:
        """
        Retrieve a VideoMetadataModel by its job_id.

        Args:
            db (AsyncSession): SQLAlchemy async session.
            job_id (int): Job ID.

        Returns:
            Optional[VideoMetadataModel]: The metadata model, or None if not found.
        """
        result = await db.execute(
            select(VideoMetadataModel).filter(VideoMetadataModel.job_id == job_id)
        )
        return result.scalars().first()
</file>

<file path="apps/core/operations/video_repository.py">
"""
Repository for VideoModel data access operations.

This module provides a repository class implementing the repository pattern for
VideoModel entities. It abstracts database access operations, providing methods
for creating and retrieving video records. The repository focuses solely on data
access with no business logic, accepting a SQLAlchemy Session for each operation.

Usage:
    from sqlalchemy.orm import Session
    from apps.core.operations.video_repository import VideoRepository

    # Create a new video
    video_repo = VideoRepository()
    new_video = video_repo.create(
        db=db_session,
        uploader_user_id="user123",
        original_filename="video.mp4",
        storage_path="uploads/video.mp4",
        content_type="video/mp4",
        size_bytes=1024000
    )

    # Get a video by ID
    video = video_repo.get_by_id(db=db_session, video_id=1)
"""

from typing import Optional

from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm import Session

from apps.core.models.video_model import VideoModel


class VideoRepository:
    """
    Repository for VideoModel data access.
    """

    @staticmethod
    async def create(
        db: AsyncSession,
        uploader_user_id: str,
        original_filename: str,
        storage_path: str,
        content_type: str,
        size_bytes: int,
    ) -> VideoModel:
        """
        Create and persist a new VideoModel.

        Args:
            db (AsyncSession): SQLAlchemy async session.
            uploader_user_id (str): Supabase Auth user ID.
            original_filename (str): Original filename.
            storage_path (str): Path in storage backend.
            content_type (str): MIME type.
            size_bytes (int): File size in bytes.

        Returns:
            VideoModel: The created video model.
        """
        video = VideoModel(
            uploader_user_id=uploader_user_id,
            original_filename=original_filename,
            storage_path=storage_path,
            content_type=content_type,
            size_bytes=size_bytes,
        )
        db.add(video)
        await db.flush()  # Assigns ID
        return video

    @staticmethod
    async def get_by_id(db: AsyncSession, video_id: int) -> Optional[VideoModel]:
        """
        Retrieve a VideoModel by its ID.

        Args:
            db (AsyncSession): SQLAlchemy async session.
            video_id (int): Video ID.

        Returns:
            Optional[VideoModel]: The video model, or None if not found.
        """
        result = await db.execute(select(VideoModel).filter(VideoModel.id == video_id))
        return result.scalars().first()


async def get_video_repository() -> VideoRepository:
    """
    FastAPI dependency for getting a VideoRepository instance.
    Used for dependency injection in API endpoints.

    Returns:
        VideoRepository: An instance of the VideoRepository.
    """
    return VideoRepository()
</file>

<file path="apps/core/services/__init__.py">
from services.ai_service import AIService, get_ai_service
from services.auth_service import AuthService, get_auth_service
from services.chat_service import ChatService, get_chat_service
from services.user_service import UserService, get_user_service

__all__ = [
    "UserService",
    "get_user_service",
    "AuthService",
    "get_auth_service",
    "ChatService",
    "get_chat_service",
    "AIService",
    "get_ai_service",
]
</file>

<file path="apps/core/services/ai_service.py">
import asyncio
import json
from typing import Any, AsyncGenerator, Dict, List, cast
from uuid import UUID

from fastapi import Depends

# Import and configure OpenAI
from openai import AsyncOpenAI
from openai.types.chat import ChatCompletionMessageParam
from operations.chat_repository import ChatRepository, get_chat_repository

from apps.core.core.config import settings

# NOTE: OpenAI client is now instantiated inside methods for easier testing/mocking.


class AIService:
    def __init__(self, chat_repository: ChatRepository):
        self.chat_repository = chat_repository

    async def generate_ai_response(
        self, message_content: str, chat_id: UUID
    ) -> Dict[str, Any]:
        """
        Generate AI response using OpenAI API
        """
        # Get chat history for context
        chat_history = await self.get_chat_history(chat_id)

        # Add the current message to history
        chat_history.append({"role": "user", "content": message_content})

        # Call OpenAI API to get a response
        client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY)
        response = await client.chat.completions.create(
            model="o4-mini",
            messages=cast(List[ChatCompletionMessageParam], chat_history),
        )

        ai_response = response.choices[0].message.content

        # Create and store the AI response message
        message_data = {
            "content": ai_response,
            "is_from_ai": True,
            "chat_id": chat_id,
        }

        ai_message = await self.chat_repository.create_message(message_data)

        return {
            "id": ai_message.id,
            "content": ai_message.content,
            "is_from_ai": bool(ai_message.is_from_ai),
            "created_at": ai_message.created_at,
            "chat_id": ai_message.chat_id,
        }

    async def get_chat_history(self, chat_id: UUID) -> List[Dict[str, Any]]:
        """Get the chat history in a format usable for AI context"""
        messages = await self.chat_repository.get_messages_by_chat(chat_id)
        result = []

        for msg in messages:
            # Create a new Python dictionary instead of modifying one
            if hasattr(msg, "is_from_ai"):
                source_value = getattr(msg, "is_from_ai")
                if source_value == 1:
                    role = "assistant"
                else:
                    role = "user"
            else:
                role = "user"

            # Create new dict with all values at once
            message_dict = {"role": role, "content": msg.content}

            result.append(message_dict)

        return result

    async def stream_ai_response(
        self, message_content: str, chat_id: UUID, protocol: str = "data"
    ) -> AsyncGenerator[str, None]:
        """
        Stream an AI response according to the Vercel AI protocol
        """
        # Get chat history for context
        chat_history = await self.get_chat_history(chat_id)

        # Add the current message to history
        chat_history.append({"role": "user", "content": message_content})

        # Save the user message to the database
        user_message_data = {
            "content": message_content,
            "is_from_ai": False,
            "chat_id": chat_id,
        }
        await self.chat_repository.create_message(user_message_data)

        # Use OpenAI streaming API
        complete_response = ""

        # Create a streaming response from OpenAI
        client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY)
        stream = await client.chat.completions.create(
            model="o4-mini",
            messages=cast(List[ChatCompletionMessageParam], chat_history),
            stream=True,
        )

        if protocol == "text":
            async for chunk in stream:
                if chunk.choices and chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    complete_response += content
                    yield content

        elif protocol == "data":
            async for chunk in stream:
                if chunk.choices and chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    complete_response += content
                    yield f"0:{json.dumps(content)}\n"

            # Send the completion message
            yield f'd:{{"finishReason":"stop","usage":{{"promptTokens":0,"completionTokens":{len(complete_response)}}}}}\n'

        # Save the complete AI response to the database
        ai_message_data = {
            "content": complete_response,
            "is_from_ai": True,
            "chat_id": chat_id,
        }
        await self.chat_repository.create_message(ai_message_data)

    async def convert_to_openai_messages(self, client_messages: List[Dict[str, Any]]):
        """
        Convert client messages to OpenAI format
        In a real implementation, you would handle attachments and tool invocations
        """
        openai_messages = []

        for message in client_messages:
            # Basic conversion for text content
            openai_messages.append(
                {
                    "role": message.get("role", "user"),
                    "content": message.get("content", ""),
                }
            )

        return openai_messages

    async def process_chat_stream(
        self,
        client_messages: List[Dict[str, Any]],
        chat_id: UUID,
        protocol: str = "data",
    ) -> AsyncGenerator[str, None]:
        """
        Process a complete chat interaction with streaming response
        This matches the example's pattern for handling chat requests
        """
        # In a real app, you would process the full message history
        # For this dummy implementation, we'll just use the last message from the user
        if client_messages and client_messages[-1]["role"] == "user":
            last_message = client_messages[-1]
            message_content = last_message.get("content", "")

            # Get a streaming response
            async for chunk in self.stream_ai_response(
                message_content, chat_id, protocol
            ):
                yield chunk
        else:
            # No valid messages found
            yield "No valid user messages found"


async def get_ai_service(
    chat_repository: ChatRepository = Depends(get_chat_repository),
) -> AIService:
    return AIService(chat_repository)
</file>

<file path="apps/core/services/auth_service.py">
import hashlib
from typing import Any, Dict, Optional

from fastapi import Depends, HTTPException, status

# Corrected import paths
from apps.core.operations.user_repository import UserRepository, get_user_repository


class AuthService:
    def __init__(self, user_repository: UserRepository):
        self.user_repository = user_repository

    async def authenticate_user(
        self, username: str, password: str
    ) -> Optional[Dict[str, Any]]:
        # Find the user
        user = await self.user_repository.get_user_by_username(username)
        if not user:
            return None

        # Validate password (in real app, use proper password hashing)
        hashed_password = hashlib.sha256(password.encode()).hexdigest()
        if str(user.hashed_password) != hashed_password:
            return None

        # Return user without sensitive information
        return {
            "id": user.id,
            "username": user.username,
            "email": user.email,
            "full_name": user.full_name,
            "is_active": user.is_active,
        }

    async def register_user(self, user_data: Dict[str, Any]) -> Dict[str, Any]:
        # Check if username or email already exists
        email = user_data.get("email")
        if not email:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Email is required",
            )
        if await self.user_repository.get_user_by_email(email):
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Email already registered",
            )

        username = user_data.get("username")
        if not username:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Username is required",
            )
        if await self.user_repository.get_user_by_username(username):
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Username already taken",
            )

        # Hash password (in real app, use proper password hashing)
        password = user_data.pop("password", "")
        user_data["hashed_password"] = hashlib.sha256(password.encode()).hexdigest()

        # Create user
        user = await self.user_repository.create_user(user_data)

        # Return user without sensitive information
        return {
            "id": user.id,
            "username": user.username,
            "email": user.email,
            "full_name": user.full_name,
            "is_active": user.is_active,
        }


async def get_auth_service(
    user_repository: UserRepository = Depends(get_user_repository),
) -> AuthService:
    return AuthService(user_repository)
</file>

<file path="apps/core/services/chat_service.py">
from typing import Any, Dict, List
from uuid import UUID

from fastapi import Depends, HTTPException, status

# Corrected import path
from apps.core.operations.chat_repository import ChatRepository, get_chat_repository


class ChatService:
    def __init__(self, chat_repository: ChatRepository):
        self.chat_repository = chat_repository

    # Chat operations
    async def get_chats(self, skip: int = 0, limit: int = 20) -> List[Dict[str, Any]]:
        chats = await self.chat_repository.get_chats(skip=skip, limit=limit)
        return [
            {
                "id": chat.id,
                "title": chat.title
                if chat.title is not None
                else f"Chat {chat.id}",  # Default title if none is provided
                "created_at": chat.created_at,
                "updated_at": chat.updated_at,
            }
            for chat in chats
        ]

    async def get_chat(self, chat_id: UUID) -> Dict[str, Any]:
        chat = await self.chat_repository.get_chat(chat_id)
        if not chat:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND, detail="Chat not found"
            )

        # Get messages for this chat
        messages = await self.chat_repository.get_messages_by_chat(chat_id)

        return {
            "id": chat.id,
            "title": chat.title if chat.title is not None else f"Chat {chat.id}",
            "created_at": chat.created_at,
            "updated_at": chat.updated_at,
            "messages": [
                {
                    "id": message.id,
                    "content": message.content,
                    "is_from_ai": bool(message.is_from_ai),
                    "created_at": message.created_at,
                    "chat_id": message.chat_id,
                }
                for message in messages
            ],
        }

    async def create_chat(self, chat_data: Dict[str, Any]) -> Dict[str, Any]:
        # Create new chat
        chat = await self.chat_repository.create_chat(chat_data)

        return {
            "id": chat.id,
            "title": chat.title if chat.title is not None else f"Chat {chat.id}",
            "created_at": chat.created_at,
            "updated_at": chat.updated_at,
            "messages": [],
        }

    async def update_chat(
        self, chat_id: UUID, chat_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        # Check if chat exists
        chat = await self.chat_repository.get_chat(chat_id)
        if not chat:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND, detail="Chat not found"
            )

        # Update chat
        updated_chat = await self.chat_repository.update_chat(chat_id, chat_data)
        if not updated_chat:
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="Failed to update chat",
            )

        return {
            "id": updated_chat.id,
            "title": updated_chat.title
            if updated_chat.title is not None
            else f"Chat {updated_chat.id}",
            "created_at": updated_chat.created_at,
            "updated_at": updated_chat.updated_at,
        }

    async def delete_chat(self, chat_id: UUID) -> Dict[str, Any]:
        # Check if chat exists
        chat = await self.chat_repository.get_chat(chat_id)
        if not chat:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND, detail="Chat not found"
            )

        # Delete chat
        await self.chat_repository.delete_chat(chat_id)

        return {"success": True, "message": "Chat deleted successfully"}

    # Message operations
    async def create_message(self, message_data: Dict[str, Any]) -> Dict[str, Any]:
        # Check if chat exists
        chat_id = message_data.get("chat_id")
        if not chat_id:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Chat ID is required",
            )

        chat = await self.chat_repository.get_chat(chat_id)
        if not chat:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND, detail="Chat not found"
            )

        # Create message
        message = await self.chat_repository.create_message(message_data)

        return {
            "id": message.id,
            "content": message.content,
            "is_from_ai": bool(message.is_from_ai),
            "created_at": message.created_at,
            "chat_id": message.chat_id,
        }

    async def get_chat_messages(
        self, chat_id: UUID, skip: int = 0, limit: int = 50
    ) -> List[Dict[str, Any]]:
        # Check if chat exists
        chat = await self.chat_repository.get_chat(chat_id)
        if not chat:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND, detail="Chat not found"
            )

        # Get messages
        messages = await self.chat_repository.get_messages_by_chat(
            chat_id, skip=skip, limit=limit
        )

        return [
            {
                "id": message.id,
                "content": message.content,
                "is_from_ai": bool(message.is_from_ai),
                "created_at": message.created_at,
                "chat_id": message.chat_id,
            }
            for message in messages
        ]


def get_chat_service(
    chat_repository: ChatRepository = Depends(get_chat_repository),
) -> ChatService:
    return ChatService(chat_repository)
</file>

<file path="apps/core/services/job_service.py">
"""
Service layer for job-related operations.
"""

from typing import List, Optional

from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm import Session

from apps.core.models.enums import ProcessingStatus
from apps.core.models.video_job_model import VideoJobModel
from apps.core.operations.video_job_repository import VideoJobRepository

# Placeholder for CRUD operations if we create a crud_jobs.py
# from apps.core.crud.crud_jobs import get_jobs_by_user_and_statuses


async def get_user_jobs_by_statuses(
    db: AsyncSession,  # Changed to AsyncSession
    user_id: str,  # Supabase User ID (string/UUID)
    statuses: Optional[List[ProcessingStatus]] = None,
) -> List[VideoJobModel]:
    """
    Retrieves video processing jobs for a specific user, filtered by specified statuses.

    Args:
        db: SQLAlchemy async session.
        user_id: The ID of the user (Supabase string UUID).
        statuses: An optional list of ProcessingStatus enums to filter by.
                  If None or empty, this service will default to PENDING and PROCESSING.

    Returns:
        A list of VideoJobModel objects matching the criteria.
    """
    # If no specific statuses are requested by the client,
    # default to fetching PENDING and PROCESSING jobs.
    if not statuses:
        statuses_to_fetch = [ProcessingStatus.PENDING, ProcessingStatus.PROCESSING]
    else:
        statuses_to_fetch = statuses

    # Repository method is now async, so await the call.
    jobs = await VideoJobRepository.get_by_user_id_and_statuses(
        db=db,
        user_id=user_id,
        statuses=statuses_to_fetch,
        # We can add limit/offset parameters here if needed by the API endpoint later
    )
    return jobs
</file>

<file path="apps/core/services/metadata_service.py">
"""
Metadata service for generating and managing video metadata.

This module provides services for generating video metadata components including
titles, descriptions, tags, and thumbnails.
"""

import logging
import os
from typing import Dict, List

from apps.core.core.exceptions import MetadataGenerationError
from apps.core.lib.ai.base_adapter import AIAdapterInterface
from apps.core.lib.storage.file_storage import FileStorageService
from apps.core.models.video_metadata_model import VideoMetadata


class MetadataService:
    """
    Service for generating video metadata.

    This service handles the generation of various metadata components for videos
    using AI services, including titles, descriptions, tags, and thumbnails.
    """

    def __init__(
        self,
        ai_adapter: AIAdapterInterface,
        storage_adapter: FileStorageService,
        output_dir: str = "metadata",
    ):
        """
        Initialize the MetadataService with required dependencies.

        Args:
            ai_adapter: AI adapter for content generation
            storage_adapter: Storage adapter for file operations
            output_dir: Directory for generated metadata files
        """
        self._ai = ai_adapter
        self._storage = storage_adapter
        self._output_dir = output_dir

        # Ensure output directory exists
        os.makedirs(output_dir, exist_ok=True)

        logging.info(f"Initialized MetadataService with output_dir={output_dir}")

    def generate_metadata(self, transcript: str) -> VideoMetadata:
        """
        Generate complete metadata from a transcript.

        Args:
            transcript: Transcript text

        Returns:
            VideoMetadata object with all metadata components

        Raises:
            MetadataGenerationError: If metadata generation fails
        """
        try:
            logging.info("Generating complete metadata from transcript")

            # Delegate to AI service to generate all metadata components at once
            metadata_dict = self._ai.generate_metadata(transcript)

            # Create VideoMetadata object
            metadata = VideoMetadata(
                title=metadata_dict.get("title", "Untitled Video"),
                description=metadata_dict.get("description", ""),
                tags=metadata_dict.get("tags", []),
                show_notes=metadata_dict.get("show_notes", ""),
                chapters=metadata_dict.get("chapters", []),
            )

            logging.info(
                f"Successfully generated metadata with title: {metadata.title}"
            )
            return metadata

        except Exception as e:
            error_msg = f"Failed to generate metadata: {str(e)}"
            logging.error(error_msg)
            raise MetadataGenerationError(error_msg) from e

    def generate_title(self, transcript: str) -> str:
        """
        Generate a title from a transcript.

        Args:
            transcript: Transcript text

        Returns:
            Generated title

        Raises:
            MetadataGenerationError: If title generation fails
        """
        try:
            logging.info("Generating title from transcript")

            # Use AI to generate title and keywords
            title_tags = self._generate_title_tags(transcript)

            title = title_tags.get("Description", "Untitled Video")
            logging.info(f"Generated title: {title}")
            return title

        except Exception as e:
            error_msg = f"Failed to generate title: {str(e)}"
            logging.error(error_msg)
            raise MetadataGenerationError(error_msg) from e

    def generate_description(self, transcript: str, max_length: int = 500) -> str:
        """
        Generate a description from a transcript.

        Args:
            transcript: Transcript text
            max_length: Maximum length of the description

        Returns:
            Generated description

        Raises:
            MetadataGenerationError: If description generation fails
        """
        try:
            logging.info(
                f"Generating description from transcript (max {max_length} chars)"
            )

            # Use AI to summarize content
            description = self._ai.summarize_content(transcript, max_length)

            logging.info(f"Generated description ({len(description)} chars)")
            return description

        except Exception as e:
            error_msg = f"Failed to generate description: {str(e)}"
            logging.error(error_msg)
            raise MetadataGenerationError(error_msg) from e

    def generate_tags(self, transcript: str, max_tags: int = 10) -> List[str]:
        """
        Generate tags from a transcript.

        Args:
            transcript: Transcript text
            max_tags: Maximum number of tags to generate

        Returns:
            List of generated tags

        Raises:
            MetadataGenerationError: If tag generation fails
        """
        try:
            logging.info(f"Generating tags from transcript (max {max_tags} tags)")

            # Use AI to generate title and keywords
            title_tags = self._generate_title_tags(transcript)

            # Convert comma-separated keywords to list and limit to max_tags
            keywords = title_tags.get("Keywords", "video,content")
            tags = [tag.strip() for tag in keywords.split(",") if tag.strip()][
                :max_tags
            ]

            logging.info(f"Generated {len(tags)} tags")
            return tags

        except Exception as e:
            error_msg = f"Failed to generate tags: {str(e)}"
            logging.error(error_msg)
            raise MetadataGenerationError(error_msg) from e

    def generate_thumbnail_description(
        self, transcript: str, timestamp: float = 30.0
    ) -> str:
        """
        Generate a description for a thumbnail at a specific timestamp.

        Args:
            transcript: Transcript text
            timestamp: Time in seconds for the thumbnail

        Returns:
            Description for the thumbnail

        Raises:
            MetadataGenerationError: If description generation fails
        """
        try:
            logging.info(f"Generating thumbnail description at timestamp {timestamp}s")

            # Delegate to AI adapter
            description = self._ai.generate_thumbnail_description(transcript, timestamp)

            logging.info(f"Generated thumbnail description: {description}")
            return description

        except Exception as e:
            error_msg = f"Failed to generate thumbnail description: {str(e)}"
            logging.error(error_msg)
            raise MetadataGenerationError(error_msg) from e

    def save_metadata_to_json(self, metadata: VideoMetadata, filename: str) -> str:
        """
        Save metadata to a JSON file.

        Args:
            metadata: VideoMetadata object
            filename: Base filename without extension

        Returns:
            Path to the saved JSON file

        Raises:
            MetadataGenerationError: If saving fails
        """
        try:
            # Ensure filename has .json extension
            if not filename.endswith(".json"):
                filename = f"{filename}.json"

            output_path = os.path.join(self._output_dir, filename)

            # Convert metadata to dictionary
            metadata_dict = metadata.to_dict()

            # Save to storage
            json_content = metadata.to_json()
            self._storage.upload_from_string(
                json_content, output_path, content_type="application/json"
            )

            logging.info(f"Saved metadata to {output_path}")
            return output_path

        except Exception as e:
            error_msg = f"Failed to save metadata to JSON: {str(e)}"
            logging.error(error_msg)
            raise MetadataGenerationError(error_msg) from e

    def _generate_title_tags(self, transcript: str) -> Dict[str, str]:
        """
        Generate title and tags as a dictionary from transcript.

        Args:
            transcript: Transcript text

        Returns:
            Dictionary with "Description" (title) and "Keywords" (comma-separated tags)

        Raises:
            MetadataGenerationError: If generation fails
        """
        try:
            # This is a wrapper around the AI adapter method to simplify testing
            # and to provide consistent error handling
            result = self._ai._generate_title_tags(transcript)

            # Ensure required keys are present
            if "Description" not in result:
                result["Description"] = "Untitled Video"

            if "Keywords" not in result:
                result["Keywords"] = "video,content"

            return result

        except Exception as e:
            error_msg = f"Failed to generate title and tags: {str(e)}"
            logging.error(error_msg)
            # Return default values instead of raising to make this more robust
            return {"Description": "Untitled Video", "Keywords": "video,content"}
</file>

<file path="apps/core/services/user_service.py">
from typing import Any, Dict, Optional

from fastapi import Depends, HTTPException, status
from sqlalchemy.ext.asyncio import AsyncSession

from apps.core.lib.auth.supabase_auth import AuthenticatedUser
from apps.core.models.user_model import User
from apps.core.operations.user_repository import UserRepository, get_user_repository


class UserService:
    def __init__(self, user_repository: UserRepository):
        self.user_repository = user_repository

    async def get_user_profile(self, user_id: int) -> Dict[str, Any]:
        user = await self.user_repository.get_user(user_id)
        if not user:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND, detail="User not found"
            )

        # Business logic: exclude sensitive information
        return {
            "id": user.id,
            "username": user.username,
            "email": user.email,
            "full_name": user.full_name,
            "is_active": user.is_active,
        }

    async def get_or_create_user_profile(self, auth_user: AuthenticatedUser) -> User:
        """
        Ensures a local user profile exists for the authenticated user.
        Looks up by email; creates a new user if not found.

        Args:
            auth_user (AuthenticatedUser): Authenticated user from Supabase JWT.

        Returns:
            User: The user model instance.
        """
        if not auth_user.email:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Authenticated user missing email",
            )
        user = await self.user_repository.get_user_by_email(auth_user.email)
        if user:
            return user

        # Generate a username from email prefix or fallback to user id string
        username = (
            auth_user.email.split("@")[0]
            if "@" in auth_user.email
            else f"user_{auth_user.id}"
        )
        user_data = {
            "username": username,
            "email": auth_user.email,
            "full_name": "",
            "hashed_password": "",  # Not used for Supabase-auth users
            "is_active": True,
        }
        user = await self.user_repository.create_user(user_data)
        return user

    async def create_user(self, user_data: Dict[str, Any]) -> Dict[str, Any]:
        # Check if username or email already exists
        email = user_data.get("email")
        if not email:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Email is required",
            )
        if await self.user_repository.get_user_by_email(email):
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Email already registered",
            )

        username = user_data.get("username")
        if not username:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Username is required",
            )
        if await self.user_repository.get_user_by_username(username):
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Username already taken",
            )

        # Create user
        user = await self.user_repository.create_user(user_data)

        # Return user without sensitive information
        return {
            "id": user.id,
            "username": user.username,
            "email": user.email,
            "full_name": user.full_name,
            "is_active": user.is_active,
        }


async def get_user_service(
    user_repository: UserRepository = Depends(get_user_repository),
) -> UserService:
    return UserService(user_repository)
</file>

<file path="apps/core/services/video_processing_service.py">
"""
Service for orchestrating the video processing pipeline.

This module implements the core business logic for video processing workflows,
handling the entire pipeline from initial upload through processing stages to
completion. It coordinates between repositories, storage systems, AI services,
and utility libraries to process videos and extract metadata.

The service manages background tasks, error handling, and provides status tracking
of processing jobs, implementing a robust pipeline for video analysis.

Usage:
    from fastapi import BackgroundTasks, Depends
    from sqlalchemy.orm import Session
    from apps.core.services.video_processing_service import VideoProcessingService

    # Inject dependencies and create service
    video_processing_service = VideoProcessingService(
        video_repo=VideoRepository(),
        job_repo=VideoJobRepository(),
        metadata_repo=VideoMetadataRepository(),
        storage=file_storage_service,
        ai_adapter=ai_adapter,
        ffmpeg_utils=ffmpeg_utils,
        subtitle_utils=subtitle_utils,
        file_utils=file_utils
    )

    # Initiate video processing
    job = await video_processing_service.initiate_video_processing(
        db=db_session,
        original_filename="video.mp4",
        video_content=file_bytes,
        content_type="video/mp4",
        uploader_user_id=user_id,
        background_tasks=background_tasks
    )

    # Get job status
    job_details = await video_processing_service.get_job_details(
        db=db_session,
        job_id=job.id,
        user_id=user_id
    )
"""

from typing import Optional

from fastapi import BackgroundTasks, HTTPException
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm import Session

from apps.core.core.exceptions import VideoProcessingError
from apps.core.lib.ai.base_adapter import AIAdapterInterface
from apps.core.lib.auth.supabase_auth import AuthenticatedUser
from apps.core.lib.database.connection import AsyncSessionLocal, create_async_session
from apps.core.lib.storage.file_storage import FileStorageService
from apps.core.lib.utils.ffmpeg_utils import FfmpegUtils
from apps.core.lib.utils.file_utils import FileUtils
from apps.core.lib.utils.subtitle_utils import SubtitleUtils
from apps.core.models.enums import ProcessingStatus
from apps.core.models.video_job_model import VideoJobModel
from apps.core.models.video_metadata_model import VideoMetadataModel
from apps.core.models.video_model import VideoModel
from apps.core.operations.video_job_repository import VideoJobRepository
from apps.core.operations.video_metadata_repository import VideoMetadataRepository
from apps.core.operations.video_repository import VideoRepository


class VideoProcessingService:
    """
    Service layer for orchestrating the video processing pipeline.

    This service coordinates the end-to-end processing of video uploads, including
    storage, metadata extraction, AI processing, and status tracking. It manages the
    complex workflow of video analysis while keeping the API layer simple.

    Attributes:
        video_repo (VideoRepository): Repository for video data access.
        job_repo (VideoJobRepository): Repository for job data access.
        metadata_repo (VideoMetadataRepository): Repository for metadata access.
        storage (FileStorageService): Service for file storage operations.
        ai_adapter (AIAdapterInterface): AI service for text generation and transcription.
        ffmpeg_utils (FfmpegUtils): Utilities for video processing operations.
        subtitle_utils (SubtitleUtils): Utilities for subtitle generation.
        file_utils (FileUtils): Utilities for file system operations.
    """

    def __init__(
        self,
        video_repo: VideoRepository,
        job_repo: VideoJobRepository,
        metadata_repo: VideoMetadataRepository,
        storage: FileStorageService,
        ai_adapter: AIAdapterInterface,
        ffmpeg_utils: FfmpegUtils,
        subtitle_utils: SubtitleUtils,
        file_utils: FileUtils,
    ):
        self.video_repo = video_repo
        self.job_repo = job_repo
        self.metadata_repo = metadata_repo
        self.storage = storage
        self.ai_adapter = ai_adapter
        self.ffmpeg_utils = ffmpeg_utils
        self.subtitle_utils = subtitle_utils
        self.file_utils = file_utils

    async def initiate_video_processing(
        self,
        db: AsyncSession,
        original_filename: str,
        video_content: bytes,
        content_type: str,
        uploader_user_id: str,
        background_tasks: BackgroundTasks,
    ) -> VideoJobModel:
        """
        Initiate the video processing pipeline for a newly uploaded video.

        This method handles the initial steps of the video processing workflow:
        1. Saves the uploaded video to storage
        2. Creates database records for the video and processing job
        3. Schedules the full processing pipeline as a background task

        Args:
            db (AsyncSession): Database async session for database operations
            original_filename (str): Original filename of the uploaded video
            video_content (bytes): Raw video file content
            content_type (str): MIME type of the video file (e.g., "video/mp4")
            uploader_user_id (str): ID of the user who uploaded the video
            background_tasks (BackgroundTasks): FastAPI background tasks manager

        Returns:
            VideoJobModel: Created job model with PENDING status

        Note:
            This method commits the transaction before returning, ensuring the
            records are visible to the background task that will process the video.
        """
        # Save video file
        stored_video_path = await self.storage.save_file(
            file_content=video_content,
            filename=original_filename,
            subdir=f"uploads/{uploader_user_id}",
        )
        # Create VideoModel
        video = await self.video_repo.create(
            db=db,
            uploader_user_id=uploader_user_id,
            original_filename=original_filename,
            storage_path=stored_video_path,
            content_type=content_type,
            size_bytes=len(video_content),
        )
        # Create VideoJobModel
        job = await self.job_repo.create(
            db=db,
            video_id=video.id,  # type: ignore[arg-type]
            status=ProcessingStatus.PENDING,
            processing_stages=None,
            error_message=None,
        )
        await db.commit()
        # Schedule background processing
        background_tasks.add_task(
            self._execute_processing_pipeline,
            job.id,  # type: ignore[arg-type]
            stored_video_path,  # type: ignore[arg-type]
        )
        return job

    async def _execute_processing_pipeline(
        self,
        job_id: int,
        video_storage_path: str,
    ):
        """
        Execute the full video processing pipeline as a background task.

        This method is the core of the video processing workflow, handling all
        steps from downloading the video through processing to metadata generation.
        It's designed to run as a background task and updates the job status
        throughout the process.

        Processing steps:
        1. Set up a database session and temporary directory
        2. Download the video from storage to local temp directory
        3. Extract basic video metadata (duration, resolution, format)
        4. Extract audio track from the video
        5. Transcribe audio to text using AI service
        6. Generate content metadata (title, description, tags) using AI
        7. Generate subtitle files in multiple formats
        8. Extract thumbnail image from the video
        9. Update job status to COMPLETED when done

        Args:
            job_id (int): ID of the video processing job
            video_storage_path (str): Storage path of the uploaded video

        Note:
            This method handles its own error management, updating the job status to FAILED
            if any step encounters an exception. It also ensures proper cleanup of temporary
            files and database connections.
        """
        async with AsyncSessionLocal() as db_bg:
            temp_dir = self.file_utils.create_temp_dir()
            try:
                job = await self.job_repo.get_by_id(db_bg, job_id)
                if not job:
                    raise VideoProcessingError(
                        f"Job {job_id} not found or video relationship missing"
                    )

                await self.job_repo.update_status(
                    db_bg, job_id, ProcessingStatus.PROCESSING
                )
                await db_bg.commit()

                # Download video to temp dir
                if job.video is None:
                    raise VideoProcessingError(
                        f"Video data not found for job {job_id}. Ensure video relationship is loaded."
                    )
                local_video_path = f"{temp_dir}/{job.video.original_filename}"
                await self.storage.download_file(video_storage_path, local_video_path)

                # Step 1: Basic Metadata
                video_metadata = self.ffmpeg_utils.get_video_metadata_sync(
                    local_video_path
                )
                await self.metadata_repo.create_or_update(
                    db_bg,
                    job_id,
                    extracted_video_duration_seconds=video_metadata.get("duration"),
                    extracted_video_resolution=video_metadata.get("resolution"),
                    extracted_video_format=video_metadata.get("format"),
                )
                await db_bg.commit()

                # Step 2: Extract Audio
                audio_path = f"{temp_dir}/audio.wav"
                self.ffmpeg_utils.extract_audio_sync(local_video_path, audio_path)

                # Step 3: Transcript
                transcript_text = await self.ai_adapter.transcribe_audio(audio_path)
                transcript_file_path = f"{temp_dir}/transcript.txt"
                with open(transcript_file_path, "w") as f:
                    f.write(transcript_text)
                transcript_url = await self.storage.save_file(
                    file_content=transcript_text.encode("utf-8"),
                    filename="transcript.txt",
                    subdir=f"transcripts/{job.video.uploader_user_id}",
                )

                await self.metadata_repo.create_or_update(
                    db_bg,
                    job_id,
                    transcript_text=transcript_text,
                    transcript_file_url=transcript_url,
                )
                await db_bg.commit()

                # Step 4: Content Metadata
                title = await self.ai_adapter.generate_text(
                    prompt="Generate a YouTube-style title for this video.",
                    context=transcript_text,
                )
                description = await self.ai_adapter.generate_text(
                    prompt="Generate a YouTube-style description for this video.",
                    context=transcript_text,
                )
                tags = await self.ai_adapter.generate_text(
                    prompt="Generate a comma-separated list of tags for this video.",
                    context=transcript_text,
                )
                show_notes = await self.ai_adapter.generate_text(
                    prompt="Generate show notes for this video.",
                    context=transcript_text,
                )
                await self.metadata_repo.create_or_update(
                    db_bg,
                    job_id,
                    title=title,
                    description=description,
                    tags=[t.strip() for t in tags.split(",")],
                    show_notes_text=show_notes,
                )
                await db_bg.commit()

                # Step 5: Subtitles
                segments = [
                    {"text": line, "start_time": 0.0, "end_time": 0.0}
                    for line in transcript_text.splitlines()
                ]
                vtt_content = self.subtitle_utils.generate_vtt(segments)
                srt_content = self.subtitle_utils.generate_srt(segments)
                vtt_url = await self.storage.save_file(
                    file_content=vtt_content.encode("utf-8"),
                    filename="subtitles.vtt",
                    subdir=f"subtitles/{job.video.uploader_user_id}",
                )
                srt_url = await self.storage.save_file(
                    file_content=srt_content.encode("utf-8"),
                    filename="subtitles.srt",
                    subdir=f"subtitles/{job.video.uploader_user_id}",
                )
                await self.metadata_repo.create_or_update(
                    db_bg,
                    job_id,
                    subtitle_files_urls={"vtt": vtt_url, "srt": srt_url},
                )
                await db_bg.commit()

                # Step 6: Thumbnail
                thumbnail_path = f"{temp_dir}/thumbnail.jpg"
                self.ffmpeg_utils.extract_frame_sync(
                    local_video_path, 1.0, thumbnail_path
                )
                with open(thumbnail_path, "rb") as f:
                    thumbnail_bytes = f.read()
                thumbnail_url = await self.storage.save_file(
                    file_content=thumbnail_bytes,
                    filename="thumbnail.jpg",
                    subdir=f"thumbnails/{job.video.uploader_user_id}",
                )
                await self.metadata_repo.create_or_update(
                    db_bg,
                    job_id,
                    thumbnail_file_url=thumbnail_url,
                )
                await db_bg.commit()

                # Mark job as completed
                await self.job_repo.update_status(
                    db_bg, job_id, ProcessingStatus.COMPLETED
                )
                await db_bg.commit()
            except Exception as e:
                await self.job_repo.update_status(
                    db_bg, job_id, ProcessingStatus.FAILED
                )
                await self.job_repo.add_processing_stage(
                    db_bg, job_id, f"Error: {str(e)}"
                )
                await db_bg.commit()
            finally:
                self.file_utils.cleanup_temp_dir(temp_dir)
                await db_bg.close()

    async def get_job_details(
        self, db: AsyncSession, job_id: int, user_id: str
    ) -> Optional[VideoJobModel]:
        """
        Retrieve details of a specific video processing job.

        Ensures that the job belongs to the requesting user before returning details.

        Args:
            db (AsyncSession): Database async session for database operations.
            job_id (int): ID of the video processing job.
            user_id (str): ID of the user requesting the job details.

        Returns:
            Optional[VideoJobModel]: The job model if found and user is authorized,
                                     otherwise None or raises HTTPException.
        """
        job = await self.job_repo.get_by_id(db, job_id)
        if not job:
            raise HTTPException(status_code=404, detail="Job not found")

        # Ensure video relationship is loaded by get_by_id or handle potential None
        if job.video is None or job.video.uploader_user_id != user_id:
            raise HTTPException(
                status_code=403, detail="User not authorized to view this job"
            )
        return job
</file>

<file path="apps/core/tests/api/__init__.py">

</file>

<file path="apps/core/tests/api/test_jobs_api.py">
"""
Integration tests for the Jobs API endpoints.
"""

from typing import List, Optional
from unittest.mock import ANY, AsyncMock, MagicMock, patch

import pytest
from fastapi import HTTPException

from apps.core.api.schemas.video_processing_schemas import (
    VideoJobSchema,  # For response validation
    VideoMetadataSchema,
    VideoSchema,
)
from apps.core.lib.auth.supabase_auth import (
    AuthenticatedUser,  # For mocking get_current_user
    get_current_user,
)
from apps.core.models.enums import ProcessingStatus


@pytest.fixture
def mock_authenticated_user_fixture() -> AuthenticatedUser:
    return AuthenticatedUser(
        id="test-user-id", email="test@example.com", aud="authenticated"
    )


@pytest.fixture
def auth_override(mock_authenticated_user_fixture: AuthenticatedUser):
    """Overrides the get_current_user dependency for testing."""

    # It's important that this inner function matches the signature of the original dependency
    async def _override():
        return mock_authenticated_user_fixture

    return _override


@pytest.fixture
def unauth_override():
    async def _override_raise_401():
        raise HTTPException(status_code=401, detail="Not authenticated")

    return _override_raise_401


# Test cases for GET /api/v1/jobs/


def test_get_my_processing_jobs_success_default_statuses(
    test_client_fixture,
    auth_override,
    mock_authenticated_user_fixture: AuthenticatedUser,
):
    """Test successful retrieval of jobs with default status handling in service."""
    app = test_client_fixture.app
    app.dependency_overrides[get_current_user] = auth_override

    # Mock the service call
    # Provide None for optional nested schemas if not testing their content
    mock_job1 = VideoJobSchema(
        id=1, video_id=1, status=ProcessingStatus.PENDING, video=None, metadata=None
    )
    mock_job2 = VideoJobSchema(
        id=2, video_id=2, status=ProcessingStatus.PROCESSING, video=None, metadata=None
    )
    mock_service_response = [mock_job1, mock_job2]

    with patch(
        "apps.core.api.endpoints.jobs_endpoints.get_user_jobs_by_statuses",
        new_callable=AsyncMock,
    ) as mock_service_call:

        async def async_mock_service(*args, **kwargs):
            return mock_service_response

        mock_service_call.return_value = mock_service_response

        response = test_client_fixture.get("/api/v1/jobs/")

        assert response.status_code == 200
        response_data = response.json()
        assert len(response_data) == 2
        assert response_data[0]["id"] == mock_job1.id
        assert response_data[1]["id"] == mock_job2.id
        # Service should be called with current_user.id and default statuses (handled by service)
        mock_service_call.assert_awaited_once_with(
            user_id=mock_authenticated_user_fixture.id,
            db=ANY,
            statuses=None,
        )

    app.dependency_overrides.clear()  # Clear overrides


def test_get_my_processing_jobs_with_specific_statuses(
    test_client_fixture,
    auth_override,
    mock_authenticated_user_fixture: AuthenticatedUser,
):
    app = test_client_fixture.app
    app.dependency_overrides[get_current_user] = auth_override

    mock_job_completed = VideoJobSchema(
        id=3, video_id=3, status=ProcessingStatus.COMPLETED, video=None, metadata=None
    )
    mock_service_response_completed = [mock_job_completed]

    with patch(
        "apps.core.api.endpoints.jobs_endpoints.get_user_jobs_by_statuses",
        new_callable=AsyncMock,
    ) as mock_service_call:

        async def async_mock_service_completed(*args, **kwargs):
            if kwargs.get("statuses") == [ProcessingStatus.COMPLETED]:
                return mock_service_response_completed
            return []

        mock_service_call.return_value = mock_service_response_completed

        response = test_client_fixture.get("/api/v1/jobs/?status=COMPLETED")
        assert response.status_code == 200
        response_data = response.json()
        assert len(response_data) == 1
        assert response_data[0]["id"] == mock_job_completed.id
        mock_service_call.assert_awaited_once_with(
            user_id=mock_authenticated_user_fixture.id,
            db=ANY,
            statuses=[ProcessingStatus.COMPLETED],
        )

    app.dependency_overrides.clear()  # Clear overrides


def test_get_my_processing_jobs_unauthenticated(test_client_fixture, unauth_override):
    """Test API returns 401 if user is not authenticated."""

    app = test_client_fixture.app
    # Override get_current_user to simulate unauthenticated state
    app.dependency_overrides[get_current_user] = unauth_override

    response = test_client_fixture.get("/api/v1/jobs/")
    assert response.status_code == 401

    app.dependency_overrides.clear()


def test_get_my_processing_jobs_invalid_status_parameter(
    test_client_fixture, auth_override
):
    """Test API returns 422 for invalid status query parameter."""
    app = test_client_fixture.app
    app.dependency_overrides[get_current_user] = auth_override

    response = test_client_fixture.get("/api/v1/jobs/?status=INVALID_STATUS_VALUE")
    assert response.status_code == 422  # Unprocessable Entity

    app.dependency_overrides.clear()  # Clear overrides
</file>

<file path="apps/core/tests/integration/api/test_job_status_retrieval.py">
import pytest
from fastapi import FastAPI, status
from httpx import AsyncClient

from apps.core.lib.auth.supabase_auth import get_current_user
from apps.core.models.enums import ProcessingStatus

pytestmark = pytest.mark.integration


@pytest.mark.asyncio
async def test_get_job_status_successful(client: AsyncClient, populated_db):
    """Test successful retrieval of job status for an authorized user."""
    # Get the job from the populated database
    job = populated_db["job"]

    # Make the request
    response = await client.get(f"/api/v1/videos/jobs/{job.id}")

    # Assert response status
    assert response.status_code == status.HTTP_200_OK

    # Verify response format
    json_response = response.json()
    assert "id" in json_response
    assert "status" in json_response
    assert "processing_stages" in json_response
    assert "video" in json_response

    # Verify job data
    assert json_response["id"] == job.id
    assert json_response["status"] == ProcessingStatus.COMPLETED.value

    # Verify video data
    assert json_response["video"]["id"] == populated_db["video"].id
    assert json_response["video"]["uploader_user_id"] == "test-user-id"
    assert json_response["video"]["original_filename"] == "test_video.mp4"


@pytest.mark.asyncio
async def test_get_job_status_nonexistent_job(client: AsyncClient):
    """Test error handling for non-existent job ID."""
    # Use a job ID that doesn't exist
    non_existent_job_id = 9999

    # Make the request
    response = await client.get(f"/api/v1/videos/jobs/{non_existent_job_id}")

    # Should return 404 Not Found
    assert response.status_code == status.HTTP_404_NOT_FOUND


@pytest.mark.asyncio
async def test_get_job_status_unauthorized_user(client: AsyncClient, populated_db):
    """Test unauthorized access to a job owned by another user."""
    # Get the job from the populated database
    job = populated_db["job"]

    # Temporarily override the auth dependency to return a different user
    from apps.core.lib.auth.supabase_auth import AuthenticatedUser
    from apps.core.main import app

    # Create a different user
    async def mock_different_user():
        return AuthenticatedUser(
            id="different-user-id", email="different@example.com", aud="authenticated"
        )

    # Apply the override
    original_override = app.dependency_overrides.get(get_current_user)
    app.dependency_overrides[get_current_user] = mock_different_user

    try:
        # Make the request
        response = await client.get(f"/api/v1/videos/jobs/{job.id}")

        # Should return 403 Forbidden since the job belongs to another user
        assert response.status_code == status.HTTP_403_FORBIDDEN

    finally:
        # Restore the original override
        if original_override:
            app.dependency_overrides[get_current_user] = original_override
        else:
            del app.dependency_overrides[get_current_user]


@pytest.mark.asyncio
async def test_get_job_status_unauthenticated(client: AsyncClient, populated_db):
    """Test job status retrieval for unauthenticated user."""
    # Get the job from the populated database
    job = populated_db["job"]

    # Temporarily override the auth dependency to simulate unauthenticated request
    from fastapi import HTTPException

    from apps.core.main import app

    # Create a function that raises an authentication error
    async def mock_unauthenticated_user():
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Could not validate credentials",
            headers={"WWW-Authenticate": "Bearer"},
        )

    # Apply the override
    original_override = app.dependency_overrides.get(get_current_user)
    app.dependency_overrides[get_current_user] = mock_unauthenticated_user

    try:
        # Make the request
        response = await client.get(f"/api/v1/videos/jobs/{job.id}")

        # Should return 401 Unauthorized
        assert response.status_code == status.HTTP_401_UNAUTHORIZED

    finally:
        # Restore the original override
        if original_override:
            app.dependency_overrides[get_current_user] = original_override
        else:
            del app.dependency_overrides[get_current_user]
</file>

<file path="apps/core/tests/integration/api/test_video_upload_flow.py">
import io
import os

import pytest
from fastapi import FastAPI, status
from httpx import AsyncClient
from sqlalchemy.ext.asyncio import AsyncSession

from apps.core.api.schemas.video_processing_schemas import VideoUploadResponseSchema
from apps.core.lib.database.connection import get_db_session
from apps.core.models.enums import ProcessingStatus

# Import the fixtures from conftest.py
pytestmark = pytest.mark.integration


@pytest.mark.asyncio
async def test_upload_video_successful(
    client: AsyncClient, test_video_file: str, db_session: AsyncSession
):
    """Test successful video upload and initial job creation"""
    # Read the test video file
    with open(test_video_file, "rb") as f:
        file_content = f.read()

    # Create file-like object for multipart upload
    file = io.BytesIO(file_content)

    # Make the request
    response = await client.post(
        "/api/v1/videos/upload",
        files={"file": ("test_video.mp4", file, "video/mp4")},
    )

    # Assert response status and format
    assert response.status_code == status.HTTP_200_OK
    json_response = response.json()

    # Verify response format matches VideoUploadResponseSchema
    assert "job_id" in json_response
    assert "status" in json_response

    # Get the job ID
    job_id = json_response["job_id"]

    # Verify job was created with PENDING status
    assert json_response["status"] == ProcessingStatus.PENDING.value

    # Verify job exists in database
    from apps.core.operations.video_job_repository import VideoJobRepository

    job = await VideoJobRepository.get_by_id(db_session, job_id)

    assert job is not None
    assert job.status == ProcessingStatus.PENDING

    # Verify video was created in database
    from apps.core.operations.video_repository import VideoRepository

    video_id_value: int = job.video_id
    video = await VideoRepository.get_by_id(db_session, video_id_value)

    assert video is not None
    assert video.uploader_user_id == "test-user-id"
    assert video.original_filename == "test_video.mp4"
    assert video.content_type == "video/mp4"


@pytest.mark.asyncio
async def test_upload_video_no_file(client: AsyncClient):
    """Test uploading without a file returns 422"""
    response = await client.post("/api/v1/videos/upload")
    assert response.status_code == status.HTTP_422_UNPROCESSABLE_ENTITY


@pytest.mark.asyncio
async def test_upload_video_unsupported_file_type(client: AsyncClient):
    """Test uploading an unsupported file type"""
    # Create a text file
    file = io.BytesIO(b"This is not a video")

    response = await client.post(
        "/api/v1/videos/upload",
        files={"file": ("test.txt", file, "text/plain")},
    )

    # Should return 400 Bad Request for unsupported content type
    assert response.status_code == status.HTTP_400_BAD_REQUEST


@pytest.mark.asyncio
async def test_upload_video_unauthenticated(client: AsyncClient, test_video_file: str):
    """Test upload fails with invalid authentication"""
    # Temporarily override the auth dependency to simulate unauthenticated request
    from fastapi import HTTPException

    from apps.core.lib.auth.supabase_auth import get_current_user
    from apps.core.main import app

    # Create a function that raises an authentication error
    async def mock_unauthenticated_user():
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Could not validate credentials",
            headers={"WWW-Authenticate": "Bearer"},
        )

    # Apply the override
    original_override = app.dependency_overrides.get(get_current_user)
    app.dependency_overrides[get_current_user] = mock_unauthenticated_user

    try:
        # Read the test video file
        with open(test_video_file, "rb") as f:
            file_content = f.read()

        file = io.BytesIO(file_content)

        # Make the request
        response = await client.post(
            "/api/v1/videos/upload",
            files={"file": ("test_video.mp4", file, "video/mp4")},
        )

        # Should return 401 Unauthorized
        assert response.status_code == status.HTTP_401_UNAUTHORIZED

    finally:
        # Restore the original override
        if original_override:
            app.dependency_overrides[get_current_user] = original_override
        else:
            del app.dependency_overrides[get_current_user]


@pytest.mark.asyncio
async def test_upload_large_video(client: AsyncClient):
    """Test handling of large video files"""
    # Create a large file (10MB)
    large_file = io.BytesIO(b"0" * (10 * 1024 * 1024))

    response = await client.post(
        "/api/v1/videos/upload",
        files={"file": ("large_video.mp4", large_file, "video/mp4")},
    )

    # Should still succeed (assuming no file size limit in the API)
    assert response.status_code == status.HTTP_200_OK
</file>

<file path="apps/core/tests/integration/conftest.py">
import os
import tempfile
from typing import Any, Dict, Generator

import pytest
from fastapi.testclient import TestClient
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

from apps.core.lib.auth.supabase_auth import AuthenticatedUser, get_current_user
from apps.core.lib.database.connection import Base, get_db_session
from apps.core.main import app
from apps.core.models.enums import ProcessingStatus
from apps.core.models.video_job_model import VideoJobModel
from apps.core.models.video_model import VideoModel

# Create test database engine and session
TEST_DB_URL = "sqlite:///./test.db"
engine = create_engine(TEST_DB_URL)
TestingSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)


# Override the get_db dependency
def override_get_db() -> Generator:
    try:
        db = TestingSessionLocal()
        yield db
    finally:
        db.close()


# Override the auth dependency to return test user
def override_get_current_user() -> AuthenticatedUser:
    return AuthenticatedUser(
        id="test-user-id", email="test@example.com", aud="authenticated"
    )


# Apply test dependency overrides
app.dependency_overrides[get_db_session] = override_get_db
app.dependency_overrides[get_current_user] = override_get_current_user


@pytest.fixture
def client() -> TestClient:
    """
    Test client for FastAPI application.
    """
    return TestClient(app)


@pytest.fixture(scope="function")
def db_session() -> Generator:
    """
    Create a fresh database session for each test.
    """
    # Create all tables
    Base.metadata.create_all(bind=engine)

    # Use the session
    try:
        db = TestingSessionLocal()
        yield db
    finally:
        db.close()
        # Drop all tables for a clean slate
        Base.metadata.drop_all(bind=engine)


@pytest.fixture
def authenticated_user() -> AuthenticatedUser:
    """
    Return a mock authenticated user.
    """
    return override_get_current_user()


@pytest.fixture
def test_video_file() -> Generator:
    """
    Create a temporary test video file (mock).
    """
    # Create a temporary file
    fd, path = tempfile.mkstemp(suffix=".mp4")

    # Write some dummy data
    with os.fdopen(fd, "wb") as f:
        f.write(b"mock video data")

    # Return the file path
    yield path

    # Clean up after the test
    if os.path.exists(path):
        os.unlink(path)


@pytest.fixture
def populated_db(db_session) -> Dict[str, Any]:
    """
    Populate the database with test data and return the created objects.
    """
    # Create a test video
    test_video = VideoModel(
        uploader_user_id="test-user-id",
        original_filename="test_video.mp4",
        storage_path="uploads/test-user-id/test_video.mp4",
        content_type="video/mp4",
        size_bytes=1024,
    )
    db_session.add(test_video)
    db_session.flush()

    # Create a test job
    test_job = VideoJobModel(
        video_id=test_video.id,
        status=ProcessingStatus.COMPLETED,
        processing_stages={"transcription": True, "metadata": True},
    )
    db_session.add(test_job)
    db_session.commit()

    return {"video": test_video, "job": test_job}
</file>

<file path="apps/core/tests/integration/test_video_processing_api.py">
import os
import tempfile
from typing import Optional
from unittest.mock import AsyncMock, patch

import pytest
from fastapi import Header, HTTPException, status
from fastapi.testclient import TestClient
from httpx import AsyncClient

import apps.core.models  # Ensure all models are registered before app/db usage
from apps.core.lib.auth.supabase_auth import AuthenticatedUser, get_current_user
from apps.core.main import app


# Dummy AI Adapter for testing
class DummyAIAdapter:
    async def generate_text(self, prompt: str, context: Optional[str] = None) -> str:
        return "dummy ai response"

    async def transcribe_audio(self, audio_file_path: str) -> str:
        return "dummy transcript"


def override_get_ai_adapter(settings_instance=None):
    return DummyAIAdapter()


import sys
from unittest.mock import patch

from apps.core.lib.ai import ai_client_factory


@pytest.fixture(autouse=True, scope="module")
def patch_get_ai_adapter():
    # Patch get_ai_adapter at the import location used by the endpoint
    with patch(
        "apps.core.api.endpoints.video_processing_endpoints.get_ai_adapter",
        new=override_get_ai_adapter,
    ):
        yield


app.dependency_overrides[ai_client_factory.get_ai_adapter] = override_get_ai_adapter

# NOTE: This is a scaffold for integration/E2E tests of the video processing API.
#       Actual test logic, fixtures, and mocks should be implemented as the next step.


# Override get_current_user dependency to bypass JWT validation for tests
# while still requiring an Authorization header to be present
async def override_get_current_user(authorization: Optional[str] = Header(None)):
    if not authorization or not authorization.startswith("Bearer "):
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Invalid authentication credentials",
            headers={"WWW-Authenticate": "Bearer"},
        )
    # If we have an Authorization header, return a test user
    return AuthenticatedUser(
        id="test-user-id", email="test@example.com", aud="authenticated"
    )


app.dependency_overrides = getattr(app, "dependency_overrides", {})
app.dependency_overrides[get_current_user] = override_get_current_user

# client = TestClient(app) # REMOVE: Client will be injected by pytest fixture


# Patch OpenAI client for all tests to avoid real API calls and missing API key errors
@pytest.fixture(autouse=True, scope="module")
def patch_openai_client():
    with patch(
        "openai.resources.chat.completions.AsyncCompletions.create",
        new_callable=AsyncMock,
    ) as mock_create:
        # Return a dummy response structure matching OpenAI's API
        mock_create.return_value = AsyncMock(
            choices=[
                type(
                    "obj",
                    (),
                    {"message": type("msg", (), {"content": "dummy response"})()},
                )()
            ]
        )
        yield mock_create


@pytest.fixture(scope="module")
def test_video_file():
    # Create a temporary dummy video file for upload tests
    fd, path = tempfile.mkstemp(suffix=".mp4")
    with os.fdopen(fd, "wb") as f:
        f.write(os.urandom(1024 * 1024))  # 1MB random data
    yield path
    os.remove(path)


@pytest.mark.asyncio
async def test_upload_video_success(test_video_file, client: AsyncClient):
    """
    Test uploading a video with valid authentication and check response structure.
    """
    # TODO: Replace with a real or properly mocked JWT for Supabase
    valid_token = os.environ.get("TEST_AUTH_TOKEN", "test-token")
    with open(test_video_file, "rb") as f:
        response = await client.post(
            "/api/v1/videos/upload",
            files={"file": ("test.mp4", f, "video/mp4")},
            headers={"Authorization": f"Bearer {valid_token}"},
        )
    assert response.status_code == 200, (
        f"Unexpected status: {response.status_code}, body: {response.text}"
    )
    data = response.json()
    assert "job_id" in data and isinstance(data["job_id"], int)
    assert "status" in data and data["status"] in ("PENDING", "PROCESSING", "COMPLETED")
    # Store job_id for potential use in dependent tests but don't return it
    job_id = data["job_id"]
    assert job_id > 0


@pytest.mark.asyncio
async def test_upload_video_unauthorized(test_video_file, client: AsyncClient):
    """
    Test uploading a video without authentication should fail.
    """
    with open(test_video_file, "rb") as f:
        response = await client.post(
            "/api/v1/videos/upload",
            files={"file": ("test.mp4", f, "video/mp4")},
        )
    assert response.status_code in (401, 403)


@pytest.mark.asyncio
async def test_get_job_details_success(
    monkeypatch, test_video_file, client: AsyncClient
):
    """
    Test retrieving job details after uploading a video.
    """
    # Upload a video and get job_id
    valid_token = os.environ.get("TEST_AUTH_TOKEN", "test-token")
    with open(test_video_file, "rb") as f:
        upload_response = await client.post(
            "/api/v1/videos/upload",
            files={"file": ("test.mp4", f, "video/mp4")},
            headers={"Authorization": f"Bearer {valid_token}"},
        )
    if upload_response.status_code != 200:
        pytest.skip("Upload failed, cannot test job details.")
    job_id = upload_response.json()["job_id"]

    # Retrieve job details
    response = await client.get(
        f"/api/v1/videos/jobs/{job_id}",
        headers={"Authorization": f"Bearer {valid_token}"},
    )
    assert response.status_code == 200, (
        f"Unexpected status: {response.status_code}, body: {response.text}"
    )
    data = response.json()
    assert "id" in data and data["id"] == job_id
    assert "status" in data
    assert "video" in data
    assert "metadata" in data


@pytest.mark.asyncio
async def test_get_job_details_unauthorized(client: AsyncClient):
    """
    Test retrieving job details without authentication should fail.
    """
    job_id = 1  # Arbitrary
    response = await client.get(
        f"/api/v1/videos/jobs/{job_id}",
    )
    assert response.status_code in (401, 403)


@pytest.mark.asyncio
async def test_upload_invalid_file_type(client: AsyncClient):
    """
    Test uploading a non-video file should fail or be handled gracefully.
    """
    valid_token = os.environ.get("TEST_AUTH_TOKEN", "test-token")
    with tempfile.NamedTemporaryFile(suffix=".txt") as f:
        f.write(b"not a video")
        f.flush()
        f.seek(0)
        response = await client.post(
            "/api/v1/videos/upload",
            files={"file": ("test.txt", f, "text/plain")},
            headers={"Authorization": f"Bearer {valid_token}"},
        )
    # Acceptable: 400 Bad Request, 422 Unprocessable Entity, or handled error
    assert response.status_code in (400, 422, 415, 500)


# TODO: Add more E2E scenarios (full pipeline, error cases, etc.)
</file>

<file path="apps/core/tests/operations/__init__.py">

</file>

<file path="apps/core/tests/operations/test_video_job_repository.py">
"""
Unit tests for the VideoJobRepository.
"""

from datetime import datetime, timedelta
from typing import AsyncGenerator, List

import pytest
from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession

from apps.core.lib.database.connection import Base
from apps.core.models.enums import ProcessingStatus
from apps.core.models.video_job_model import VideoJobModel
from apps.core.models.video_model import VideoModel
from apps.core.operations.video_job_repository import VideoJobRepository

# Setup in-memory SQLite database for testing
# engine = create_engine("sqlite:///:memory:")
# TestingSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# db_session fixture - REMOVED (now comes from conftest.py as db_session_fixture)
# @pytest.fixture(scope="function")
# def db_session() -> Generator[Session, None, None]:
#     """Creates a new database session for a test."""
#     Base.metadata.create_all(bind=engine)  # Create tables
#     session = TestingSessionLocal()
#     try:
#         yield session
#     finally:
#         session.close()
#         Base.metadata.drop_all(bind=engine)  # Drop tables after test


class TestVideoJobRepository:
    @pytest.mark.asyncio
    async def test_get_by_user_id_and_statuses_no_jobs(
        self, db_session_fixture: AsyncSession
    ):
        """Test retrieving jobs when no jobs exist for the user."""
        user_id = "test_user_1"
        # Ensure VideoModel for the user exists, otherwise join will fail if jobs were present
        # For this specific test (no jobs), it's fine, but good practice for others.
        video_for_user = VideoModel(
            uploader_user_id=user_id,
            original_filename="test.mp4",
            storage_path="test/path",
            content_type="video/mp4",
            size_bytes=100,
        )
        db_session_fixture.add(video_for_user)
        await db_session_fixture.commit()  # Commit the video

        jobs = await VideoJobRepository.get_by_user_id_and_statuses(
            db=db_session_fixture, user_id=user_id, statuses=[ProcessingStatus.PENDING]
        )
        assert len(jobs) == 0

    @pytest.mark.asyncio
    async def test_get_by_user_id_and_statuses_filters_by_user(
        self, db_session_fixture: AsyncSession
    ):
        """Test that jobs are correctly filtered by user_id."""
        user1_id = "user_1"
        user2_id = "user_2"

        # Video for user 1
        video1 = VideoModel(
            uploader_user_id=user1_id,
            original_filename="video1.mp4",
            storage_path="path1",
            content_type="video/mp4",
            size_bytes=100,
        )
        db_session_fixture.add(video1)
        await db_session_fixture.commit()  # Commit video1 before creating job1
        job1 = VideoJobModel(video_id=video1.id, status=ProcessingStatus.PENDING)
        db_session_fixture.add(job1)
        # await db_session_fixture.commit() # Commit job1 separately if needed, or commit all at once

        # Video for user 2
        video2 = VideoModel(
            uploader_user_id=user2_id,
            original_filename="video2.mp4",
            storage_path="path2",
            content_type="video/mp4",
            size_bytes=100,
        )
        db_session_fixture.add(video2)
        await db_session_fixture.commit()  # Commit video2 before creating job2
        job2 = VideoJobModel(video_id=video2.id, status=ProcessingStatus.PENDING)
        db_session_fixture.add(job2)
        await db_session_fixture.commit()  # Commit jobs

        jobs_user1 = await VideoJobRepository.get_by_user_id_and_statuses(
            db=db_session_fixture, user_id=user1_id, statuses=[ProcessingStatus.PENDING]
        )
        assert len(jobs_user1) == 1
        assert bool(jobs_user1[0].id == job1.id)
        assert bool(jobs_user1[0].video.uploader_user_id == user1_id)

        jobs_user2 = await VideoJobRepository.get_by_user_id_and_statuses(
            db=db_session_fixture, user_id=user2_id, statuses=[ProcessingStatus.PENDING]
        )
        assert len(jobs_user2) == 1
        assert bool(jobs_user2[0].id == job2.id)
        assert bool(jobs_user2[0].video.uploader_user_id == user2_id)

    @pytest.mark.asyncio
    async def test_get_by_user_id_and_statuses_filters_by_multiple_statuses(
        self, db_session_fixture: AsyncSession
    ):
        user_id = "multi_status_user"
        video = VideoModel(
            uploader_user_id=user_id,
            original_filename="video.mp4",
            storage_path="path",
            content_type="video/mp4",
            size_bytes=100,
        )
        db_session_fixture.add(video)
        await db_session_fixture.commit()

        job_pending = VideoJobModel(
            video_id=video.id,
            status=ProcessingStatus.PENDING,
            created_at=datetime.utcnow() - timedelta(hours=2),
        )
        job_processing = VideoJobModel(
            video_id=video.id,
            status=ProcessingStatus.PROCESSING,
            created_at=datetime.utcnow() - timedelta(hours=1),
        )
        job_completed = VideoJobModel(
            video_id=video.id,
            status=ProcessingStatus.COMPLETED,
            created_at=datetime.utcnow(),
        )
        db_session_fixture.add_all([job_pending, job_processing, job_completed])
        await db_session_fixture.commit()

        # Test fetching PENDING and PROCESSING
        jobs_pending_processing = await VideoJobRepository.get_by_user_id_and_statuses(
            db=db_session_fixture,
            user_id=user_id,
            statuses=[ProcessingStatus.PENDING, ProcessingStatus.PROCESSING],
        )
        assert len(jobs_pending_processing) == 2
        job_ids_pending_processing = {job.id for job in jobs_pending_processing}
        assert job_pending.id in job_ids_pending_processing
        assert job_processing.id in job_ids_pending_processing

        # Test fetching only COMPLETED
        jobs_completed_list = await VideoJobRepository.get_by_user_id_and_statuses(
            db=db_session_fixture,
            user_id=user_id,
            statuses=[ProcessingStatus.COMPLETED],
        )
        assert len(jobs_completed_list) == 1
        assert bool(jobs_completed_list[0].id == job_completed.id)

    @pytest.mark.asyncio
    async def test_get_by_user_id_and_statuses_no_status_filter(
        self, db_session_fixture: AsyncSession
    ):
        """Test behavior when statuses is None (should return all for user)."""
        user_id = "no_status_filter_user"
        video = VideoModel(
            uploader_user_id=user_id,
            original_filename="video.mp4",
            storage_path="path",
            content_type="video/mp4",
            size_bytes=100,
        )
        db_session_fixture.add(video)
        await db_session_fixture.commit()

        job_pending = VideoJobModel(video_id=video.id, status=ProcessingStatus.PENDING)
        job_completed = VideoJobModel(
            video_id=video.id, status=ProcessingStatus.COMPLETED
        )
        db_session_fixture.add_all([job_pending, job_completed])
        await db_session_fixture.commit()

        jobs = await VideoJobRepository.get_by_user_id_and_statuses(
            db=db_session_fixture, user_id=user_id, statuses=None
        )
        assert len(jobs) == 2

    @pytest.mark.asyncio
    async def test_get_by_user_id_and_statuses_ordering(
        self, db_session_fixture: AsyncSession
    ):
        user_id = "ordering_user"
        video = VideoModel(
            uploader_user_id=user_id,
            original_filename="video.mp4",
            storage_path="path",
            content_type="video/mp4",
            size_bytes=100,
        )
        db_session_fixture.add(video)
        await db_session_fixture.commit()

        # Timestamps are important here
        job1_older = VideoJobModel(
            video_id=video.id,
            status=ProcessingStatus.PENDING,
            created_at=datetime.utcnow() - timedelta(minutes=10),
        )
        job2_newer = VideoJobModel(
            video_id=video.id,
            status=ProcessingStatus.PENDING,
            created_at=datetime.utcnow() - timedelta(minutes=1),
        )
        job3_oldest = VideoJobModel(
            video_id=video.id,
            status=ProcessingStatus.PROCESSING,
            created_at=datetime.utcnow() - timedelta(minutes=20),
        )
        db_session_fixture.add_all([job1_older, job2_newer, job3_oldest])
        await db_session_fixture.commit()

        jobs = await VideoJobRepository.get_by_user_id_and_statuses(
            db=db_session_fixture, user_id=user_id, statuses=None
        )
        assert len(jobs) == 3
        assert bool(jobs[0].id == job2_newer.id)  # Newest first
        assert bool(jobs[1].id == job1_older.id)
        assert bool(jobs[2].id == job3_oldest.id)  # Oldest last

    @pytest.mark.asyncio
    async def test_get_by_user_id_and_statuses_pagination(
        self, db_session_fixture: AsyncSession
    ):
        user_id = "pagination_user"
        video = VideoModel(
            uploader_user_id=user_id,
            original_filename="video.mp4",
            storage_path="path",
            content_type="video/mp4",
            size_bytes=100,
        )
        db_session_fixture.add(video)
        await db_session_fixture.commit()

        all_jobs_data = []
        for i in range(5):  # Create 5 jobs
            job = VideoJobModel(
                video_id=video.id,
                status=ProcessingStatus.PENDING,
                created_at=datetime.utcnow() - timedelta(minutes=i),
            )
            all_jobs_data.append(job)
        db_session_fixture.add_all(all_jobs_data)
        await db_session_fixture.commit()

        # Test fetching first page (limit 2)
        jobs_page1 = await VideoJobRepository.get_by_user_id_and_statuses(
            db=db_session_fixture,
            user_id=user_id,
            statuses=[ProcessingStatus.PENDING],
            limit=2,
            offset=0,
        )
        assert len(jobs_page1) == 2
        # Assuming jobs are ordered by created_at desc by default (newest first)
        # Newest is -0 minutes ago, then -1 minutes ago
        assert bool(jobs_page1[0].created_at > jobs_page1[1].created_at)

        # Test fetching second page (limit 2, offset 2)
        jobs_page2 = await VideoJobRepository.get_by_user_id_and_statuses(
            db=db_session_fixture,
            user_id=user_id,
            statuses=[ProcessingStatus.PENDING],
            limit=2,
            offset=2,
        )
        assert len(jobs_page2) == 2
        assert bool(
            jobs_page1[1].created_at > jobs_page2[0].created_at
        )  # End of page 1 vs start of page 2

        # Test fetching a page that exceeds total items
        jobs_page_exceed = await VideoJobRepository.get_by_user_id_and_statuses(
            db=db_session_fixture,
            user_id=user_id,
            statuses=[ProcessingStatus.PENDING],
            limit=2,
            offset=4,  # 5 items total, offset 4 means 5th item
        )
        assert len(jobs_page_exceed) == 1

        # Test fetching with limit only (no offset)
        jobs_limit_only = await VideoJobRepository.get_by_user_id_and_statuses(
            db=db_session_fixture,
            user_id=user_id,
            statuses=[ProcessingStatus.PENDING],
            limit=3,
        )
        assert len(jobs_limit_only) == 3

    @pytest.mark.asyncio
    async def test_get_by_user_id_and_statuses_no_matching_status(
        self, db_session_fixture: AsyncSession
    ):
        user_id = "no_match_status_user"
        video = VideoModel(
            uploader_user_id=user_id,
            original_filename="video.mp4",
            storage_path="path",
            content_type="video/mp4",
            size_bytes=100,
        )
        db_session_fixture.add(video)
        await db_session_fixture.commit()

        job_pending = VideoJobModel(video_id=video.id, status=ProcessingStatus.PENDING)
        db_session_fixture.add(job_pending)
        await db_session_fixture.commit()

        jobs = await VideoJobRepository.get_by_user_id_and_statuses(
            db=db_session_fixture,
            user_id=user_id,
            statuses=[ProcessingStatus.COMPLETED],
        )
        assert len(jobs) == 0

    @pytest.mark.asyncio
    async def test_eager_loading(self, db_session_fixture: AsyncSession):
        """Test that video and video_metadata are eagerly loaded."""
        user_id = "eager_loading_user"
        video = VideoModel(
            uploader_user_id=user_id,
            original_filename="video_eager.mp4",
            storage_path="path_eager",
            content_type="video/mp4",
            size_bytes=100,
            # video_metadata field is implicitly handled via backref if VideoMetadataModel has one
            # or can be explicitly set if VideoMetadataModel instance is created and linked
        )
        db_session_fixture.add(video)
        await db_session_fixture.commit()  # Commit video first to get its ID

        # Create a job linked to this video
        job = VideoJobModel(video_id=video.id, status=ProcessingStatus.PENDING)
        db_session_fixture.add(job)
        await db_session_fixture.commit()

        # Clear the session to ensure objects are loaded from DB, not cache, for testing eager loading
        db_session_fixture.expunge_all()
        # Alternatively, and often better for testing eager loads against the DB:
        # await db_session_fixture.close()
        # db_session_fixture = await anext(db_session_fixture_gen()) # if db_session_fixture was a generator

        # Retrieve the job.
        # The get_by_user_id_and_statuses method should use joinedload/selectinload
        retrieved_jobs = await VideoJobRepository.get_by_user_id_and_statuses(
            db=db_session_fixture, user_id=user_id, statuses=[ProcessingStatus.PENDING]
        )
        assert len(retrieved_jobs) == 1
        retrieved_job = retrieved_jobs[0]

        # Accessing .video and .video.video_metadata should not trigger new SQL queries
        # This is hard to assert directly without inspecting SQL queries (e.g. using an event listener)
        # For now, we assume the repository's query options handle this.
        # A simple check is that the attributes are accessible:
        assert retrieved_job.video is not None
        assert retrieved_job.video.original_filename == "video_eager.mp4"
        # If VideoMetadataModel was setup and linked, you would check it too:
        # assert retrieved_job.video.video_metadata is not None
        # assert retrieved_job.video.video_metadata.title == "Some Title" # if metadata was created and linked

        # To truly test eager loading, you'd need to mock the session or use SQLAlchemy events
        # to count queries. For this test, we rely on the implementation detail of the repository.
        # One indirect way is to check if the relationship is loaded without error after expunging.
        # If it wasn't eagerly loaded, accessing it might raise a DetachedInstanceError or similar,
        # or it would be None if the session was completely closed and reopened.
        # Since we are just expunging, the objects are detached but still in memory.
        # A more robust test would involve a fresh session or query counting.

        # For this test, let's ensure the related video's uploader_user_id is correct,
        # which implies 'video' was loaded.
        assert retrieved_job.video.uploader_user_id == user_id

    # TODO:
    # - (No outstanding major categories from previous TODO, covered above)
</file>

<file path="apps/core/tests/services/__init__.py">

</file>

<file path="apps/core/tests/services/test_job_service.py">
"""
Unit tests for the JobService.
"""

from typing import List, Optional
from unittest.mock import AsyncMock, MagicMock, patch

import pytest
from sqlalchemy.ext.asyncio import AsyncSession

from apps.core.models.enums import ProcessingStatus
from apps.core.models.video_job_model import VideoJobModel
from apps.core.services.job_service import get_user_jobs_by_statuses


@pytest.mark.asyncio
async def test_get_user_jobs_by_statuses_with_specific_statuses():
    """Test service passes specific statuses to the repository."""
    mock_db_session = AsyncMock(spec=AsyncSession)
    user_id = "test_user"
    specific_statuses = [ProcessingStatus.COMPLETED]
    expected_jobs_data = [
        VideoJobModel(id=1, video_id=101, status=ProcessingStatus.COMPLETED)
    ]

    with patch(
        "apps.core.services.job_service.VideoJobRepository.get_by_user_id_and_statuses",
        new_callable=AsyncMock,
    ) as mock_repo_call:
        mock_repo_call.return_value = expected_jobs_data

        result_jobs = await get_user_jobs_by_statuses(
            db=mock_db_session, user_id=user_id, statuses=specific_statuses
        )

        mock_repo_call.assert_awaited_once_with(
            db=mock_db_session, user_id=user_id, statuses=specific_statuses
        )
        assert result_jobs == expected_jobs_data


@pytest.mark.asyncio
async def test_get_user_jobs_by_statuses_with_no_statuses_defaults_correctly():
    """Test service defaults to PENDING and PROCESSING when no statuses are provided."""
    mock_db_session = AsyncMock(spec=AsyncSession)
    user_id = "test_user_default"
    default_statuses = [ProcessingStatus.PENDING, ProcessingStatus.PROCESSING]
    expected_jobs_data = [
        VideoJobModel(id=2, video_id=102, status=ProcessingStatus.PENDING),
        VideoJobModel(id=3, video_id=103, status=ProcessingStatus.PROCESSING),
    ]

    with patch(
        "apps.core.services.job_service.VideoJobRepository.get_by_user_id_and_statuses",
        new_callable=AsyncMock,
    ) as mock_repo_call:
        mock_repo_call.return_value = expected_jobs_data

        # Test with statuses=None
        result_jobs_none = await get_user_jobs_by_statuses(
            db=mock_db_session, user_id=user_id, statuses=None
        )
        mock_repo_call.assert_awaited_with(
            db=mock_db_session,
            user_id=user_id,
            statuses=default_statuses,
        )
        assert result_jobs_none == expected_jobs_data

        # Test with statuses=[] (empty list)
        result_jobs_empty = await get_user_jobs_by_statuses(
            db=mock_db_session, user_id=user_id, statuses=[]
        )
        mock_repo_call.assert_awaited_with(
            db=mock_db_session,
            user_id=user_id,
            statuses=default_statuses,
        )
        assert result_jobs_empty == expected_jobs_data

        # To be very precise about both calls:
        assert mock_repo_call.await_count == 2
        call_args_list = mock_repo_call.await_args_list
        assert call_args_list[0].kwargs["statuses"] == default_statuses
        assert call_args_list[1].kwargs["statuses"] == default_statuses


@pytest.mark.asyncio
async def test_get_user_jobs_by_statuses_returns_repository_result():
    """Test that the service function returns whatever the repository provides."""
    mock_db_session = AsyncMock(spec=AsyncSession)
    user_id = "test_user_return"
    mock_jobs_from_repo = [
        VideoJobModel(id=1, video_id=1, status=ProcessingStatus.PENDING),
        VideoJobModel(id=2, video_id=2, status=ProcessingStatus.PROCESSING),
    ]

    with patch(
        "apps.core.services.job_service.VideoJobRepository.get_by_user_id_and_statuses",
        new_callable=AsyncMock,
    ) as mock_repo_call:
        mock_repo_call.return_value = mock_jobs_from_repo

        result_jobs = await get_user_jobs_by_statuses(
            db=mock_db_session, user_id=user_id, statuses=[ProcessingStatus.PENDING]
        )
        mock_repo_call.assert_awaited_once_with(
            db=mock_db_session, user_id=user_id, statuses=[ProcessingStatus.PENDING]
        )
        assert result_jobs == mock_jobs_from_repo
</file>

<file path="apps/core/tests/unit/lib/ai/__init__.py">
"""
Unit tests for AI adapters and services.
"""
</file>

<file path="apps/core/tests/unit/lib/ai/test_ai_client_factory.py">
"""
Unit tests for the AI client factory.
"""

from unittest.mock import patch

import pytest
from core.config import Settings

from apps.core.lib.ai.ai_client_factory import get_ai_adapter
from apps.core.lib.ai.base_adapter import AIAdapterInterface
from apps.core.lib.ai.gemini_adapter import GeminiAdapter


@pytest.fixture
def mock_settings_gemini():
    """Create mock settings with Gemini API key."""
    settings = Settings()
    settings.GEMINI_API_KEY = "fake-gemini-api-key"
    return settings


@pytest.fixture
def mock_settings_no_keys():
    """Create mock settings without any API keys."""
    settings = Settings()
    settings.GEMINI_API_KEY = None
    return settings


class TestAIClientFactory:
    """Test cases for the AI client factory."""

    def test_get_ai_adapter_with_gemini_key(self, mock_settings_gemini):
        """Test get_ai_adapter returns GeminiAdapter when Gemini API key is available."""
        with patch("apps.core.lib.ai.gemini_adapter.GeminiAdapter") as mock_gemini:
            # Configure the mock to return itself when called
            mock_gemini.return_value = mock_gemini

            # Call the factory function
            adapter = get_ai_adapter(mock_settings_gemini)

            # Verify GeminiAdapter was created with the settings
            mock_gemini.assert_called_once_with(mock_settings_gemini)

            # Verify correct adapter was returned
            assert adapter == mock_gemini

    def test_get_ai_adapter_with_no_keys(self, mock_settings_no_keys):
        """Test get_ai_adapter falls back to GeminiAdapter when no keys are available."""
        # This will raise an error since the GeminiAdapter requires an API key
        with pytest.raises(ValueError) as excinfo:
            get_ai_adapter(mock_settings_no_keys)

        assert "GEMINI_API_KEY must be set" in str(excinfo.value)

    @patch("core.config.settings")
    def test_get_ai_adapter_uses_global_settings(self, mock_global_settings):
        """Test get_ai_adapter uses global settings when none are provided."""
        # Configure the global settings mock
        mock_global_settings.GEMINI_API_KEY = "global-gemini-key"

        with patch("apps.core.lib.ai.gemini_adapter.GeminiAdapter") as mock_gemini:
            # Configure the mock to return itself when called
            mock_gemini.return_value = mock_gemini

            # Call the factory function without settings
            adapter = get_ai_adapter()

            # Verify GeminiAdapter was created with the global settings
            mock_gemini.assert_called_once_with(mock_global_settings)

            # Verify correct adapter was returned
            assert adapter == mock_gemini

    def test_get_ai_adapter_fallback_behavior(self):
        """Test the fallback behavior of get_ai_adapter."""
        custom_settings = Settings()
        custom_settings.GEMINI_API_KEY = "test-key"

        # Create a patch for GeminiAdapter that verifies it was called with our settings
        with patch("apps.core.lib.ai.gemini_adapter.GeminiAdapter") as mock_gemini:
            adapter = get_ai_adapter(custom_settings)
            mock_gemini.assert_called_once_with(custom_settings)
</file>

<file path="apps/core/tests/unit/lib/ai/test_gemini_adapter.py">
"""
Unit tests for the Gemini AI adapter.
"""

import asyncio
import json
import os
from unittest.mock import AsyncMock, MagicMock, patch

import pytest
from core.config import Settings
from core.exceptions import VideoProcessingError

from apps.core.lib.ai.gemini_adapter import AINoResponseError, GeminiAdapter


@pytest.fixture
def mock_settings():
    """Create mock settings with a valid Gemini API key."""
    settings = Settings()
    settings.GEMINI_API_KEY = "fake-api-key"
    return settings


@pytest.fixture
def mock_settings_no_api_key():
    """Create mock settings without a Gemini API key."""
    settings = Settings()
    settings.GEMINI_API_KEY = None
    return settings


@pytest.fixture
def mock_audio_file():
    """Create a temporary audio file for testing."""
    import tempfile

    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as temp_file:
        temp_file.write(b"fake audio data")
        temp_file_path = temp_file.name

    yield temp_file_path

    # Clean up
    if os.path.exists(temp_file_path):
        os.unlink(temp_file_path)


@pytest.fixture
def mock_genai():
    """Mock the Google Generative AI library."""
    with patch("lib.ai.gemini_adapter.genai") as mock_genai:
        # Mock the GenerativeModel class
        mock_text_model = MagicMock()
        mock_vision_model = MagicMock()

        # Mock the text response
        mock_response = MagicMock()
        mock_response.text = "Generated text from Gemini"
        mock_text_model.generate_content.return_value = mock_response

        # Set up the GenerativeModel constructor to return our mocks
        mock_genai.GenerativeModel.side_effect = (
            lambda model_name: mock_text_model
            if model_name == "gemini-pro"
            else mock_vision_model
        )

        yield mock_genai


class TestGeminiAdapter:
    """Test cases for the GeminiAdapter class."""

    def test_initialization_with_valid_api_key(self, mock_settings, mock_genai):
        """Test adapter initialization with a valid API key."""
        adapter = GeminiAdapter(mock_settings)

        # Verify genai was configured with the API key
        mock_genai.configure.assert_called_once_with(api_key="fake-api-key")

        # Verify models were initialized
        assert adapter.text_model is not None
        assert adapter.vision_model is not None

    def test_initialization_without_api_key(self, mock_settings_no_api_key):
        """Test adapter initialization fails without an API key."""
        with pytest.raises(ValueError) as excinfo:
            GeminiAdapter(mock_settings_no_api_key)

        assert "GEMINI_API_KEY must be set" in str(excinfo.value)

    @pytest.mark.asyncio
    async def test_generate_text_with_prompt_only(self, mock_settings, mock_genai):
        """Test generate_text with a prompt but no context."""
        adapter = GeminiAdapter(mock_settings)

        result = await adapter.generate_text("Generate a poem about AI")

        # Verify the model was called with the correct prompt
        adapter.text_model.generate_content.assert_called_once_with(
            "Generate a poem about AI"
        )

        # Verify the result
        assert result == "Generated text from Gemini"

    @pytest.mark.asyncio
    async def test_generate_text_with_prompt_and_context(
        self, mock_settings, mock_genai
    ):
        """Test generate_text with both prompt and context."""
        adapter = GeminiAdapter(mock_settings)

        result = await adapter.generate_text(
            prompt="Generate a poem about AI",
            context="Make it sound hopeful and optimistic",
        )

        # Verify the model was called with the combined prompt and context
        adapter.text_model.generate_content.assert_called_once_with(
            "Make it sound hopeful and optimistic\n\nGenerate a poem about AI"
        )

        # Verify the result
        assert result == "Generated text from Gemini"

    @pytest.mark.asyncio
    async def test_generate_text_handles_errors(self, mock_settings, mock_genai):
        """Test generate_text handles errors properly."""
        adapter = GeminiAdapter(mock_settings)

        # Set up the mock to raise an exception
        adapter.text_model.generate_content.side_effect = Exception("API error")

        # Test that our method wraps the exception properly
        with pytest.raises(AINoResponseError) as excinfo:
            await adapter.generate_text("Generate a poem about AI")

        assert "Error generating text with Gemini" in str(excinfo.value)

    @pytest.mark.asyncio
    async def test_generate_text_handles_empty_response(
        self, mock_settings, mock_genai
    ):
        """Test generate_text handles empty response."""
        adapter = GeminiAdapter(mock_settings)

        # Set up the mock to return None
        adapter.text_model.generate_content.return_value = None

        # Test that our method detects the empty response
        with pytest.raises(AINoResponseError) as excinfo:
            await adapter.generate_text("Generate a poem about AI")

        assert "Gemini failed to generate a response" in str(excinfo.value)

    @pytest.mark.asyncio
    async def test_transcribe_audio(self, mock_settings, mock_genai, mock_audio_file):
        """Test transcribe_audio method."""
        adapter = GeminiAdapter(mock_settings)

        # Since Gemini doesn't natively support audio transcription (per the implementation),
        # verify it raises NotImplementedError wrapped in our AINoResponseError
        with pytest.raises(AINoResponseError) as excinfo:
            await adapter.transcribe_audio(mock_audio_file)

        assert "not supported by Gemini" in str(excinfo.value)

    @pytest.mark.asyncio
    async def test_transcribe_audio_file_not_found(self, mock_settings, mock_genai):
        """Test transcribe_audio with a non-existent file."""
        adapter = GeminiAdapter(mock_settings)

        with pytest.raises(FileNotFoundError):
            await adapter.transcribe_audio("/nonexistent/audio.mp3")

    @pytest.mark.asyncio
    async def test_analyze_content(self, mock_settings, mock_genai):
        """Test analyze_content method."""
        adapter = GeminiAdapter(mock_settings)

        # Mock the JSON response
        adapter.text_model.generate_content.return_value.text = json.dumps(
            {
                "title": "Test Title",
                "description": "Test description",
                "tags": ["test", "ai", "gemini"],
                "key_points": ["Point 1", "Point 2", "Point 3"],
                "sentiment": "positive",
            }
        )

        result = await adapter.analyze_content("This is content to analyze")

        # Verify the model was called with the structured prompt
        assert adapter.text_model.generate_content.called

        # Verify the result contains expected keys
        assert "title" in result
        assert "description" in result
        assert "tags" in result
        assert "key_points" in result
        assert "sentiment" in result

        # Verify specific values
        assert result["title"] == "Test Title"
        assert result["tags"] == ["test", "ai", "gemini"]

    @pytest.mark.asyncio
    async def test_analyze_content_handles_malformed_json(
        self, mock_settings, mock_genai
    ):
        """Test analyze_content handles malformed JSON."""
        adapter = GeminiAdapter(mock_settings)

        # Mock malformed JSON response
        adapter.text_model.generate_content.return_value.text = "Not a valid JSON"

        # Test that our method wraps the JSON decode exception
        with pytest.raises(AINoResponseError) as excinfo:
            await adapter.analyze_content("This is content to analyze")

        assert "Gemini returned malformed JSON" in str(excinfo.value)

    @pytest.mark.asyncio
    async def test_segment_transcript(self, mock_settings, mock_genai):
        """Test segment_transcript method."""
        adapter = GeminiAdapter(mock_settings)

        # Mock the JSON response for transcript segmentation
        adapter.text_model.generate_content.return_value.text = json.dumps(
            [
                {"text": "First segment", "start_time": 0.0, "end_time": 5.0},
                {"text": "Second segment", "start_time": 5.0, "end_time": 10.0},
            ]
        )

        result = await adapter.segment_transcript("This is a transcript to segment")

        # Verify the model was called with the structured prompt
        assert adapter.text_model.generate_content.called

        # Verify the result is a list of segments
        assert isinstance(result, list)
        assert len(result) == 2

        # Verify each segment has required fields
        for segment in result:
            assert "text" in segment
            assert "start_time" in segment
            assert "end_time" in segment

    @pytest.mark.asyncio
    async def test_summarize_text(self, mock_settings, mock_genai):
        """Test summarize_text method."""
        adapter = GeminiAdapter(mock_settings)

        # Test without max_length
        result1 = await adapter.summarize_text("This is text to summarize")

        # Verify the model was called with the right prompt
        adapter.text_model.generate_content.assert_called_with(
            "Summarize the following text in a concise manner:\n\nThis is text to summarize"
        )

        # Test with max_length
        result2 = await adapter.summarize_text(
            "This is text to summarize", max_length=100
        )

        # Verify the model was called with the right prompt including max_length
        adapter.text_model.generate_content.assert_called_with(
            "Summarize the following text in a concise manner in 100 characters or less:\n\nThis is text to summarize"
        )
</file>

<file path="apps/core/tests/unit/lib/auth/__init__.py">
"""
Unit tests for authentication utilities.
"""
</file>

<file path="apps/core/tests/unit/lib/auth/test_supabase_auth.py">
"""
Unit tests for Supabase authentication utilities.
"""

from datetime import datetime, timedelta
from unittest.mock import AsyncMock, MagicMock, patch

import pytest
from fastapi import HTTPException
from jose import jwt

from apps.core.core.config import Settings
from apps.core.lib.auth.supabase_auth import (
    AuthenticatedUser,
    get_current_user,
    oauth2_scheme,
)


@pytest.fixture
def mock_settings():
    """Create a mock settings object with JWT configuration."""
    settings = Settings()
    settings.SUPABASE_JWT_SECRET = "test_secret_key"
    settings.ALGORITHM = "HS256"
    return settings


@pytest.fixture
def valid_token_payload():
    """Create a valid token payload."""
    return {
        "sub": "user-id-123",
        "email": "test@example.com",
        "aud": "authenticated",
        "exp": datetime.utcnow() + timedelta(minutes=15),
    }


@pytest.fixture
def valid_jwt(valid_token_payload, mock_settings):
    """Create a valid JWT token."""
    with patch("apps.core.lib.auth.supabase_auth.settings", mock_settings):
        return jwt.encode(
            valid_token_payload,
            mock_settings.SUPABASE_JWT_SECRET,
            algorithm=mock_settings.ALGORITHM,
        )


class TestAuthenticatedUser:
    """Test cases for the AuthenticatedUser model."""

    def test_authenticated_user_model(self):
        """Test creating an AuthenticatedUser instance."""
        user = AuthenticatedUser(
            id="user-id-123", email="test@example.com", aud="authenticated"
        )

        assert user.id == "user-id-123"
        assert user.email == "test@example.com"
        assert user.aud == "authenticated"

    def test_authenticated_user_optional_fields(self):
        """Test creating an AuthenticatedUser with only required fields."""
        user = AuthenticatedUser(id="user-id-456")

        assert user.id == "user-id-456"
        assert user.email is None
        assert user.aud is None


class TestGetCurrentUser:
    """Test cases for the get_current_user function."""

    @pytest.mark.asyncio
    async def test_get_current_user_valid_token(
        self, valid_jwt, mock_settings, valid_token_payload
    ):
        """Test getting the current user with a valid token."""
        with patch("apps.core.lib.auth.supabase_auth.settings", mock_settings):
            user = await get_current_user(valid_jwt)

            assert user.id == valid_token_payload["sub"]
            assert user.email == valid_token_payload["email"]
            assert user.aud == valid_token_payload["aud"]

    @pytest.mark.asyncio
    async def test_get_current_user_invalid_token(self, mock_settings):
        """Test getting the current user with an invalid token."""
        with patch("apps.core.lib.auth.supabase_auth.settings", mock_settings):
            with pytest.raises(HTTPException) as excinfo:
                await get_current_user("invalid_token")

            assert excinfo.value.status_code == 401
            assert "Could not validate Supabase credentials" in excinfo.value.detail

    @pytest.mark.asyncio
    async def test_get_current_user_missing_sub(self, mock_settings):
        """Test getting the current user with a token missing the 'sub' claim."""
        # Create a token without the 'sub' claim
        payload = {
            "email": "test@example.com",
            "aud": "authenticated",
            "exp": datetime.utcnow() + timedelta(minutes=15),
        }
        token = jwt.encode(
            payload,
            mock_settings.SUPABASE_JWT_SECRET,
            algorithm=mock_settings.ALGORITHM,
        )

        with patch("apps.core.lib.auth.supabase_auth.settings", mock_settings):
            with pytest.raises(HTTPException) as excinfo:
                await get_current_user(token)

            assert excinfo.value.status_code == 401

    @pytest.mark.asyncio
    async def test_get_current_user_expired_token(self, mock_settings):
        """Test getting the current user with an expired token."""
        # Create an expired token
        payload = {
            "sub": "user-id-123",
            "email": "test@example.com",
            "aud": "authenticated",
            "exp": datetime.utcnow() - timedelta(minutes=15),  # Expired 15 minutes ago
        }
        token = jwt.encode(
            payload,
            mock_settings.SUPABASE_JWT_SECRET,
            algorithm=mock_settings.ALGORITHM,
        )

        with patch("apps.core.lib.auth.supabase_auth.settings", mock_settings):
            with pytest.raises(HTTPException) as excinfo:
                await get_current_user(token)

            assert excinfo.value.status_code == 401

    @pytest.mark.asyncio
    async def test_get_current_user_wrong_audience(self, mock_settings):
        """Test getting the current user with a token having the wrong audience."""
        # Create a token with a wrong audience
        payload = {
            "sub": "user-id-123",
            "email": "test@example.com",
            "aud": "wrong-audience",
            "exp": datetime.utcnow() + timedelta(minutes=15),
        }
        token = jwt.encode(
            payload,
            mock_settings.SUPABASE_JWT_SECRET,
            algorithm=mock_settings.ALGORITHM,
        )

        with patch("apps.core.lib.auth.supabase_auth.settings", mock_settings):
            with pytest.raises(HTTPException) as excinfo:
                await get_current_user(token)

            assert excinfo.value.status_code == 401

    @pytest.mark.asyncio
    async def test_oauth2_scheme_dependency(self, valid_jwt):
        """Test that the oauth2_scheme dependency is used correctly."""
        # Mock the OAuth2PasswordBearer to return our valid JWT
        mock_oauth2 = AsyncMock(return_value=valid_jwt)

        # Test the get_current_user function with the mocked dependency
        with patch("apps.core.lib.auth.supabase_auth.oauth2_scheme", mock_oauth2):
            # This will pass our valid JWT to get_current_user
            user = await get_current_user()

            # We expect oauth2_scheme to be called
            mock_oauth2.assert_called_once()
</file>

<file path="apps/core/tests/unit/lib/cache/__init__.py">
"""
Unit tests for cache implementations.
"""
</file>

<file path="apps/core/tests/unit/lib/cache/test_redis_cache.py">
"""
Unit tests for the RedisCache class.
"""

from unittest.mock import AsyncMock, MagicMock, patch

import pytest

from apps.core.lib.cache.redis_cache import RedisCache


@pytest.fixture
def mock_redis_client():
    """Create a mock Redis async client."""
    with patch("redis.asyncio.Redis") as mock_redis:
        # Create AsyncMock instances for the Redis methods we'll use
        mock_client = AsyncMock()
        mock_client.get = AsyncMock()
        mock_client.set = AsyncMock()
        mock_client.close = AsyncMock()

        # Configure the Redis constructor to return our mock client
        mock_redis.return_value = mock_client

        # Return both the Redis constructor mock and the client mock for verification
        yield mock_redis, mock_client


class TestRedisCache:
    """Test cases for the RedisCache class."""

    def test_initialization(self, mock_redis_client):
        """Test initializing the RedisCache with settings."""
        mock_redis, mock_client = mock_redis_client

        # Initialize the cache
        cache = RedisCache()

        # Verify Redis client was initialized with the correct parameters
        mock_redis.assert_called_once()

        # Check the parameters (note: we can't check the exact values as they come from settings)
        args, kwargs = mock_redis.call_args
        assert "host" in kwargs
        assert "port" in kwargs
        assert "db" in kwargs
        assert "password" in kwargs
        assert kwargs["decode_responses"] is True

    @pytest.mark.asyncio
    async def test_get_existing_value(self, mock_redis_client):
        """Test retrieving an existing value from the cache."""
        mock_redis, mock_client = mock_redis_client

        # Configure the mock to return a specific value
        mock_client.get.return_value = "cached_value"

        # Initialize the cache and call get
        cache = RedisCache()
        result = await cache.get("test_key")

        # Verify get was called with the correct key
        mock_client.get.assert_called_once_with("test_key")

        # Verify the result
        assert result == "cached_value"

    @pytest.mark.asyncio
    async def test_get_nonexistent_value(self, mock_redis_client):
        """Test retrieving a non-existent value from the cache."""
        mock_redis, mock_client = mock_redis_client

        # Configure the mock to return None (key not found)
        mock_client.get.return_value = None

        # Initialize the cache and call get
        cache = RedisCache()
        result = await cache.get("nonexistent_key")

        # Verify get was called with the correct key
        mock_client.get.assert_called_once_with("nonexistent_key")

        # Verify the result is None
        assert result is None

    @pytest.mark.asyncio
    async def test_set_with_default_ttl(self, mock_redis_client):
        """Test setting a value in the cache with the default TTL."""
        mock_redis, mock_client = mock_redis_client

        # Initialize the cache and call set
        cache = RedisCache()
        await cache.set("test_key", "test_value")

        # Verify set was called with the correct parameters
        mock_client.set.assert_called_once_with("test_key", "test_value", ex=3600)

    @pytest.mark.asyncio
    async def test_set_with_custom_ttl(self, mock_redis_client):
        """Test setting a value in the cache with a custom TTL."""
        mock_redis, mock_client = mock_redis_client

        # Initialize the cache and call set with a custom TTL
        cache = RedisCache()
        await cache.set("test_key", "test_value", ttl_seconds=600)

        # Verify set was called with the correct parameters
        mock_client.set.assert_called_once_with("test_key", "test_value", ex=600)

    @pytest.mark.asyncio
    async def test_set_non_string_value(self, mock_redis_client):
        """Test setting a non-string value in the cache (should be stringified)."""
        mock_redis, mock_client = mock_redis_client

        # Initialize the cache and call set with a non-string value
        cache = RedisCache()
        await cache.set("test_key", 123)

        # Verify set was called with the stringified value
        mock_client.set.assert_called_once_with("test_key", "123", ex=3600)

    @pytest.mark.asyncio
    async def test_close(self, mock_redis_client):
        """Test closing the Redis connection."""
        mock_redis, mock_client = mock_redis_client

        # Initialize the cache and call close
        cache = RedisCache()
        await cache.close()

        # Verify close was called
        mock_client.close.assert_called_once()
</file>

<file path="apps/core/tests/unit/lib/publishing/test_youtube_adapter.py">
"""
Unit tests for the YouTube adapter.
"""

import json
import os
import tempfile
from unittest.mock import MagicMock, patch

import pytest
from core.exceptions import PublishingError
from googleapiclient.http import MediaFileUpload

from apps.core.lib.publishing.youtube_adapter import YouTubeAdapter


@pytest.fixture
def mock_credentials():
    """Create a mock OAuth credentials file for testing."""
    # Create a temporary file with mock credentials
    with tempfile.NamedTemporaryFile(delete=False, mode="w") as temp_file:
        credentials = {
            "token": "mock_token",
            "refresh_token": "mock_refresh_token",
            "token_uri": "https://oauth2.googleapis.com/token",
            "client_id": "mock_client_id",
            "client_secret": "mock_client_secret",
        }
        json.dump(credentials, temp_file)
        temp_file_path = temp_file.name

    yield temp_file_path

    # Clean up the temporary file
    os.unlink(temp_file_path)


@pytest.fixture
def mock_video_file():
    """Create a mock video file for testing."""
    # Create a temporary file as a mock video
    with tempfile.NamedTemporaryFile(delete=False, mode="wb") as temp_file:
        temp_file.write(b"mock video content")
        temp_file_path = temp_file.name

    yield temp_file_path

    # Clean up the temporary file
    os.unlink(temp_file_path)


@pytest.fixture
def mock_youtube_api():
    """Mock the YouTube API client."""
    with patch("googleapiclient.discovery.build") as mock_build:
        # Create mock YouTube API
        mock_youtube = MagicMock()
        mock_build.return_value = mock_youtube

        # Set up video responses
        mock_videos = MagicMock()
        mock_youtube.videos.return_value = mock_videos

        # Set up insert operation
        mock_insert = MagicMock()
        mock_videos.insert.return_value = mock_insert

        # Set up list operation
        mock_list = MagicMock()
        mock_videos.list.return_value = mock_list
        mock_list.execute.return_value = {
            "items": [
                {
                    "id": "test_video_id",
                    "snippet": {
                        "title": "Test Video",
                        "description": "Test Description",
                        "tags": ["test", "video"],
                        "categoryId": "22",
                    },
                    "status": {
                        "privacyStatus": "private",
                        "selfDeclaredMadeForKids": False,
                    },
                    "processingDetails": {
                        "processingStatus": "processing",
                    },
                }
            ]
        }

        # Set up update operation
        mock_update = MagicMock()
        mock_videos.update.return_value = mock_update
        mock_update.execute.return_value = {"id": "test_video_id"}

        # Set up delete operation
        mock_delete = MagicMock()
        mock_videos.delete.return_value = mock_delete

        # Set up captions
        mock_captions = MagicMock()
        mock_youtube.captions.return_value = mock_captions

        # Set up caption insert
        mock_caption_insert = MagicMock()
        mock_captions.insert.return_value = mock_caption_insert
        mock_caption_insert.execute.return_value = {"id": "test_caption_id"}

        yield mock_youtube


@pytest.fixture
def youtube_adapter(mock_credentials, mock_youtube_api):
    """Create a YouTubeAdapter instance for testing."""
    # Mock the client_secrets_file which isn't used in our tests
    mock_client_secrets = "/path/to/client_secrets.json"

    # Create the adapter
    adapter = YouTubeAdapter(
        client_secrets_file=mock_client_secrets,
        oauth_token_file=mock_credentials,
    )

    # Ensure the YouTube API is initialized
    adapter._youtube = mock_youtube_api

    return adapter


class TestYouTubeAdapter:
    """Test cases for the YouTubeAdapter class."""

    def test_initialization(self, mock_credentials, mock_youtube_api):
        """Test adapter initialization."""
        # Mock the client_secrets_file which isn't used in our tests
        mock_client_secrets = "/path/to/client_secrets.json"

        # Create the adapter
        adapter = YouTubeAdapter(
            client_secrets_file=mock_client_secrets,
            oauth_token_file=mock_credentials,
        )

        # Check that the adapter was initialized correctly
        assert adapter._client_secrets_file == mock_client_secrets
        assert adapter._oauth_token_file == mock_credentials
        assert adapter._youtube is not None

    def test_upload_video(self, youtube_adapter, mock_video_file):
        """Test uploading a video."""
        # Set up the mock response for the video upload
        mock_insert_request = youtube_adapter._youtube.videos().insert()
        mock_insert_request.next_chunk.side_effect = [
            (None, None),  # First chunk (progress)
            (None, {"id": "test_video_id"}),  # Final chunk (completion)
        ]

        # Call the method
        video_id = youtube_adapter.upload_video(
            video_file=mock_video_file,
            metadata={
                "title": "Test Video",
                "description": "Test Description",
                "tags": ["test", "video"],
                "privacy_status": "private",
            },
        )

        # Check the result
        assert video_id == "test_video_id"

        # Verify the insert method was called
        youtube_adapter._youtube.videos().insert.assert_called()

        # Verify part and body parameters were passed as expected
        # This is less strict than assert_called_once_with but still verifies parameters
        args, kwargs = youtube_adapter._youtube.videos().insert.call_args
        assert "part" in kwargs
        assert "body" in kwargs
        assert "media_body" in kwargs

        # Check that the body contains expected metadata
        body = kwargs["body"]
        assert body["snippet"]["title"] == "Test Video"
        assert body["snippet"]["description"] == "Test Description"
        assert body["status"]["privacyStatus"] == "private"

    def test_update_metadata(self, youtube_adapter):
        """Test updating video metadata."""
        # Call the method
        result = youtube_adapter.update_metadata(
            video_id="test_video_id",
            metadata={
                "title": "Updated Title",
                "description": "Updated Description",
                "tags": ["updated", "tags"],
                "privacy_status": "public",
            },
        )

        # Check the result
        assert result is True

        # Verify the right methods were called
        youtube_adapter._youtube.videos().list.assert_called_once_with(
            part="snippet,status", id="test_video_id"
        )
        youtube_adapter._youtube.videos().update.assert_called_once()

    def test_get_upload_status(self, youtube_adapter):
        """Test getting upload status."""
        # Call the method
        status = youtube_adapter.get_upload_status(video_id="test_video_id")

        # Check the result
        assert status == "processing"

        # Verify the right methods were called
        youtube_adapter._youtube.videos().list.assert_called_once_with(
            part="processingDetails,status", id="test_video_id"
        )

    def test_delete_video(self, youtube_adapter):
        """Test deleting a video."""
        # Call the method
        result = youtube_adapter.delete_video(video_id="test_video_id")

        # Check the result
        assert result is True

        # Verify the right methods were called
        youtube_adapter._youtube.videos().delete.assert_called_once_with(
            id="test_video_id"
        )

    def test_get_video_url(self, youtube_adapter):
        """Test getting a video URL."""
        # Call the method
        url = youtube_adapter.get_video_url(video_id="test_video_id")

        # Check the result
        assert url == "https://www.youtube.com/watch?v=test_video_id"

    def test_upload_caption(self, youtube_adapter, mock_video_file):
        """Test uploading captions."""
        # Create a temporary caption file
        with tempfile.NamedTemporaryFile(
            suffix=".vtt", delete=False, mode="w"
        ) as temp_file:
            temp_file.write("WEBVTT\n\n00:00:00.000 --> 00:00:05.000\nTest caption")
            caption_file = temp_file.name

        try:
            # Call the method
            result = youtube_adapter.upload_caption(
                video_id="test_video_id",
                caption_file=caption_file,
                language="en",
            )

            # Check the result
            assert result is True

            # Verify the right methods were called
            youtube_adapter._youtube.captions().insert.assert_called_once()
        finally:
            # Clean up
            os.unlink(caption_file)

    def test_set_publishing_time(self, youtube_adapter):
        """Test setting publishing time."""
        # Test immediate publishing
        result1 = youtube_adapter.set_publishing_time(
            video_id="test_video_id",
            publish_at=None,
        )
        assert result1 is True

        # Test scheduled publishing
        result2 = youtube_adapter.set_publishing_time(
            video_id="test_video_id",
            publish_at="2025-12-31T23:59:59Z",
        )
        assert result2 is True

        # Verify the right methods were called
        assert youtube_adapter._youtube.videos().list.call_count == 2
        assert youtube_adapter._youtube.videos().update.call_count == 2

    def test_error_handling(self, youtube_adapter):
        """Test error handling."""
        # Test missing video ID
        with pytest.raises(PublishingError):
            youtube_adapter.get_video_url(video_id=None)

        # Test file not found error
        with pytest.raises(PublishingError):
            youtube_adapter.upload_video(
                video_file="/nonexistent/file.mp4",
                metadata={},
            )
</file>

<file path="apps/core/tests/unit/lib/storage/__init__.py">
"""
Unit tests for storage adapters and services.
"""
</file>

<file path="apps/core/tests/unit/lib/storage/test_file_storage.py">
"""
Unit tests for the file storage service.
"""

import asyncio
import os
import shutil
import tempfile
from pathlib import Path
from unittest.mock import MagicMock, patch

import pytest
from core.config import Settings

from apps.core.lib.storage.file_storage import FileStorageService


@pytest.fixture
def temp_dir():
    """Create a temporary directory for testing local storage."""
    temp_dir = tempfile.mkdtemp()
    yield temp_dir
    # Clean up
    shutil.rmtree(temp_dir)


@pytest.fixture
def mock_settings_local(temp_dir):
    """Create mock settings configured for local storage."""
    settings = Settings()
    settings.STORAGE_BACKEND = "local"
    settings.LOCAL_STORAGE_PATH = temp_dir
    settings.BASE_DIR = Path("/fake/base/dir")  # Not used for local tests
    return settings


@pytest.fixture
def mock_settings_gcs():
    """Create mock settings configured for GCS storage."""
    settings = Settings()
    settings.STORAGE_BACKEND = "gcs"
    settings.GCS_BUCKET_NAME = "test-bucket"
    settings.GOOGLE_APPLICATION_CREDENTIALS_PATH = None  # Use default credentials
    return settings


@pytest.fixture
def mock_gcs_client():
    """Create a mock GCS client."""
    with patch("apps.core.lib.storage.file_storage.storage") as mock_storage:
        # Create mock bucket and blob
        mock_blob = MagicMock()
        mock_bucket = MagicMock()
        mock_bucket.blob.return_value = mock_blob

        # Create mock client
        mock_client = MagicMock()
        mock_client.bucket.return_value = mock_bucket

        # Set up return value for the Client constructor
        mock_storage.Client.return_value = mock_client

        # Set GCS_AVAILABLE to True
        with patch("apps.core.lib.storage.file_storage.GCS_AVAILABLE", True):
            yield mock_client


class TestFileStorageService:
    """Test cases for the FileStorageService class."""

    def test_init_local_storage(self, mock_settings_local):
        """Test initialization with local storage backend."""
        service = FileStorageService(mock_settings_local)

        # Verify the local storage path was set correctly
        assert service.local_storage_path == Path(
            mock_settings_local.LOCAL_STORAGE_PATH
        )

        # Verify the directory was created
        assert os.path.exists(mock_settings_local.LOCAL_STORAGE_PATH)

    def test_init_gcs_storage(self, mock_settings_gcs, mock_gcs_client):
        """Test initialization with GCS storage backend."""
        service = FileStorageService(mock_settings_gcs)

        # Verify the GCS client was initialized
        assert service.gcs_client is not None

    def test_init_gcs_without_dependencies(self, mock_settings_gcs):
        """Test initialization fails when GCS is selected but dependencies aren't available."""
        with patch("apps.core.lib.storage.file_storage.GCS_AVAILABLE", False):
            with pytest.raises(ImportError) as excinfo:
                FileStorageService(mock_settings_gcs)

            assert "Google Cloud Storage dependencies are not installed" in str(
                excinfo.value
            )

    def test_init_gcs_without_bucket(self, mock_gcs_client):
        """Test initialization fails when GCS is selected but no bucket is specified."""
        settings = Settings()
        settings.STORAGE_BACKEND = "gcs"
        settings.GCS_BUCKET_NAME = None

        with pytest.raises(ValueError) as excinfo:
            FileStorageService(settings)

        assert "GCS_BUCKET_NAME must be set" in str(excinfo.value)

    @pytest.mark.asyncio
    async def test_init_unsupported_backend(self):
        """Test initialization fails with an unsupported storage backend."""
        settings = Settings()
        settings.STORAGE_BACKEND = "unsupported"

        # This should not raise an error on init, only when methods are called
        service = FileStorageService(settings)

        # But operations should fail
        with pytest.raises(ValueError) as excinfo:
            await service.save_file(b"test content", "test.txt")

        assert "Unsupported storage backend" in str(excinfo.value)

    @pytest.mark.asyncio
    async def test_save_file_local(self, mock_settings_local):
        """Test saving a file to local storage."""
        service = FileStorageService(mock_settings_local)

        # Test file data
        test_content = b"This is test content"
        test_filename = "test.txt"

        # Save the file
        relative_path = await service.save_file(test_content, test_filename)

        # Verify the path is returned correctly
        assert relative_path.startswith("uploads/")
        assert relative_path.endswith(".txt")

        # Verify the file was saved
        saved_path = os.path.join(mock_settings_local.LOCAL_STORAGE_PATH, relative_path)
        assert os.path.exists(saved_path)

        # Verify the content
        with open(saved_path, "rb") as f:
            saved_content = f.read()
        assert saved_content == test_content

    @pytest.mark.asyncio
    async def test_save_file_gcs(self, mock_settings_gcs, mock_gcs_client):
        """Test saving a file to GCS."""
        service = FileStorageService(mock_settings_gcs)

        # Test file data
        test_content = b"This is test content"
        test_filename = "test.txt"

        # Save the file
        storage_path = await service.save_file(test_content, test_filename)

        # Verify the path is returned correctly
        assert storage_path.startswith(
            f"gs://{mock_settings_gcs.GCS_BUCKET_NAME}/uploads/"
        )
        assert storage_path.endswith(".txt")

        # Verify the GCS upload was called
        mock_bucket = mock_gcs_client.bucket.return_value
        mock_blob = mock_bucket.blob.return_value
        mock_blob.upload_from_string.assert_called_once()

        # Verify the correct parameters were used
        call_args = mock_blob.upload_from_string.call_args[0]
        assert call_args[0] == test_content

    @pytest.mark.asyncio
    async def test_download_file_local(self, mock_settings_local):
        """Test downloading a file from local storage."""
        service = FileStorageService(mock_settings_local)

        # Create a test file
        test_content = b"This is test content for download"
        test_filename = "test_download.txt"
        source_path = await service.save_file(test_content, test_filename)

        # Create a temporary directory for the download destination
        with tempfile.TemporaryDirectory() as dest_dir:
            dest_path = os.path.join(dest_dir, "downloaded.txt")

            # Download the file
            result_path = await service.download_file(source_path, dest_path)

            # Verify the correct path was returned
            assert result_path == dest_path

            # Verify the file was downloaded
            assert os.path.exists(dest_path)

            # Verify the content
            with open(dest_path, "rb") as f:
                downloaded_content = f.read()
            assert downloaded_content == test_content

    @pytest.mark.asyncio
    async def test_download_file_gcs(self, mock_settings_gcs, mock_gcs_client):
        """Test downloading a file from GCS."""
        service = FileStorageService(mock_settings_gcs)

        # Mock GCS URI
        gcs_uri = f"gs://{mock_settings_gcs.GCS_BUCKET_NAME}/test_folder/test.txt"

        # Create a temporary directory for the download destination
        with tempfile.TemporaryDirectory() as dest_dir:
            dest_path = os.path.join(dest_dir, "downloaded.txt")

            # Download the file
            result_path = await service.download_file(gcs_uri, dest_path)

            # Verify the correct path was returned
            assert result_path == dest_path

            # Verify download_to_filename was called on the blob
            mock_bucket = mock_gcs_client.bucket.return_value
            mock_blob = mock_bucket.blob.return_value
            mock_blob.download_to_filename.assert_called_once_with(dest_path)

    @pytest.mark.asyncio
    async def test_get_public_url_local(self, mock_settings_local):
        """Test getting a public URL for a local file."""
        service = FileStorageService(mock_settings_local)

        # Local files don't have public URLs
        url = await service.get_public_url("uploads/test.txt")
        assert url is None

    @pytest.mark.asyncio
    async def test_get_public_url_gcs(self, mock_settings_gcs, mock_gcs_client):
        """Test getting a public URL for a GCS file."""
        service = FileStorageService(mock_settings_gcs)

        # Test with a GCS URI
        gcs_uri = f"gs://{mock_settings_gcs.GCS_BUCKET_NAME}/test_folder/test.txt"
        url = await service.get_public_url(gcs_uri)

        # Verify the URL format
        assert (
            url
            == f"https://storage.googleapis.com/{mock_settings_gcs.GCS_BUCKET_NAME}/test_folder/test.txt"
        )

        # Test with just a blob path
        blob_path = "test_folder/test.txt"
        url = await service.get_public_url(blob_path)

        # Verify the URL format
        assert (
            url
            == f"https://storage.googleapis.com/{mock_settings_gcs.GCS_BUCKET_NAME}/{blob_path}"
        )

    def test_parse_gcs_uri(self, mock_settings_gcs, mock_gcs_client):
        """Test parsing a GCS URI."""
        service = FileStorageService(mock_settings_gcs)

        # Valid URI
        bucket_name, blob_name = service._parse_gcs_uri(
            "gs://test-bucket/path/to/file.txt"
        )
        assert bucket_name == "test-bucket"
        assert blob_name == "path/to/file.txt"

        # Invalid URI (no gs:// prefix)
        with pytest.raises(ValueError) as excinfo:
            service._parse_gcs_uri("invalid-uri")
        assert "Invalid GCS URI" in str(excinfo.value)

        # Invalid URI (no blob name)
        with pytest.raises(ValueError) as excinfo:
            service._parse_gcs_uri("gs://test-bucket")
        assert "Invalid GCS URI format" in str(excinfo.value)

    def test_upload_from_string_local(self, mock_settings_local):
        """Test uploading a string to local storage."""
        service = FileStorageService(mock_settings_local)

        # Test content
        test_content = "This is string content"
        storage_path = "test_folder/string_file.txt"

        # Upload the string
        service.upload_from_string(test_content, storage_path)

        # Verify the file was created
        full_path = os.path.join(mock_settings_local.LOCAL_STORAGE_PATH, storage_path)
        assert os.path.exists(full_path)

        # Verify the content
        with open(full_path, "r", encoding="utf-8") as f:
            saved_content = f.read()
        assert saved_content == test_content

    def test_upload_from_string_gcs(self, mock_settings_gcs, mock_gcs_client):
        """Test uploading a string to GCS."""
        service = FileStorageService(mock_settings_gcs)

        # Test content
        test_content = "This is string content"
        storage_path = "test_folder/string_file.txt"
        content_type = "text/plain"

        # Upload the string
        service.upload_from_string(test_content, storage_path, content_type)

        # Verify upload_from_string was called on the blob
        mock_bucket = mock_gcs_client.bucket.return_value
        mock_blob = mock_bucket.blob.return_value
        mock_blob.upload_from_string.assert_called_once_with(
            test_content, content_type=content_type
        )
</file>

<file path="apps/core/tests/unit/lib/utils/__init__.py">
"""
Unit tests for utility classes and functions.
"""
</file>

<file path="apps/core/tests/unit/lib/utils/test_ffmpeg_utils.py">
"""
Unit tests for the FfmpegUtils class.
"""

import json
import os
import subprocess
import tempfile
from unittest.mock import AsyncMock, MagicMock, patch

import pytest

from apps.core.lib.utils.ffmpeg_utils import FfmpegUtils


class TestFfmpegUtils:
    """Test cases for the FfmpegUtils class."""

    @patch("apps.core.lib.utils.ffmpeg_utils.subprocess.run")
    def test_extract_audio_sync_success(self, mock_run):
        """Test successful audio extraction from a video file."""
        # Set up the mock
        mock_result = MagicMock()
        mock_result.returncode = 0
        mock_run.return_value = mock_result

        # Call the method
        FfmpegUtils.extract_audio_sync("test_video.mp4", "output_audio.wav")

        # Verify subprocess.run was called with correct arguments
        mock_run.assert_called_once()
        args, kwargs = mock_run.call_args

        # Check the command list
        cmd = args[0]
        assert cmd[0] == "ffmpeg"
        assert "-i" in cmd
        assert "test_video.mp4" in cmd
        assert "output_audio.wav" in cmd

        # Check that stdout and stderr are captured
        assert kwargs["capture_output"] is True
        assert kwargs["text"] is True
        assert kwargs["check"] is False

    @patch("apps.core.lib.utils.ffmpeg_utils.subprocess.run")
    def test_extract_audio_sync_failure(self, mock_run):
        """Test handling of ffmpeg failure during audio extraction."""
        # Set up the mock for failure
        mock_result = MagicMock()
        mock_result.returncode = 1
        mock_result.stderr = "ffmpeg error message"
        mock_run.return_value = mock_result

        # Call the method and expect an exception
        with pytest.raises(RuntimeError) as excinfo:
            FfmpegUtils.extract_audio_sync("test_video.mp4", "output_audio.wav")

        # Verify the error message
        assert "FFmpeg audio extraction failed" in str(excinfo.value)
        assert "ffmpeg error message" in str(excinfo.value)

    @patch("apps.core.lib.utils.ffmpeg_utils.subprocess.run")
    def test_extract_frame_sync_success(self, mock_run):
        """Test successful frame extraction from a video file."""
        # Set up the mock
        mock_result = MagicMock()
        mock_result.returncode = 0
        mock_run.return_value = mock_result

        # Call the method
        FfmpegUtils.extract_frame_sync("test_video.mp4", 10.5, "output_frame.jpg")

        # Verify subprocess.run was called with correct arguments
        mock_run.assert_called_once()
        args, kwargs = mock_run.call_args

        # Check the command list
        cmd = args[0]
        assert cmd[0] == "ffmpeg"
        assert "-ss" in cmd
        assert "10.5" in cmd
        assert "-i" in cmd
        assert "test_video.mp4" in cmd
        assert "output_frame.jpg" in cmd

        assert kwargs["capture_output"] is True
        assert kwargs["text"] is True
        assert kwargs["check"] is False

    @patch("apps.core.lib.utils.ffmpeg_utils.subprocess.run")
    def test_extract_frame_sync_failure(self, mock_run):
        """Test handling of ffmpeg failure during frame extraction."""
        # Set up the mock for failure
        mock_result = MagicMock()
        mock_result.returncode = 1
        mock_result.stderr = "ffmpeg error message"
        mock_run.return_value = mock_result

        # Call the method and expect an exception
        with pytest.raises(RuntimeError) as excinfo:
            FfmpegUtils.extract_frame_sync("test_video.mp4", 10.5, "output_frame.jpg")

        # Verify the error message
        assert "FFmpeg frame extraction failed" in str(excinfo.value)
        assert "ffmpeg error message" in str(excinfo.value)

    @patch("apps.core.lib.utils.ffmpeg_utils.subprocess.run")
    def test_get_video_metadata_sync_success(self, mock_run):
        """Test successful metadata extraction from a video file."""
        # Sample ffprobe JSON output
        sample_metadata = {
            "streams": [
                {
                    "codec_type": "video",
                    "width": 1920,
                    "height": 1080,
                    "duration": "60.000000",
                    "r_frame_rate": "30/1",
                },
                {"codec_type": "audio", "sample_rate": "44100", "channels": 2},
            ],
            "format": {
                "duration": "60.000000",
                "bit_rate": "1000000",
                "format_name": "mp4",
            },
        }

        # Set up the mock
        mock_result = MagicMock()
        mock_result.returncode = 0
        mock_result.stdout = json.dumps(sample_metadata)
        mock_run.return_value = mock_result

        # Call the method
        metadata = FfmpegUtils.get_video_metadata_sync("test_video.mp4")

        # Verify subprocess.run was called with correct arguments
        mock_run.assert_called_once()
        args, kwargs = mock_run.call_args

        # Check the command list
        cmd = args[0]
        assert cmd[0] == "ffprobe"
        assert "-print_format" in cmd
        assert "json" in cmd
        assert "test_video.mp4" in cmd

        assert kwargs["capture_output"] is True
        assert kwargs["text"] is True
        assert kwargs["check"] is False

        # Verify the parsed metadata
        assert metadata == sample_metadata
        assert metadata["streams"][0]["width"] == 1920
        assert metadata["format"]["duration"] == "60.000000"

    @patch("apps.core.lib.utils.ffmpeg_utils.subprocess.run")
    def test_get_video_metadata_sync_failure(self, mock_run):
        """Test handling of ffprobe failure during metadata extraction."""
        # Set up the mock for failure
        mock_result = MagicMock()
        mock_result.returncode = 1
        mock_result.stderr = "ffprobe error message"
        mock_run.return_value = mock_result

        # Call the method and expect an exception
        with pytest.raises(RuntimeError) as excinfo:
            FfmpegUtils.get_video_metadata_sync("test_video.mp4")

        # Verify the error message
        assert "ffprobe metadata extraction failed" in str(excinfo.value)
        assert "ffprobe error message" in str(excinfo.value)

    def test_real_command_structure(self):
        """
        Test the actual structure of commands without executing them.
        This verifies the command construction logic without mocking.
        """

        # Extract audio command
        with patch("apps.core.lib.utils.ffmpeg_utils.subprocess.run") as mock_run:
            FfmpegUtils.extract_audio_sync("video.mp4", "audio.wav")
            cmd = mock_run.call_args[0][0]
            assert cmd[0:3] == ["ffmpeg", "-y", "-i"]
            assert "video.mp4" in cmd
            assert "-vn" in cmd
            assert "audio.wav" in cmd

        # Extract frame command
        with patch("apps.core.lib.utils.ffmpeg_utils.subprocess.run") as mock_run:
            FfmpegUtils.extract_frame_sync("video.mp4", 5.5, "frame.jpg")
            cmd = mock_run.call_args[0][0]
            assert cmd[0:3] == ["ffmpeg", "-y", "-ss"]
            assert cmd[3] == "5.5"
            assert "video.mp4" in cmd
            assert "-frames:v" in cmd
            assert "1" in cmd
            assert "frame.jpg" in cmd

        # Get metadata command
        with patch("apps.core.lib.utils.ffmpeg_utils.subprocess.run") as mock_run:
            FfmpegUtils.get_video_metadata_sync("video.mp4")
            cmd = mock_run.call_args[0][0]
            assert cmd[0:3] == ["ffprobe", "-v", "error"]
            assert "-show_entries" in cmd
            assert "format:stream" in cmd
            assert "-print_format" in cmd
            assert "json" in cmd
            assert "video.mp4" in cmd
</file>

<file path="apps/core/tests/unit/lib/utils/test_file_utils.py">
"""
Unit tests for the FileUtils class.
"""

import os
import shutil
from unittest.mock import patch

import pytest

from apps.core.lib.utils.file_utils import FileUtils


class TestFileUtils:
    """Test cases for the FileUtils class."""

    def test_create_temp_dir_default_prefix(self):
        """Test creating a temporary directory with the default prefix."""
        with patch("tempfile.mkdtemp") as mock_mkdtemp:
            mock_mkdtemp.return_value = "/tmp/echo_tmp_12345"

            # Call the method
            temp_dir = FileUtils.create_temp_dir()

            # Verify tempfile.mkdtemp was called with the default prefix
            mock_mkdtemp.assert_called_once_with(prefix="echo_tmp_")

            # Verify the return value
            assert temp_dir == "/tmp/echo_tmp_12345"

    def test_create_temp_dir_custom_prefix(self):
        """Test creating a temporary directory with a custom prefix."""
        with patch("tempfile.mkdtemp") as mock_mkdtemp:
            mock_mkdtemp.return_value = "/tmp/custom_prefix_12345"

            # Call the method with a custom prefix
            temp_dir = FileUtils.create_temp_dir(prefix="custom_prefix_")

            # Verify tempfile.mkdtemp was called with the custom prefix
            mock_mkdtemp.assert_called_once_with(prefix="custom_prefix_")

            # Verify the return value
            assert temp_dir == "/tmp/custom_prefix_12345"

    def test_cleanup_temp_dir_existing(self):
        """Test cleaning up an existing temporary directory."""
        # Create a real temp directory for testing
        temp_dir = os.path.join(os.path.dirname(__file__), "test_temp_dir")
        os.makedirs(temp_dir, exist_ok=True)

        # Create a test file in the directory
        test_file = os.path.join(temp_dir, "test_file.txt")
        with open(test_file, "w") as f:
            f.write("test content")

        # Verify the directory and file exist
        assert os.path.exists(temp_dir)
        assert os.path.exists(test_file)

        # Call the method
        FileUtils.cleanup_temp_dir(temp_dir)

        # Verify the directory and file are gone
        assert not os.path.exists(temp_dir)
        assert not os.path.exists(test_file)

    def test_cleanup_temp_dir_nonexistent(self):
        """Test cleaning up a non-existent directory doesn't raise an error."""
        non_existent_dir = "/tmp/non_existent_dir_12345"

        # Make sure the directory doesn't exist
        if os.path.exists(non_existent_dir):
            shutil.rmtree(non_existent_dir)

        # Verify the directory doesn't exist
        assert not os.path.exists(non_existent_dir)

        # This should not raise an exception
        FileUtils.cleanup_temp_dir(non_existent_dir)

    def test_actual_directory_creation(self):
        """Test the actual creation of a temporary directory."""
        # Call the method
        temp_dir = FileUtils.create_temp_dir(prefix="test_file_utils_")

        try:
            # Verify the directory exists
            assert os.path.exists(temp_dir)

            # Verify the prefix
            assert os.path.basename(temp_dir).startswith("test_file_utils_")

            # Create a test file in the directory
            test_file = os.path.join(temp_dir, "test_file.txt")
            with open(test_file, "w") as f:
                f.write("test content")

            # Verify the file exists
            assert os.path.exists(test_file)

        finally:
            # Clean up
            FileUtils.cleanup_temp_dir(temp_dir)

            # Verify the cleanup worked
            assert not os.path.exists(temp_dir)
</file>

<file path="apps/core/tests/unit/lib/utils/test_subtitle_utils.py">
"""
Unit tests for the SubtitleUtils class.
"""

import re
from typing import Dict, List

import pytest

from apps.core.lib.utils.subtitle_utils import SubtitleUtils


class TestSubtitleUtils:
    """Test cases for the SubtitleUtils class."""

    @pytest.fixture
    def sample_transcript_segments(self) -> List[Dict]:
        """
        Creates a sample transcript segments list for testing.
        """
        return [
            {"text": "This is the first segment.", "start_time": 0.0, "end_time": 5.5},
            {
                "text": "This is the second segment.",
                "start_time": 5.5,
                "end_time": 10.0,
            },
            {"text": "This spans over a minute.", "start_time": 59.0, "end_time": 65.0},
            {
                "text": "This spans over an hour.",
                "start_time": 3599.0,
                "end_time": 3605.0,
            },
        ]

    def test_generate_vtt_format(self, sample_transcript_segments):
        """Test VTT formatting with sample transcript segments."""
        vtt_content = SubtitleUtils.generate_vtt(sample_transcript_segments)

        # Verify basic structure
        assert vtt_content.startswith("WEBVTT")

        # Split lines and analyze
        lines = vtt_content.strip().split("\n")

        # Verify we have the right number of segments
        # Each segment has: timestamp line, text line, empty line
        # Plus the WEBVTT header and a final empty line
        expected_lines = 1 + (3 * len(sample_transcript_segments))
        assert len(lines) == expected_lines

        # Verify timestamp format (HH:MM:SS.mmm --> HH:MM:SS.mmm)
        timestamp_pattern = r"^\d{2}:\d{2}:\d{2}\.\d{3} --> \d{2}:\d{2}:\d{2}\.\d{3}$"
        for i in range(1, len(lines), 3):
            assert re.match(timestamp_pattern, lines[i]), (
                f"Line {i} is not a valid VTT timestamp: {lines[i]}"
            )

        # Verify the text content for each segment
        for i, segment in enumerate(sample_transcript_segments):
            text_line_index = 2 + (i * 3)
            assert lines[text_line_index] == segment["text"]

    def test_generate_vtt_timestamps(self, sample_transcript_segments):
        """Test VTT timestamp formatting specifically."""
        vtt_content = SubtitleUtils.generate_vtt(sample_transcript_segments)
        lines = vtt_content.strip().split("\n")

        # First segment: 00:00:00.000 --> 00:00:05.500
        assert lines[1] == "00:00:00.000 --> 00:00:05.500"

        # Second segment: 00:00:05.500 --> 00:00:10.000
        assert lines[4] == "00:00:05.500 --> 00:00:10.000"

        # Minute spanning: 00:00:59.000 --> 00:01:05.000
        assert lines[7] == "00:00:59.000 --> 00:01:05.000"

        # Hour spanning: 00:59:59.000 --> 01:00:05.000
        assert lines[10] == "00:59:59.000 --> 01:00:05.000"

    def test_generate_srt_format(self, sample_transcript_segments):
        """Test SRT formatting with sample transcript segments."""
        srt_content = SubtitleUtils.generate_srt(sample_transcript_segments)

        # Split lines and analyze
        lines = srt_content.strip().split("\n")

        # Verify we have the right number of segments
        # Each segment has: index line, timestamp line, text line, empty line
        expected_lines = 4 * len(sample_transcript_segments)
        assert len(lines) == expected_lines

        # Verify sequence numbers
        for i in range(0, len(lines), 4):
            seq_num = i // 4 + 1
            assert lines[i] == str(seq_num)

        # Verify timestamp format (HH:MM:SS,mmm --> HH:MM:SS,mmm)
        timestamp_pattern = r"^\d{2}:\d{2}:\d{2},\d{3} --> \d{2}:\d{2}:\d{2},\d{3}$"
        for i in range(1, len(lines), 4):
            assert re.match(timestamp_pattern, lines[i]), (
                f"Line {i} is not a valid SRT timestamp: {lines[i]}"
            )

        # Verify the text content for each segment
        for i, segment in enumerate(sample_transcript_segments):
            text_line_index = 2 + (i * 4)
            assert lines[text_line_index] == segment["text"]

    def test_generate_srt_timestamps(self, sample_transcript_segments):
        """Test SRT timestamp formatting specifically."""
        srt_content = SubtitleUtils.generate_srt(sample_transcript_segments)
        lines = srt_content.strip().split("\n")

        # First segment: 00:00:00,000 --> 00:00:05,500
        assert lines[1] == "00:00:00,000 --> 00:00:05,500"

        # Second segment: 00:00:05,500 --> 00:00:10,000
        assert lines[5] == "00:00:05,500 --> 00:00:10,000"

        # Minute spanning: 00:00:59,000 --> 00:01:05,000
        assert lines[9] == "00:00:59,000 --> 00:01:05,000"

        # Hour spanning: 00:59:59,000 --> 01:00:05,000
        assert lines[13] == "00:59:59,000 --> 01:00:05,000"

    def test_empty_transcript(self):
        """Test generating subtitles with an empty transcript."""
        empty_segments = []

        # VTT should just have the header
        vtt_content = SubtitleUtils.generate_vtt(empty_segments)
        assert vtt_content == "WEBVTT\n"

        # SRT should be empty
        srt_content = SubtitleUtils.generate_srt(empty_segments)
        assert srt_content == ""

    def test_malformed_segments(self):
        """Test handling of malformed segment data."""
        # Missing start_time
        malformed_segments = [
            {"text": "This segment is missing start_time.", "end_time": 5.0}
        ]

        # This should raise a KeyError
        with pytest.raises(KeyError):
            SubtitleUtils.generate_vtt(malformed_segments)

        with pytest.raises(KeyError):
            SubtitleUtils.generate_srt(malformed_segments)

        # Missing text
        malformed_segments = [{"start_time": 0.0, "end_time": 5.0}]

        # This should raise a KeyError
        with pytest.raises(KeyError):
            SubtitleUtils.generate_vtt(malformed_segments)

        with pytest.raises(KeyError):
            SubtitleUtils.generate_srt(malformed_segments)
</file>

<file path="apps/core/tests/unit/operations/__init__.py">
"""
Unit tests for operations (repositories) layer.
"""
</file>

<file path="apps/core/tests/unit/operations/test_video_job_repository.py">
"""
Unit tests for the VideoJobRepository.
"""

import json
from unittest.mock import AsyncMock, MagicMock, patch

import pytest
from sqlalchemy.ext.asyncio import AsyncSession

from apps.core.models.enums import ProcessingStatus
from apps.core.models.video_job_model import VideoJobModel
from apps.core.operations.video_job_repository import VideoJobRepository


@pytest.fixture
def mock_db_session_async() -> AsyncMock:
    """Create a mock SQLAlchemy AsyncSession."""
    mock_session = AsyncMock(spec=AsyncSession)

    return mock_session


@pytest.fixture
def sample_job_data():
    """Sample video job data for testing."""
    return {
        "video_id": 42,
        "status": ProcessingStatus.PENDING,
        "processing_stages": [],
        "error_message": None,
    }


class TestVideoJobRepository:
    """Test cases for the VideoJobRepository class."""

    @pytest.mark.asyncio
    async def test_create(self, mock_db_session_async: AsyncMock, sample_job_data):
        """Test creating a new video job."""
        job = await VideoJobRepository.create(
            mock_db_session_async,
            video_id=sample_job_data["video_id"],
            status=sample_job_data["status"],
        )

        assert isinstance(job, VideoJobModel)
        assert job.video_id == sample_job_data["video_id"]
        assert job.status == sample_job_data["status"]

        mock_db_session_async.add.assert_called_once()
        mock_db_session_async.flush.assert_awaited_once()
        mock_db_session_async.refresh.assert_awaited_once()

    @pytest.mark.asyncio
    async def test_create_with_defaults(self, mock_db_session_async: AsyncMock):
        """Test creating a job with default values."""
        job = await VideoJobRepository.create(mock_db_session_async, video_id=42)

        assert isinstance(job, VideoJobModel)
        assert job.video_id == 42
        assert job.status == ProcessingStatus.PENDING

        mock_db_session_async.add.assert_called_once()
        mock_db_session_async.flush.assert_awaited_once()
        mock_db_session_async.refresh.assert_awaited_once()

    @pytest.mark.asyncio
    async def test_get_by_id_found(
        self, mock_db_session_async: AsyncMock, sample_job_data
    ):
        """Test retrieving a job by ID when it exists."""
        mock_job_instance = VideoJobModel(**sample_job_data)
        mock_job_instance.id = 123

        mock_execute_result = AsyncMock()
        mock_scalars_result = AsyncMock()

        mock_db_session_async.execute.return_value = mock_execute_result
        mock_execute_result.scalars.return_value = mock_scalars_result
        mock_scalars_result.first.return_value = mock_job_instance

        job = await VideoJobRepository.get_by_id(mock_db_session_async, 123)

        assert job is mock_job_instance
        assert job.id == 123
        mock_db_session_async.execute.assert_awaited_once()

    @pytest.mark.asyncio
    async def test_get_by_id_not_found(self, mock_db_session_async: AsyncMock):
        """Test retrieving a job by ID when it doesn't exist."""
        mock_execute_result = AsyncMock()
        mock_scalars_result = AsyncMock()

        mock_db_session_async.execute.return_value = mock_execute_result
        mock_execute_result.scalars.return_value = mock_scalars_result
        mock_scalars_result.first.return_value = None

        job = await VideoJobRepository.get_by_id(mock_db_session_async, 999)

        assert job is None
        mock_db_session_async.execute.assert_awaited_once()

    @pytest.mark.asyncio
    async def test_update_status(
        self, mock_db_session_async: AsyncMock, sample_job_data
    ):
        """Test updating a job's status."""
        mock_job_to_update = VideoJobModel(**sample_job_data)  # type: ignore
        mock_job_to_update.id = 123

        with patch(
            "apps.core.operations.video_job_repository.VideoJobRepository.get_by_id",
            new_callable=AsyncMock,
        ) as mock_get_by_id:
            mock_get_by_id.return_value = mock_job_to_update

            updated_job = await VideoJobRepository.update_status(
                mock_db_session_async, 123, ProcessingStatus.PROCESSING
            )

            mock_get_by_id.assert_awaited_once_with(mock_db_session_async, 123)
            assert updated_job is not None  # Explicitly assert not None
            if updated_job:  # Guard subsequent attribute access
                assert updated_job is mock_job_to_update
                assert updated_job.status == ProcessingStatus.PROCESSING
                assert updated_job.error_message is None

            mock_db_session_async.flush.assert_awaited_once()
            # Ensure refresh is called with the object that get_by_id returned (which is mock_job_to_update)
            mock_db_session_async.refresh.assert_awaited_once_with(mock_job_to_update)

    @pytest.mark.asyncio
    async def test_update_status_with_error(
        self, mock_db_session_async: AsyncMock, sample_job_data
    ):
        """Test updating a job's status with an error message."""
        mock_job_to_update = VideoJobModel(**sample_job_data)  # type: ignore
        mock_job_to_update.id = 123

        with patch(
            "apps.core.operations.video_job_repository.VideoJobRepository.get_by_id",
            new_callable=AsyncMock,
        ) as mock_get_by_id:
            mock_get_by_id.return_value = mock_job_to_update

            error_msg = "Something went wrong"
            updated_job = await VideoJobRepository.update_status(
                mock_db_session_async,
                123,
                ProcessingStatus.FAILED,
                error_message=error_msg,
            )

            mock_get_by_id.assert_awaited_once_with(mock_db_session_async, 123)
            assert updated_job is not None  # Explicitly assert not None
            if updated_job:  # Guard subsequent attribute access
                assert updated_job is mock_job_to_update
                assert updated_job.status == ProcessingStatus.FAILED
                assert updated_job.error_message == error_msg

            mock_db_session_async.flush.assert_awaited_once()
            mock_db_session_async.refresh.assert_awaited_once_with(mock_job_to_update)

    @pytest.mark.asyncio
    async def test_update_status_not_found(self, mock_db_session_async: AsyncMock):
        """Test updating status when job doesn't exist."""
        with patch(
            "apps.core.operations.video_job_repository.VideoJobRepository.get_by_id",
            new_callable=AsyncMock,
        ) as mock_get_by_id:
            mock_get_by_id.return_value = None  # Simulate job not found

            updated_job = await VideoJobRepository.update_status(
                mock_db_session_async, 999, ProcessingStatus.PROCESSING
            )

            mock_get_by_id.assert_awaited_once_with(mock_db_session_async, 999)
            assert updated_job is None
            assert mock_db_session_async.flush.await_count == 0
            assert mock_db_session_async.refresh.await_count == 0

    @pytest.mark.asyncio
    async def test_add_processing_stage_new_list(
        self, mock_db_session_async: AsyncMock
    ):
        """Test adding a processing stage to a job with no existing stages."""
        mock_job = VideoJobModel(video_id=42, processing_stages=None)  # type: ignore
        mock_job.id = 123

        with patch(
            "apps.core.operations.video_job_repository.VideoJobRepository.get_by_id",
            new_callable=AsyncMock,
        ) as mock_get_by_id:
            mock_get_by_id.return_value = mock_job

            stage = "transcription_started"
            updated_job = await VideoJobRepository.add_processing_stage(
                mock_db_session_async, 123, stage
            )

            mock_get_by_id.assert_awaited_once_with(mock_db_session_async, 123)
            assert updated_job is not None
            if updated_job:
                assert updated_job is mock_job
                # The repository method should handle initializing the list
                assert updated_job.processing_stages == [stage]

            mock_db_session_async.flush.assert_awaited_once()
            mock_db_session_async.refresh.assert_awaited_once_with(mock_job)

    @pytest.mark.asyncio
    async def test_add_processing_stage_existing_list(
        self, mock_db_session_async: AsyncMock
    ):
        """Test adding a processing stage to a job with existing stages."""
        existing_stages = ["upload_complete", "validation_complete"]
        mock_job = VideoJobModel(video_id=42, processing_stages=existing_stages)  # type: ignore
        mock_job.id = 123

        with patch(
            "apps.core.operations.video_job_repository.VideoJobRepository.get_by_id",
            new_callable=AsyncMock,
        ) as mock_get_by_id:
            mock_get_by_id.return_value = mock_job

            new_stage = "transcription_started"
            updated_job = await VideoJobRepository.add_processing_stage(
                mock_db_session_async, 123, new_stage
            )

            mock_get_by_id.assert_awaited_once_with(mock_db_session_async, 123)
            assert updated_job is not None
            if updated_job:
                assert updated_job is mock_job  # The same instance is modified
                assert updated_job.processing_stages == existing_stages + [new_stage]

            mock_db_session_async.flush.assert_awaited_once()
            mock_db_session_async.refresh.assert_awaited_once_with(mock_job)

    @pytest.mark.asyncio
    async def test_add_processing_stage_json_string(
        self, mock_db_session_async: AsyncMock
    ):
        """Test adding a processing stage when stages are stored as a JSON string."""
        existing_stages_json = json.dumps(["upload_complete"])
        # Ensure the mock_job.processing_stages is set as if read from DB (i.e., already a string)
        mock_job = VideoJobModel(video_id=42, processing_stages=existing_stages_json)  # type: ignore
        mock_job.id = 123

        with patch(
            "apps.core.operations.video_job_repository.VideoJobRepository.get_by_id",
            new_callable=AsyncMock,
        ) as mock_get_by_id:
            mock_get_by_id.return_value = mock_job

            new_stage = "validation_complete"
            updated_job = await VideoJobRepository.add_processing_stage(
                mock_db_session_async, 123, new_stage
            )

            mock_get_by_id.assert_awaited_once_with(mock_db_session_async, 123)
            assert updated_job is not None
            if updated_job:  # Guard attribute access
                assert updated_job is mock_job
                # The repository method should deserialize, append, and reserialize (or store as list if column type allows)
                # Assuming the repository method correctly handles JSON string to list conversion and back, or stores as Python list directly.
                # If it stores as Python list, then this assertion is fine.
                # If it converts back to JSON string, this assertion needs to change.
                # Based on VideoJobModel.processing_stages being potentially `JSON` type which SQLAlchemy handles,
                # it likely becomes a Python list in the model instance after load/modification.
                current_stages = json.loads(
                    existing_stages_json
                )  # Before adding new_stage
                current_stages.append(new_stage)
                assert updated_job.processing_stages == current_stages

            mock_db_session_async.flush.assert_awaited_once()
            mock_db_session_async.refresh.assert_awaited_once_with(mock_job)

    @pytest.mark.asyncio
    async def test_add_processing_stage_invalid_json(
        self, mock_db_session_async: AsyncMock
    ):
        """Test adding a stage when processing_stages is an invalid JSON string."""
        mock_job = VideoJobModel(video_id=42, processing_stages="not_a_valid_json[")  # type: ignore
        mock_job.id = 123

        with patch(
            "apps.core.operations.video_job_repository.VideoJobRepository.get_by_id",
            new_callable=AsyncMock,
        ) as mock_get_by_id:
            mock_get_by_id.return_value = mock_job

            new_stage = "validation_complete"
            # Depending on how add_processing_stage handles json.JSONDecodeError,
            # this might raise an exception, or log an error and initialize stages to [new_stage].
            # For this test, let's assume it logs error and initializes a new list.
            # If it's expected to raise, use pytest.raises.
            updated_job = await VideoJobRepository.add_processing_stage(
                mock_db_session_async, 123, new_stage
            )

            mock_get_by_id.assert_awaited_once_with(mock_db_session_async, 123)
            assert updated_job is not None
            if updated_job:
                assert updated_job is mock_job
                # Assuming repository initializes to [new_stage] on JSON error
                assert updated_job.processing_stages == [new_stage]

            mock_db_session_async.flush.assert_awaited_once()
            mock_db_session_async.refresh.assert_awaited_once_with(mock_job)

    @pytest.mark.asyncio
    async def test_add_processing_stage_not_found(
        self, mock_db_session_async: AsyncMock
    ):
        """Test adding a processing stage when the job doesn't exist."""
        with patch(
            "apps.core.operations.video_job_repository.VideoJobRepository.get_by_id",
            new_callable=AsyncMock,
        ) as mock_get_by_id:
            mock_get_by_id.return_value = None  # Simulate job not found

            new_stage = "transcription_started"
            updated_job = await VideoJobRepository.add_processing_stage(
                mock_db_session_async, 999, new_stage
            )

            mock_get_by_id.assert_awaited_once_with(mock_db_session_async, 999)
            assert updated_job is None
            assert mock_db_session_async.flush.await_count == 0
            assert mock_db_session_async.refresh.await_count == 0

    @pytest.mark.asyncio
    async def test_add_processing_stage_non_list_object(
        self, mock_db_session_async: AsyncMock
    ):
        """Test adding a stage when processing_stages is not a list or JSON list (e.g., a dict)."""
        # This scenario depends on how robust the add_processing_stage method is.
        # It might raise a TypeError, or attempt to handle it gracefully.
        # Let's assume it attempts to initialize to a new list with the stage.
        mock_job = VideoJobModel(video_id=42, processing_stages={"key": "value"})  # type: ignore
        mock_job.id = 123

        with patch(
            "apps.core.operations.video_job_repository.VideoJobRepository.get_by_id",
            new_callable=AsyncMock,
        ) as mock_get_by_id:
            mock_get_by_id.return_value = mock_job

            new_stage = "processing_initiated"
            updated_job = await VideoJobRepository.add_processing_stage(
                mock_db_session_async, 123, new_stage
            )

            mock_get_by_id.assert_awaited_once_with(mock_db_session_async, 123)
            assert updated_job is not None
            if updated_job:
                assert updated_job is mock_job
                # Assuming it re-initializes or similar graceful handling
                assert updated_job.processing_stages == [new_stage]

            mock_db_session_async.flush.assert_awaited_once()
            mock_db_session_async.refresh.assert_awaited_once_with(mock_job)
</file>

<file path="apps/core/tests/unit/operations/test_video_metadata_repository.py">
"""
Unit tests for the VideoMetadataRepository.
"""

from unittest.mock import AsyncMock, MagicMock, patch

import pytest
from sqlalchemy.ext.asyncio import AsyncSession

from apps.core.models.video_metadata_model import VideoMetadataModel
from apps.core.operations.video_metadata_repository import VideoMetadataRepository


@pytest.fixture
def mock_db_session_async() -> AsyncMock:
    """Create a mock SQLAlchemy AsyncSession."""
    mock_session = AsyncMock(spec=AsyncSession)
    # Specific chain setup (execute, scalars, first) will be done in tests as needed.
    return mock_session


@pytest.fixture
def sample_metadata_data():
    """Sample video metadata for testing."""
    return {
        "job_id": 42,
        "title": "Test Video Title",
        "description": "A test video description",
        "tags": ["test", "video", "unittest"],
        "transcript_text": "This is a test transcript.",
        "extracted_video_duration_seconds": 120.5,
        "extracted_video_resolution": "1920x1080",
    }


class TestVideoMetadataRepository:
    """Test cases for the VideoMetadataRepository class."""

    @pytest.mark.asyncio
    async def test_create_new_metadata(
        self, mock_db_session_async: AsyncMock, sample_metadata_data
    ):
        """Test creating new metadata when none exists."""
        # Configure the mock for the internal get_by_job_id call to return None
        mock_execute_result_get = AsyncMock()
        mock_scalars_result_get = AsyncMock()
        mock_db_session_async.execute.return_value = (
            mock_execute_result_get  # This will be for the get call
        )
        mock_execute_result_get.scalars.return_value = mock_scalars_result_get
        mock_scalars_result_get.first.return_value = None  # Simulate metadata not found

        # Call the repository method (which is now async)
        metadata = await VideoMetadataRepository.create_or_update(
            mock_db_session_async,  # Use the async mock session
            job_id=sample_metadata_data["job_id"],
            title=sample_metadata_data["title"],
            description=sample_metadata_data["description"],
        )

        # Verify the metadata model was created correctly
        assert isinstance(metadata, VideoMetadataModel)
        assert metadata.job_id == sample_metadata_data["job_id"]
        assert metadata.title == sample_metadata_data["title"]
        assert metadata.description == sample_metadata_data["description"]
        assert metadata.tags is None  # Not provided in this call
        assert metadata.transcript_text is None  # Not provided

        # Verify session operations
        # execute was called once for the initial get_by_job_id check
        mock_db_session_async.execute.assert_awaited_once()
        mock_db_session_async.add.assert_called_once()  # metadata instance passed to add
        mock_db_session_async.flush.assert_awaited_once()
        # Assuming create_or_update also refreshes the new instance
        mock_db_session_async.refresh.assert_awaited_once_with(metadata)

    @pytest.mark.asyncio
    async def test_update_existing_metadata(
        self, mock_db_session_async: AsyncMock, sample_metadata_data
    ):
        """Test updating existing metadata."""
        existing_metadata_instance = VideoMetadataModel(
            job_id=sample_metadata_data["job_id"],
            title="Old Title",
            description="Old Description",
        )

        # Configure the mock for the internal get_by_job_id call to return existing_metadata_instance
        mock_execute_result_get = AsyncMock()
        mock_scalars_result_get = AsyncMock()
        # Reset execute mock if it's the same instance from a previous test/setup in a class
        # For function-scoped mock_db_session_async, it's a fresh mock each time.
        mock_db_session_async.execute.return_value = mock_execute_result_get
        mock_execute_result_get.scalars.return_value = mock_scalars_result_get
        mock_scalars_result_get.first.return_value = existing_metadata_instance

        new_title = "Updated Title"
        new_tags = ["updated", "tags"]
        updated_metadata = await VideoMetadataRepository.create_or_update(
            mock_db_session_async,
            job_id=sample_metadata_data["job_id"],
            title=new_title,
            tags=new_tags,
        )

        # Verify the metadata was updated correctly
        assert updated_metadata is existing_metadata_instance
        assert updated_metadata.title == new_title
        assert updated_metadata.tags == new_tags
        assert updated_metadata.description == "Old Description"  # Unchanged

        # Verify session operations
        mock_db_session_async.execute.assert_awaited_once()  # For get_by_job_id
        mock_db_session_async.add.assert_not_called()  # No new object added
        mock_db_session_async.flush.assert_awaited_once()
        mock_db_session_async.refresh.assert_awaited_once_with(
            existing_metadata_instance
        )

    @pytest.mark.asyncio
    async def test_update_multiple_fields(
        self, mock_db_session_async: AsyncMock, sample_metadata_data
    ):
        """Test updating multiple fields at once."""
        existing_metadata_instance = VideoMetadataModel(
            job_id=sample_metadata_data["job_id"],
        )

        # Mock the internal get_by_job_id call
        mock_execute_result_get = AsyncMock()
        mock_scalars_result_get = AsyncMock()
        mock_db_session_async.execute.return_value = mock_execute_result_get
        mock_execute_result_get.scalars.return_value = mock_scalars_result_get
        mock_scalars_result_get.first.return_value = existing_metadata_instance

        # Call the repository method with multiple fields
        updated_metadata = await VideoMetadataRepository.create_or_update(
            mock_db_session_async,
            job_id=sample_metadata_data["job_id"],
            **sample_metadata_data,  # Update with all fields from the fixture
        )

        assert updated_metadata is existing_metadata_instance
        for key, value in sample_metadata_data.items():
            # job_id is part of the key for lookup, not an updatable field by kwargs in this manner usually
            # if key != "job_id":
            # The create_or_update likely iterates through kwargs and sets them.
            assert getattr(updated_metadata, key) == value

        mock_db_session_async.execute.assert_awaited_once()
        mock_db_session_async.add.assert_not_called()
        mock_db_session_async.flush.assert_awaited_once()
        mock_db_session_async.refresh.assert_awaited_once_with(
            existing_metadata_instance
        )

    @pytest.mark.asyncio
    async def test_get_by_job_id_found(
        self, mock_db_session_async: AsyncMock, sample_metadata_data
    ):
        """Test retrieving metadata by job_id when it exists."""
        mock_metadata_instance = VideoMetadataModel(**sample_metadata_data)  # type: ignore

        mock_execute_result = AsyncMock()
        mock_scalars_result = AsyncMock()
        mock_db_session_async.execute.return_value = mock_execute_result
        mock_execute_result.scalars.return_value = mock_scalars_result
        mock_scalars_result.first.return_value = mock_metadata_instance

        metadata = await VideoMetadataRepository.get_by_job_id(
            mock_db_session_async, sample_metadata_data["job_id"]
        )

        assert metadata is mock_metadata_instance
        if metadata:  # Guard for linter
            assert metadata.job_id == sample_metadata_data["job_id"]

        mock_db_session_async.execute.assert_awaited_once()

    @pytest.mark.asyncio
    async def test_get_by_job_id_not_found(self, mock_db_session_async: AsyncMock):
        """Test retrieving metadata by job_id when it doesn't exist."""
        mock_execute_result = AsyncMock()
        mock_scalars_result = AsyncMock()
        mock_db_session_async.execute.return_value = mock_execute_result
        mock_execute_result.scalars.return_value = mock_scalars_result
        mock_scalars_result.first.return_value = None  # Simulate not found

        metadata = await VideoMetadataRepository.get_by_job_id(
            mock_db_session_async, 999
        )

        assert metadata is None
        mock_db_session_async.execute.assert_awaited_once()

    @pytest.mark.asyncio
    async def test_create_with_empty_kwargs(self, mock_db_session_async: AsyncMock):
        """Test creating metadata with only job_id."""
        # Mock the internal get_by_job_id call to return None
        mock_execute_result_get = AsyncMock()
        mock_scalars_result_get = AsyncMock()
        mock_db_session_async.execute.return_value = mock_execute_result_get
        mock_execute_result_get.scalars.return_value = mock_scalars_result_get
        mock_scalars_result_get.first.return_value = None  # No existing metadata

        job_id_val = 123
        metadata = await VideoMetadataRepository.create_or_update(
            mock_db_session_async,
            job_id=job_id_val,
            # No other kwargs passed
        )

        assert isinstance(metadata, VideoMetadataModel)
        if metadata:  # Guard for linter
            assert metadata.job_id == job_id_val
            assert metadata.title is None
            assert metadata.description is None
            assert metadata.tags is None

        mock_db_session_async.execute.assert_awaited_once()
        mock_db_session_async.add.assert_called_once()  # With the new metadata instance
        mock_db_session_async.flush.assert_awaited_once()
        if metadata:  # metadata will not be None here due to creation path
            mock_db_session_async.refresh.assert_awaited_once_with(metadata)
</file>

<file path="apps/core/tests/unit/operations/test_video_repository.py">
"""
Unit tests for the VideoRepository.
"""

from unittest.mock import AsyncMock, MagicMock, patch

import pytest
from sqlalchemy.ext.asyncio import AsyncSession

from apps.core.models.video_model import VideoModel
from apps.core.operations.video_repository import VideoRepository


@pytest.fixture
def mock_db_session_async() -> AsyncMock:
    """Create a mock SQLAlchemy AsyncSession."""
    mock_session = AsyncMock(spec=AsyncSession)
    return mock_session


@pytest.fixture
def sample_video_data():
    """Sample video data for testing."""
    return {
        "uploader_user_id": "test-user-123",
        "original_filename": "test_video.mp4",
        "storage_path": "uploads/test-user-123/abc123.mp4",
        "content_type": "video/mp4",
        "size_bytes": 1024000,
    }


class TestVideoRepository:
    """Test cases for the VideoRepository class."""

    @pytest.mark.asyncio
    async def test_create(self, mock_db_session_async: AsyncMock, sample_video_data):
        """Test creating a new video."""
        video = await VideoRepository.create(mock_db_session_async, **sample_video_data)

        assert isinstance(video, VideoModel)
        assert video.uploader_user_id == sample_video_data["uploader_user_id"]
        assert video.original_filename == sample_video_data["original_filename"]
        assert video.storage_path == sample_video_data["storage_path"]
        assert video.content_type == sample_video_data["content_type"]
        assert video.size_bytes == sample_video_data["size_bytes"]

        mock_db_session_async.add.assert_called_once_with(video)
        mock_db_session_async.flush.assert_awaited_once()
        mock_db_session_async.refresh.assert_awaited_once_with(video)

    @pytest.mark.asyncio
    async def test_get_by_id_found(
        self, mock_db_session_async: AsyncMock, sample_video_data
    ):
        """Test retrieving a video by ID when it exists."""
        mock_video_instance = VideoModel(**sample_video_data)
        mock_video_instance.id = 123

        mock_execute_result = AsyncMock()
        mock_scalars_result = AsyncMock()
        mock_db_session_async.execute.return_value = mock_execute_result
        mock_execute_result.scalars.return_value = mock_scalars_result
        mock_scalars_result.first.return_value = mock_video_instance

        video = await VideoRepository.get_by_id(mock_db_session_async, 123)

        assert video is mock_video_instance
        if video:
            assert video.id == 123
        mock_db_session_async.execute.assert_awaited_once()

    @pytest.mark.asyncio
    async def test_get_by_id_not_found(self, mock_db_session_async: AsyncMock):
        """Test retrieving a video by ID when it doesn't exist."""
        mock_execute_result = AsyncMock()
        mock_scalars_result = AsyncMock()
        mock_db_session_async.execute.return_value = mock_execute_result
        mock_execute_result.scalars.return_value = mock_scalars_result
        mock_scalars_result.first.return_value = None

        video = await VideoRepository.get_by_id(mock_db_session_async, 999)

        assert video is None
        mock_db_session_async.execute.assert_awaited_once()

    @pytest.mark.asyncio
    async def test_db_error_handling(
        self, mock_db_session_async: AsyncMock, sample_video_data
    ):
        """Test handling of database errors during create's flush."""
        mock_db_session_async.flush = AsyncMock(side_effect=Exception("Database error"))

        with pytest.raises(Exception) as excinfo:
            await VideoRepository.create(mock_db_session_async, **sample_video_data)

        assert "Database error" in str(excinfo.value)
        mock_db_session_async.add.assert_called_once()
        mock_db_session_async.flush.assert_awaited_once()
</file>

<file path="apps/core/tests/unit/services/test_user_service.py">
"""
Unit tests for the UserService.
"""

from unittest.mock import AsyncMock, MagicMock, patch

import pytest
from fastapi import HTTPException
from sqlalchemy.ext.asyncio import AsyncSession

from apps.core.lib.auth.supabase_auth import AuthenticatedUser
from apps.core.models.user_model import User
from apps.core.operations.user_repository import UserRepository
from apps.core.services.user_service import UserService


@pytest.fixture
def mock_user_repository_async() -> AsyncMock:
    """Create a mock async UserRepository."""
    return AsyncMock(spec=UserRepository)


@pytest.fixture
def user_service_async(mock_user_repository_async: AsyncMock) -> UserService:
    """Create a UserService instance with mock async dependencies."""
    return UserService(user_repository=mock_user_repository_async)


@pytest.fixture
def mock_db_async() -> AsyncMock:
    """Mock SQLAlchemy AsyncSession."""
    return AsyncMock(spec=AsyncSession)


@pytest.fixture
def sample_user_data() -> dict:
    """Sample user data for testing."""
    return {
        "id": 1,
        "username": "testuser",
        "email": "test@example.com",
        "full_name": "Test User",
        "is_active": True,
        "supabase_auth_id": "some-auth-id-123",
    }


@pytest.fixture
def sample_user_async(sample_user_data: dict) -> AsyncMock:
    """Create a sample async mock User model instance."""
    user = AsyncMock(spec=User)
    for key, value in sample_user_data.items():
        setattr(user, key, value)
    user.hashed_password = "hashed_password"
    return user


@pytest.fixture
def auth_user() -> AuthenticatedUser:
    """Create a sample AuthenticatedUser for get_or_create tests."""
    return AuthenticatedUser(
        id="some-auth-id-123",
        email="test@example.com",
        aud="authenticated",
    )


class TestUserService:
    """Test cases for the UserService class."""

    @pytest.mark.asyncio
    async def test_get_user_profile_found(
        self,
        user_service_async: UserService,
        mock_user_repository_async: AsyncMock,
        sample_user_async: AsyncMock,
    ):
        """Test getting a user profile when the user exists."""
        test_user_id = sample_user_async.id
        mock_user_repository_async.get_user.return_value = sample_user_async

        user_profile_dict = await user_service_async.get_user_profile(test_user_id)

        assert user_profile_dict is not None
        if user_profile_dict:
            assert user_profile_dict["id"] == sample_user_async.id
            assert user_profile_dict["username"] == sample_user_async.username
            assert user_profile_dict["email"] == sample_user_async.email
            assert user_profile_dict["full_name"] == sample_user_async.full_name
            assert user_profile_dict["is_active"] == sample_user_async.is_active
            assert "hashed_password" not in user_profile_dict

        mock_user_repository_async.get_user.assert_awaited_once_with(test_user_id)

    @pytest.mark.asyncio
    async def test_get_user_profile_not_found(
        self, user_service_async: UserService, mock_user_repository_async: AsyncMock
    ):
        """Test getting a user profile when the user doesn't exist."""
        test_user_id = 999
        mock_user_repository_async.get_user.return_value = None

        with pytest.raises(HTTPException) as excinfo:
            await user_service_async.get_user_profile(test_user_id)

        assert excinfo.value.status_code == 404
        assert excinfo.value.detail == "User not found"
        mock_user_repository_async.get_user.assert_awaited_once_with(test_user_id)

    @pytest.mark.asyncio
    async def test_get_or_create_user_profile_existing(
        self,
        user_service_async: UserService,
        mock_user_repository_async: AsyncMock,
        sample_user_async: AsyncMock,
        auth_user: AuthenticatedUser,
    ):
        """Test getting an existing user profile via get_or_create_user_profile."""
        mock_user_repository_async.get_user_by_email.return_value = sample_user_async

        result_user = await user_service_async.get_or_create_user_profile(auth_user)

        assert result_user is sample_user_async
        mock_user_repository_async.get_user_by_email.assert_awaited_once_with(
            auth_user.email
        )
        mock_user_repository_async.create_user.assert_not_awaited()  # Should not be called if user exists

    @pytest.mark.asyncio
    async def test_get_or_create_user_profile_new(
        self,
        user_service_async: UserService,
        mock_user_repository_async: AsyncMock,
        sample_user_async: AsyncMock,
        auth_user: AuthenticatedUser,
    ):
        """Test creating a new user profile via get_or_create_user_profile."""
        mock_user_repository_async.get_user_by_email.return_value = (
            None  # Simulate user not found by email
        )
        mock_user_repository_async.create_user.return_value = (
            sample_user_async  # Mock the created user
        )

        result_user = await user_service_async.get_or_create_user_profile(auth_user)

        assert result_user is sample_user_async
        mock_user_repository_async.get_user_by_email.assert_awaited_once_with(
            auth_user.email
        )
        mock_user_repository_async.create_user.assert_awaited_once()

        # Verify the data passed to create_user (it's the first positional arg to the mock)
        # call_args[0] is for positional args, call_args[1] for kwargs
        # create_user in repo takes (user_data: dict)
        created_user_data_arg = mock_user_repository_async.create_user.await_args[0][0]
        assert created_user_data_arg["email"] == auth_user.email
        assert (
            auth_user.email is not None
        )  # Ensure email is not None before split for linter
        assert created_user_data_arg["username"] == auth_user.email.split("@")[0]
        assert created_user_data_arg["is_active"] is True
        # Assuming supabase_auth_id is also set, if that's part of User model and create logic
        # If UserService itself sets supabase_auth_id, it should be checked here.
        # The current UserRepo.create_user takes user_data dict, so it depends on what UserService puts in that dict.
        # The service logic for username generation is: auth_user.email.split("@")[0]
        # The service logic for other fields might be specific. For example, hashed_password = "" in the service.
        assert created_user_data_arg["hashed_password"] == ""

    @pytest.mark.asyncio
    async def test_get_or_create_user_profile_no_email(
        self, user_service_async: UserService, mock_user_repository_async: AsyncMock
    ):
        """Test handling when auth_user has no email."""
        # Create auth user without email
        auth_user_no_email = AuthenticatedUser(
            id="auth123",
            email=None,
            aud="authenticated",
        )

        # Call the service method and expect exception
        with pytest.raises(HTTPException) as excinfo:
            await user_service_async.get_or_create_user_profile(auth_user_no_email)

        # Verify exception
        assert excinfo.value.status_code == 400
        assert excinfo.value.detail == "Authenticated user missing email"

        # Verify repository not called
        mock_user_repository_async.get_user_by_email.assert_not_awaited()

    @pytest.mark.asyncio
    async def test_get_or_create_user_profile_with_fallback_username(
        self,
        user_service_async: UserService,
        mock_user_repository_async: AsyncMock,
        sample_user_async: AsyncMock,
    ):
        """Test creating a user with fallback username when email has no @ symbol."""
        # Create auth user with unusual email (no @)
        auth_user_unusual_email = AuthenticatedUser(
            id="auth123",
            email="invalid-email",
            aud="authenticated",
        )

        # Set up mock returns
        mock_user_repository_async.get_user_by_email.return_value = None
        mock_user_repository_async.create_user.return_value = sample_user_async

        # Call the service method
        result = await user_service_async.get_or_create_user_profile(
            auth_user_unusual_email
        )

        # Verify results
        assert result is sample_user_async

        # Verify repository calls
        mock_user_repository_async.get_user_by_email.assert_awaited_once_with(
            "invalid-email"
        )
        mock_user_repository_async.create_user.assert_awaited_once()

        # Verify the created user data uses fallback username
        created_user_data = mock_user_repository_async.create_user.await_args[0][0]
        assert created_user_data["username"] == f"user_{auth_user_unusual_email.id}"
        assert created_user_data["email"] == "invalid-email"

    @pytest.mark.asyncio
    async def test_create_user_success(
        self,
        user_service_async: UserService,
        mock_user_repository_async: AsyncMock,
        sample_user_async: AsyncMock,
        sample_user_data: dict,
    ):
        """Test creating a new user successfully."""
        # Set up mock returns for validation checks
        mock_user_repository_async.get_user_by_email.return_value = None
        mock_user_repository_async.get_user_by_username.return_value = None
        mock_user_repository_async.create_user.return_value = sample_user_async

        # Remove id as it's not part of input data
        user_input_dict = sample_user_data.copy()
        # Ensure we are creating a new user, so ID from sample_user_data (which implies existing) should not be used.
        # UserService.create_user expects a dict. Let's simulate the Pydantic model or dict it might receive.
        user_input_for_create = {
            "username": user_input_dict["username"],
            "email": user_input_dict["email"],
            "full_name": user_input_dict.get(
                "full_name"
            ),  # Use .get for optional fields
            "hashed_password": "hashed_password",  # create_user service method expects this
            "is_active": user_input_dict.get(
                "is_active", True
            ),  # Default if not in sample
            "supabase_auth_id": user_input_dict.get("supabase_auth_id"),
        }

        # Call the service method
        result_dict = await user_service_async.create_user(user_input_for_create)

        # Verify results
        assert result_dict["id"] == sample_user_async.id
        assert result_dict["username"] == sample_user_async.username
        assert result_dict["email"] == sample_user_async.email
        assert result_dict["full_name"] == sample_user_async.full_name
        assert result_dict["is_active"] == sample_user_async.is_active
        assert "hashed_password" not in result_dict  # Sensitive info excluded

        # Verify repository calls
        mock_user_repository_async.get_user_by_email.assert_awaited_once_with(
            user_input_for_create["email"]
        )
        mock_user_repository_async.get_user_by_username.assert_awaited_once_with(
            user_input_for_create["username"]
        )
        # Verify create_user was called with the correct structure
        # The service method constructs user_create_dict then passes its .model_dump() (if pydantic)
        # or the dict itself to repository's create_user.
        # Assuming user_input_for_create is what's ultimately passed (or its equivalent after Pydantic processing)
        mock_user_repository_async.create_user.assert_awaited_once_with(
            user_input_for_create
        )

    @pytest.mark.asyncio
    async def test_create_user_email_exists(
        self,
        user_service_async: UserService,
        mock_user_repository_async: AsyncMock,
        sample_user_async: AsyncMock,
        sample_user_data: dict,
    ):
        """Test creating a user when the email already exists."""
        # Set up mock returns for validation checks
        mock_user_repository_async.get_user_by_email.return_value = (
            sample_user_async  # Email exists
        )
        mock_user_repository_async.get_user_by_username.return_value = None

        user_input_dict = sample_user_data.copy()
        user_input_for_create = {
            "username": "newusername",  # Different username
            "email": user_input_dict["email"],  # Existing email
            "full_name": user_input_dict.get("full_name"),
            "hashed_password": "hashed_password",
            "is_active": user_input_dict.get("is_active", True),
            "supabase_auth_id": user_input_dict.get("supabase_auth_id"),
        }

        # Call the service method and expect exception
        with pytest.raises(HTTPException) as excinfo:
            await user_service_async.create_user(user_input_for_create)

        # Verify exception
        assert excinfo.value.status_code == 400
        assert excinfo.value.detail == "Email already registered"

        # Verify repository calls
        mock_user_repository_async.get_user_by_email.assert_awaited_once_with(
            user_input_for_create["email"]
        )
        mock_user_repository_async.get_user_by_username.assert_not_awaited()  # Should not be called if email check fails first
        mock_user_repository_async.create_user.assert_not_awaited()

    @pytest.mark.asyncio
    async def test_create_user_username_exists(
        self,
        user_service_async: UserService,
        mock_user_repository_async: AsyncMock,
        sample_user_async: AsyncMock,
        sample_user_data: dict,
    ):
        """Test creating a user when the username already exists."""
        # Set up mock returns for validation checks
        mock_user_repository_async.get_user_by_email.return_value = (
            None  # Email is unique
        )
        mock_user_repository_async.get_user_by_username.return_value = (
            sample_user_async  # Username exists
        )

        user_input_dict = sample_user_data.copy()
        user_input_for_create = {
            "username": user_input_dict["username"],  # Existing username
            "email": "newemail@example.com",  # Different email
            "full_name": user_input_dict.get("full_name"),
            "hashed_password": "hashed_password",
            "is_active": user_input_dict.get("is_active", True),
            "supabase_auth_id": user_input_dict.get("supabase_auth_id"),
        }

        # Call the service method and expect exception
        with pytest.raises(HTTPException) as excinfo:
            await user_service_async.create_user(user_input_for_create)

        # Verify exception
        assert excinfo.value.status_code == 400
        assert excinfo.value.detail == "Username already registered"

        # Verify repository calls
        mock_user_repository_async.get_user_by_email.assert_awaited_once_with(
            user_input_for_create["email"]
        )
        mock_user_repository_async.get_user_by_username.assert_awaited_once_with(
            user_input_for_create["username"]
        )
        mock_user_repository_async.create_user.assert_not_awaited()

    @pytest.mark.asyncio
    async def test_create_user_missing_email(
        self, user_service_async: UserService, mock_user_repository_async: AsyncMock
    ):
        """Test creating a user with missing email (should be caught by Pydantic model if UserCreate schema is used)."""
        user_input_for_create = {
            "username": "someuser",
            # "email": "missing@example.com", # Email is missing
            "full_name": "Some User",
            "hashed_password": "hashed_password",
        }
        # Depending on how UserService.create_user handles input (e.g. if it uses a Pydantic model UserCreate for validation)
        # this might raise a Pydantic ValidationError or an HTTPException if the service catches it.
        # For this test, let's assume the service raises HTTPException for simplicity if basic fields are missing,
        # or Pydantic ValidationError if it uses a model.
        # If UserService create_user uses a Pydantic model UserCreate that requires email:
        # from pydantic import ValidationError
        # with pytest.raises(ValidationError): # Or HTTPException if service translates it
        #     await user_service_async.create_user(user_input_for_create)

        # If the service's create_user method itself checks for 'email' in the dict:
        with pytest.raises(
            HTTPException
        ) as excinfo:  # Or TypeError if dict access fails like user_data["email"]
            await user_service_async.create_user(user_input_for_create)  # Pass the dict

        # This assertion depends on the actual error raised by create_user for missing fields.
        # If UserCreate Pydantic model is used, it would be a ValidationError.
        # If the service manually checks and raises HTTPException:
        assert (
            excinfo.value.status_code == 422
        )  # Unprocessable Entity (typical for validation errors)
        # Or if a KeyError/TypeError happens before validation and is not caught:
        # assert isinstance(excinfo.value, (KeyError, TypeError))

        mock_user_repository_async.create_user.assert_not_awaited()

    @pytest.mark.asyncio
    async def test_create_user_missing_username(
        self, user_service_async: UserService, mock_user_repository_async: AsyncMock
    ):
        """Test creating a user with missing username."""
        user_input_for_create = {
            # "username": "someuser", # Username is missing
            "email": "test@example.com",
            "full_name": "Some User",
            "hashed_password": "hashed_password",
        }

        with pytest.raises(
            HTTPException
        ) as excinfo:  # Assuming HTTPException for validation
            await user_service_async.create_user(user_input_for_create)

        assert excinfo.value.status_code == 422  # Unprocessable Entity
        mock_user_repository_async.create_user.assert_not_awaited()
</file>

<file path="apps/core/tests/unit/services/test_video_processing_service.py">
"""
Unit tests for the VideoProcessingService.
"""

import os
from unittest.mock import AsyncMock, MagicMock, Mock, call, patch

import pytest
from fastapi import BackgroundTasks, HTTPException

# Assuming AsyncSession is needed for type hints if db mocks are AsyncSession
from sqlalchemy.ext.asyncio import AsyncSession

from apps.core.core.exceptions import VideoProcessingError
from apps.core.models.enums import ProcessingStatus
from apps.core.models.video_job_model import VideoJobModel
from apps.core.models.video_metadata_model import VideoMetadataModel
from apps.core.models.video_model import VideoModel
from apps.core.services.video_processing_service import VideoProcessingService


@pytest.fixture
def mock_dependencies():
    """Create mock dependencies for the VideoProcessingService."""
    return {
        "video_repo": AsyncMock(),  # Repositories are now async
        "job_repo": AsyncMock(),  # Repositories are now async
        "metadata_repo": AsyncMock(),  # Repositories are now async
        "storage": AsyncMock(),  # Already AsyncMock
        "ai_adapter": AsyncMock(),  # Already AsyncMock
        # Assuming these utils remain synchronous. If any method called by service is async, these would need adjustment.
        "ffmpeg_utils": MagicMock(),
        "subtitle_utils": MagicMock(),
        "file_utils": MagicMock(),
    }


@pytest.fixture
def service(mock_dependencies):
    """Create a VideoProcessingService instance with mock dependencies."""
    return VideoProcessingService(
        video_repo=mock_dependencies["video_repo"],
        job_repo=mock_dependencies["job_repo"],
        metadata_repo=mock_dependencies["metadata_repo"],
        storage=mock_dependencies["storage"],
        ai_adapter=mock_dependencies["ai_adapter"],
        ffmpeg_utils=mock_dependencies["ffmpeg_utils"],
        subtitle_utils=mock_dependencies["subtitle_utils"],
        file_utils=mock_dependencies["file_utils"],
    )


@pytest.fixture
def mock_db_async() -> AsyncMock:  # Renamed and returns AsyncMock
    """Mock SQLAlchemy AsyncSession."""
    return AsyncMock(spec=AsyncSession)


@pytest.fixture
def mock_background_tasks():
    """Mock FastAPI BackgroundTasks."""
    # BackgroundTasks itself is not async, its add_task method is sync.
    return MagicMock(spec=BackgroundTasks)


@pytest.fixture
def sample_video_data():
    """Sample video data for testing."""
    return {
        "original_filename": "test_video.mp4",
        "video_content": b"test video content",
        "content_type": "video/mp4",
        "uploader_user_id": "test-user-123",
    }


class TestVideoProcessingService:
    """Test cases for the VideoProcessingService class."""

    async def test_initiate_video_processing(
        self,
        service: VideoProcessingService,
        mock_db_async: AsyncMock,  # Use the async db mock
        mock_background_tasks: MagicMock,
        mock_dependencies: dict,
        sample_video_data: dict,
    ):
        """Test initiating video processing pipeline."""
        # Set up mock returns
        # storage.save_file is async, ensure it's awaited in service or its return is awaitable if mock is AsyncMock
        mock_dependencies[
            "storage"
        ].save_file.return_value = "gs://bucket/uploads/test-user-123/test_video.mp4"

        mock_video = AsyncMock(
            spec=VideoModel
        )  # Using AsyncMock if its attributes are accessed or methods called async
        mock_video.id = 1
        # repo.create is now async, so its mock should handle await or be an AsyncMock itself
        mock_dependencies["video_repo"].create.return_value = mock_video

        mock_job = AsyncMock(spec=VideoJobModel)
        mock_job.id = 42
        mock_dependencies["job_repo"].create.return_value = mock_job

        # Call the service method (already awaited)
        result = await service.initiate_video_processing(
            db=mock_db_async,  # Pass async_db_mock
            **sample_video_data,
            background_tasks=mock_background_tasks,
        )

        assert result is mock_job

        # storage.save_file is async
        mock_dependencies["storage"].save_file.assert_awaited_once_with(
            file_content=sample_video_data["video_content"],
            filename=sample_video_data["original_filename"],
            subdir=f"uploads/{sample_video_data['uploader_user_id']}",
        )

        # video_repo.create is async
        mock_dependencies["video_repo"].create.assert_awaited_once_with(
            db=mock_db_async,
            uploader_user_id=sample_video_data["uploader_user_id"],
            original_filename=sample_video_data["original_filename"],
            storage_path="gs://bucket/uploads/test-user-123/test_video.mp4",
            content_type=sample_video_data["content_type"],
            size_bytes=len(sample_video_data["video_content"]),
        )

        # job_repo.create is async
        mock_dependencies["job_repo"].create.assert_awaited_once_with(
            db=mock_db_async,
            video_id=mock_video.id,
            status=ProcessingStatus.PENDING,
            processing_stages=None,  # Assuming default
            error_message=None,  # Assuming default
        )

        # DB commit is async
        mock_db_async.commit.assert_awaited_once()

        # BackgroundTasks.add_task is synchronous
        mock_background_tasks.add_task.assert_called_once_with(
            service._execute_processing_pipeline,  # Target function
            mock_job.id,  # args for the target function
            "gs://bucket/uploads/test-user-123/test_video.mp4",  # args for the target function
        )

    @patch("apps.core.services.video_processing_service.AsyncSessionLocal")
    async def test_execute_processing_pipeline_success(
        self,
        mock_AsyncSessionLocal: MagicMock,  # Patched AsyncSessionLocal factory
        service: VideoProcessingService,
        mock_dependencies: dict,
    ):
        """Test successful execution of video processing pipeline."""
        # Setup mock for the async context manager produced by AsyncSessionLocal()
        mock_db_async_cm = AsyncMock()  # This is the context manager object
        mock_db_async_session = AsyncMock(
            spec=AsyncSession
        )  # This is the session yielded by __aenter__
        mock_AsyncSessionLocal.return_value = mock_db_async_cm
        mock_db_async_cm.__aenter__.return_value = mock_db_async_session

        # Mock job and related objects
        mock_video = AsyncMock(spec=VideoModel)  # Use AsyncMock for spec consistency
        mock_video.original_filename = "test_video.mp4"
        mock_video.uploader_user_id = "test-user-123"

        mock_job = AsyncMock(spec=VideoJobModel)
        mock_job.id = 42
        mock_job.video = mock_video  # Assuming direct attribute assignment for mock

        # job_repo.get_by_id is async
        mock_dependencies["job_repo"].get_by_id.return_value = mock_job

        # Mock file utilities (assuming these remain synchronous)
        mock_dependencies["file_utils"].create_temp_dir.return_value = "/tmp/test_dir"

        # Mock ffmpeg utilities (assuming sync)
        mock_dependencies["ffmpeg_utils"].get_video_metadata_sync.return_value = {
            "duration": 120.5,
            "resolution": "1920x1080",
            "format": "mp4",
        }

        # Mock AI adapter (methods are async)
        mock_dependencies[
            "ai_adapter"
        ].transcribe_audio.return_value = "This is a test transcript."
        mock_dependencies["ai_adapter"].generate_text.side_effect = [
            "Test Video Title",
            "Test video description.",
            "test, video, processing",
            "Show notes for the test video.",
        ]

        # Mock subtitle utils (assuming sync)
        mock_dependencies[
            "subtitle_utils"
        ].generate_vtt.return_value = (
            "WEBVTT\n\n00:00:00.000 --> 00:00:01.000\nThis is a test transcript."
        )
        mock_dependencies[
            "subtitle_utils"
        ].generate_srt.return_value = (
            "1\n00:00:00,000 --> 00:00:01,000\nThis is a test transcript."
        )

        # Mock storage.save_file (async)
        # Use a list for side_effect if called multiple times with different return values in sequence
        mock_dependencies["storage"].save_file.side_effect = [
            "gs://bucket/transcripts/test-user-123/transcript.txt",
            "gs://bucket/subtitles/test-user-123/subtitles.vtt",
            "gs://bucket/subtitles/test-user-123/subtitles.srt",
            "gs://bucket/thumbnails/test-user-123/thumbnail.jpg",
        ]

        mock_open = MagicMock()  # For patching builtins.open (sync)
        mock_file_content = MagicMock()
        mock_open.return_value.__enter__.return_value = mock_file_content
        mock_file_content.read.return_value = b"test thumbnail data"

        with patch("builtins.open", mock_open):
            await service._execute_processing_pipeline(
                42, "gs://bucket/uploads/test-user-123/test_video.mp4"
            )

        # --- Assertions ---

        # Step 0: Job status update to PROCESSING
        mock_dependencies["job_repo"].update_status.assert_any_await_with(
            mock_db_async_session, 42, ProcessingStatus.PROCESSING
        )

        # Step 1: Download video (if service._download_video is called and is async)
        # service._download_video might call storage.download_file_to_temp, which is async.
        # Assuming it's called, and storage.download_file_to_temp is the underlying async call.
        # This depends on the internal structure of _execute_processing_pipeline and _download_video.
        # For now, let's assume _download_video is called and it uses storage.download_file_to_temp.
        # If _download_video is a helper that orchestrates this, we might not mock storage.download directly here
        # unless _download_video itself is mocked. Given it's a private method, we test its effects.
        # The existing test doesn't mock/assert a download step explicitly other than file_utils.create_temp_dir.
        # So, we'll stick to what was previously being asserted or implied.
        mock_dependencies[
            "file_utils"
        ].create_temp_dir.assert_called_once()  # For local processing

        # Step 2: Metadata extraction (ffmpeg - sync)
        mock_dependencies["ffmpeg_utils"].get_video_metadata_sync.assert_called_once()
        mock_dependencies["metadata_repo"].create_or_update.assert_any_await_with(
            mock_db_async_session,
            42,
            extracted_video_duration_seconds=120.5,
            extracted_video_resolution="1920x1080",
            extracted_video_format="mp4",
        )

        # Step 3: Audio extraction (ffmpeg - sync) and transcription (AI - async)
        mock_dependencies[
            "ffmpeg_utils"
        ].extract_audio_sync.assert_called_once()  # Sync
        mock_dependencies["ai_adapter"].transcribe_audio.assert_awaited_once()  # Async
        #   Save transcript text (storage.save_file - async)
        mock_dependencies["storage"].save_file.assert_any_await_with(
            file_content="This is a test transcript.",
            filename="transcript.txt",
            subdir=f"transcripts/{mock_video.uploader_user_id}",
            content_type="text/plain",
        )
        mock_dependencies["metadata_repo"].create_or_update.assert_any_await_with(
            mock_db_async_session,
            42,
            transcript_text="This is a test transcript.",
            transcript_file_url="gs://bucket/transcripts/test-user-123/transcript.txt",  # From save_file side_effect
        )

        # Step 4: Content metadata generation (AI - async)
        assert mock_dependencies["ai_adapter"].generate_text.await_count == 4
        mock_dependencies["metadata_repo"].create_or_update.assert_any_await_with(
            mock_db_async_session,
            42,
            title="Test Video Title",
            description="Test video description.",
            tags=["test", "video", "processing"],
            # show_notes_text="Show notes for the test video.", # If this is a field
        )

        # Step 5: Subtitles generation (sync) and saving (async)
        mock_dependencies["subtitle_utils"].generate_vtt.assert_called_once()
        mock_dependencies["subtitle_utils"].generate_srt.assert_called_once()
        #   Save VTT (storage.save_file - async)
        mock_dependencies["storage"].save_file.assert_any_await_with(
            file_content="WEBVTT\n\n00:00:00.000 --> 00:00:01.000\nThis is a test transcript.",
            filename="subtitles.vtt",
            subdir=f"subtitles/{mock_video.uploader_user_id}",
            content_type="text/vtt",
        )
        #   Save SRT (storage.save_file - async)
        mock_dependencies["storage"].save_file.assert_any_await_with(
            file_content="1\n00:00:00,000 --> 00:00:01,000\nThis is a test transcript.",
            filename="subtitles.srt",
            subdir=f"subtitles/{mock_video.uploader_user_id}",
            content_type="application/x-subrip",
        )
        mock_dependencies["metadata_repo"].create_or_update.assert_any_await_with(
            mock_db_async_session,
            42,
            subtitle_files_urls={
                "vtt": "gs://bucket/subtitles/test-user-123/subtitles.vtt",  # From save_file side_effect
                "srt": "gs://bucket/subtitles/test-user-123/subtitles.srt",  # From save_file side_effect
            },
        )

        # Step 6: Thumbnail extraction (ffmpeg - sync) and saving (async)
        # Assuming extract_frame_sync takes the local video path and output path
        # The exact args depend on how ffmpeg_utils.extract_frame_sync is structured.
        # Let's assume it takes an output path like "/tmp/test_dir/thumbnail.jpg"
        mock_dependencies["ffmpeg_utils"].extract_frame_sync.assert_called_once()
        #   Patching builtins.open was done to simulate reading this thumbnail file.
        #   Save thumbnail (storage.save_file - async)
        mock_dependencies["storage"].save_file.assert_any_await_with(
            file_content=b"test thumbnail data",  # From the mock_file.read.return_value
            filename="thumbnail.jpg",
            subdir=f"thumbnails/{mock_video.uploader_user_id}",
            content_type="image/jpeg",
        )
        mock_dependencies["metadata_repo"].create_or_update.assert_any_await_with(
            mock_db_async_session,
            42,
            thumbnail_file_url="gs://bucket/thumbnails/test-user-123/thumbnail.jpg",  # From save_file side_effect
        )

        # Final step: Mark job as completed
        mock_dependencies["job_repo"].update_status.assert_any_await_with(
            mock_db_async_session, 42, ProcessingStatus.COMPLETED
        )

        # DB Commit at the end of successful pipeline
        mock_db_async_session.commit.assert_awaited_once()

        # Cleanup local temp files (sync)
        mock_dependencies["file_utils"].remove_dir.assert_called_once_with(
            "/tmp/test_dir"
        )

    @patch("apps.core.services.video_processing_service.AsyncSessionLocal")
    async def test_execute_processing_pipeline_error(
        self,
        mock_AsyncSessionLocal: MagicMock,  # Patched AsyncSessionLocal factory
        service: VideoProcessingService,
        mock_dependencies: dict,
    ):
        """Test handling of errors in the processing pipeline."""
        # Setup mock for the async context manager produced by AsyncSessionLocal()
        mock_db_async_cm = AsyncMock()  # This is the context manager object
        mock_db_async_session = AsyncMock(
            spec=AsyncSession
        )  # This is the session yielded by __aenter__
        mock_AsyncSessionLocal.return_value = mock_db_async_cm
        mock_db_async_cm.__aenter__.return_value = mock_db_async_session

        # Mock job and related objects
        mock_video = AsyncMock(spec=VideoModel)
        mock_video.original_filename = "test_video.mp4"
        mock_video.uploader_user_id = "test-user-123"

        mock_job = AsyncMock(spec=VideoJobModel)
        mock_job.id = 42
        mock_job.video = mock_video

        # job_repo.get_by_id is async
        mock_dependencies["job_repo"].get_by_id.return_value = mock_job

        # Mock file utilities
        mock_dependencies["file_utils"].create_temp_dir.return_value = "/tmp/test_dir"

        # Set up an error during processing
        mock_dependencies[
            "ffmpeg_utils"
        ].get_video_metadata_sync.side_effect = Exception("FFmpeg error")

        # Call the method
        await service._execute_processing_pipeline(
            42, "gs://bucket/uploads/test-user-123/test_video.mp4"
        )

        # Verify error handling
        mock_dependencies["job_repo"].update_status.assert_any_call(
            mock_db_async_session, 42, ProcessingStatus.FAILED
        )
        mock_dependencies["job_repo"].add_processing_stage.assert_awaited_once_with(
            mock_db_async_session, 42, "Error: FFmpeg error"
        )

        # Verify cleanup still happens
        mock_dependencies["file_utils"].remove_dir.assert_called_once_with(
            "/tmp/test_dir"
        )
        mock_db_async_session.commit.assert_awaited_once()

    @patch("apps.core.services.video_processing_service.AsyncSessionLocal")
    async def test_execute_processing_pipeline_job_not_found(
        self,
        mock_AsyncSessionLocal: MagicMock,
        service: VideoProcessingService,
        mock_dependencies: dict,
    ):
        """Test pipeline behavior when the initial job ID is not found."""
        mock_db_async_cm = AsyncMock()
        mock_db_async_session = AsyncMock(spec=AsyncSession)
        mock_AsyncSessionLocal.return_value = mock_db_async_cm
        mock_db_async_cm.__aenter__.return_value = mock_db_async_session

        # Simulate job_repo.get_by_id returning None
        mock_dependencies["job_repo"].get_by_id.return_value = None

        # Temp dir might still be created before job is fetched, or not, depending on service logic.
        # If it is, we need to mock its creation and assert its removal.
        temp_dir_path = "/tmp/job_not_found_dir"
        mock_dependencies["file_utils"].create_temp_dir.return_value = temp_dir_path

        job_id_not_found = 999
        video_url = "gs://bucket/uploads/some_video.mp4"

        await service._execute_processing_pipeline(job_id_not_found, video_url)

        # Verify that no processing steps were attempted if job not found early.
        # For example, ffmpeg_utils should not have been called.
        mock_dependencies["ffmpeg_utils"].extract_audio_sync.assert_not_called()
        mock_dependencies["ffmpeg_utils"].get_video_metadata_sync.assert_not_called()
        mock_dependencies["ai_adapter"].transcribe_audio.assert_not_awaited()

        # Verify no status updates were attempted for a non-existent job ID on job_repo.
        # If job_repo.update_status was called with job_id_not_found, it would likely fail or be a no-op.
        # We are checking that the service logic bails out before trying to update status.
        # Count calls to job_repo.update_status with specific non-existent job_id
        update_status_calls = [
            call_args
            for call_args in mock_dependencies["job_repo"].update_status.await_args_list
            if call_args[0][1] == job_id_not_found  # args[0] is db, args[1] is job_id
        ]
        assert len(update_status_calls) == 0

        # Check that commit/rollback were not called as no db changes should have been made related to this job.
        mock_db_async_session.commit.assert_not_awaited()
        mock_db_async_session.rollback.assert_not_awaited()

        # Check if temp dir cleanup was still called if it was created.
        # This depends on the service's try/finally structure for temp dir management.
        # If create_temp_dir is called regardless, remove_dir should also be called.
        if mock_dependencies["file_utils"].create_temp_dir.called:
            mock_dependencies["file_utils"].remove_dir.assert_called_once_with(
                temp_dir_path
            )
        else:
            mock_dependencies["file_utils"].remove_dir.assert_not_called()

    async def test_get_job_details_found(
        self,
        service: VideoProcessingService,
        mock_db_async: AsyncMock,
        mock_dependencies: dict,
    ):
        """Test retrieving job details when job exists and user is owner."""
        mock_video = AsyncMock(spec=VideoModel)
        mock_video.uploader_user_id = "test-user-123"

        mock_job = AsyncMock(spec=VideoJobModel)
        mock_job.id = 42
        mock_job.video = mock_video  # Link video to job for uploader_user_id check

        mock_dependencies["job_repo"].get_by_id.return_value = mock_job

        result = await service.get_job_details(mock_db_async, 42, "test-user-123")

        assert result is mock_job
        mock_dependencies["job_repo"].get_by_id.assert_awaited_once_with(
            mock_db_async, 42
        )

    async def test_get_job_details_not_found(
        self,
        service: VideoProcessingService,
        mock_db_async: AsyncMock,
        mock_dependencies: dict,
    ):
        """Test retrieving job details when job does not exist."""
        mock_dependencies["job_repo"].get_by_id.return_value = None

        with pytest.raises(HTTPException) as excinfo:
            await service.get_job_details(mock_db_async, 999, "test-user-123")

        assert excinfo.value.status_code == 404
        assert excinfo.value.detail == "Job not found"
        mock_dependencies["job_repo"].get_by_id.assert_awaited_once_with(
            mock_db_async, 999
        )

    async def test_get_job_details_unauthorized(
        self,
        service: VideoProcessingService,
        mock_db_async: AsyncMock,
        mock_dependencies: dict,
    ):
        """Test retrieving job details when user is not the owner."""
        mock_video = AsyncMock(spec=VideoModel)
        mock_video.uploader_user_id = "other-user-456"  # Different owner

        mock_job = AsyncMock(spec=VideoJobModel)
        mock_job.id = 42
        mock_job.video = mock_video

        mock_dependencies["job_repo"].get_by_id.return_value = mock_job

        with pytest.raises(HTTPException) as excinfo:
            await service.get_job_details(
                mock_db_async, 42, "test-user-123"
            )  # Current user is test-user-123

        assert (
            excinfo.value.status_code == 404
        )  # Or 403 Forbidden, depending on service logic
        # The original test asserted 404, so we keep it consistent.
        # A 403 might be more semantically correct if the job exists but user can't access.
        # However, often services return 404 to avoid revealing existence of a resource.
        assert excinfo.value.detail == "Job not found"
        mock_dependencies["job_repo"].get_by_id.assert_awaited_once_with(
            mock_db_async, 42
        )
</file>

<file path="apps/core/tests/conftest.py">
import asyncio
from typing import AsyncGenerator, Generator

import pytest
import pytest_asyncio
from core.lib.database.connection import Base, get_async_db_session

# Assuming your FastAPI app instance is in 'main.py' at the root of 'apps/core'
# Adjust the import path if your main app instance is located elsewhere.
from main import app
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine
from sqlalchemy.orm import sessionmaker
from starlette.testclient import TestClient

# Use a separate in-memory SQLite database for tests
# Using a file-based SQLite for easier inspection if needed: ./test.db
# For true in-memory, use "sqlite+aiosqlite:///:memory:"
# However, :memory: dbs are distinct per connection, which can be tricky with SQLAlchemy engines/sessions.
# A file-based one ensures all connections in a test session hit the same DB.
TEST_DATABASE_URL = "sqlite+aiosqlite:///./test_db_file.db"


@pytest.fixture(scope="session")
def event_loop() -> Generator[asyncio.AbstractEventLoop, None, None]:
    """Create an instance of the default event loop for each test session."""
    loop = asyncio.get_event_loop_policy().new_event_loop()
    yield loop
    loop.close()


@pytest_asyncio.fixture(scope="session")
async def async_engine_fixture():  # Renamed to avoid conflict if a var is named async_engine
    """Create an async engine for the test database for the entire session."""
    engine = create_async_engine(TEST_DATABASE_URL)
    async with engine.begin() as conn:
        # Drop all tables first to ensure a clean state for each test session
        await conn.run_sync(Base.metadata.drop_all)
        await conn.run_sync(Base.metadata.create_all)
    yield engine
    await engine.dispose()
    # Consider removing the test_db_file.db if created
    # import os
    # if os.path.exists("./test_db_file.db"):
    #     os.remove("./test_db_file.db")


@pytest_asyncio.fixture(scope="function")
async def db_session_fixture(
    async_engine_fixture,
) -> AsyncGenerator[AsyncSession, None]:  # Renamed
    """Yield an AsyncSession for each test function, ensuring transaction rollback."""
    # sessionmaker for test sessions
    AsyncTestSessionLocal = sessionmaker(
        bind=async_engine_fixture,
        class_=AsyncSession,
        expire_on_commit=False,
        autoflush=False,
    )

    async with AsyncTestSessionLocal() as session:
        # Begin a transaction
        await session.begin()
        try:
            yield session
        finally:
            # Rollback the transaction to ensure test isolation
            await session.rollback()
            await session.close()


@pytest.fixture(scope="function")  # Changed to function scope
def test_client_fixture(
    db_session_fixture: AsyncSession,
) -> Generator[TestClient, None, None]:  # Renamed
    """
    Create a TestClient for API tests for each function.
    Overrides the get_async_db_session dependency with the test session.
    """

    async def override_get_async_db_session() -> AsyncGenerator[AsyncSession, None]:
        yield db_session_fixture

    app.dependency_overrides[get_async_db_session] = override_get_async_db_session
    with TestClient(app) as client:
        yield client
    # Clean up the override after the test
    del app.dependency_overrides[get_async_db_session]
</file>

<file path="apps/core/tests/test_api.py">
import pytest
from httpx import AsyncClient  # Changed from fastapi.testclient import TestClient
from sqlalchemy.ext.asyncio import AsyncSession

# main.app and its dependency_overrides will be handled by test_client_fixture from conftest
# from main import app
# from lib.database import Base, create_session # Not used directly anymore
# from sqlalchemy import create_engine # Not used directly anymore
# from sqlalchemy.orm import sessionmaker # Not used directly anymore
# from sqlalchemy.pool import StaticPool # Not used directly anymore

# Setup in-memory SQLite for testing - This is now handled by conftest.py
# SQLALCHEMY_DATABASE_URL = "sqlite:///:memory:"
# engine = create_engine(
# SQLALCHEMY_DATABASE_URL,
# connect_args={"check_same_thread": False},
# poolclass=StaticPool,
# )
# TestingSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)


# Override the get_db dependency - This is now handled by test_client_fixture in conftest.py
# def override_get_db():
# db = TestingSessionLocal()
# try:
# yield db
# finally:
# db.close()


# app.dependency_overrides[create_session] = override_get_db

# client = TestClient(app) # Client will come from test_client_fixture


# @pytest.fixture(scope="function")
# def test_db():
# # Create the database tables - Handled by async_engine_fixture in conftest.py
# Base.metadata.create_all(bind=engine)
# yield
# # Drop the database tables
# Base.metadata.drop_all(bind=engine)


@pytest.mark.asyncio
async def test_create_user(
    client: AsyncClient,  # Changed from TestClient
):  # client injected from conftest.test_client_fixture
    response = await client.post(  # Added await, client is now AsyncClient
        "/api/v1/users/",
        json={
            "username": "testuser",
            "email": "test@example.com",
            "full_name": "Test User",
            "password": "password123",
        },
    )
    assert response.status_code == 201
    data = response.json()
    assert data["username"] == "testuser"
    assert data["email"] == "test@example.com"
    assert data["full_name"] == "Test User"
    assert "id" in data
    assert "password" not in data


@pytest.mark.asyncio
async def test_get_user(
    client: AsyncClient,  # Changed from TestClient
):  # client injected from conftest.test_client_fixture
    # First create a user
    response_create = await client.post(  # Added await
        "/api/v1/users/",
        json={
            "username": "testuser_get",  # Use a different username to avoid conflicts if tests run in parallel or state leaks
            "email": "testget@example.com",
            "full_name": "Test User Get",
            "password": "password123",
        },
    )
    assert response_create.status_code == 201
    user_id = response_create.json()["id"]

    # Now get the user
    response_get = await client.get(f"/api/v1/users/{user_id}")  # Added await
    assert response_get.status_code == 200
    data_get = response_get.json()
    assert data_get["username"] == "testuser_get"
    assert data_get["email"] == "testget@example.com"
    assert data_get["id"] == user_id
</file>

<file path="apps/core/tests/test_architecture.py">
import ast
from pathlib import Path


def get_import_modules(file_path):
    """Extract all import statements from a Python file"""
    with open(file_path, "r") as f:
        file_content = f.read()

    tree = ast.parse(file_content)
    imports = []

    for node in ast.walk(tree):
        # Check for import statements (import x, import x.y)
        if isinstance(node, ast.Import):
            for name in node.names:
                imports.append(name.name)
        # Check for from import statements (from x import y)
        elif isinstance(node, ast.ImportFrom) and node.module is not None:
            imports.append(node.module)

    return imports


def check_imports(directory, forbidden_imports, error_msg_template):
    """Helper function to check imports in a directory against forbidden ones"""
    # Get the project root directory
    project_root = Path(__file__).parent.parent
    target_dir = project_root / directory

    # Get all Python files in the target directory
    py_files = [f for f in target_dir.glob("*.py") if f.is_file()]

    # Verify there are files to check
    assert len(py_files) > 0, f"No Python files found in the {directory} directory"

    violations = []
    for file_path in py_files:
        imports = get_import_modules(file_path)

        for forbidden_prefix in forbidden_imports:
            illegal_imports = [
                imp for imp in imports if imp.startswith(forbidden_prefix)
            ]
            if illegal_imports:
                violation = {
                    "file": file_path.name,
                    "forbidden_prefix": forbidden_prefix,
                    "imports": illegal_imports,
                }
                violations.append(violation)
                print(
                    error_msg_template.format(
                        file=file_path.name,
                        layer=forbidden_prefix,
                        imports=illegal_imports,
                    )
                )

    return violations


def test_api_layer_architecture():
    """
    Test that the API layer follows architectural boundaries by
    not importing directly from operations or models
    """
    violations = check_imports(
        directory="api",
        forbidden_imports=["operations", "models"],
        error_msg_template="File {file} directly imports from {layer} layer: {imports}",
    )

    assert not violations, (
        "API layer should not import directly from operations or models layers"
    )


def test_service_layer_architecture():
    """
    Test that the Service layer follows architectural boundaries by
    not importing directly from models layer (should use operations layer)
    """
    violations = check_imports(
        directory="services",
        forbidden_imports=["models"],
        error_msg_template="File {file} directly imports from {layer} layer: {imports}",
    )

    assert not violations, (
        "Service layer should not import directly from models layer (use operations layer instead)"
    )


def test_all_architectural_boundaries():
    """Comprehensive test of all architectural boundaries in the layered design"""
    # Define the layer boundaries
    layer_boundaries = {
        "api": [
            "operations",
            "models",
        ],  # API should not import from operations or models
        "services": ["models"],  # Services should not import from models
    }

    all_violations = []

    for layer, forbidden in layer_boundaries.items():
        violations = check_imports(
            directory=layer,
            forbidden_imports=forbidden,
            error_msg_template=f"Architectural violation in {layer}: {{file}} imports from {{layer}} layer: {{imports}}",
        )
        all_violations.extend(violations)

    # Detailed report of violations
    if all_violations:
        violation_report = "\n".join(
            [
                f"- {v['file']} imports from {v['forbidden_prefix']}: {v['imports']}"
                for v in all_violations
            ]
        )
        assert False, f"Architectural boundary violations found:\n{violation_report}"
</file>

<file path="apps/core/.env.production">
ENVIRONMENT="production"

# Supabase (Production/Hosted)
SUPABASE_URL="https://atvyovuiqftrksyetnjw.supabase.co"
SUPABASE_ANON_KEY="eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImF0dnlvdnVpcWZ0cmtzeWV0bmp3Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3NDYyMjU5NzcsImV4cCI6MjA2MTgwMTk3N30.3y2E7VZZySXH5P_Kq8H989mH7XsVWVZwgzJISuaDQls"
SUPABASE_SERVICE_ROLE_KEY="eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImF0dnlvdnVpcWZ0cmtzeWV0bmp3Iiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc0NjIyNTk3NywiZXhwIjoyMDYxODAxOTc3fQ.cqURht0Dc1IN2BIM01Gwqg75BTdDJyzgJO-Ge2GNiUI"
SUPABASE_PROJECT_ID="atvyovuiqftrksyetnjw"
SUPABASE_JWT_SECRET="pj95jDEKB629r4fM2V77kWEndWrJeDT8sHtyf1ddWqIgXsG+hJAojyDTbJuHsr2mUPShFM66Q0oSAvab3fjrSQ=="
DATABASE_URL="your_production_database_url"

# Google Cloud Settings (Production)
GOOGLE_APPLICATION_CREDENTIALS="./config/secrets/automations-457120-2c820f705e5e.json"
GCS_UPLOAD_BUCKET="automations-youtube-videos-2025"
REGION="us-east1"
GOOGLE_CLOUD_PROJECT="automations-457120"

# AI Service (Example Gemini)
GEMINI_API_KEY="your_production_gemini_api_key"

# Storage (GCS for prod)
STORAGE_BACKEND="gcs"
GCS_BUCKET_NAME="automations-youtube-videos-2025"
GOOGLE_APPLICATION_CREDENTIALS_PATH="./config/secrets/automations-457120-2c820f705e5e.json"

# Redis (if used for caching in production)
REDIS_HOST="your_production_redis_host"
REDIS_PORT="your_production_redis_port"
</file>

<file path="apps/core/.gitignore">
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# Distribution / packaging
dist/
build/
*.egg-info/

# Virtual environments
venv/
.venv/
env/
ENV/

# Environment variables
.env.local

# Database
*.db
*.sqlite3

# Testing
.coverage
htmlcov/
.pytest_cache/

# IDE
.idea/

# Logs
*.log 

.mypy_cache/
.ruff_cache/
</file>

<file path="apps/core/.python-version">
3.13
</file>

<file path="apps/core/main.py">
import os

from fastapi import BackgroundTasks, FastAPI, File, HTTPException, UploadFile

import apps.core.models
from apps.core.api.endpoints import router as video_api_router
from apps.core.api.endpoints.jobs_endpoints import router as jobs_api_router

app = FastAPI()

# Register routers
app.include_router(video_api_router, prefix="/api/v1/videos", tags=["Video Processing"])
app.include_router(jobs_api_router, prefix="/api/v1/jobs", tags=["Jobs"])


# Add a simple startup message
@app.get("/")
async def root():
    return {"message": "Video Processing API is running"}


# Simple test endpoint for video upload without authentication
@app.post("/test/upload")
async def test_upload(file: UploadFile = File(...)):
    """Test endpoint for uploading videos without authentication"""
    print(f"Received file: {file.filename}, content_type: {file.content_type}")

    # For testing, we'll accept any file type
    # if not file.content_type or not file.content_type.startswith("video/"):
    #     return {"error": "File must be a video"}

    if not file.filename:
        raise HTTPException(status_code=400, detail="Missing filename")

    # Save the file to a temporary location using an absolute path
    content = await file.read()

    # Get the absolute path to the core directory - we're in apps/core/main.py
    core_dir = os.path.dirname(os.path.abspath(__file__))
    test_upload_dir = os.path.join(core_dir, "output_files", "uploads", "test")

    # Create directory if it doesn't exist
    os.makedirs(test_upload_dir, exist_ok=True)

    # Build full file path
    save_path = os.path.join(test_upload_dir, file.filename)

    # Save the file
    with open(save_path, "wb") as f:
        f.write(content)

    return {
        "message": "Video uploaded successfully for testing",
        "filename": file.filename,
        "content_type": file.content_type,
        "size": len(content),
        "saved_path": save_path,
    }


# Run the application if this script is executed directly
if __name__ == "__main__":
    import uvicorn

    print("Starting FastAPI server...")
    uvicorn.run(app, host="0.0.0.0", port=8000)
</file>

<file path="apps/core/package.json">
{
    "name": "@echo/core",
    "version": "1.0.0",
    "description": "Python API Core Service",
    "private": true,
    "scripts": {
      "test": "./bin/test.sh",
      "dev": "./bin/dev.sh",
      "setup-env": "./bin/setup.sh",
      "lint": "./bin/lint.sh",
      "lint:fix": "./bin/lint-fix.sh",
      "format": "./bin/format.sh",
      "typecheck": "./bin/typecheck.sh"
    },
    "keywords": [
      "python",
      "api",
      "fastapi"
    ],
    "author": "",
    "license": "ISC"
  }
</file>

<file path="apps/core/pyproject.toml">
[project]
name = "echo"
version = "0.1.0"
description = "Video processing pipeline for Echo project"
readme = "README.md"
requires-python = ">=3.13"

dependencies = [
    # Core FastAPI & SQLAlchemy
    "fastapi>=0.115.12",
    "uvicorn[standard]>=0.34.2", # [standard] includes websockets and other common needs
    "sqlalchemy>=2.0.40",
    "asyncpg>=0.29.0", # For PostgreSQL with SQLAlchemy async
    "psycopg2-binary", # For some sync tools or if other libs pull it in
    "aiosqlite>=0.20.0", # For SQLite if used in testing/dev
    # Pydantic & Settings
    "pydantic>=2.11.3", # Your current Pydantic
    "pydantic-settings",
    "python-dotenv>=1.1.0",
    # API & Web Interaction
    "httpx>=0.28.1",
    "python-multipart>=0.0.20", # For file uploads in FastAPI
    "jinja2>=3.1.6",
    # Authentication & Security
    "pyjwt>=2.10.1",
    "python-jose[cryptography]",
    "email-validator>=2.2.0",
    # Google Cloud & AI
    "google-cloud-storage==2.10.0",
    "google-generativeai",
    "google-cloud-aiplatform", # Vertex AI
    "google-api-python-client>=2.80.0",
    "google-auth-oauthlib>=1.0.0",
    "google-auth-httplib2>=0.1.0",
    "google-auth>=2.40.1",
    "google-cloud-secret-manager>=2.16.0",
    # Video/Image Processing
    "ffmpeg-python",
    "pillow>=11.2.1",
    # Other Utilities
    "redis>=5.2.1",
    "openai>=1.75.0",
    # Supabase Pydantic for model generation (runtime for generated models)
    # Cloud Functions (if still deploying parts as Cloud Functions)
    "functions-framework", # If you use Google Cloud Functions
    "supabase-pydantic>=0.18.3",
]

[project.optional-dependencies]
dev = [
    # Code Generation tools
    "sqlacodegen>=3.0.0rc5",         # For SQLAlchemy ORM models from DB schema
    "pydantic-to-typescript>=2.0.0", # For generating TS types from Pydantic models

    # Linters & Formatters
    "ruff>=0.4.0", # Covers linting, formatting, import sorting
    "mypy>=1.15.0",

    # Testing
    "pytest>=8.3.5",
    "pytest-asyncio",
    "pytest-mock==3.11.1",
    "pytest-cov==4.1.0",

    # Dev tools
    "pre-commit>=3.0.0",
]

[tool.mypy]
python_version = "3.13"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = false # Keep as false if you have untyped legacy code
namespace_packages = true
explicit_package_bases = true
# Exclude the generated pydantic models path if it causes mypy issues or you don't want to type-check generated code.
exclude = ['venv', '.venv', '__pycache__', '.pytest_cache', 'apps/core/app/db_pydantic_models/']

[tool.setuptools.packages.find]
where = ["."]
# Adjust 'include' if your main Python package source code is structured differently
# e.g., if 'apps/core/src/echo_core' is your package, then include = ["echo_core*"] and where = ["src"]
# For now, assuming 'apps.core' is part of your import paths.
include = ["apps.core*"]
exclude = ["tests*", "video_processor*"]

[tool.ruff]
# Ruff configuration can go here or in a separate ruff.toml or .ruff.toml
# See https://docs.astral.sh/ruff/configuration/
line-length = 88 # Example, adjust as needed
select = [
    "E",  # pycodestyle errors
    "F",  # pyflakes
    "W",  # pycodestyle warnings
    "I",  # isort (import sorting)
    "UP", # pyupgrade
    "PL", # Pylint
    "RUF",# Ruff-specific rules
    "C90", # McCabe complexity
    "ASYNC", # Ruff's async-specific rules
]
ignore = [
    "E501", # Line too long (Handled by formatter)
    "PLR0913", # Too many arguments
    "PLR2004", # Magic value used in comparison
]
target-version = "py313"

[tool.ruff.lint.isort]
known-first-party = ["apps.core"] # Helps ruff sort your project's imports correctly

[tool.ruff.format]
quote-style = "double"
# indent-style = "space" # Default is space
# skip-magic-trailing-comma = false # Default is false
# line-ending = "lf" # Default is auto
</file>

<file path="apps/core/README.md">
# Echo Core Application

## Project Overview

The Echo Core Application is a backend service for video processing featuring:

- Video upload, processing, and metadata extraction
- Integration with AI services for transcription and content analysis
- Secure storage in cloud or local filesystem
- Support for Supabase authentication and PostgreSQL
- Standardized API for frontend integration

## Architecture

The application follows a clean, layered architecture:

```
apps/core/
├── api/             # API Layer (FastAPI endpoints, Pydantic schemas)
├── core/            # Core configurations and shared utilities
├── lib/             # Common libraries and adapters
│   ├── ai/             # AI service adapters (Gemini, cache)
│   ├── publishing/     # Publishing adapters (YouTube)
│   ├── storage/        # Storage adapters (GCS, local)
│   └── utils/          # Helper utilities (FFmpeg, file, subtitle)
├── models/          # SQLAlchemy data models
├── operations/      # Data access layer (repositories)
├── services/        # Business logic and orchestration
└── tests/           # Automated tests
    ├── integration/    # API and service integration tests
    └── unit/           # Component-level unit tests
```

### Architecture Layers

1. **API Layer** - HTTP interface using FastAPI
2. **Service Layer** - Business logic orchestration
3. **Operations Layer** - Data access through repositories
4. **Model Layer** - Database schema definitions
5. **Library Layer** - Common utilities and external integrations:
   - **AI Adapters** - Integrations with AI services (Gemini)
   - **Storage Adapters** - File storage implementations (GCS, local)
   - **Publishing Adapters** - Distribution channel integrations (YouTube)
   - **Utilities** - Common tools for video/audio processing

## Local Development Setup

### Prerequisites

- Python 3.10+ installed
- [uv](https://github.com/astral-sh/uv) for package management
- [Docker](https://www.docker.com/) for running Supabase locally
- [Supabase CLI](https://supabase.com/docs/guides/cli) for local development

### Environment Setup

1. Clone the repository and navigate to the core application:

```bash
cd apps/core
```

2. Create and activate a virtual environment:

```bash
uv venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

3. Install dependencies:

```bash
uv pip install -r pyproject.toml
```

### Supabase Local Setup

1. Install Supabase CLI:

```bash
npm install supabase --save-dev
```

2. Initialize and start local Supabase:

```bash
cd ../../  # Navigate to the project root
supabase init
supabase start
```

3. Copy the environment variables displayed by the Supabase CLI.

### Environment Configuration

1. Create a `.env` file in `apps/core/`:

```bash
cp .env.example .env
```

2. Edit the `.env` file with your local Supabase credentials and other environment variables.

### Database Migrations

Apply migrations to your local database:

```bash
cd apps/core
alembic upgrade head
```

### Starting the API Server

```bash
cd apps/core
uvicorn api.main:app --reload
```

The API will be available at `http://localhost:8000`.

## API Endpoints

### Authentication

Authentication is handled by Supabase. The backend expects a JWT token in the `Authorization` header.

### Video Processing API

#### Upload a Video

```
POST /api/v1/videos/upload
```

**Request:**
- Multipart form data with `file` field containing the video

**Response:**
```json
{
  "job_id": 123,
  "status": "PENDING"
}
```

#### Get Job Status

```
GET /api/v1/videos/jobs/{job_id}
```

**Response:**
```json
{
  "id": 123,
  "video_id": 456,
  "status": "COMPLETED",
  "processing_stages": {
    "transcription": true,
    "metadata": true
  },
  "error_message": null,
  "created_at": "2025-05-16T12:00:00Z",
  "updated_at": "2025-05-16T12:05:00Z",
  "video": {
    "id": 456,
    "uploader_user_id": "user-uuid",
    "original_filename": "my-video.mp4",
    "storage_path": "uploads/user-uuid/my-video.mp4",
    "content_type": "video/mp4",
    "size_bytes": 1024000,
    "created_at": "2025-05-16T12:00:00Z",
    "updated_at": "2025-05-16T12:00:00Z"
  },
  "metadata": {
    "id": 789,
    "job_id": 123,
    "title": "Auto-generated title",
    "description": "Auto-generated description",
    "tags": ["tag1", "tag2"],
    "transcript_text": "Full transcript of the video...",
    "transcript_file_url": "https://example.com/transcripts/123.txt",
    "subtitle_files_urls": {
      "vtt": "https://example.com/subtitles/123.vtt",
      "srt": "https://example.com/subtitles/123.srt"
    },
    "thumbnail_file_url": "https://example.com/thumbnails/123.jpg",
    "extracted_video_duration_seconds": 120.5,
    "extracted_video_resolution": "1920x1080",
    "extracted_video_format": "mp4",
    "show_notes_text": "Auto-generated show notes...",
    "created_at": "2025-05-16T12:05:00Z",
    "updated_at": "2025-05-16T12:05:00Z"
  }
}
```

## Environment Variables

| Variable                         | Description                        | Default          |
| -------------------------------- | ---------------------------------- | ---------------- |
| `ENVIRONMENT`                    | Development/production environment | `development`    |
| `DATABASE_URL`                   | PostgreSQL connection string       |                  |
| `SUPABASE_URL`                   | Supabase project URL               |                  |
| `SUPABASE_ANON_KEY`              | Supabase anonymous key             |                  |
| `SUPABASE_SERVICE_ROLE_KEY`      | Supabase service role key          |                  |
| `SUPABASE_JWT_SECRET`            | Supabase JWT secret                |                  |
| `STORAGE_BACKEND`                | Storage backend (`local` or `gcs`) | `local`          |
| `LOCAL_STORAGE_PATH`             | Path for local file storage        | `./output_files` |
| `GCS_BUCKET_NAME`                | Google Cloud Storage bucket name   |                  |
| `GOOGLE_APPLICATION_CREDENTIALS` | Path to GCP credentials JSON       |                  |
| `GEMINI_API_KEY`                 | Google Gemini AI API key           |                  |
| `REDIS_URL`                      | Redis connection URL for caching   |                  |

## Testing

### Running Tests

```bash
cd apps/core

# Run all tests
pytest

# Run unit tests only
pytest tests/unit

# Run integration tests only
pytest tests/integration

# Run with coverage report
pytest --cov=.
```

### Test Structure

- **Unit Tests**: Test individual components in isolation
  - Mock dependencies to focus on component behavior
  - Fast and independent of external systems
  
- **Integration Tests**: Test API endpoints and database interactions
  - `tests/integration/api/`: Tests for API endpoints
  - `tests/integration/conftest.py`: Common fixtures for database and API testing
  - Test authentication, error handling, and success paths
  
- **Test Fixtures**: Common test utilities and setup in `conftest.py` files
  - Database session management
  - Authentication helpers
  - File upload utilities
  - Mocked services

## Video Processing Architecture

The video processing functionality is distributed across several modules following clean architecture principles:

1. **Domain Models** (`models/`): Define the core entities
   - Video, VideoJob, VideoMetadata models with SQLAlchemy
   - Pydantic schemas for API validation and responses

2. **Service Layer** (`services/`): Contains core business logic
   - Video processing orchestration
   - Transcription and metadata generation
   - Job status management

3. **Adapters** (`lib/`): Interface implementations
   - AI adapters for transcription and content analysis
   - Storage adapters for file management
   - Publishing adapters for distribution (YouTube)

4. **API Layer** (`api/endpoints/`): External interface
   - FastAPI endpoints for video upload and processing
   - Authentication and validation middleware
   - Response formatting

This architecture ensures:
- **Testability**: Each layer can be tested in isolation
- **Maintainability**: Changes in one layer don't affect others
- **Flexibility**: Easy to swap implementations (e.g., storage providers)

## Deployment

The application can be deployed as a container or as a standard Python application. For production, ensure:

1. Set `ENVIRONMENT=production` in environment variables
2. Use a production-ready ASGI server like Gunicorn with Uvicorn workers
3. Set up proper logging and monitoring
4. Configure proper security settings for Supabase
</file>

<file path="apps/web/app/components/form/select-field.tsx">
import { useFieldContext } from "~/lib/form";

import { Label } from "../ui/label";
import {
  Select,
  SelectContent,
  SelectItem,
  SelectTrigger,
  SelectValue,
} from "../ui/select";

type Props<TType extends "string" | "number" = "string"> = {
  label: string;
  options: { value: TType extends "string" ? string : number; label: string }[];
  type: TType;
  required?: boolean;
};

export const SelectField = <TType extends "string" | "number" = "string">({
  label,
  options,
  required,
  type,
}: Props<TType>) => {
  const field = useFieldContext<string | number>();

  return (
    <Label htmlFor={field.name}>
      {label}
      {required ? " *" : ""}
      <Select
        value={field.state.value?.toString() ?? ""}
        onValueChange={(value) => {
          field.handleChange(type === "number" ? Number(value) : value);
        }}
      >
        <SelectTrigger>
          <SelectValue placeholder={`Select a ${label}`} />
        </SelectTrigger>
        <SelectContent>
          {options.map((option) => (
            <SelectItem key={option.value} value={`${option.value}`}>
              {option.label}
            </SelectItem>
          ))}
        </SelectContent>
      </Select>
    </Label>
  );
};
</file>

<file path="apps/web/app/components/form/submit-button.tsx">
import { useFormContext } from "~/lib/form";
import { Button } from "../ui/button";
import { Loader2 } from "lucide-react";

type Props = {
  label: string;
};

export const SubmitButton = ({ label }: Props) => {
  const form = useFormContext();

  return (
    <form.Subscribe
      selector={(state) => [state.isSubmitting, state.canSubmit]}
      children={([isSubmitting, canSubmit]) => (
        <Button disabled={isSubmitting || !canSubmit} type="submit">
          {label}
          {isSubmitting && <Loader2 className="ml-2 h-4 w-4 animate-spin" />}
        </Button>
      )}
    />
  );
};
</file>

<file path="apps/web/app/components/form/text-field.tsx">
import { useFieldContext } from "~/lib/form";
import { Input } from "../ui/input";
import { Label } from "../ui/label";

type Props = {
  label: string;
  type?: "text" | "email" | "password";
  required?: boolean;
};

export const TextField = ({ label, type = "text", required }: Props) => {
  const field = useFieldContext<string>();

  return (
    <Label htmlFor={field.name}>
      {label}
      {required ? " *" : ""}
      <Input
        name={field.name}
        id={field.name}
        value={field.state.value ?? ""}
        onChange={(e) => field.handleChange(e.target.value)}
        type={type}
      />
    </Label>
  );
};
</file>

<file path="apps/web/app/components/home/hero.tsx">
import Container from "../shared/container";
import {
	Tabs,
	TabsContent,
	TabsList,
	TabsTrigger,
} from "../ui/tabs";

// Props interface currently empty, update if needed for future enhancements.
type Props = {};

export default function Hero({}: Props) {
	return (
		<Container spacer={true}>
			{/* Main container using flexbox for vertical stacking */}
			<div className="flex flex-col items-center text-center py-16">
				{/* Title Section */}
				<div className="flex items-center justify-center bg-[var(--accent-blue)] text-white h-24 w-24 rounded-full mb-6">
					<span className="text-2xl font-bold">VIDEO</span>
				</div>

				{/* Main Heading */}
				<h1 className="text-7xl text-[var(--accent-blue)] lg:text-6xl md:text-5xl sm:text-4xl">
					VIDEO AI PIPELINE
				</h1>

				{/* Tagline */}
				<p className="text-xl text-[var(--foreground)] mt-4 md:text-lg sm:text-base max-w-2xl">
					Automate your video publishing workflow with AI-powered metadata
					generation and YouTube integration
				</p>

				{/* Feature Icons as Text */}
				<div className="my-8 flex items-center justify-center gap-8">
					<div className="flex flex-col items-center">
						<div className="bg-[var(--accent-blue)] text-white h-12 w-12 rounded-full flex items-center justify-center">
							<span className="font-bold">AI</span>
						</div>
						<span className="text-sm mt-1">Gemini</span>
					</div>
					<div className="flex flex-col items-center">
						<div className="bg-red-600 text-white h-12 w-12 rounded-full flex items-center justify-center">
							<span className="font-bold">YT</span>
						</div>
						<span className="text-sm mt-1">YouTube</span>
					</div>
					<div className="flex flex-col items-center">
						<div className="bg-gray-700 text-white h-12 w-12 rounded-full flex items-center justify-center">
							<span className="font-bold">GCP</span>
						</div>
						<span className="text-sm mt-1">Cloud</span>
					</div>
				</div>

				{/* Separator */}
				<hr className="my-6 w-1/5 border-[var(--accent-blue)] border-t-2" />

				{/* Feature Tabs Section */}
				<div className="w-full max-w-2xl mt-8">
					<Tabs defaultValue="upload" className="w-full">
						<TabsList className="grid w-full grid-cols-4">
							<TabsTrigger value="upload">Upload</TabsTrigger>
							<TabsTrigger value="process">Process</TabsTrigger>
							<TabsTrigger value="metadata">Metadata</TabsTrigger>
							<TabsTrigger value="publish">Publish</TabsTrigger>
						</TabsList>
						<TabsContent value="upload" className="mt-4 text-left space-y-2">
							<p>
								<strong>Drag & Drop:</strong> Simple video upload interface
							</p>
							<p>
								<strong>Multi-Channel:</strong> Support for both daily and main
								channels
							</p>
							<p>
								<strong>Cloud Storage:</strong> Videos stored securely in Google
								Cloud Storage
							</p>
							<p>
								<strong>Real-time:</strong> Live status updates as your video
								moves through the pipeline
							</p>
						</TabsContent>
						<TabsContent value="process" className="mt-4 text-left space-y-2">
							<p>
								<strong>Automatic:</strong> Hands-off video processing workflow
							</p>
							<p>
								<strong>AI-Powered:</strong> Gemini 2.5 Pro generates
								high-quality metadata
							</p>
							<p>
								<strong>Transcription:</strong> Accurate speech-to-text for your
								entire video
							</p>
							<p>
								<strong>Chapters:</strong> Smart chapter markers generated from
								video content
							</p>
						</TabsContent>
						<TabsContent value="metadata" className="mt-4 text-left space-y-2">
							<p>
								<strong>Title Generation:</strong> AI creates engaging,
								SEO-friendly titles
							</p>
							<p>
								<strong>Description:</strong> Comprehensive video descriptions
								with keywords
							</p>
							<p>
								<strong>Thumbnails:</strong> Generate 10 thumbnails with Imagen3
								+ Pillow
							</p>
							<p>
								<strong>Editable:</strong> Review and customize all metadata
								before publishing
							</p>
						</TabsContent>
						<TabsContent value="publish" className="mt-4 text-left space-y-2">
							<p>
								<strong>YouTube Integration:</strong> Direct upload to your
								YouTube channel
							</p>
							<p>
								<strong>Scheduling:</strong> Set publication dates and times
							</p>
							<p>
								<strong>Status Tracking:</strong> Monitor progress from
								processing to published
							</p>
							<p>
								<strong>Error Handling:</strong> Robust error recovery and
								notification
							</p>
						</TabsContent>
					</Tabs>
				</div>

				{/* Key Benefits Section */}
				<div className="w-full max-w-2xl mt-16">
					<h2 className="font-bold text-3xl text-[var(--accent-blue)] md:text-2xl sm:text-xl mb-6">
						KEY BENEFITS
					</h2>
					<ul className="grid grid-cols-2 gap-4 text-base text-[var(--foreground)]">
						<li className="flex items-center gap-2">
							<span className="text-[var(--accent-blue)]">✓</span> Save hours on
							video publishing
						</li>
						<li className="flex items-center gap-2">
							<span className="text-[var(--accent-blue)]">✓</span> Consistent,
							high-quality metadata
						</li>
						<li className="flex items-center gap-2">
							<span className="text-[var(--accent-blue)]">✓</span> AI-generated
							thumbnails
						</li>
						<li className="flex items-center gap-2">
							<span className="text-[var(--accent-blue)]">✓</span> Real-time
							status tracking
						</li>
						<li className="flex items-center gap-2">
							<span className="text-[var(--accent-blue)]">✓</span> Full editing
							control
						</li>
						<li className="flex items-center gap-2">
							<span className="text-[var(--accent-blue)]">✓</span> Cloud-native
							architecture
						</li>
					</ul>
				</div>

				{/* CTA Button */}
				<div className="mt-12">
					<a
						href="/dashboard"
						className="bg-[var(--accent-blue)] text-white px-8 py-3 rounded-md text-lg hover:bg-opacity-90 transition-all"
					>
						Get Started
					</a>
				</div>
			</div>
		</Container>
	);
}
</file>

<file path="apps/web/app/components/shared/container.tsx">
import { cn } from "~/lib/utils";

type Props = {
  children: React.ReactNode;
  tag?: "div" | "section" | "header" | "footer";
  className?: string;
  id?: string;
  spacer?: boolean;
  padding?: boolean;
};

export default function Container({
  children,
  tag = "div",
  className,
  id,
  spacer = false,
  padding = true,
}: Props) {
  const Tag = tag;
  return (
    <Tag
      className={cn(
        "w-full flex flex-col",
        spacer ? "mt-19" : "",
        padding ? "px-6 md:px-8 lg:px-10" : "",
        className,
      )}
      id={id}
    >
      {children}
    </Tag>
  );
}
</file>

<file path="apps/web/app/components/shared/navbar.tsx">
import { cn } from "~/lib/utils";
import { Link } from "@tanstack/react-router";
import { Home, Menu, Search, X } from "lucide-react";
import { useState } from "react";
import { Button } from "../ui/button";
import Container from "./container";

type Props = {};

export default function Navbar({}: Props) {
  const [isMenuOpen, setIsMenuOpen] = useState(false);

  const navItems = [
    {
      label: "Home",
      href: "/",
    },
    {
      label: "Upload",
      href: "/upload",
    },
    {
      label: "Dashboard",
      href: "/dashboard",
    },
    {
      label: "Settings",
      href: "/settings",
    },
  ];

  return (
    <div className="w-full bg-background/90 backdrop-blur-sm border-b border-border/40 sticky top-0 z-50">
      <Container className="flex h-16 items-center justify-between">
        {/* Logo */}
        <div className="flex items-center">
          <Link to="/" className="flex items-center space-x-2">
            <div className="flex h-8 w-8 items-center justify-center rounded-md bg-primary">
              <Home className="h-4 w-4 text-primary-foreground" />
            </div>
            <span className="font-bold text-lg tracking-tight">UrcKe</span>
          </Link>
        </div>

        {/* Desktop navigation */}
        <nav className="hidden md:flex">
          <ul className="flex items-center space-x-8">
            {navItems.map((item) => (
              <li key={item.href}>
                <Link
                  to={item.href}
                  className={
                    "text-sm font-medium transition-colors hover:text-primary"
                  }
                  activeOptions={{ exact: true }}
                  activeProps={{
                    className: "text-primary font-semibold",
                  }}
                >
                  {item.label}
                </Link>
              </li>
            ))}
          </ul>
        </nav>

        {/* Actions */}
        <div className="flex items-center space-x-4">
          <Button variant="ghost" size="icon" className="hidden md:flex">
            <Search className="h-4 w-4" />
            <span className="sr-only">Search</span>
          </Button>
          <Button className="hidden md:flex">Get Started</Button>

          {/* Mobile menu button */}
          <Button
            variant="ghost"
            size="icon"
            className="md:hidden"
            onClick={() => setIsMenuOpen(!isMenuOpen)}
          >
            {isMenuOpen ? (
              <X className="h-5 w-5" />
            ) : (
              <Menu className="h-5 w-5" />
            )}
            <span className="sr-only">Toggle menu</span>
          </Button>
        </div>
      </Container>

      {/* Mobile navigation */}
      <div
        className={cn(
          "md:hidden border-t border-border/40",
          isMenuOpen ? "block" : "hidden",
        )}
      >
        <Container className="py-4 px-6 space-y-4">
          <nav>
            <ul className="space-y-4">
              {navItems.map((item) => (
                <li key={item.href}>
                  <Link
                    to={item.href}
                    className="block text-sm font-medium transition-colors hover:text-primary"
                    activeOptions={{ exact: true }}
                    activeProps={{
                      className: "text-primary font-semibold",
                    }}
                    onClick={() => setIsMenuOpen(false)}
                  >
                    {item.label}
                  </Link>
                </li>
              ))}
            </ul>
          </nav>
          <div className="flex flex-col space-y-3 pt-3 border-t border-border/40">
            <Button
              variant="outline"
              className="w-full justify-start"
              size="sm"
            >
              <Search className="mr-2 h-4 w-4" />
              Search
            </Button>
            <Button className="w-full" size="sm">
              Get Started
            </Button>
          </div>
        </Container>
      </div>
    </div>
  );
}
</file>

<file path="apps/web/app/components/ui/accordion.tsx">
import * as AccordionPrimitive from "@radix-ui/react-accordion";
import { ChevronDownIcon } from "lucide-react";
import type * as React from "react";

import { cn } from "~/lib/utils";

function Accordion({
  ...props
}: React.ComponentProps<typeof AccordionPrimitive.Root>) {
  return <AccordionPrimitive.Root data-slot="accordion" {...props} />;
}

function AccordionItem({
  className,
  ...props
}: React.ComponentProps<typeof AccordionPrimitive.Item>) {
  return (
    <AccordionPrimitive.Item
      data-slot="accordion-item"
      className={cn("border-b last:border-b-0", className)}
      {...props}
    />
  );
}

function AccordionTrigger({
  className,
  children,
  ...props
}: React.ComponentProps<typeof AccordionPrimitive.Trigger>) {
  return (
    <AccordionPrimitive.Header className="flex">
      <AccordionPrimitive.Trigger
        data-slot="accordion-trigger"
        className={cn(
          "focus-visible:border-ring focus-visible:ring-ring/50 flex flex-1 items-start justify-between gap-4 rounded-md py-4 text-left text-sm font-medium transition-all outline-none hover:underline focus-visible:ring-[3px] disabled:pointer-events-none disabled:opacity-50 [&[data-state=open]>svg]:rotate-180",
          className,
        )}
        {...props}
      >
        {children}
        <ChevronDownIcon className="text-muted-foreground pointer-events-none size-4 shrink-0 translate-y-0.5 transition-transform duration-200" />
      </AccordionPrimitive.Trigger>
    </AccordionPrimitive.Header>
  );
}

function AccordionContent({
  className,
  children,
  ...props
}: React.ComponentProps<typeof AccordionPrimitive.Content>) {
  return (
    <AccordionPrimitive.Content
      data-slot="accordion-content"
      className="data-[state=closed]:animate-accordion-up data-[state=open]:animate-accordion-down overflow-hidden text-sm"
      {...props}
    >
      <div className={cn("pt-0 pb-4", className)}>{children}</div>
    </AccordionPrimitive.Content>
  );
}

export { Accordion, AccordionItem, AccordionTrigger, AccordionContent };
</file>

<file path="apps/web/app/components/ui/alert-dialog.tsx">
"use client";

import * as AlertDialogPrimitive from "@radix-ui/react-alert-dialog";
import type * as React from "react";

import { buttonVariants } from "~/components/ui/button";
import { cn } from "~/lib/utils";

function AlertDialog({
  ...props
}: React.ComponentProps<typeof AlertDialogPrimitive.Root>) {
  return <AlertDialogPrimitive.Root data-slot="alert-dialog" {...props} />;
}

function AlertDialogTrigger({
  ...props
}: React.ComponentProps<typeof AlertDialogPrimitive.Trigger>) {
  return (
    <AlertDialogPrimitive.Trigger data-slot="alert-dialog-trigger" {...props} />
  );
}

function AlertDialogPortal({
  ...props
}: React.ComponentProps<typeof AlertDialogPrimitive.Portal>) {
  return (
    <AlertDialogPrimitive.Portal data-slot="alert-dialog-portal" {...props} />
  );
}

function AlertDialogOverlay({
  className,
  ...props
}: React.ComponentProps<typeof AlertDialogPrimitive.Overlay>) {
  return (
    <AlertDialogPrimitive.Overlay
      data-slot="alert-dialog-overlay"
      className={cn(
        "data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 fixed inset-0 z-50 bg-black/50",
        className,
      )}
      {...props}
    />
  );
}

function AlertDialogContent({
  className,
  ...props
}: React.ComponentProps<typeof AlertDialogPrimitive.Content>) {
  return (
    <AlertDialogPortal>
      <AlertDialogOverlay />
      <AlertDialogPrimitive.Content
        data-slot="alert-dialog-content"
        className={cn(
          "bg-background data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 fixed top-[50%] left-[50%] z-50 grid w-full max-w-[calc(100%-2rem)] translate-x-[-50%] translate-y-[-50%] gap-4 rounded-lg border p-6 shadow-lg duration-200 sm:max-w-lg",
          className,
        )}
        {...props}
      />
    </AlertDialogPortal>
  );
}

function AlertDialogHeader({
  className,
  ...props
}: React.ComponentProps<"div">) {
  return (
    <div
      data-slot="alert-dialog-header"
      className={cn("flex flex-col gap-2 text-center sm:text-left", className)}
      {...props}
    />
  );
}

function AlertDialogFooter({
  className,
  ...props
}: React.ComponentProps<"div">) {
  return (
    <div
      data-slot="alert-dialog-footer"
      className={cn(
        "flex flex-col-reverse gap-2 sm:flex-row sm:justify-end",
        className,
      )}
      {...props}
    />
  );
}

function AlertDialogTitle({
  className,
  ...props
}: React.ComponentProps<typeof AlertDialogPrimitive.Title>) {
  return (
    <AlertDialogPrimitive.Title
      data-slot="alert-dialog-title"
      className={cn("text-lg font-semibold", className)}
      {...props}
    />
  );
}

function AlertDialogDescription({
  className,
  ...props
}: React.ComponentProps<typeof AlertDialogPrimitive.Description>) {
  return (
    <AlertDialogPrimitive.Description
      data-slot="alert-dialog-description"
      className={cn("text-muted-foreground text-sm", className)}
      {...props}
    />
  );
}

function AlertDialogAction({
  className,
  ...props
}: React.ComponentProps<typeof AlertDialogPrimitive.Action>) {
  return (
    <AlertDialogPrimitive.Action
      className={cn(buttonVariants(), className)}
      {...props}
    />
  );
}

function AlertDialogCancel({
  className,
  ...props
}: React.ComponentProps<typeof AlertDialogPrimitive.Cancel>) {
  return (
    <AlertDialogPrimitive.Cancel
      className={cn(buttonVariants({ variant: "outline" }), className)}
      {...props}
    />
  );
}

export {
  AlertDialog,
  AlertDialogPortal,
  AlertDialogOverlay,
  AlertDialogTrigger,
  AlertDialogContent,
  AlertDialogHeader,
  AlertDialogFooter,
  AlertDialogTitle,
  AlertDialogDescription,
  AlertDialogAction,
  AlertDialogCancel,
};
</file>

<file path="apps/web/app/components/ui/alert.tsx">
import { type VariantProps, cva } from "class-variance-authority";
import type * as React from "react";

import { cn } from "~/lib/utils";

const alertVariants = cva(
  "relative w-full rounded-lg border px-4 py-3 text-sm grid has-[>svg]:grid-cols-[calc(var(--spacing)*4)_1fr] grid-cols-[0_1fr] has-[>svg]:gap-x-3 gap-y-0.5 items-start [&>svg]:size-4 [&>svg]:translate-y-0.5 [&>svg]:text-current",
  {
    variants: {
      variant: {
        default: "bg-card text-card-foreground",
        destructive:
          "text-destructive bg-card [&>svg]:text-current *:data-[slot=alert-description]:text-destructive/90",
      },
    },
    defaultVariants: {
      variant: "default",
    },
  },
);

function Alert({
  className,
  variant,
  ...props
}: React.ComponentProps<"div"> & VariantProps<typeof alertVariants>) {
  return (
    <div
      data-slot="alert"
      role="alert"
      className={cn(alertVariants({ variant }), className)}
      {...props}
    />
  );
}

function AlertTitle({ className, ...props }: React.ComponentProps<"div">) {
  return (
    <div
      data-slot="alert-title"
      className={cn(
        "col-start-2 line-clamp-1 min-h-4 font-medium tracking-tight",
        className,
      )}
      {...props}
    />
  );
}

function AlertDescription({
  className,
  ...props
}: React.ComponentProps<"div">) {
  return (
    <div
      data-slot="alert-description"
      className={cn(
        "text-muted-foreground col-start-2 grid justify-items-start gap-1 text-sm [&_p]:leading-relaxed",
        className,
      )}
      {...props}
    />
  );
}

export { Alert, AlertTitle, AlertDescription };
</file>

<file path="apps/web/app/components/ui/aspect-ratio.tsx">
import * as AspectRatioPrimitive from "@radix-ui/react-aspect-ratio";

function AspectRatio({
	...props
}: React.ComponentProps<typeof AspectRatioPrimitive.Root>) {
	return <AspectRatioPrimitive.Root data-slot="aspect-ratio" {...props} />;
}

export { AspectRatio };
</file>

<file path="apps/web/app/components/ui/avatar.tsx">
"use client";

import * as AvatarPrimitive from "@radix-ui/react-avatar";
import type * as React from "react";

import { cn } from "~/lib/utils";

function Avatar({
  className,
  ...props
}: React.ComponentProps<typeof AvatarPrimitive.Root>) {
  return (
    <AvatarPrimitive.Root
      data-slot="avatar"
      className={cn(
        "relative flex size-8 shrink-0 overflow-hidden rounded-full",
        className,
      )}
      {...props}
    />
  );
}

function AvatarImage({
  className,
  ...props
}: React.ComponentProps<typeof AvatarPrimitive.Image>) {
  return (
    <AvatarPrimitive.Image
      data-slot="avatar-image"
      className={cn("aspect-square size-full", className)}
      {...props}
    />
  );
}

function AvatarFallback({
  className,
  ...props
}: React.ComponentProps<typeof AvatarPrimitive.Fallback>) {
  return (
    <AvatarPrimitive.Fallback
      data-slot="avatar-fallback"
      className={cn(
        "bg-muted flex size-full items-center justify-center rounded-full",
        className,
      )}
      {...props}
    />
  );
}

export { Avatar, AvatarImage, AvatarFallback };
</file>

<file path="apps/web/app/components/ui/badge.tsx">
import { Slot } from "@radix-ui/react-slot";
import { type VariantProps, cva } from "class-variance-authority";
import type * as React from "react";

import { cn } from "~/lib/utils";

const badgeVariants = cva(
  "inline-flex items-center justify-center rounded-md border px-2 py-0.5 text-xs font-medium w-fit whitespace-nowrap shrink-0 [&>svg]:size-3 gap-1 [&>svg]:pointer-events-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive transition-[color,box-shadow] overflow-hidden",
  {
    variants: {
      variant: {
        default:
          "border-transparent bg-primary text-primary-foreground [a&]:hover:bg-primary/90",
        secondary:
          "border-transparent bg-secondary text-secondary-foreground [a&]:hover:bg-secondary/90",
        destructive:
          "border-transparent bg-destructive text-white [a&]:hover:bg-destructive/90 focus-visible:ring-destructive/20 dark:focus-visible:ring-destructive/40 dark:bg-destructive/60",
        outline:
          "text-foreground [a&]:hover:bg-accent [a&]:hover:text-accent-foreground",
      },
    },
    defaultVariants: {
      variant: "default",
    },
  },
);

function Badge({
  className,
  variant,
  asChild = false,
  ...props
}: React.ComponentProps<"span"> &
  VariantProps<typeof badgeVariants> & { asChild?: boolean }) {
  const Comp = asChild ? Slot : "span";

  return (
    <Comp
      data-slot="badge"
      className={cn(badgeVariants({ variant }), className)}
      {...props}
    />
  );
}

export { Badge, badgeVariants };
</file>

<file path="apps/web/app/components/ui/breadcrumb.tsx">
import { Slot } from "@radix-ui/react-slot";
import { ChevronRight, MoreHorizontal } from "lucide-react";
import type * as React from "react";

import { cn } from "@/lib/utils";

function Breadcrumb({ ...props }: React.ComponentProps<"nav">) {
	return <nav aria-label="breadcrumb" data-slot="breadcrumb" {...props} />;
}

function BreadcrumbList({ className, ...props }: React.ComponentProps<"ol">) {
	return (
		<ol
			data-slot="breadcrumb-list"
			className={cn(
				"text-muted-foreground flex flex-wrap items-center gap-1.5 text-sm break-words sm:gap-2.5",
				className,
			)}
			{...props}
		/>
	);
}

function BreadcrumbItem({ className, ...props }: React.ComponentProps<"li">) {
	return (
		<li
			data-slot="breadcrumb-item"
			className={cn("inline-flex items-center gap-1.5", className)}
			{...props}
		/>
	);
}

function BreadcrumbLink({
	asChild,
	className,
	...props
}: React.ComponentProps<"a"> & {
	asChild?: boolean;
}) {
	const Comp = asChild ? Slot : "a";

	return (
		<Comp
			data-slot="breadcrumb-link"
			className={cn("hover:text-foreground transition-colors", className)}
			{...props}
		/>
	);
}

function BreadcrumbPage({ className, ...props }: React.ComponentProps<"span">) {
	return (
		<span
			data-slot="breadcrumb-page"
			role="link"
			aria-disabled="true"
			aria-current="page"
			className={cn("text-foreground font-normal", className)}
			{...props}
		/>
	);
}

function BreadcrumbSeparator({
	children,
	className,
	...props
}: React.ComponentProps<"li">) {
	return (
		<li
			data-slot="breadcrumb-separator"
			role="presentation"
			aria-hidden="true"
			className={cn("[&>svg]:size-3.5", className)}
			{...props}
		>
			{children ?? <ChevronRight />}
		</li>
	);
}

function BreadcrumbEllipsis({
	className,
	...props
}: React.ComponentProps<"span">) {
	return (
		<span
			data-slot="breadcrumb-ellipsis"
			role="presentation"
			aria-hidden="true"
			className={cn("flex size-9 items-center justify-center", className)}
			{...props}
		>
			<MoreHorizontal className="size-4" />
			<span className="sr-only">More</span>
		</span>
	);
}

export {
	Breadcrumb,
	BreadcrumbList,
	BreadcrumbItem,
	BreadcrumbLink,
	BreadcrumbPage,
	BreadcrumbSeparator,
	BreadcrumbEllipsis,
};
</file>

<file path="apps/web/app/components/ui/button.tsx">
import { Slot } from "@radix-ui/react-slot";
import { type VariantProps, cva } from "class-variance-authority";
import type * as React from "react";

import { cn } from "~/lib/utils";

const buttonVariants = cva(
  "inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-all disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg:not([class*='size-'])]:size-4 shrink-0 [&_svg]:shrink-0 outline-none focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive",
  {
    variants: {
      variant: {
        default:
          "bg-primary text-primary-foreground shadow-xs hover:bg-primary/90",
        destructive:
          "bg-destructive text-white shadow-xs hover:bg-destructive/90 focus-visible:ring-destructive/20 dark:focus-visible:ring-destructive/40 dark:bg-destructive/60",
        outline:
          "border bg-background shadow-xs hover:bg-accent hover:text-accent-foreground dark:bg-input/30 dark:border-input dark:hover:bg-input/50",
        secondary:
          "bg-secondary text-secondary-foreground shadow-xs hover:bg-secondary/80",
        ghost:
          "hover:bg-accent hover:text-accent-foreground dark:hover:bg-accent/50",
        link: "text-primary underline-offset-4 hover:underline",
      },
      size: {
        default: "h-9 px-4 py-2 has-[>svg]:px-3",
        sm: "h-8 rounded-md gap-1.5 px-3 has-[>svg]:px-2.5",
        lg: "h-10 rounded-md px-6 has-[>svg]:px-4",
        icon: "size-9",
      },
    },
    defaultVariants: {
      variant: "default",
      size: "default",
    },
  },
);

function Button({
  className,
  variant,
  size,
  asChild = false,
  ...props
}: React.ComponentProps<"button"> &
  VariantProps<typeof buttonVariants> & {
    asChild?: boolean;
  }) {
  const Comp = asChild ? Slot : "button";

  return (
    <Comp
      data-slot="button"
      className={cn(buttonVariants({ variant, size, className }))}
      {...props}
    />
  );
}

export { Button, buttonVariants };
</file>

<file path="apps/web/app/components/ui/calendar.tsx">
import { ChevronLeft, ChevronRight } from "lucide-react";
import type * as React from "react";
import { DayPicker } from "react-day-picker";

import { buttonVariants } from "~/components/ui/button";
import { cn } from "~/lib/utils";

function Calendar({
  className,
  classNames,
  showOutsideDays = true,
  ...props
}: React.ComponentProps<typeof DayPicker>) {
  return (
    <DayPicker
      showOutsideDays={showOutsideDays}
      className={cn("p-3", className)}
      classNames={{
        months: "flex flex-col sm:flex-row gap-2",
        month: "flex flex-col gap-4",
        caption: "flex justify-center pt-1 relative items-center w-full",
        caption_label: "text-sm font-medium",
        nav: "flex items-center gap-1",
        nav_button: cn(
          buttonVariants({ variant: "outline" }),
          "size-7 bg-transparent p-0 opacity-50 hover:opacity-100",
        ),
        nav_button_previous: "absolute left-1",
        nav_button_next: "absolute right-1",
        table: "w-full border-collapse space-x-1",
        head_row: "flex",
        head_cell:
          "text-muted-foreground rounded-md w-8 font-normal text-[0.8rem]",
        row: "flex w-full mt-2",
        cell: cn(
          "relative p-0 text-center text-sm focus-within:relative focus-within:z-20 [&:has([aria-selected])]:bg-accent [&:has([aria-selected].day-range-end)]:rounded-r-md",
          props.mode === "range"
            ? "[&:has(>.day-range-end)]:rounded-r-md [&:has(>.day-range-start)]:rounded-l-md first:[&:has([aria-selected])]:rounded-l-md last:[&:has([aria-selected])]:rounded-r-md"
            : "[&:has([aria-selected])]:rounded-md",
        ),
        day: cn(
          buttonVariants({ variant: "ghost" }),
          "size-8 p-0 font-normal aria-selected:opacity-100",
        ),
        day_range_start:
          "day-range-start aria-selected:bg-primary aria-selected:text-primary-foreground",
        day_range_end:
          "day-range-end aria-selected:bg-primary aria-selected:text-primary-foreground",
        day_selected:
          "bg-primary text-primary-foreground hover:bg-primary hover:text-primary-foreground focus:bg-primary focus:text-primary-foreground",
        day_today: "bg-accent text-accent-foreground",
        day_outside:
          "day-outside text-muted-foreground aria-selected:text-muted-foreground",
        day_disabled: "text-muted-foreground opacity-50",
        day_range_middle:
          "aria-selected:bg-accent aria-selected:text-accent-foreground",
        day_hidden: "invisible",
        ...classNames,
      }}
      components={{
        IconLeft: ({ className, ...props }) => (
          <ChevronLeft className={cn("size-4", className)} {...props} />
        ),
        IconRight: ({ className, ...props }) => (
          <ChevronRight className={cn("size-4", className)} {...props} />
        ),
      }}
      {...props}
    />
  );
}

export { Calendar };
</file>

<file path="apps/web/app/components/ui/card.tsx">
import type * as React from "react";

import { cn } from "~/lib/utils";

function Card({ className, ...props }: React.ComponentProps<"div">) {
  return (
    <div
      data-slot="card"
      className={cn(
        "bg-card text-card-foreground flex flex-col gap-6 rounded-xl border py-6 shadow-sm",
        className,
      )}
      {...props}
    />
  );
}

function CardHeader({ className, ...props }: React.ComponentProps<"div">) {
  return (
    <div
      data-slot="card-header"
      className={cn(
        "@container/card-header grid auto-rows-min grid-rows-[auto_auto] items-start gap-1.5 px-6 has-data-[slot=card-action]:grid-cols-[1fr_auto] [.border-b]:pb-6",
        className,
      )}
      {...props}
    />
  );
}

function CardTitle({ className, ...props }: React.ComponentProps<"div">) {
  return (
    <div
      data-slot="card-title"
      className={cn("leading-none font-semibold", className)}
      {...props}
    />
  );
}

function CardDescription({ className, ...props }: React.ComponentProps<"div">) {
  return (
    <div
      data-slot="card-description"
      className={cn("text-muted-foreground text-sm", className)}
      {...props}
    />
  );
}

function CardAction({ className, ...props }: React.ComponentProps<"div">) {
  return (
    <div
      data-slot="card-action"
      className={cn(
        "col-start-2 row-span-2 row-start-1 self-start justify-self-end",
        className,
      )}
      {...props}
    />
  );
}

function CardContent({ className, ...props }: React.ComponentProps<"div">) {
  return (
    <div
      data-slot="card-content"
      className={cn("px-6", className)}
      {...props}
    />
  );
}

function CardFooter({ className, ...props }: React.ComponentProps<"div">) {
  return (
    <div
      data-slot="card-footer"
      className={cn("flex items-center px-6 [.border-t]:pt-6", className)}
      {...props}
    />
  );
}

export {
  Card,
  CardHeader,
  CardFooter,
  CardTitle,
  CardAction,
  CardDescription,
  CardContent,
};
</file>

<file path="apps/web/app/components/ui/carousel.tsx">
"use client";

import useEmblaCarousel, {
  type UseEmblaCarouselType,
} from "embla-carousel-react";
import { ArrowLeft, ArrowRight } from "lucide-react";
import * as React from "react";

import { Button } from "~/components/ui/button";
import { cn } from "~/lib/utils";

type CarouselApi = UseEmblaCarouselType[1];
type UseCarouselParameters = Parameters<typeof useEmblaCarousel>;
type CarouselOptions = UseCarouselParameters[0];
type CarouselPlugin = UseCarouselParameters[1];

type CarouselProps = {
  opts?: CarouselOptions;
  plugins?: CarouselPlugin;
  orientation?: "horizontal" | "vertical";
  setApi?: (api: CarouselApi) => void;
};

type CarouselContextProps = {
  carouselRef: ReturnType<typeof useEmblaCarousel>[0];
  api: ReturnType<typeof useEmblaCarousel>[1];
  scrollPrev: () => void;
  scrollNext: () => void;
  canScrollPrev: boolean;
  canScrollNext: boolean;
} & CarouselProps;

const CarouselContext = React.createContext<CarouselContextProps | null>(null);

function useCarousel() {
  const context = React.useContext(CarouselContext);

  if (!context) {
    throw new Error("useCarousel must be used within a <Carousel />");
  }

  return context;
}

function Carousel({
  orientation = "horizontal",
  opts,
  setApi,
  plugins,
  className,
  children,
  ...props
}: React.ComponentProps<"div"> & CarouselProps) {
  const [carouselRef, api] = useEmblaCarousel(
    {
      ...opts,
      axis: orientation === "horizontal" ? "x" : "y",
    },
    plugins,
  );
  const [canScrollPrev, setCanScrollPrev] = React.useState(false);
  const [canScrollNext, setCanScrollNext] = React.useState(false);

  const onSelect = React.useCallback((api: CarouselApi) => {
    if (!api) return;
    setCanScrollPrev(api.canScrollPrev());
    setCanScrollNext(api.canScrollNext());
  }, []);

  const scrollPrev = React.useCallback(() => {
    api?.scrollPrev();
  }, [api]);

  const scrollNext = React.useCallback(() => {
    api?.scrollNext();
  }, [api]);

  const handleKeyDown = React.useCallback(
    (event: React.KeyboardEvent<HTMLDivElement>) => {
      if (event.key === "ArrowLeft") {
        event.preventDefault();
        scrollPrev();
      } else if (event.key === "ArrowRight") {
        event.preventDefault();
        scrollNext();
      }
    },
    [scrollPrev, scrollNext],
  );

  React.useEffect(() => {
    if (!api || !setApi) return;
    setApi(api);
  }, [api, setApi]);

  React.useEffect(() => {
    if (!api) return;
    onSelect(api);
    api.on("reInit", onSelect);
    api.on("select", onSelect);

    return () => {
      api?.off("select", onSelect);
    };
  }, [api, onSelect]);

  return (
    <CarouselContext.Provider
      value={{
        carouselRef,
        api: api,
        opts,
        orientation:
          orientation || (opts?.axis === "y" ? "vertical" : "horizontal"),
        scrollPrev,
        scrollNext,
        canScrollPrev,
        canScrollNext,
      }}
    >
      <div
        onKeyDownCapture={handleKeyDown}
        className={cn("relative", className)}
        role="region"
        aria-roledescription="carousel"
        data-slot="carousel"
        {...props}
      >
        {children}
      </div>
    </CarouselContext.Provider>
  );
}

function CarouselContent({ className, ...props }: React.ComponentProps<"div">) {
  const { carouselRef, orientation } = useCarousel();

  return (
    <div
      ref={carouselRef}
      className="overflow-hidden"
      data-slot="carousel-content"
    >
      <div
        className={cn(
          "flex",
          orientation === "horizontal" ? "-ml-4" : "-mt-4 flex-col",
          className,
        )}
        {...props}
      />
    </div>
  );
}

function CarouselItem({ className, ...props }: React.ComponentProps<"div">) {
  const { orientation } = useCarousel();

  return (
    <div
      role="group"
      aria-roledescription="slide"
      data-slot="carousel-item"
      className={cn(
        "min-w-0 shrink-0 grow-0 basis-full",
        orientation === "horizontal" ? "pl-4" : "pt-4",
        className,
      )}
      {...props}
    />
  );
}

function CarouselPrevious({
  className,
  variant = "outline",
  size = "icon",
  ...props
}: React.ComponentProps<typeof Button>) {
  const { orientation, scrollPrev, canScrollPrev } = useCarousel();

  return (
    <Button
      data-slot="carousel-previous"
      variant={variant}
      size={size}
      className={cn(
        "absolute size-8 rounded-full",
        orientation === "horizontal"
          ? "top-1/2 -left-12 -translate-y-1/2"
          : "-top-12 left-1/2 -translate-x-1/2 rotate-90",
        className,
      )}
      disabled={!canScrollPrev}
      onClick={scrollPrev}
      {...props}
    >
      <ArrowLeft />
      <span className="sr-only">Previous slide</span>
    </Button>
  );
}

function CarouselNext({
  className,
  variant = "outline",
  size = "icon",
  ...props
}: React.ComponentProps<typeof Button>) {
  const { orientation, scrollNext, canScrollNext } = useCarousel();

  return (
    <Button
      data-slot="carousel-next"
      variant={variant}
      size={size}
      className={cn(
        "absolute size-8 rounded-full",
        orientation === "horizontal"
          ? "top-1/2 -right-12 -translate-y-1/2"
          : "-bottom-12 left-1/2 -translate-x-1/2 rotate-90",
        className,
      )}
      disabled={!canScrollNext}
      onClick={scrollNext}
      {...props}
    >
      <ArrowRight />
      <span className="sr-only">Next slide</span>
    </Button>
  );
}

export {
  type CarouselApi,
  Carousel,
  CarouselContent,
  CarouselItem,
  CarouselPrevious,
  CarouselNext,
};
</file>

<file path="apps/web/app/components/ui/chart.tsx">
import * as React from "react";
import * as RechartsPrimitive from "recharts";

import { cn } from "~/lib/utils";

// Format: { THEME_NAME: CSS_SELECTOR }
const THEMES = { light: "", dark: ".dark" } as const;

export type ChartConfig = {
  [k in string]: {
    label?: React.ReactNode;
    icon?: React.ComponentType;
  } & (
    | { color?: string; theme?: never }
    | { color?: never; theme: Record<keyof typeof THEMES, string> }
  );
};

type ChartContextProps = {
  config: ChartConfig;
};

const ChartContext = React.createContext<ChartContextProps | null>(null);

function useChart() {
  const context = React.useContext(ChartContext);

  if (!context) {
    throw new Error("useChart must be used within a <ChartContainer />");
  }

  return context;
}

function ChartContainer({
  id,
  className,
  children,
  config,
  ...props
}: React.ComponentProps<"div"> & {
  config: ChartConfig;
  children: React.ComponentProps<
    typeof RechartsPrimitive.ResponsiveContainer
  >["children"];
}) {
  const uniqueId = React.useId();
  const chartId = `chart-${id || uniqueId.replace(/:/g, "")}`;

  return (
    <ChartContext.Provider value={{ config }}>
      <div
        data-slot="chart"
        data-chart={chartId}
        className={cn(
          "[&_.recharts-cartesian-axis-tick_text]:fill-muted-foreground [&_.recharts-cartesian-grid_line[stroke='#ccc']]:stroke-border/50 [&_.recharts-curve.recharts-tooltip-cursor]:stroke-border [&_.recharts-polar-grid_[stroke='#ccc']]:stroke-border [&_.recharts-radial-bar-background-sector]:fill-muted [&_.recharts-rectangle.recharts-tooltip-cursor]:fill-muted [&_.recharts-reference-line_[stroke='#ccc']]:stroke-border flex aspect-video justify-center text-xs [&_.recharts-dot[stroke='#fff']]:stroke-transparent [&_.recharts-layer]:outline-hidden [&_.recharts-sector]:outline-hidden [&_.recharts-sector[stroke='#fff']]:stroke-transparent [&_.recharts-surface]:outline-hidden",
          className,
        )}
        {...props}
      >
        <ChartStyle id={chartId} config={config} />
        <RechartsPrimitive.ResponsiveContainer>
          {children}
        </RechartsPrimitive.ResponsiveContainer>
      </div>
    </ChartContext.Provider>
  );
}

const ChartStyle = ({ id, config }: { id: string; config: ChartConfig }) => {
  const colorConfig = Object.entries(config).filter(
    ([, config]) => config.theme || config.color,
  );

  if (!colorConfig.length) {
    return null;
  }

  return (
    <style
      dangerouslySetInnerHTML={{
        __html: Object.entries(THEMES)
          .map(
            ([theme, prefix]) => `
${prefix} [data-chart=${id}] {
${colorConfig
  .map(([key, itemConfig]) => {
    const color =
      itemConfig.theme?.[theme as keyof typeof itemConfig.theme] ||
      itemConfig.color;
    return color ? `  --color-${key}: ${color};` : null;
  })
  .join("\n")}
}
`,
          )
          .join("\n"),
      }}
    />
  );
};

const ChartTooltip = RechartsPrimitive.Tooltip;

function ChartTooltipContent({
  active,
  payload,
  className,
  indicator = "dot",
  hideLabel = false,
  hideIndicator = false,
  label,
  labelFormatter,
  labelClassName,
  formatter,
  color,
  nameKey,
  labelKey,
}: React.ComponentProps<typeof RechartsPrimitive.Tooltip> &
  React.ComponentProps<"div"> & {
    hideLabel?: boolean;
    hideIndicator?: boolean;
    indicator?: "line" | "dot" | "dashed";
    nameKey?: string;
    labelKey?: string;
  }) {
  const { config } = useChart();

  const tooltipLabel = React.useMemo(() => {
    if (hideLabel || !payload?.length) {
      return null;
    }

    const [item] = payload;
    const key = `${labelKey || item?.dataKey || item?.name || "value"}`;
    const itemConfig = getPayloadConfigFromPayload(config, item, key);
    const value =
      !labelKey && typeof label === "string"
        ? config[label as keyof typeof config]?.label || label
        : itemConfig?.label;

    if (labelFormatter) {
      return (
        <div className={cn("font-medium", labelClassName)}>
          {labelFormatter(value, payload)}
        </div>
      );
    }

    if (!value) {
      return null;
    }

    return <div className={cn("font-medium", labelClassName)}>{value}</div>;
  }, [
    label,
    labelFormatter,
    payload,
    hideLabel,
    labelClassName,
    config,
    labelKey,
  ]);

  if (!active || !payload?.length) {
    return null;
  }

  const nestLabel = payload.length === 1 && indicator !== "dot";

  return (
    <div
      className={cn(
        "border-border/50 bg-background grid min-w-[8rem] items-start gap-1.5 rounded-lg border px-2.5 py-1.5 text-xs shadow-xl",
        className,
      )}
    >
      {!nestLabel ? tooltipLabel : null}
      <div className="grid gap-1.5">
        {payload.map((item, index) => {
          const key = `${nameKey || item.name || item.dataKey || "value"}`;
          const itemConfig = getPayloadConfigFromPayload(config, item, key);
          const indicatorColor = color || item.payload.fill || item.color;

          return (
            <div
              key={item.dataKey}
              className={cn(
                "[&>svg]:text-muted-foreground flex w-full flex-wrap items-stretch gap-2 [&>svg]:h-2.5 [&>svg]:w-2.5",
                indicator === "dot" && "items-center",
              )}
            >
              {formatter && item?.value !== undefined && item.name ? (
                formatter(item.value, item.name, item, index, item.payload)
              ) : (
                <>
                  {itemConfig?.icon ? (
                    <itemConfig.icon />
                  ) : (
                    !hideIndicator && (
                      <div
                        className={cn(
                          "shrink-0 rounded-[2px] border-(--color-border) bg-(--color-bg)",
                          {
                            "h-2.5 w-2.5": indicator === "dot",
                            "w-1": indicator === "line",
                            "w-0 border-[1.5px] border-dashed bg-transparent":
                              indicator === "dashed",
                            "my-0.5": nestLabel && indicator === "dashed",
                          },
                        )}
                        style={
                          {
                            "--color-bg": indicatorColor,
                            "--color-border": indicatorColor,
                          } as React.CSSProperties
                        }
                      />
                    )
                  )}
                  <div
                    className={cn(
                      "flex flex-1 justify-between leading-none",
                      nestLabel ? "items-end" : "items-center",
                    )}
                  >
                    <div className="grid gap-1.5">
                      {nestLabel ? tooltipLabel : null}
                      <span className="text-muted-foreground">
                        {itemConfig?.label || item.name}
                      </span>
                    </div>
                    {item.value && (
                      <span className="text-foreground font-mono font-medium tabular-nums">
                        {item.value.toLocaleString()}
                      </span>
                    )}
                  </div>
                </>
              )}
            </div>
          );
        })}
      </div>
    </div>
  );
}

const ChartLegend = RechartsPrimitive.Legend;

function ChartLegendContent({
  className,
  hideIcon = false,
  payload,
  verticalAlign = "bottom",
  nameKey,
}: React.ComponentProps<"div"> &
  Pick<RechartsPrimitive.LegendProps, "payload" | "verticalAlign"> & {
    hideIcon?: boolean;
    nameKey?: string;
  }) {
  const { config } = useChart();

  if (!payload?.length) {
    return null;
  }

  return (
    <div
      className={cn(
        "flex items-center justify-center gap-4",
        verticalAlign === "top" ? "pb-3" : "pt-3",
        className,
      )}
    >
      {payload.map((item) => {
        const key = `${nameKey || item.dataKey || "value"}`;
        const itemConfig = getPayloadConfigFromPayload(config, item, key);

        return (
          <div
            key={item.value}
            className={cn(
              "[&>svg]:text-muted-foreground flex items-center gap-1.5 [&>svg]:h-3 [&>svg]:w-3",
            )}
          >
            {itemConfig?.icon && !hideIcon ? (
              <itemConfig.icon />
            ) : (
              <div
                className="h-2 w-2 shrink-0 rounded-[2px]"
                style={{
                  backgroundColor: item.color,
                }}
              />
            )}
            {itemConfig?.label}
          </div>
        );
      })}
    </div>
  );
}

// Helper to extract item config from a payload.
function getPayloadConfigFromPayload(
  config: ChartConfig,
  payload: unknown,
  key: string,
) {
  if (typeof payload !== "object" || payload === null) {
    return undefined;
  }

  const payloadPayload =
    "payload" in payload &&
    typeof payload.payload === "object" &&
    payload.payload !== null
      ? payload.payload
      : undefined;

  let configLabelKey: string = key;

  if (
    key in payload &&
    typeof payload[key as keyof typeof payload] === "string"
  ) {
    configLabelKey = payload[key as keyof typeof payload] as string;
  } else if (
    payloadPayload &&
    key in payloadPayload &&
    typeof payloadPayload[key as keyof typeof payloadPayload] === "string"
  ) {
    configLabelKey = payloadPayload[
      key as keyof typeof payloadPayload
    ] as string;
  }

  return configLabelKey in config
    ? config[configLabelKey]
    : config[key as keyof typeof config];
}

export {
  ChartContainer,
  ChartTooltip,
  ChartTooltipContent,
  ChartLegend,
  ChartLegendContent,
  ChartStyle,
};
</file>

<file path="apps/web/app/components/ui/checkbox.tsx">
"use client";

import * as CheckboxPrimitive from "@radix-ui/react-checkbox";
import { CheckIcon } from "lucide-react";
import type * as React from "react";

import { cn } from "~/lib/utils";

function Checkbox({
  className,
  ...props
}: React.ComponentProps<typeof CheckboxPrimitive.Root>) {
  return (
    <CheckboxPrimitive.Root
      data-slot="checkbox"
      className={cn(
        "peer border-input dark:bg-input/30 data-[state=checked]:bg-primary data-[state=checked]:text-primary-foreground dark:data-[state=checked]:bg-primary data-[state=checked]:border-primary focus-visible:border-ring focus-visible:ring-ring/50 aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive size-4 shrink-0 rounded-[4px] border shadow-xs transition-shadow outline-none focus-visible:ring-[3px] disabled:cursor-not-allowed disabled:opacity-50",
        className,
      )}
      {...props}
    >
      <CheckboxPrimitive.Indicator
        data-slot="checkbox-indicator"
        className="flex items-center justify-center text-current transition-none"
      >
        <CheckIcon className="size-3.5" />
      </CheckboxPrimitive.Indicator>
    </CheckboxPrimitive.Root>
  );
}

export { Checkbox };
</file>

<file path="apps/web/app/components/ui/collapsible.tsx">
import * as CollapsiblePrimitive from "@radix-ui/react-collapsible";

function Collapsible({
	...props
}: React.ComponentProps<typeof CollapsiblePrimitive.Root>) {
	return <CollapsiblePrimitive.Root data-slot="collapsible" {...props} />;
}

function CollapsibleTrigger({
	...props
}: React.ComponentProps<typeof CollapsiblePrimitive.CollapsibleTrigger>) {
	return (
		<CollapsiblePrimitive.CollapsibleTrigger
			data-slot="collapsible-trigger"
			{...props}
		/>
	);
}

function CollapsibleContent({
	...props
}: React.ComponentProps<typeof CollapsiblePrimitive.CollapsibleContent>) {
	return (
		<CollapsiblePrimitive.CollapsibleContent
			data-slot="collapsible-content"
			{...props}
		/>
	);
}

export { Collapsible, CollapsibleTrigger, CollapsibleContent };
</file>

<file path="apps/web/app/components/ui/combo-box.tsx">
"use client";

import { Check, ChevronsUpDown } from "lucide-react";
import * as React from "react";

import { Button } from "~/components/ui/button";
import {
  Command,
  CommandEmpty,
  CommandGroup,
  CommandInput,
  CommandItem,
  CommandList,
} from "~/components/ui/command";
import {
  Popover,
  PopoverContent,
  PopoverTrigger,
} from "~/components/ui/popover";
import { cn } from "~/lib/utils";

const frameworks = [
  {
    value: "next.js",
    label: "Next.js",
  },
  {
    value: "sveltekit",
    label: "SvelteKit",
  },
  {
    value: "nuxt.js",
    label: "Nuxt.js",
  },
  {
    value: "remix",
    label: "Remix",
  },
  {
    value: "astro",
    label: "Astro",
  },
];

export function ComboboxDemo() {
  const [open, setOpen] = React.useState(false);
  const [value, setValue] = React.useState("");

  return (
    <Popover open={open} onOpenChange={setOpen}>
      <PopoverTrigger asChild>
        <Button
          variant="outline"
          role="combobox"
          aria-expanded={open}
          className="w-[200px] justify-between"
        >
          {value
            ? frameworks.find((framework) => framework.value === value)?.label
            : "Select framework..."}
          <ChevronsUpDown className="opacity-50" />
        </Button>
      </PopoverTrigger>
      <PopoverContent className="w-[200px] p-0">
        <Command>
          <CommandInput placeholder="Search framework..." className="h-9" />
          <CommandList>
            <CommandEmpty>No framework found.</CommandEmpty>
            <CommandGroup>
              {frameworks.map((framework) => (
                <CommandItem
                  key={framework.value}
                  value={framework.value}
                  onSelect={(currentValue) => {
                    setValue(currentValue === value ? "" : currentValue);
                    setOpen(false);
                  }}
                >
                  {framework.label}
                  <Check
                    className={cn(
                      "ml-auto",
                      value === framework.value ? "opacity-100" : "opacity-0",
                    )}
                  />
                </CommandItem>
              ))}
            </CommandGroup>
          </CommandList>
        </Command>
      </PopoverContent>
    </Popover>
  );
}
</file>

<file path="apps/web/app/components/ui/command.tsx">
"use client";

import { Command as CommandPrimitive } from "cmdk";
import { SearchIcon } from "lucide-react";
import type * as React from "react";

import {
  Dialog,
  DialogContent,
  DialogDescription,
  DialogHeader,
  DialogTitle,
} from "~/components/ui/dialog";
import { cn } from "~/lib/utils";

function Command({
  className,
  ...props
}: React.ComponentProps<typeof CommandPrimitive>) {
  return (
    <CommandPrimitive
      data-slot="command"
      className={cn(
        "bg-popover text-popover-foreground flex h-full w-full flex-col overflow-hidden rounded-md",
        className,
      )}
      {...props}
    />
  );
}

function CommandDialog({
  title = "Command Palette",
  description = "Search for a command to run...",
  children,
  ...props
}: React.ComponentProps<typeof Dialog> & {
  title?: string;
  description?: string;
}) {
  return (
    <Dialog {...props}>
      <DialogHeader className="sr-only">
        <DialogTitle>{title}</DialogTitle>
        <DialogDescription>{description}</DialogDescription>
      </DialogHeader>
      <DialogContent className="overflow-hidden p-0">
        <Command className="[&_[cmdk-group-heading]]:text-muted-foreground **:data-[slot=command-input-wrapper]:h-12 [&_[cmdk-group-heading]]:px-2 [&_[cmdk-group-heading]]:font-medium [&_[cmdk-group]]:px-2 [&_[cmdk-group]:not([hidden])_~[cmdk-group]]:pt-0 [&_[cmdk-input-wrapper]_svg]:h-5 [&_[cmdk-input-wrapper]_svg]:w-5 [&_[cmdk-input]]:h-12 [&_[cmdk-item]]:px-2 [&_[cmdk-item]]:py-3 [&_[cmdk-item]_svg]:h-5 [&_[cmdk-item]_svg]:w-5">
          {children}
        </Command>
      </DialogContent>
    </Dialog>
  );
}

function CommandInput({
  className,
  ...props
}: React.ComponentProps<typeof CommandPrimitive.Input>) {
  return (
    <div
      data-slot="command-input-wrapper"
      className="flex h-9 items-center gap-2 border-b px-3"
    >
      <SearchIcon className="size-4 shrink-0 opacity-50" />
      <CommandPrimitive.Input
        data-slot="command-input"
        className={cn(
          "placeholder:text-muted-foreground flex h-10 w-full rounded-md bg-transparent py-3 text-sm outline-hidden disabled:cursor-not-allowed disabled:opacity-50",
          className,
        )}
        {...props}
      />
    </div>
  );
}

function CommandList({
  className,
  ...props
}: React.ComponentProps<typeof CommandPrimitive.List>) {
  return (
    <CommandPrimitive.List
      data-slot="command-list"
      className={cn(
        "max-h-[300px] scroll-py-1 overflow-x-hidden overflow-y-auto",
        className,
      )}
      {...props}
    />
  );
}

function CommandEmpty({
  ...props
}: React.ComponentProps<typeof CommandPrimitive.Empty>) {
  return (
    <CommandPrimitive.Empty
      data-slot="command-empty"
      className="py-6 text-center text-sm"
      {...props}
    />
  );
}

function CommandGroup({
  className,
  ...props
}: React.ComponentProps<typeof CommandPrimitive.Group>) {
  return (
    <CommandPrimitive.Group
      data-slot="command-group"
      className={cn(
        "text-foreground [&_[cmdk-group-heading]]:text-muted-foreground overflow-hidden p-1 [&_[cmdk-group-heading]]:px-2 [&_[cmdk-group-heading]]:py-1.5 [&_[cmdk-group-heading]]:text-xs [&_[cmdk-group-heading]]:font-medium",
        className,
      )}
      {...props}
    />
  );
}

function CommandSeparator({
  className,
  ...props
}: React.ComponentProps<typeof CommandPrimitive.Separator>) {
  return (
    <CommandPrimitive.Separator
      data-slot="command-separator"
      className={cn("bg-border -mx-1 h-px", className)}
      {...props}
    />
  );
}

function CommandItem({
  className,
  ...props
}: React.ComponentProps<typeof CommandPrimitive.Item>) {
  return (
    <CommandPrimitive.Item
      data-slot="command-item"
      className={cn(
        "data-[selected=true]:bg-accent data-[selected=true]:text-accent-foreground [&_svg:not([class*='text-'])]:text-muted-foreground relative flex cursor-default items-center gap-2 rounded-sm px-2 py-1.5 text-sm outline-hidden select-none data-[disabled=true]:pointer-events-none data-[disabled=true]:opacity-50 [&_svg]:pointer-events-none [&_svg]:shrink-0 [&_svg:not([class*='size-'])]:size-4",
        className,
      )}
      {...props}
    />
  );
}

function CommandShortcut({
  className,
  ...props
}: React.ComponentProps<"span">) {
  return (
    <span
      data-slot="command-shortcut"
      className={cn(
        "text-muted-foreground ml-auto text-xs tracking-widest",
        className,
      )}
      {...props}
    />
  );
}

export {
  Command,
  CommandDialog,
  CommandInput,
  CommandList,
  CommandEmpty,
  CommandGroup,
  CommandItem,
  CommandShortcut,
  CommandSeparator,
};
</file>

<file path="apps/web/app/components/ui/context-menu.tsx">
"use client";

import * as ContextMenuPrimitive from "@radix-ui/react-context-menu";
import { CheckIcon, ChevronRightIcon, CircleIcon } from "lucide-react";
import type * as React from "react";

import { cn } from "~/lib/utils";

function ContextMenu({
  ...props
}: React.ComponentProps<typeof ContextMenuPrimitive.Root>) {
  return <ContextMenuPrimitive.Root data-slot="context-menu" {...props} />;
}

function ContextMenuTrigger({
  ...props
}: React.ComponentProps<typeof ContextMenuPrimitive.Trigger>) {
  return (
    <ContextMenuPrimitive.Trigger data-slot="context-menu-trigger" {...props} />
  );
}

function ContextMenuGroup({
  ...props
}: React.ComponentProps<typeof ContextMenuPrimitive.Group>) {
  return (
    <ContextMenuPrimitive.Group data-slot="context-menu-group" {...props} />
  );
}

function ContextMenuPortal({
  ...props
}: React.ComponentProps<typeof ContextMenuPrimitive.Portal>) {
  return (
    <ContextMenuPrimitive.Portal data-slot="context-menu-portal" {...props} />
  );
}

function ContextMenuSub({
  ...props
}: React.ComponentProps<typeof ContextMenuPrimitive.Sub>) {
  return <ContextMenuPrimitive.Sub data-slot="context-menu-sub" {...props} />;
}

function ContextMenuRadioGroup({
  ...props
}: React.ComponentProps<typeof ContextMenuPrimitive.RadioGroup>) {
  return (
    <ContextMenuPrimitive.RadioGroup
      data-slot="context-menu-radio-group"
      {...props}
    />
  );
}

function ContextMenuSubTrigger({
  className,
  inset,
  children,
  ...props
}: React.ComponentProps<typeof ContextMenuPrimitive.SubTrigger> & {
  inset?: boolean;
}) {
  return (
    <ContextMenuPrimitive.SubTrigger
      data-slot="context-menu-sub-trigger"
      data-inset={inset}
      className={cn(
        "focus:bg-accent focus:text-accent-foreground data-[state=open]:bg-accent data-[state=open]:text-accent-foreground flex cursor-default items-center rounded-sm px-2 py-1.5 text-sm outline-hidden select-none data-[inset]:pl-8 [&_svg]:pointer-events-none [&_svg]:shrink-0 [&_svg:not([class*='size-'])]:size-4",
        className,
      )}
      {...props}
    >
      {children}
      <ChevronRightIcon className="ml-auto" />
    </ContextMenuPrimitive.SubTrigger>
  );
}

function ContextMenuSubContent({
  className,
  ...props
}: React.ComponentProps<typeof ContextMenuPrimitive.SubContent>) {
  return (
    <ContextMenuPrimitive.SubContent
      data-slot="context-menu-sub-content"
      className={cn(
        "bg-popover text-popover-foreground data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2 z-50 min-w-[8rem] origin-(--radix-context-menu-content-transform-origin) overflow-hidden rounded-md border p-1 shadow-lg",
        className,
      )}
      {...props}
    />
  );
}

function ContextMenuContent({
  className,
  ...props
}: React.ComponentProps<typeof ContextMenuPrimitive.Content>) {
  return (
    <ContextMenuPrimitive.Portal>
      <ContextMenuPrimitive.Content
        data-slot="context-menu-content"
        className={cn(
          "bg-popover text-popover-foreground data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2 z-50 max-h-(--radix-context-menu-content-available-height) min-w-[8rem] origin-(--radix-context-menu-content-transform-origin) overflow-x-hidden overflow-y-auto rounded-md border p-1 shadow-md",
          className,
        )}
        {...props}
      />
    </ContextMenuPrimitive.Portal>
  );
}

function ContextMenuItem({
  className,
  inset,
  variant = "default",
  ...props
}: React.ComponentProps<typeof ContextMenuPrimitive.Item> & {
  inset?: boolean;
  variant?: "default" | "destructive";
}) {
  return (
    <ContextMenuPrimitive.Item
      data-slot="context-menu-item"
      data-inset={inset}
      data-variant={variant}
      className={cn(
        "focus:bg-accent focus:text-accent-foreground data-[variant=destructive]:text-destructive data-[variant=destructive]:focus:bg-destructive/10 dark:data-[variant=destructive]:focus:bg-destructive/20 data-[variant=destructive]:focus:text-destructive data-[variant=destructive]:*:[svg]:!text-destructive [&_svg:not([class*='text-'])]:text-muted-foreground relative flex cursor-default items-center gap-2 rounded-sm px-2 py-1.5 text-sm outline-hidden select-none data-[disabled]:pointer-events-none data-[disabled]:opacity-50 data-[inset]:pl-8 [&_svg]:pointer-events-none [&_svg]:shrink-0 [&_svg:not([class*='size-'])]:size-4",
        className,
      )}
      {...props}
    />
  );
}

function ContextMenuCheckboxItem({
  className,
  children,
  checked,
  ...props
}: React.ComponentProps<typeof ContextMenuPrimitive.CheckboxItem>) {
  return (
    <ContextMenuPrimitive.CheckboxItem
      data-slot="context-menu-checkbox-item"
      className={cn(
        "focus:bg-accent focus:text-accent-foreground relative flex cursor-default items-center gap-2 rounded-sm py-1.5 pr-2 pl-8 text-sm outline-hidden select-none data-[disabled]:pointer-events-none data-[disabled]:opacity-50 [&_svg]:pointer-events-none [&_svg]:shrink-0 [&_svg:not([class*='size-'])]:size-4",
        className,
      )}
      checked={checked}
      {...props}
    >
      <span className="pointer-events-none absolute left-2 flex size-3.5 items-center justify-center">
        <ContextMenuPrimitive.ItemIndicator>
          <CheckIcon className="size-4" />
        </ContextMenuPrimitive.ItemIndicator>
      </span>
      {children}
    </ContextMenuPrimitive.CheckboxItem>
  );
}

function ContextMenuRadioItem({
  className,
  children,
  ...props
}: React.ComponentProps<typeof ContextMenuPrimitive.RadioItem>) {
  return (
    <ContextMenuPrimitive.RadioItem
      data-slot="context-menu-radio-item"
      className={cn(
        "focus:bg-accent focus:text-accent-foreground relative flex cursor-default items-center gap-2 rounded-sm py-1.5 pr-2 pl-8 text-sm outline-hidden select-none data-[disabled]:pointer-events-none data-[disabled]:opacity-50 [&_svg]:pointer-events-none [&_svg]:shrink-0 [&_svg:not([class*='size-'])]:size-4",
        className,
      )}
      {...props}
    >
      <span className="pointer-events-none absolute left-2 flex size-3.5 items-center justify-center">
        <ContextMenuPrimitive.ItemIndicator>
          <CircleIcon className="size-2 fill-current" />
        </ContextMenuPrimitive.ItemIndicator>
      </span>
      {children}
    </ContextMenuPrimitive.RadioItem>
  );
}

function ContextMenuLabel({
  className,
  inset,
  ...props
}: React.ComponentProps<typeof ContextMenuPrimitive.Label> & {
  inset?: boolean;
}) {
  return (
    <ContextMenuPrimitive.Label
      data-slot="context-menu-label"
      data-inset={inset}
      className={cn(
        "text-foreground px-2 py-1.5 text-sm font-medium data-[inset]:pl-8",
        className,
      )}
      {...props}
    />
  );
}

function ContextMenuSeparator({
  className,
  ...props
}: React.ComponentProps<typeof ContextMenuPrimitive.Separator>) {
  return (
    <ContextMenuPrimitive.Separator
      data-slot="context-menu-separator"
      className={cn("bg-border -mx-1 my-1 h-px", className)}
      {...props}
    />
  );
}

function ContextMenuShortcut({
  className,
  ...props
}: React.ComponentProps<"span">) {
  return (
    <span
      data-slot="context-menu-shortcut"
      className={cn(
        "text-muted-foreground ml-auto text-xs tracking-widest",
        className,
      )}
      {...props}
    />
  );
}

export {
  ContextMenu,
  ContextMenuTrigger,
  ContextMenuContent,
  ContextMenuItem,
  ContextMenuCheckboxItem,
  ContextMenuRadioItem,
  ContextMenuLabel,
  ContextMenuSeparator,
  ContextMenuShortcut,
  ContextMenuGroup,
  ContextMenuPortal,
  ContextMenuSub,
  ContextMenuSubContent,
  ContextMenuSubTrigger,
  ContextMenuRadioGroup,
};
</file>

<file path="apps/web/app/components/ui/date-picker.tsx">
"use client";

import { format } from "date-fns";
import { Calendar as CalendarIcon } from "lucide-react";
import * as React from "react";

import { Button } from "~/components/ui/button";
import { Calendar } from "~/components/ui/calendar";
import {
  Popover,
  PopoverContent,
  PopoverTrigger,
} from "~/components/ui/popover";
import { cn } from "~/lib/utils";

export function DatePickerDemo() {
  const [date, setDate] = React.useState<Date>();

  return (
    <Popover>
      <PopoverTrigger asChild>
        <Button
          variant={"outline"}
          className={cn(
            "w-[280px] justify-start text-left font-normal",
            !date && "text-muted-foreground",
          )}
        >
          <CalendarIcon className="mr-2 h-4 w-4" />
          {date ? format(date, "PPP") : <span>Pick a date</span>}
        </Button>
      </PopoverTrigger>
      <PopoverContent className="w-auto p-0">
        <Calendar
          mode="single"
          selected={date}
          onSelect={setDate}
          initialFocus
        />
      </PopoverContent>
    </Popover>
  );
}
</file>

<file path="apps/web/app/components/ui/dialog.tsx">
import * as DialogPrimitive from "@radix-ui/react-dialog";
import { XIcon } from "lucide-react";
import type * as React from "react";

import { cn } from "~/lib/utils";

function Dialog({
  ...props
}: React.ComponentProps<typeof DialogPrimitive.Root>) {
  return <DialogPrimitive.Root data-slot="dialog" {...props} />;
}

function DialogTrigger({
  ...props
}: React.ComponentProps<typeof DialogPrimitive.Trigger>) {
  return <DialogPrimitive.Trigger data-slot="dialog-trigger" {...props} />;
}

function DialogPortal({
  ...props
}: React.ComponentProps<typeof DialogPrimitive.Portal>) {
  return <DialogPrimitive.Portal data-slot="dialog-portal" {...props} />;
}

function DialogClose({
  ...props
}: React.ComponentProps<typeof DialogPrimitive.Close>) {
  return <DialogPrimitive.Close data-slot="dialog-close" {...props} />;
}

function DialogOverlay({
  className,
  ...props
}: React.ComponentProps<typeof DialogPrimitive.Overlay>) {
  return (
    <DialogPrimitive.Overlay
      data-slot="dialog-overlay"
      className={cn(
        "data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 fixed inset-0 z-50 bg-black/50",
        className,
      )}
      {...props}
    />
  );
}

function DialogContent({
  className,
  children,
  ...props
}: React.ComponentProps<typeof DialogPrimitive.Content>) {
  return (
    <DialogPortal data-slot="dialog-portal">
      <DialogOverlay />
      <DialogPrimitive.Content
        data-slot="dialog-content"
        className={cn(
          "bg-background data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 fixed top-[50%] left-[50%] z-50 grid w-full max-w-[calc(100%-2rem)] translate-x-[-50%] translate-y-[-50%] gap-4 rounded-lg border p-6 shadow-lg duration-200 sm:max-w-lg",
          className,
        )}
        {...props}
      >
        {children}
        <DialogPrimitive.Close className="ring-offset-background focus:ring-ring data-[state=open]:bg-accent data-[state=open]:text-muted-foreground absolute top-4 right-4 rounded-xs opacity-70 transition-opacity hover:opacity-100 focus:ring-2 focus:ring-offset-2 focus:outline-hidden disabled:pointer-events-none [&_svg]:pointer-events-none [&_svg]:shrink-0 [&_svg:not([class*='size-'])]:size-4">
          <XIcon />
          <span className="sr-only">Close</span>
        </DialogPrimitive.Close>
      </DialogPrimitive.Content>
    </DialogPortal>
  );
}

function DialogHeader({ className, ...props }: React.ComponentProps<"div">) {
  return (
    <div
      data-slot="dialog-header"
      className={cn("flex flex-col gap-2 text-center sm:text-left", className)}
      {...props}
    />
  );
}

function DialogFooter({ className, ...props }: React.ComponentProps<"div">) {
  return (
    <div
      data-slot="dialog-footer"
      className={cn(
        "flex flex-col-reverse gap-2 sm:flex-row sm:justify-end",
        className,
      )}
      {...props}
    />
  );
}

function DialogTitle({
  className,
  ...props
}: React.ComponentProps<typeof DialogPrimitive.Title>) {
  return (
    <DialogPrimitive.Title
      data-slot="dialog-title"
      className={cn("text-lg leading-none font-semibold", className)}
      {...props}
    />
  );
}

function DialogDescription({
  className,
  ...props
}: React.ComponentProps<typeof DialogPrimitive.Description>) {
  return (
    <DialogPrimitive.Description
      data-slot="dialog-description"
      className={cn("text-muted-foreground text-sm", className)}
      {...props}
    />
  );
}

export {
  Dialog,
  DialogClose,
  DialogContent,
  DialogDescription,
  DialogFooter,
  DialogHeader,
  DialogOverlay,
  DialogPortal,
  DialogTitle,
  DialogTrigger,
};
</file>

<file path="apps/web/app/components/ui/drawer.tsx">
import type * as React from "react";
import { Drawer as DrawerPrimitive } from "vaul";

import { cn } from "~/lib/utils";

function Drawer({
  ...props
}: React.ComponentProps<typeof DrawerPrimitive.Root>) {
  return <DrawerPrimitive.Root data-slot="drawer" {...props} />;
}

function DrawerTrigger({
  ...props
}: React.ComponentProps<typeof DrawerPrimitive.Trigger>) {
  return <DrawerPrimitive.Trigger data-slot="drawer-trigger" {...props} />;
}

function DrawerPortal({
  ...props
}: React.ComponentProps<typeof DrawerPrimitive.Portal>) {
  return <DrawerPrimitive.Portal data-slot="drawer-portal" {...props} />;
}

function DrawerClose({
  ...props
}: React.ComponentProps<typeof DrawerPrimitive.Close>) {
  return <DrawerPrimitive.Close data-slot="drawer-close" {...props} />;
}

function DrawerOverlay({
  className,
  ...props
}: React.ComponentProps<typeof DrawerPrimitive.Overlay>) {
  return (
    <DrawerPrimitive.Overlay
      data-slot="drawer-overlay"
      className={cn(
        "data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 fixed inset-0 z-50 bg-black/50",
        className,
      )}
      {...props}
    />
  );
}

function DrawerContent({
  className,
  children,
  ...props
}: React.ComponentProps<typeof DrawerPrimitive.Content>) {
  return (
    <DrawerPortal data-slot="drawer-portal">
      <DrawerOverlay />
      <DrawerPrimitive.Content
        data-slot="drawer-content"
        className={cn(
          "group/drawer-content bg-background fixed z-50 flex h-auto flex-col",
          "data-[vaul-drawer-direction=top]:inset-x-0 data-[vaul-drawer-direction=top]:top-0 data-[vaul-drawer-direction=top]:mb-24 data-[vaul-drawer-direction=top]:max-h-[80vh] data-[vaul-drawer-direction=top]:rounded-b-lg data-[vaul-drawer-direction=top]:border-b",
          "data-[vaul-drawer-direction=bottom]:inset-x-0 data-[vaul-drawer-direction=bottom]:bottom-0 data-[vaul-drawer-direction=bottom]:mt-24 data-[vaul-drawer-direction=bottom]:max-h-[80vh] data-[vaul-drawer-direction=bottom]:rounded-t-lg data-[vaul-drawer-direction=bottom]:border-t",
          "data-[vaul-drawer-direction=right]:inset-y-0 data-[vaul-drawer-direction=right]:right-0 data-[vaul-drawer-direction=right]:w-3/4 data-[vaul-drawer-direction=right]:border-l data-[vaul-drawer-direction=right]:sm:max-w-sm",
          "data-[vaul-drawer-direction=left]:inset-y-0 data-[vaul-drawer-direction=left]:left-0 data-[vaul-drawer-direction=left]:w-3/4 data-[vaul-drawer-direction=left]:border-r data-[vaul-drawer-direction=left]:sm:max-w-sm",
          className,
        )}
        {...props}
      >
        <div className="bg-muted mx-auto mt-4 hidden h-2 w-[100px] shrink-0 rounded-full group-data-[vaul-drawer-direction=bottom]/drawer-content:block" />
        {children}
      </DrawerPrimitive.Content>
    </DrawerPortal>
  );
}

function DrawerHeader({ className, ...props }: React.ComponentProps<"div">) {
  return (
    <div
      data-slot="drawer-header"
      className={cn("flex flex-col gap-1.5 p-4", className)}
      {...props}
    />
  );
}

function DrawerFooter({ className, ...props }: React.ComponentProps<"div">) {
  return (
    <div
      data-slot="drawer-footer"
      className={cn("mt-auto flex flex-col gap-2 p-4", className)}
      {...props}
    />
  );
}

function DrawerTitle({
  className,
  ...props
}: React.ComponentProps<typeof DrawerPrimitive.Title>) {
  return (
    <DrawerPrimitive.Title
      data-slot="drawer-title"
      className={cn("text-foreground font-semibold", className)}
      {...props}
    />
  );
}

function DrawerDescription({
  className,
  ...props
}: React.ComponentProps<typeof DrawerPrimitive.Description>) {
  return (
    <DrawerPrimitive.Description
      data-slot="drawer-description"
      className={cn("text-muted-foreground text-sm", className)}
      {...props}
    />
  );
}

export {
  Drawer,
  DrawerPortal,
  DrawerOverlay,
  DrawerTrigger,
  DrawerClose,
  DrawerContent,
  DrawerHeader,
  DrawerFooter,
  DrawerTitle,
  DrawerDescription,
};
</file>

<file path="apps/web/app/components/ui/dropdown-menu.tsx">
"use client";

import * as DropdownMenuPrimitive from "@radix-ui/react-dropdown-menu";
import { CheckIcon, ChevronRightIcon, CircleIcon } from "lucide-react";
import type * as React from "react";

import { cn } from "~/lib/utils";

function DropdownMenu({
  ...props
}: React.ComponentProps<typeof DropdownMenuPrimitive.Root>) {
  return <DropdownMenuPrimitive.Root data-slot="dropdown-menu" {...props} />;
}

function DropdownMenuPortal({
  ...props
}: React.ComponentProps<typeof DropdownMenuPrimitive.Portal>) {
  return (
    <DropdownMenuPrimitive.Portal data-slot="dropdown-menu-portal" {...props} />
  );
}

function DropdownMenuTrigger({
  ...props
}: React.ComponentProps<typeof DropdownMenuPrimitive.Trigger>) {
  return (
    <DropdownMenuPrimitive.Trigger
      data-slot="dropdown-menu-trigger"
      {...props}
    />
  );
}

function DropdownMenuContent({
  className,
  sideOffset = 4,
  ...props
}: React.ComponentProps<typeof DropdownMenuPrimitive.Content>) {
  return (
    <DropdownMenuPrimitive.Portal>
      <DropdownMenuPrimitive.Content
        data-slot="dropdown-menu-content"
        sideOffset={sideOffset}
        className={cn(
          "bg-popover text-popover-foreground data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2 z-50 max-h-(--radix-dropdown-menu-content-available-height) min-w-[8rem] origin-(--radix-dropdown-menu-content-transform-origin) overflow-x-hidden overflow-y-auto rounded-md border p-1 shadow-md",
          className,
        )}
        {...props}
      />
    </DropdownMenuPrimitive.Portal>
  );
}

function DropdownMenuGroup({
  ...props
}: React.ComponentProps<typeof DropdownMenuPrimitive.Group>) {
  return (
    <DropdownMenuPrimitive.Group data-slot="dropdown-menu-group" {...props} />
  );
}

function DropdownMenuItem({
  className,
  inset,
  variant = "default",
  ...props
}: React.ComponentProps<typeof DropdownMenuPrimitive.Item> & {
  inset?: boolean;
  variant?: "default" | "destructive";
}) {
  return (
    <DropdownMenuPrimitive.Item
      data-slot="dropdown-menu-item"
      data-inset={inset}
      data-variant={variant}
      className={cn(
        "focus:bg-accent focus:text-accent-foreground data-[variant=destructive]:text-destructive data-[variant=destructive]:focus:bg-destructive/10 dark:data-[variant=destructive]:focus:bg-destructive/20 data-[variant=destructive]:focus:text-destructive data-[variant=destructive]:*:[svg]:!text-destructive [&_svg:not([class*='text-'])]:text-muted-foreground relative flex cursor-default items-center gap-2 rounded-sm px-2 py-1.5 text-sm outline-hidden select-none data-[disabled]:pointer-events-none data-[disabled]:opacity-50 data-[inset]:pl-8 [&_svg]:pointer-events-none [&_svg]:shrink-0 [&_svg:not([class*='size-'])]:size-4",
        className,
      )}
      {...props}
    />
  );
}

function DropdownMenuCheckboxItem({
  className,
  children,
  checked,
  ...props
}: React.ComponentProps<typeof DropdownMenuPrimitive.CheckboxItem>) {
  return (
    <DropdownMenuPrimitive.CheckboxItem
      data-slot="dropdown-menu-checkbox-item"
      className={cn(
        "focus:bg-accent focus:text-accent-foreground relative flex cursor-default items-center gap-2 rounded-sm py-1.5 pr-2 pl-8 text-sm outline-hidden select-none data-[disabled]:pointer-events-none data-[disabled]:opacity-50 [&_svg]:pointer-events-none [&_svg]:shrink-0 [&_svg:not([class*='size-'])]:size-4",
        className,
      )}
      checked={checked}
      {...props}
    >
      <span className="pointer-events-none absolute left-2 flex size-3.5 items-center justify-center">
        <DropdownMenuPrimitive.ItemIndicator>
          <CheckIcon className="size-4" />
        </DropdownMenuPrimitive.ItemIndicator>
      </span>
      {children}
    </DropdownMenuPrimitive.CheckboxItem>
  );
}

function DropdownMenuRadioGroup({
  ...props
}: React.ComponentProps<typeof DropdownMenuPrimitive.RadioGroup>) {
  return (
    <DropdownMenuPrimitive.RadioGroup
      data-slot="dropdown-menu-radio-group"
      {...props}
    />
  );
}

function DropdownMenuRadioItem({
  className,
  children,
  ...props
}: React.ComponentProps<typeof DropdownMenuPrimitive.RadioItem>) {
  return (
    <DropdownMenuPrimitive.RadioItem
      data-slot="dropdown-menu-radio-item"
      className={cn(
        "focus:bg-accent focus:text-accent-foreground relative flex cursor-default items-center gap-2 rounded-sm py-1.5 pr-2 pl-8 text-sm outline-hidden select-none data-[disabled]:pointer-events-none data-[disabled]:opacity-50 [&_svg]:pointer-events-none [&_svg]:shrink-0 [&_svg:not([class*='size-'])]:size-4",
        className,
      )}
      {...props}
    >
      <span className="pointer-events-none absolute left-2 flex size-3.5 items-center justify-center">
        <DropdownMenuPrimitive.ItemIndicator>
          <CircleIcon className="size-2 fill-current" />
        </DropdownMenuPrimitive.ItemIndicator>
      </span>
      {children}
    </DropdownMenuPrimitive.RadioItem>
  );
}

function DropdownMenuLabel({
  className,
  inset,
  ...props
}: React.ComponentProps<typeof DropdownMenuPrimitive.Label> & {
  inset?: boolean;
}) {
  return (
    <DropdownMenuPrimitive.Label
      data-slot="dropdown-menu-label"
      data-inset={inset}
      className={cn(
        "px-2 py-1.5 text-sm font-medium data-[inset]:pl-8",
        className,
      )}
      {...props}
    />
  );
}

function DropdownMenuSeparator({
  className,
  ...props
}: React.ComponentProps<typeof DropdownMenuPrimitive.Separator>) {
  return (
    <DropdownMenuPrimitive.Separator
      data-slot="dropdown-menu-separator"
      className={cn("bg-border -mx-1 my-1 h-px", className)}
      {...props}
    />
  );
}

function DropdownMenuShortcut({
  className,
  ...props
}: React.ComponentProps<"span">) {
  return (
    <span
      data-slot="dropdown-menu-shortcut"
      className={cn(
        "text-muted-foreground ml-auto text-xs tracking-widest",
        className,
      )}
      {...props}
    />
  );
}

function DropdownMenuSub({
  ...props
}: React.ComponentProps<typeof DropdownMenuPrimitive.Sub>) {
  return <DropdownMenuPrimitive.Sub data-slot="dropdown-menu-sub" {...props} />;
}

function DropdownMenuSubTrigger({
  className,
  inset,
  children,
  ...props
}: React.ComponentProps<typeof DropdownMenuPrimitive.SubTrigger> & {
  inset?: boolean;
}) {
  return (
    <DropdownMenuPrimitive.SubTrigger
      data-slot="dropdown-menu-sub-trigger"
      data-inset={inset}
      className={cn(
        "focus:bg-accent focus:text-accent-foreground data-[state=open]:bg-accent data-[state=open]:text-accent-foreground flex cursor-default items-center rounded-sm px-2 py-1.5 text-sm outline-hidden select-none data-[inset]:pl-8",
        className,
      )}
      {...props}
    >
      {children}
      <ChevronRightIcon className="ml-auto size-4" />
    </DropdownMenuPrimitive.SubTrigger>
  );
}

function DropdownMenuSubContent({
  className,
  ...props
}: React.ComponentProps<typeof DropdownMenuPrimitive.SubContent>) {
  return (
    <DropdownMenuPrimitive.SubContent
      data-slot="dropdown-menu-sub-content"
      className={cn(
        "bg-popover text-popover-foreground data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2 z-50 min-w-[8rem] origin-(--radix-dropdown-menu-content-transform-origin) overflow-hidden rounded-md border p-1 shadow-lg",
        className,
      )}
      {...props}
    />
  );
}

export {
  DropdownMenu,
  DropdownMenuPortal,
  DropdownMenuTrigger,
  DropdownMenuContent,
  DropdownMenuGroup,
  DropdownMenuLabel,
  DropdownMenuItem,
  DropdownMenuCheckboxItem,
  DropdownMenuRadioGroup,
  DropdownMenuRadioItem,
  DropdownMenuSeparator,
  DropdownMenuShortcut,
  DropdownMenuSub,
  DropdownMenuSubTrigger,
  DropdownMenuSubContent,
};
</file>

<file path="apps/web/app/components/ui/dropzone.test.tsx">
/// <reference types="vitest" />
import { fireEvent, render, screen } from "@testing-library/react";
import { vi } from "vitest";
import { DropZone } from "./dropzone";

describe("DropZone", () => {
	it("renders the drop zone UI", () => {
		render(<DropZone onFilesAccepted={() => {}} />);
		// Use a function matcher to match text across element boundaries
		const dropZone = screen.getByRole("button", {
			name: /upload video files/i,
		});
		expect(dropZone.textContent?.toLowerCase()).toContain(
			"drag & drop your .mp4 file here",
		);
		expect(dropZone.textContent?.toLowerCase()).toContain(
			"or click to select from your computer",
		);
	});

	it("calls onFilesAccepted when a file is dropped", () => {
		const handleFilesAccepted = vi.fn();
		render(<DropZone onFilesAccepted={handleFilesAccepted} />);
		const dropZone = screen.getByRole("button", {
			name: /upload video files/i,
		});

		// Create a mock file
		const file = new File(["dummy content"], "test.mp4", { type: "video/mp4" });
		const dataTransfer = {
			files: [file],
			types: ["Files"],
			getData: vi.fn(),
			setData: vi.fn(),
			clearData: vi.fn(),
		};

		fireEvent.dragOver(dropZone, { dataTransfer });
		fireEvent.drop(dropZone, { dataTransfer });

		expect(handleFilesAccepted).toHaveBeenCalledWith([file]);
	});

	it("calls onFilesAccepted when a file is selected via input", () => {
		const handleFilesAccepted = vi.fn();
		render(<DropZone onFilesAccepted={handleFilesAccepted} />);
		const input = screen
			.getByLabelText(/upload video files/i)
			.querySelector("input[type='file']") as HTMLInputElement;

		// Create a mock file list
		const file = new File(["dummy content"], "test.mp4", { type: "video/mp4" });
		Object.defineProperty(input, "files", {
			value: [file],
			writable: false,
		});

		fireEvent.change(input);

		expect(handleFilesAccepted).toHaveBeenCalledWith([file]);
	});
});
</file>

<file path="apps/web/app/components/ui/dropzone.tsx">
import type React from "react";
import { useRef, useState } from "react";
import { cn } from "../../lib/utils";

interface DropZoneProps {
	onFilesAccepted: (files: FileList | File[]) => void;
	accept?: string;
	multiple?: boolean;
	className?: string;
	disabled?: boolean;
}

export const DropZone: React.FC<DropZoneProps> = ({
	onFilesAccepted,
	accept = ".mp4",
	multiple = false,
	className = "",
	disabled = false,
}) => {
	const [isDragging, setIsDragging] = useState(false);
	const inputRef = useRef<HTMLInputElement>(null);

	const handleDragOver = (e: React.DragEvent<HTMLDivElement>) => {
		if (disabled) return;
		e.preventDefault();
		e.stopPropagation();
		setIsDragging(true);
	};

	const handleDragLeave = (e: React.DragEvent<HTMLDivElement>) => {
		if (disabled) return;
		e.preventDefault();
		e.stopPropagation();
		setIsDragging(false);
	};

	const handleDrop = (e: React.DragEvent<HTMLDivElement>) => {
		if (disabled) return;
		e.preventDefault();
		e.stopPropagation();
		setIsDragging(false);
		if (e.dataTransfer.files && e.dataTransfer.files.length > 0) {
			onFilesAccepted(e.dataTransfer.files);
		}
	};

	const handleClick = () => {
		if (disabled) return;
		inputRef.current?.click();
	};

	const handleInputChange = (e: React.ChangeEvent<HTMLInputElement>) => {
		if (disabled) return;
		if (e.target.files && e.target.files.length > 0) {
			onFilesAccepted(e.target.files);
		}
	};

	return (
		<div
			className={cn(
				"flex flex-col items-center justify-center border-2 border-dashed rounded-lg p-8 cursor-pointer transition-colors",
				isDragging
					? "border-blue-500 bg-blue-50"
					: "border-gray-300 bg-white hover:border-blue-400",
				className,
			)}
			onDragOver={handleDragOver}
			onDragLeave={handleDragLeave}
			onDrop={handleDrop}
			onClick={handleClick}
			tabIndex={0}
			role="button"
			aria-label="Upload video files"
		>
			<input
				ref={inputRef}
				type="file"
				accept={accept}
				multiple={multiple}
				className="hidden"
				onChange={handleInputChange}
				tabIndex={-1}
			/>
			<div className="flex flex-col items-center">
				<svg
					className="w-12 h-12 text-blue-400 mb-2"
					fill="none"
					stroke="currentColor"
					strokeWidth={2}
					viewBox="0 0 48 48"
				>
					<path
						strokeLinecap="round"
						strokeLinejoin="round"
						d="M24 6v24m0 0l-8-8m8 8l8-8M6 36h36"
					/>
				</svg>
				<span className="text-lg font-medium text-gray-700">
					Drag & drop your <span className="text-blue-500">.mp4</span> file here
				</span>
				<span className="text-sm text-gray-500 mt-1">
					or click to select from your computer
				</span>
			</div>
		</div>
	);
};

export default DropZone;
</file>

<file path="apps/web/app/components/ui/form.tsx">
import type * as LabelPrimitive from "@radix-ui/react-label";
import { Slot } from "@radix-ui/react-slot";
import * as React from "react";
import {
  Controller,
  type ControllerProps,
  type FieldPath,
  type FieldValues,
  FormProvider,
  useFormContext,
  useFormState,
} from "react-hook-form";

import { Label } from "~/components/ui/label";
import { cn } from "~/lib/utils";

const Form = FormProvider;

type FormFieldContextValue<
  TFieldValues extends FieldValues = FieldValues,
  TName extends FieldPath<TFieldValues> = FieldPath<TFieldValues>,
> = {
  name: TName;
};

const FormFieldContext = React.createContext<FormFieldContextValue>(
  {} as FormFieldContextValue,
);

const FormField = <
  TFieldValues extends FieldValues = FieldValues,
  TName extends FieldPath<TFieldValues> = FieldPath<TFieldValues>,
>({
  ...props
}: ControllerProps<TFieldValues, TName>) => {
  return (
    <FormFieldContext.Provider value={{ name: props.name }}>
      <Controller {...props} />
    </FormFieldContext.Provider>
  );
};

const useFormField = () => {
  const fieldContext = React.useContext(FormFieldContext);
  const itemContext = React.useContext(FormItemContext);
  const { getFieldState } = useFormContext();
  const formState = useFormState({ name: fieldContext.name });
  const fieldState = getFieldState(fieldContext.name, formState);

  if (!fieldContext) {
    throw new Error("useFormField should be used within <FormField>");
  }

  const { id } = itemContext;

  return {
    id,
    name: fieldContext.name,
    formItemId: `${id}-form-item`,
    formDescriptionId: `${id}-form-item-description`,
    formMessageId: `${id}-form-item-message`,
    ...fieldState,
  };
};

type FormItemContextValue = {
  id: string;
};

const FormItemContext = React.createContext<FormItemContextValue>(
  {} as FormItemContextValue,
);

function FormItem({ className, ...props }: React.ComponentProps<"div">) {
  const id = React.useId();

  return (
    <FormItemContext.Provider value={{ id }}>
      <div
        data-slot="form-item"
        className={cn("grid gap-2", className)}
        {...props}
      />
    </FormItemContext.Provider>
  );
}

function FormLabel({
  className,
  ...props
}: React.ComponentProps<typeof LabelPrimitive.Root>) {
  const { error, formItemId } = useFormField();

  return (
    <Label
      data-slot="form-label"
      data-error={!!error}
      className={cn("data-[error=true]:text-destructive", className)}
      htmlFor={formItemId}
      {...props}
    />
  );
}

function FormControl({ ...props }: React.ComponentProps<typeof Slot>) {
  const { error, formItemId, formDescriptionId, formMessageId } =
    useFormField();

  return (
    <Slot
      data-slot="form-control"
      id={formItemId}
      aria-describedby={
        !error
          ? `${formDescriptionId}`
          : `${formDescriptionId} ${formMessageId}`
      }
      aria-invalid={!!error}
      {...props}
    />
  );
}

function FormDescription({ className, ...props }: React.ComponentProps<"p">) {
  const { formDescriptionId } = useFormField();

  return (
    <p
      data-slot="form-description"
      id={formDescriptionId}
      className={cn("text-muted-foreground text-sm", className)}
      {...props}
    />
  );
}

function FormMessage({ className, ...props }: React.ComponentProps<"p">) {
  const { error, formMessageId } = useFormField();
  const body = error ? String(error?.message ?? "") : props.children;

  if (!body) {
    return null;
  }

  return (
    <p
      data-slot="form-message"
      id={formMessageId}
      className={cn("text-destructive text-sm", className)}
      {...props}
    >
      {body}
    </p>
  );
}

export {
  useFormField,
  Form,
  FormItem,
  FormLabel,
  FormControl,
  FormDescription,
  FormMessage,
  FormField,
};
</file>

<file path="apps/web/app/components/ui/hover-card.tsx">
import * as HoverCardPrimitive from "@radix-ui/react-hover-card";
import type * as React from "react";

import { cn } from "~/lib/utils";

function HoverCard({
  ...props
}: React.ComponentProps<typeof HoverCardPrimitive.Root>) {
  return <HoverCardPrimitive.Root data-slot="hover-card" {...props} />;
}

function HoverCardTrigger({
  ...props
}: React.ComponentProps<typeof HoverCardPrimitive.Trigger>) {
  return (
    <HoverCardPrimitive.Trigger data-slot="hover-card-trigger" {...props} />
  );
}

function HoverCardContent({
  className,
  align = "center",
  sideOffset = 4,
  ...props
}: React.ComponentProps<typeof HoverCardPrimitive.Content>) {
  return (
    <HoverCardPrimitive.Portal data-slot="hover-card-portal">
      <HoverCardPrimitive.Content
        data-slot="hover-card-content"
        align={align}
        sideOffset={sideOffset}
        className={cn(
          "bg-popover text-popover-foreground data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2 z-50 w-64 origin-(--radix-hover-card-content-transform-origin) rounded-md border p-4 shadow-md outline-hidden",
          className,
        )}
        {...props}
      />
    </HoverCardPrimitive.Portal>
  );
}

export { HoverCard, HoverCardTrigger, HoverCardContent };
</file>

<file path="apps/web/app/components/ui/input-otp.tsx">
"use client";

import { OTPInput, OTPInputContext } from "input-otp";
import { MinusIcon } from "lucide-react";
import * as React from "react";

import { cn } from "~/lib/utils";

function InputOTP({
  className,
  containerClassName,
  ...props
}: React.ComponentProps<typeof OTPInput> & {
  containerClassName?: string;
}) {
  return (
    <OTPInput
      data-slot="input-otp"
      containerClassName={cn(
        "flex items-center gap-2 has-disabled:opacity-50",
        containerClassName,
      )}
      className={cn("disabled:cursor-not-allowed", className)}
      {...props}
    />
  );
}

function InputOTPGroup({ className, ...props }: React.ComponentProps<"div">) {
  return (
    <div
      data-slot="input-otp-group"
      className={cn("flex items-center", className)}
      {...props}
    />
  );
}

function InputOTPSlot({
  index,
  className,
  ...props
}: React.ComponentProps<"div"> & {
  index: number;
}) {
  const inputOTPContext = React.useContext(OTPInputContext);
  const { char, hasFakeCaret, isActive } = inputOTPContext?.slots[index] ?? {};

  return (
    <div
      data-slot="input-otp-slot"
      data-active={isActive}
      className={cn(
        "data-[active=true]:border-ring data-[active=true]:ring-ring/50 data-[active=true]:aria-invalid:ring-destructive/20 dark:data-[active=true]:aria-invalid:ring-destructive/40 aria-invalid:border-destructive data-[active=true]:aria-invalid:border-destructive dark:bg-input/30 border-input relative flex h-9 w-9 items-center justify-center border-y border-r text-sm shadow-xs transition-all outline-none first:rounded-l-md first:border-l last:rounded-r-md data-[active=true]:z-10 data-[active=true]:ring-[3px]",
        className,
      )}
      {...props}
    >
      {char}
      {hasFakeCaret && (
        <div className="pointer-events-none absolute inset-0 flex items-center justify-center">
          <div className="animate-caret-blink bg-foreground h-4 w-px duration-1000" />
        </div>
      )}
    </div>
  );
}

function InputOTPSeparator({ ...props }: React.ComponentProps<"div">) {
  return (
    <div data-slot="input-otp-separator" role="separator" {...props}>
      <MinusIcon />
    </div>
  );
}

export { InputOTP, InputOTPGroup, InputOTPSlot, InputOTPSeparator };
</file>

<file path="apps/web/app/components/ui/input.tsx">
import type * as React from "react";

import { cn } from "~/lib/utils";

function Input({ className, type, ...props }: React.ComponentProps<"input">) {
  return (
    <input
      type={type}
      data-slot="input"
      className={cn(
        "file:text-foreground placeholder:text-muted-foreground selection:bg-primary selection:text-primary-foreground dark:bg-input/30 border-input flex h-9 w-full min-w-0 rounded-md border bg-transparent px-3 py-1 text-base shadow-xs transition-[color,box-shadow] outline-none file:inline-flex file:h-7 file:border-0 file:bg-transparent file:text-sm file:font-medium disabled:pointer-events-none disabled:cursor-not-allowed disabled:opacity-50 md:text-sm",
        "focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px]",
        "aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive",
        className,
      )}
      {...props}
    />
  );
}

export { Input };
</file>

<file path="apps/web/app/components/ui/label.tsx">
"use client";

import * as LabelPrimitive from "@radix-ui/react-label";
import type * as React from "react";

import { cn } from "~/lib/utils";

function Label({
  className,
  ...props
}: React.ComponentProps<typeof LabelPrimitive.Root>) {
  return (
    <LabelPrimitive.Root
      data-slot="label"
      className={cn(
        "flex items-center gap-2 text-sm leading-none font-medium select-none group-data-[disabled=true]:pointer-events-none group-data-[disabled=true]:opacity-50 peer-disabled:cursor-not-allowed peer-disabled:opacity-50",
        className,
      )}
      {...props}
    />
  );
}

export { Label };
</file>

<file path="apps/web/app/components/ui/menubar.tsx">
import * as MenubarPrimitive from "@radix-ui/react-menubar";
import { CheckIcon, ChevronRightIcon, CircleIcon } from "lucide-react";
import type * as React from "react";

import { cn } from "~/lib/utils";

function Menubar({
  className,
  ...props
}: React.ComponentProps<typeof MenubarPrimitive.Root>) {
  return (
    <MenubarPrimitive.Root
      data-slot="menubar"
      className={cn(
        "bg-background flex h-9 items-center gap-1 rounded-md border p-1 shadow-xs",
        className,
      )}
      {...props}
    />
  );
}

function MenubarMenu({
  ...props
}: React.ComponentProps<typeof MenubarPrimitive.Menu>) {
  return <MenubarPrimitive.Menu data-slot="menubar-menu" {...props} />;
}

function MenubarGroup({
  ...props
}: React.ComponentProps<typeof MenubarPrimitive.Group>) {
  return <MenubarPrimitive.Group data-slot="menubar-group" {...props} />;
}

function MenubarPortal({
  ...props
}: React.ComponentProps<typeof MenubarPrimitive.Portal>) {
  return <MenubarPrimitive.Portal data-slot="menubar-portal" {...props} />;
}

function MenubarRadioGroup({
  ...props
}: React.ComponentProps<typeof MenubarPrimitive.RadioGroup>) {
  return (
    <MenubarPrimitive.RadioGroup data-slot="menubar-radio-group" {...props} />
  );
}

function MenubarTrigger({
  className,
  ...props
}: React.ComponentProps<typeof MenubarPrimitive.Trigger>) {
  return (
    <MenubarPrimitive.Trigger
      data-slot="menubar-trigger"
      className={cn(
        "focus:bg-accent focus:text-accent-foreground data-[state=open]:bg-accent data-[state=open]:text-accent-foreground flex items-center rounded-sm px-2 py-1 text-sm font-medium outline-hidden select-none",
        className,
      )}
      {...props}
    />
  );
}

function MenubarContent({
  className,
  align = "start",
  alignOffset = -4,
  sideOffset = 8,
  ...props
}: React.ComponentProps<typeof MenubarPrimitive.Content>) {
  return (
    <MenubarPortal>
      <MenubarPrimitive.Content
        data-slot="menubar-content"
        align={align}
        alignOffset={alignOffset}
        sideOffset={sideOffset}
        className={cn(
          "bg-popover text-popover-foreground data-[state=open]:animate-in data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2 z-50 min-w-[12rem] origin-(--radix-menubar-content-transform-origin) overflow-hidden rounded-md border p-1 shadow-md",
          className,
        )}
        {...props}
      />
    </MenubarPortal>
  );
}

function MenubarItem({
  className,
  inset,
  variant = "default",
  ...props
}: React.ComponentProps<typeof MenubarPrimitive.Item> & {
  inset?: boolean;
  variant?: "default" | "destructive";
}) {
  return (
    <MenubarPrimitive.Item
      data-slot="menubar-item"
      data-inset={inset}
      data-variant={variant}
      className={cn(
        "focus:bg-accent focus:text-accent-foreground data-[variant=destructive]:text-destructive data-[variant=destructive]:focus:bg-destructive/10 dark:data-[variant=destructive]:focus:bg-destructive/20 data-[variant=destructive]:focus:text-destructive data-[variant=destructive]:*:[svg]:!text-destructive [&_svg:not([class*='text-'])]:text-muted-foreground relative flex cursor-default items-center gap-2 rounded-sm px-2 py-1.5 text-sm outline-hidden select-none data-[disabled]:pointer-events-none data-[disabled]:opacity-50 data-[inset]:pl-8 [&_svg]:pointer-events-none [&_svg]:shrink-0 [&_svg:not([class*='size-'])]:size-4",
        className,
      )}
      {...props}
    />
  );
}

function MenubarCheckboxItem({
  className,
  children,
  checked,
  ...props
}: React.ComponentProps<typeof MenubarPrimitive.CheckboxItem>) {
  return (
    <MenubarPrimitive.CheckboxItem
      data-slot="menubar-checkbox-item"
      className={cn(
        "focus:bg-accent focus:text-accent-foreground relative flex cursor-default items-center gap-2 rounded-xs py-1.5 pr-2 pl-8 text-sm outline-hidden select-none data-[disabled]:pointer-events-none data-[disabled]:opacity-50 [&_svg]:pointer-events-none [&_svg]:shrink-0 [&_svg:not([class*='size-'])]:size-4",
        className,
      )}
      checked={checked}
      {...props}
    >
      <span className="pointer-events-none absolute left-2 flex size-3.5 items-center justify-center">
        <MenubarPrimitive.ItemIndicator>
          <CheckIcon className="size-4" />
        </MenubarPrimitive.ItemIndicator>
      </span>
      {children}
    </MenubarPrimitive.CheckboxItem>
  );
}

function MenubarRadioItem({
  className,
  children,
  ...props
}: React.ComponentProps<typeof MenubarPrimitive.RadioItem>) {
  return (
    <MenubarPrimitive.RadioItem
      data-slot="menubar-radio-item"
      className={cn(
        "focus:bg-accent focus:text-accent-foreground relative flex cursor-default items-center gap-2 rounded-xs py-1.5 pr-2 pl-8 text-sm outline-hidden select-none data-[disabled]:pointer-events-none data-[disabled]:opacity-50 [&_svg]:pointer-events-none [&_svg]:shrink-0 [&_svg:not([class*='size-'])]:size-4",
        className,
      )}
      {...props}
    >
      <span className="pointer-events-none absolute left-2 flex size-3.5 items-center justify-center">
        <MenubarPrimitive.ItemIndicator>
          <CircleIcon className="size-2 fill-current" />
        </MenubarPrimitive.ItemIndicator>
      </span>
      {children}
    </MenubarPrimitive.RadioItem>
  );
}

function MenubarLabel({
  className,
  inset,
  ...props
}: React.ComponentProps<typeof MenubarPrimitive.Label> & {
  inset?: boolean;
}) {
  return (
    <MenubarPrimitive.Label
      data-slot="menubar-label"
      data-inset={inset}
      className={cn(
        "px-2 py-1.5 text-sm font-medium data-[inset]:pl-8",
        className,
      )}
      {...props}
    />
  );
}

function MenubarSeparator({
  className,
  ...props
}: React.ComponentProps<typeof MenubarPrimitive.Separator>) {
  return (
    <MenubarPrimitive.Separator
      data-slot="menubar-separator"
      className={cn("bg-border -mx-1 my-1 h-px", className)}
      {...props}
    />
  );
}

function MenubarShortcut({
  className,
  ...props
}: React.ComponentProps<"span">) {
  return (
    <span
      data-slot="menubar-shortcut"
      className={cn(
        "text-muted-foreground ml-auto text-xs tracking-widest",
        className,
      )}
      {...props}
    />
  );
}

function MenubarSub({
  ...props
}: React.ComponentProps<typeof MenubarPrimitive.Sub>) {
  return <MenubarPrimitive.Sub data-slot="menubar-sub" {...props} />;
}

function MenubarSubTrigger({
  className,
  inset,
  children,
  ...props
}: React.ComponentProps<typeof MenubarPrimitive.SubTrigger> & {
  inset?: boolean;
}) {
  return (
    <MenubarPrimitive.SubTrigger
      data-slot="menubar-sub-trigger"
      data-inset={inset}
      className={cn(
        "focus:bg-accent focus:text-accent-foreground data-[state=open]:bg-accent data-[state=open]:text-accent-foreground flex cursor-default items-center rounded-sm px-2 py-1.5 text-sm outline-none select-none data-[inset]:pl-8",
        className,
      )}
      {...props}
    >
      {children}
      <ChevronRightIcon className="ml-auto h-4 w-4" />
    </MenubarPrimitive.SubTrigger>
  );
}

function MenubarSubContent({
  className,
  ...props
}: React.ComponentProps<typeof MenubarPrimitive.SubContent>) {
  return (
    <MenubarPrimitive.SubContent
      data-slot="menubar-sub-content"
      className={cn(
        "bg-popover text-popover-foreground data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2 z-50 min-w-[8rem] origin-(--radix-menubar-content-transform-origin) overflow-hidden rounded-md border p-1 shadow-lg",
        className,
      )}
      {...props}
    />
  );
}

export {
  Menubar,
  MenubarPortal,
  MenubarMenu,
  MenubarTrigger,
  MenubarContent,
  MenubarGroup,
  MenubarSeparator,
  MenubarLabel,
  MenubarItem,
  MenubarShortcut,
  MenubarCheckboxItem,
  MenubarRadioGroup,
  MenubarRadioItem,
  MenubarSub,
  MenubarSubTrigger,
  MenubarSubContent,
};
</file>

<file path="apps/web/app/components/ui/navigation-menu.tsx">
import * as NavigationMenuPrimitive from "@radix-ui/react-navigation-menu";
import { cva } from "class-variance-authority";
import { ChevronDownIcon } from "lucide-react";
import type * as React from "react";

import { cn } from "~/lib/utils";

function NavigationMenu({
  className,
  children,
  viewport = true,
  ...props
}: React.ComponentProps<typeof NavigationMenuPrimitive.Root> & {
  viewport?: boolean;
}) {
  return (
    <NavigationMenuPrimitive.Root
      data-slot="navigation-menu"
      data-viewport={viewport}
      className={cn(
        "group/navigation-menu relative flex max-w-max flex-1 items-center justify-center",
        className,
      )}
      {...props}
    >
      {children}
      {viewport && <NavigationMenuViewport />}
    </NavigationMenuPrimitive.Root>
  );
}

function NavigationMenuList({
  className,
  ...props
}: React.ComponentProps<typeof NavigationMenuPrimitive.List>) {
  return (
    <NavigationMenuPrimitive.List
      data-slot="navigation-menu-list"
      className={cn(
        "group flex flex-1 list-none items-center justify-center gap-1",
        className,
      )}
      {...props}
    />
  );
}

function NavigationMenuItem({
  className,
  ...props
}: React.ComponentProps<typeof NavigationMenuPrimitive.Item>) {
  return (
    <NavigationMenuPrimitive.Item
      data-slot="navigation-menu-item"
      className={cn("relative", className)}
      {...props}
    />
  );
}

const navigationMenuTriggerStyle = cva(
  "group inline-flex h-9 w-max items-center justify-center rounded-md bg-background px-4 py-2 text-sm font-medium hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground disabled:pointer-events-none disabled:opacity-50 data-[state=open]:hover:bg-accent data-[state=open]:text-accent-foreground data-[state=open]:focus:bg-accent data-[state=open]:bg-accent/50 focus-visible:ring-ring/50 outline-none transition-[color,box-shadow] focus-visible:ring-[3px] focus-visible:outline-1",
);

function NavigationMenuTrigger({
  className,
  children,
  ...props
}: React.ComponentProps<typeof NavigationMenuPrimitive.Trigger>) {
  return (
    <NavigationMenuPrimitive.Trigger
      data-slot="navigation-menu-trigger"
      className={cn(navigationMenuTriggerStyle(), "group", className)}
      {...props}
    >
      {children}{" "}
      <ChevronDownIcon
        className="relative top-[1px] ml-1 size-3 transition duration-300 group-data-[state=open]:rotate-180"
        aria-hidden="true"
      />
    </NavigationMenuPrimitive.Trigger>
  );
}

function NavigationMenuContent({
  className,
  ...props
}: React.ComponentProps<typeof NavigationMenuPrimitive.Content>) {
  return (
    <NavigationMenuPrimitive.Content
      data-slot="navigation-menu-content"
      className={cn(
        "data-[motion^=from-]:animate-in data-[motion^=to-]:animate-out data-[motion^=from-]:fade-in data-[motion^=to-]:fade-out data-[motion=from-end]:slide-in-from-right-52 data-[motion=from-start]:slide-in-from-left-52 data-[motion=to-end]:slide-out-to-right-52 data-[motion=to-start]:slide-out-to-left-52 top-0 left-0 w-full p-2 pr-2.5 md:absolute md:w-auto",
        "group-data-[viewport=false]/navigation-menu:bg-popover group-data-[viewport=false]/navigation-menu:text-popover-foreground group-data-[viewport=false]/navigation-menu:data-[state=open]:animate-in group-data-[viewport=false]/navigation-menu:data-[state=closed]:animate-out group-data-[viewport=false]/navigation-menu:data-[state=closed]:zoom-out-95 group-data-[viewport=false]/navigation-menu:data-[state=open]:zoom-in-95 group-data-[viewport=false]/navigation-menu:data-[state=open]:fade-in-0 group-data-[viewport=false]/navigation-menu:data-[state=closed]:fade-out-0 group-data-[viewport=false]/navigation-menu:top-full group-data-[viewport=false]/navigation-menu:mt-1.5 group-data-[viewport=false]/navigation-menu:overflow-hidden group-data-[viewport=false]/navigation-menu:rounded-md group-data-[viewport=false]/navigation-menu:border group-data-[viewport=false]/navigation-menu:shadow group-data-[viewport=false]/navigation-menu:duration-200 **:data-[slot=navigation-menu-link]:focus:ring-0 **:data-[slot=navigation-menu-link]:focus:outline-none",
        className,
      )}
      {...props}
    />
  );
}

function NavigationMenuViewport({
  className,
  ...props
}: React.ComponentProps<typeof NavigationMenuPrimitive.Viewport>) {
  return (
    <div
      className={cn(
        "absolute top-full left-0 isolate z-50 flex justify-center",
      )}
    >
      <NavigationMenuPrimitive.Viewport
        data-slot="navigation-menu-viewport"
        className={cn(
          "origin-top-center bg-popover text-popover-foreground data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-90 relative mt-1.5 h-[var(--radix-navigation-menu-viewport-height)] w-full overflow-hidden rounded-md border shadow md:w-[var(--radix-navigation-menu-viewport-width)]",
          className,
        )}
        {...props}
      />
    </div>
  );
}

function NavigationMenuLink({
  className,
  ...props
}: React.ComponentProps<typeof NavigationMenuPrimitive.Link>) {
  return (
    <NavigationMenuPrimitive.Link
      data-slot="navigation-menu-link"
      className={cn(
        "data-[active=true]:focus:bg-accent data-[active=true]:hover:bg-accent data-[active=true]:bg-accent/50 data-[active=true]:text-accent-foreground hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground focus-visible:ring-ring/50 [&_svg:not([class*='text-'])]:text-muted-foreground flex flex-col gap-1 rounded-sm p-2 text-sm transition-all outline-none focus-visible:ring-[3px] focus-visible:outline-1 [&_svg:not([class*='size-'])]:size-4",
        className,
      )}
      {...props}
    />
  );
}

function NavigationMenuIndicator({
  className,
  ...props
}: React.ComponentProps<typeof NavigationMenuPrimitive.Indicator>) {
  return (
    <NavigationMenuPrimitive.Indicator
      data-slot="navigation-menu-indicator"
      className={cn(
        "data-[state=visible]:animate-in data-[state=hidden]:animate-out data-[state=hidden]:fade-out data-[state=visible]:fade-in top-full z-[1] flex h-1.5 items-end justify-center overflow-hidden",
        className,
      )}
      {...props}
    >
      <div className="bg-border relative top-[60%] h-2 w-2 rotate-45 rounded-tl-sm shadow-md" />
    </NavigationMenuPrimitive.Indicator>
  );
}

export {
  NavigationMenu,
  NavigationMenuList,
  NavigationMenuItem,
  NavigationMenuContent,
  NavigationMenuTrigger,
  NavigationMenuLink,
  NavigationMenuIndicator,
  NavigationMenuViewport,
  navigationMenuTriggerStyle,
};
</file>

<file path="apps/web/app/components/ui/pagination.tsx">
import {
  ChevronLeftIcon,
  ChevronRightIcon,
  MoreHorizontalIcon,
} from "lucide-react";
import type * as React from "react";

import { type Button, buttonVariants } from "~/components/ui/button";
import { cn } from "~/lib/utils";

function Pagination({ className, ...props }: React.ComponentProps<"nav">) {
  return (
    <nav
      aria-label="pagination"
      data-slot="pagination"
      className={cn("mx-auto flex w-full justify-center", className)}
      {...props}
    />
  );
}

function PaginationContent({
  className,
  ...props
}: React.ComponentProps<"ul">) {
  return (
    <ul
      data-slot="pagination-content"
      className={cn("flex flex-row items-center gap-1", className)}
      {...props}
    />
  );
}

function PaginationItem({ ...props }: React.ComponentProps<"li">) {
  return <li data-slot="pagination-item" {...props} />;
}

type PaginationLinkProps = {
  isActive?: boolean;
} & Pick<React.ComponentProps<typeof Button>, "size"> &
  React.ComponentProps<"a">;

function PaginationLink({
  className,
  isActive,
  size = "icon",
  ...props
}: PaginationLinkProps) {
  return (
    <a
      aria-current={isActive ? "page" : undefined}
      data-slot="pagination-link"
      data-active={isActive}
      className={cn(
        buttonVariants({
          variant: isActive ? "outline" : "ghost",
          size,
        }),
        className,
      )}
      {...props}
    />
  );
}

function PaginationPrevious({
  className,
  ...props
}: React.ComponentProps<typeof PaginationLink>) {
  return (
    <PaginationLink
      aria-label="Go to previous page"
      size="default"
      className={cn("gap-1 px-2.5 sm:pl-2.5", className)}
      {...props}
    >
      <ChevronLeftIcon />
      <span className="hidden sm:block">Previous</span>
    </PaginationLink>
  );
}

function PaginationNext({
  className,
  ...props
}: React.ComponentProps<typeof PaginationLink>) {
  return (
    <PaginationLink
      aria-label="Go to next page"
      size="default"
      className={cn("gap-1 px-2.5 sm:pr-2.5", className)}
      {...props}
    >
      <span className="hidden sm:block">Next</span>
      <ChevronRightIcon />
    </PaginationLink>
  );
}

function PaginationEllipsis({
  className,
  ...props
}: React.ComponentProps<"span">) {
  return (
    <span
      aria-hidden
      data-slot="pagination-ellipsis"
      className={cn("flex size-9 items-center justify-center", className)}
      {...props}
    >
      <MoreHorizontalIcon className="size-4" />
      <span className="sr-only">More pages</span>
    </span>
  );
}

export {
  Pagination,
  PaginationContent,
  PaginationLink,
  PaginationItem,
  PaginationPrevious,
  PaginationNext,
  PaginationEllipsis,
};
</file>

<file path="apps/web/app/components/ui/popover.tsx">
"use client";

import * as PopoverPrimitive from "@radix-ui/react-popover";
import type * as React from "react";

import { cn } from "~/lib/utils";

function Popover({
  ...props
}: React.ComponentProps<typeof PopoverPrimitive.Root>) {
  return <PopoverPrimitive.Root data-slot="popover" {...props} />;
}

function PopoverTrigger({
  ...props
}: React.ComponentProps<typeof PopoverPrimitive.Trigger>) {
  return <PopoverPrimitive.Trigger data-slot="popover-trigger" {...props} />;
}

function PopoverContent({
  className,
  align = "center",
  sideOffset = 4,
  ...props
}: React.ComponentProps<typeof PopoverPrimitive.Content>) {
  return (
    <PopoverPrimitive.Portal>
      <PopoverPrimitive.Content
        data-slot="popover-content"
        align={align}
        sideOffset={sideOffset}
        className={cn(
          "bg-popover text-popover-foreground data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2 z-50 w-72 origin-(--radix-popover-content-transform-origin) rounded-md border p-4 shadow-md outline-hidden",
          className,
        )}
        {...props}
      />
    </PopoverPrimitive.Portal>
  );
}

function PopoverAnchor({
  ...props
}: React.ComponentProps<typeof PopoverPrimitive.Anchor>) {
  return <PopoverPrimitive.Anchor data-slot="popover-anchor" {...props} />;
}

export { Popover, PopoverTrigger, PopoverContent, PopoverAnchor };
</file>

<file path="apps/web/app/components/ui/progress-steps.tsx">
import { cn } from "~/lib/utils";
import { CheckIcon, Loader2 } from "lucide-react";

export type Step = {
  id: string;
  label: string;
  description?: string;
  status: "pending" | "in_progress" | "completed" | "error";
  progress?: number; // 0-100
  errorMessage?: string;
};

type ProgressStepsProps = {
  steps: Step[];
  currentStepId?: string;
  className?: string;
};

export function ProgressSteps({
  steps,
  currentStepId,
  className,
}: ProgressStepsProps) {
  return (
    <div className={cn("w-full space-y-2", className)}>
      <div className="flex items-center justify-between">
        <div className="text-sm font-medium">Processing Status</div>
        <div className="text-xs text-muted-foreground">
          {steps.filter((step) => step.status === "completed").length} of{" "}
          {steps.length} completed
        </div>
      </div>
      <ul className="space-y-3">
        {steps.map((step, i) => {
          const isCurrent = step.id === currentStepId;
          const isCompleted = step.status === "completed";
          const isInProgress = step.status === "in_progress";
          const isError = step.status === "error";

          return (
            <li key={step.id} className="relative">
              <div
                className={cn(
                  "group relative flex items-start",
                  isCurrent && "animate-in fade-in duration-300",
                )}
              >
                <div
                  className={cn(
                    "flex h-9 w-9 shrink-0 items-center justify-center rounded-full border",
                    isCompleted &&
                      "bg-primary border-primary text-primary-foreground",
                    isInProgress && "border-primary/70 bg-primary/10",
                    isError &&
                      "bg-destructive border-destructive text-destructive-foreground",
                    !isCompleted &&
                      !isInProgress &&
                      !isError &&
                      "border-muted-foreground/30",
                  )}
                >
                  {isCompleted && <CheckIcon className="h-4 w-4" />}
                  {isInProgress && (
                    <Loader2 className="h-4 w-4 animate-spin text-primary" />
                  )}
                  {isError && <span className="text-xs font-bold">!</span>}
                  {!isCompleted && !isInProgress && !isError && (
                    <span className="text-xs text-muted-foreground">
                      {i + 1}
                    </span>
                  )}
                </div>

                <div className="ml-4 min-w-0 flex-1">
                  <div className="flex items-center justify-between">
                    <div
                      className={cn(
                        "text-sm font-medium",
                        isCompleted && "text-foreground",
                        isInProgress && "text-primary",
                        isError && "text-destructive",
                        !isCompleted &&
                          !isInProgress &&
                          !isError &&
                          "text-muted-foreground",
                      )}
                    >
                      {step.label}
                    </div>
                    {step.status === "in_progress" &&
                      step.progress !== undefined && (
                        <div className="text-xs text-muted-foreground">
                          {step.progress}%
                        </div>
                      )}
                  </div>

                  {step.description && (
                    <p className="text-xs text-muted-foreground mt-0.5">
                      {step.description}
                    </p>
                  )}

                  {isError && step.errorMessage && (
                    <p className="text-xs text-destructive mt-1">
                      {step.errorMessage}
                    </p>
                  )}

                  {isInProgress && step.progress !== undefined && (
                    <div className="mt-2 h-1.5 w-full overflow-hidden rounded-full bg-secondary">
                      <div
                        className="h-full bg-primary transition-all duration-300 ease-in-out"
                        style={{ width: `${step.progress}%` }}
                      />
                    </div>
                  )}
                </div>
              </div>

              {i < steps.length - 1 && (
                <div
                  className={cn(
                    "absolute left-4 top-9 h-full w-px -translate-x-1/2 bg-border",
                    isCompleted && "bg-primary",
                  )}
                  aria-hidden="true"
                />
              )}
            </li>
          );
        })}
      </ul>
    </div>
  );
}
</file>

<file path="apps/web/app/components/ui/progress.tsx">
import * as ProgressPrimitive from "@radix-ui/react-progress";
import type * as React from "react";

import { cn } from "~/lib/utils";

function Progress({
  className,
  value,
  ...props
}: React.ComponentProps<typeof ProgressPrimitive.Root>) {
  return (
    <ProgressPrimitive.Root
      data-slot="progress"
      className={cn(
        "bg-primary/20 relative h-2 w-full overflow-hidden rounded-full",
        className,
      )}
      {...props}
    >
      <ProgressPrimitive.Indicator
        data-slot="progress-indicator"
        className="bg-primary h-full w-full flex-1 transition-all"
        style={{ transform: `translateX(-${100 - (value || 0)}%)` }}
      />
    </ProgressPrimitive.Root>
  );
}

export { Progress };
</file>

<file path="apps/web/app/components/ui/radio-group.tsx">
"use client";

import * as RadioGroupPrimitive from "@radix-ui/react-radio-group";
import { CircleIcon } from "lucide-react";
import type * as React from "react";

import { cn } from "~/lib/utils";

function RadioGroup({
  className,
  ...props
}: React.ComponentProps<typeof RadioGroupPrimitive.Root>) {
  return (
    <RadioGroupPrimitive.Root
      data-slot="radio-group"
      className={cn("grid gap-3", className)}
      {...props}
    />
  );
}

function RadioGroupItem({
  className,
  ...props
}: React.ComponentProps<typeof RadioGroupPrimitive.Item>) {
  return (
    <RadioGroupPrimitive.Item
      data-slot="radio-group-item"
      className={cn(
        "border-input text-primary focus-visible:border-ring focus-visible:ring-ring/50 aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive dark:bg-input/30 aspect-square size-4 shrink-0 rounded-full border shadow-xs transition-[color,box-shadow] outline-none focus-visible:ring-[3px] disabled:cursor-not-allowed disabled:opacity-50",
        className,
      )}
      {...props}
    >
      <RadioGroupPrimitive.Indicator
        data-slot="radio-group-indicator"
        className="relative flex items-center justify-center"
      >
        <CircleIcon className="fill-primary absolute top-1/2 left-1/2 size-2 -translate-x-1/2 -translate-y-1/2" />
      </RadioGroupPrimitive.Indicator>
    </RadioGroupPrimitive.Item>
  );
}

export { RadioGroup, RadioGroupItem };
</file>

<file path="apps/web/app/components/ui/resizable.tsx">
import { GripVerticalIcon } from "lucide-react";
import type * as React from "react";
import * as ResizablePrimitive from "react-resizable-panels";

import { cn } from "~/lib/utils";

function ResizablePanelGroup({
  className,
  ...props
}: React.ComponentProps<typeof ResizablePrimitive.PanelGroup>) {
  return (
    <ResizablePrimitive.PanelGroup
      data-slot="resizable-panel-group"
      className={cn(
        "flex h-full w-full data-[panel-group-direction=vertical]:flex-col",
        className,
      )}
      {...props}
    />
  );
}

function ResizablePanel({
  ...props
}: React.ComponentProps<typeof ResizablePrimitive.Panel>) {
  return <ResizablePrimitive.Panel data-slot="resizable-panel" {...props} />;
}

function ResizableHandle({
  withHandle,
  className,
  ...props
}: React.ComponentProps<typeof ResizablePrimitive.PanelResizeHandle> & {
  withHandle?: boolean;
}) {
  return (
    <ResizablePrimitive.PanelResizeHandle
      data-slot="resizable-handle"
      className={cn(
        "bg-border focus-visible:ring-ring relative flex w-px items-center justify-center after:absolute after:inset-y-0 after:left-1/2 after:w-1 after:-translate-x-1/2 focus-visible:ring-1 focus-visible:ring-offset-1 focus-visible:outline-hidden data-[panel-group-direction=vertical]:h-px data-[panel-group-direction=vertical]:w-full data-[panel-group-direction=vertical]:after:left-0 data-[panel-group-direction=vertical]:after:h-1 data-[panel-group-direction=vertical]:after:w-full data-[panel-group-direction=vertical]:after:-translate-y-1/2 data-[panel-group-direction=vertical]:after:translate-x-0 [&[data-panel-group-direction=vertical]>div]:rotate-90",
        className,
      )}
      {...props}
    >
      {withHandle && (
        <div className="bg-border z-10 flex h-4 w-3 items-center justify-center rounded-xs border">
          <GripVerticalIcon className="size-2.5" />
        </div>
      )}
    </ResizablePrimitive.PanelResizeHandle>
  );
}

export { ResizablePanelGroup, ResizablePanel, ResizableHandle };
</file>

<file path="apps/web/app/components/ui/scroll-area.tsx">
"use client";

import * as ScrollAreaPrimitive from "@radix-ui/react-scroll-area";
import type * as React from "react";

import { cn } from "~/lib/utils";

function ScrollArea({
  className,
  children,
  ...props
}: React.ComponentProps<typeof ScrollAreaPrimitive.Root>) {
  return (
    <ScrollAreaPrimitive.Root
      data-slot="scroll-area"
      className={cn("relative", className)}
      {...props}
    >
      <ScrollAreaPrimitive.Viewport
        data-slot="scroll-area-viewport"
        className="focus-visible:ring-ring/50 size-full rounded-[inherit] transition-[color,box-shadow] outline-none focus-visible:ring-[3px] focus-visible:outline-1"
      >
        {children}
      </ScrollAreaPrimitive.Viewport>
      <ScrollBar />
      <ScrollAreaPrimitive.Corner />
    </ScrollAreaPrimitive.Root>
  );
}

function ScrollBar({
  className,
  orientation = "vertical",
  ...props
}: React.ComponentProps<typeof ScrollAreaPrimitive.ScrollAreaScrollbar>) {
  return (
    <ScrollAreaPrimitive.ScrollAreaScrollbar
      data-slot="scroll-area-scrollbar"
      orientation={orientation}
      className={cn(
        "flex touch-none p-px transition-colors select-none",
        orientation === "vertical" &&
          "h-full w-2.5 border-l border-l-transparent",
        orientation === "horizontal" &&
          "h-2.5 flex-col border-t border-t-transparent",
        className,
      )}
      {...props}
    >
      <ScrollAreaPrimitive.ScrollAreaThumb
        data-slot="scroll-area-thumb"
        className="bg-border relative flex-1 rounded-full"
      />
    </ScrollAreaPrimitive.ScrollAreaScrollbar>
  );
}

export { ScrollArea, ScrollBar };
</file>

<file path="apps/web/app/components/ui/select.tsx">
import * as SelectPrimitive from "@radix-ui/react-select";
import { CheckIcon, ChevronDownIcon, ChevronUpIcon } from "lucide-react";
import type * as React from "react";

import { cn } from "~/lib/utils";

function Select({
  ...props
}: React.ComponentProps<typeof SelectPrimitive.Root>) {
  return <SelectPrimitive.Root data-slot="select" {...props} />;
}

function SelectGroup({
  ...props
}: React.ComponentProps<typeof SelectPrimitive.Group>) {
  return <SelectPrimitive.Group data-slot="select-group" {...props} />;
}

function SelectValue({
  ...props
}: React.ComponentProps<typeof SelectPrimitive.Value>) {
  return <SelectPrimitive.Value data-slot="select-value" {...props} />;
}

function SelectTrigger({
  className,
  size = "default",
  children,
  ...props
}: React.ComponentProps<typeof SelectPrimitive.Trigger> & {
  size?: "sm" | "default";
}) {
  return (
    <SelectPrimitive.Trigger
      data-slot="select-trigger"
      data-size={size}
      className={cn(
        "border-input data-[placeholder]:text-muted-foreground [&_svg:not([class*='text-'])]:text-muted-foreground focus-visible:border-ring focus-visible:ring-ring/50 aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive dark:bg-input/30 dark:hover:bg-input/50 flex w-fit items-center justify-between gap-2 rounded-md border bg-transparent px-3 py-2 text-sm whitespace-nowrap shadow-xs transition-[color,box-shadow] outline-none focus-visible:ring-[3px] disabled:cursor-not-allowed disabled:opacity-50 data-[size=default]:h-9 data-[size=sm]:h-8 *:data-[slot=select-value]:line-clamp-1 *:data-[slot=select-value]:flex *:data-[slot=select-value]:items-center *:data-[slot=select-value]:gap-2 [&_svg]:pointer-events-none [&_svg]:shrink-0 [&_svg:not([class*='size-'])]:size-4",
        className,
      )}
      {...props}
    >
      {children}
      <SelectPrimitive.Icon asChild>
        <ChevronDownIcon className="size-4 opacity-50" />
      </SelectPrimitive.Icon>
    </SelectPrimitive.Trigger>
  );
}

function SelectContent({
  className,
  children,
  position = "popper",
  ...props
}: React.ComponentProps<typeof SelectPrimitive.Content>) {
  return (
    <SelectPrimitive.Portal>
      <SelectPrimitive.Content
        data-slot="select-content"
        className={cn(
          "bg-popover text-popover-foreground data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2 relative z-50 max-h-(--radix-select-content-available-height) min-w-[8rem] origin-(--radix-select-content-transform-origin) overflow-x-hidden overflow-y-auto rounded-md border shadow-md",
          position === "popper" &&
            "data-[side=bottom]:translate-y-1 data-[side=left]:-translate-x-1 data-[side=right]:translate-x-1 data-[side=top]:-translate-y-1",
          className,
        )}
        position={position}
        {...props}
      >
        <SelectScrollUpButton />
        <SelectPrimitive.Viewport
          className={cn(
            "p-1",
            position === "popper" &&
              "h-[var(--radix-select-trigger-height)] w-full min-w-[var(--radix-select-trigger-width)] scroll-my-1",
          )}
        >
          {children}
        </SelectPrimitive.Viewport>
        <SelectScrollDownButton />
      </SelectPrimitive.Content>
    </SelectPrimitive.Portal>
  );
}

function SelectLabel({
  className,
  ...props
}: React.ComponentProps<typeof SelectPrimitive.Label>) {
  return (
    <SelectPrimitive.Label
      data-slot="select-label"
      className={cn("text-muted-foreground px-2 py-1.5 text-xs", className)}
      {...props}
    />
  );
}

function SelectItem({
  className,
  children,
  ...props
}: React.ComponentProps<typeof SelectPrimitive.Item>) {
  return (
    <SelectPrimitive.Item
      data-slot="select-item"
      className={cn(
        "focus:bg-accent focus:text-accent-foreground [&_svg:not([class*='text-'])]:text-muted-foreground relative flex w-full cursor-default items-center gap-2 rounded-sm py-1.5 pr-8 pl-2 text-sm outline-hidden select-none data-[disabled]:pointer-events-none data-[disabled]:opacity-50 [&_svg]:pointer-events-none [&_svg]:shrink-0 [&_svg:not([class*='size-'])]:size-4 *:[span]:last:flex *:[span]:last:items-center *:[span]:last:gap-2",
        className,
      )}
      {...props}
    >
      <span className="absolute right-2 flex size-3.5 items-center justify-center">
        <SelectPrimitive.ItemIndicator>
          <CheckIcon className="size-4" />
        </SelectPrimitive.ItemIndicator>
      </span>
      <SelectPrimitive.ItemText>{children}</SelectPrimitive.ItemText>
    </SelectPrimitive.Item>
  );
}

function SelectSeparator({
  className,
  ...props
}: React.ComponentProps<typeof SelectPrimitive.Separator>) {
  return (
    <SelectPrimitive.Separator
      data-slot="select-separator"
      className={cn("bg-border pointer-events-none -mx-1 my-1 h-px", className)}
      {...props}
    />
  );
}

function SelectScrollUpButton({
  className,
  ...props
}: React.ComponentProps<typeof SelectPrimitive.ScrollUpButton>) {
  return (
    <SelectPrimitive.ScrollUpButton
      data-slot="select-scroll-up-button"
      className={cn(
        "flex cursor-default items-center justify-center py-1",
        className,
      )}
      {...props}
    >
      <ChevronUpIcon className="size-4" />
    </SelectPrimitive.ScrollUpButton>
  );
}

function SelectScrollDownButton({
  className,
  ...props
}: React.ComponentProps<typeof SelectPrimitive.ScrollDownButton>) {
  return (
    <SelectPrimitive.ScrollDownButton
      data-slot="select-scroll-down-button"
      className={cn(
        "flex cursor-default items-center justify-center py-1",
        className,
      )}
      {...props}
    >
      <ChevronDownIcon className="size-4" />
    </SelectPrimitive.ScrollDownButton>
  );
}

export {
  Select,
  SelectContent,
  SelectGroup,
  SelectItem,
  SelectLabel,
  SelectScrollDownButton,
  SelectScrollUpButton,
  SelectSeparator,
  SelectTrigger,
  SelectValue,
};
</file>

<file path="apps/web/app/components/ui/separator.tsx">
"use client";

import * as SeparatorPrimitive from "@radix-ui/react-separator";
import type * as React from "react";

import { cn } from "~/lib/utils";

function Separator({
  className,
  orientation = "horizontal",
  decorative = true,
  ...props
}: React.ComponentProps<typeof SeparatorPrimitive.Root>) {
  return (
    <SeparatorPrimitive.Root
      data-slot="separator-root"
      decorative={decorative}
      orientation={orientation}
      className={cn(
        "bg-border shrink-0 data-[orientation=horizontal]:h-px data-[orientation=horizontal]:w-full data-[orientation=vertical]:h-full data-[orientation=vertical]:w-px",
        className,
      )}
      {...props}
    />
  );
}

export { Separator };
</file>

<file path="apps/web/app/components/ui/sheet.tsx">
import * as SheetPrimitive from "@radix-ui/react-dialog";
import { XIcon } from "lucide-react";
import type * as React from "react";

import { cn } from "@/lib/utils";

function Sheet({ ...props }: React.ComponentProps<typeof SheetPrimitive.Root>) {
	return <SheetPrimitive.Root data-slot="sheet" {...props} />;
}

function SheetTrigger({
	...props
}: React.ComponentProps<typeof SheetPrimitive.Trigger>) {
	return <SheetPrimitive.Trigger data-slot="sheet-trigger" {...props} />;
}

function SheetClose({
	...props
}: React.ComponentProps<typeof SheetPrimitive.Close>) {
	return <SheetPrimitive.Close data-slot="sheet-close" {...props} />;
}

function SheetPortal({
	...props
}: React.ComponentProps<typeof SheetPrimitive.Portal>) {
	return <SheetPrimitive.Portal data-slot="sheet-portal" {...props} />;
}

function SheetOverlay({
	className,
	...props
}: React.ComponentProps<typeof SheetPrimitive.Overlay>) {
	return (
		<SheetPrimitive.Overlay
			data-slot="sheet-overlay"
			className={cn(
				"data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 fixed inset-0 z-50 bg-black/50",
				className,
			)}
			{...props}
		/>
	);
}

function SheetContent({
	className,
	children,
	side = "right",
	...props
}: React.ComponentProps<typeof SheetPrimitive.Content> & {
	side?: "top" | "right" | "bottom" | "left";
}) {
	return (
		<SheetPortal>
			<SheetOverlay />
			<SheetPrimitive.Content
				data-slot="sheet-content"
				className={cn(
					"bg-background data-[state=open]:animate-in data-[state=closed]:animate-out fixed z-50 flex flex-col gap-4 shadow-lg transition ease-in-out data-[state=closed]:duration-300 data-[state=open]:duration-500",
					side === "right" &&
						"data-[state=closed]:slide-out-to-right data-[state=open]:slide-in-from-right inset-y-0 right-0 h-full w-3/4 border-l sm:max-w-sm",
					side === "left" &&
						"data-[state=closed]:slide-out-to-left data-[state=open]:slide-in-from-left inset-y-0 left-0 h-full w-3/4 border-r sm:max-w-sm",
					side === "top" &&
						"data-[state=closed]:slide-out-to-top data-[state=open]:slide-in-from-top inset-x-0 top-0 h-auto border-b",
					side === "bottom" &&
						"data-[state=closed]:slide-out-to-bottom data-[state=open]:slide-in-from-bottom inset-x-0 bottom-0 h-auto border-t",
					className,
				)}
				{...props}
			>
				{children}
				<SheetPrimitive.Close className="ring-offset-background focus:ring-ring data-[state=open]:bg-secondary absolute top-4 right-4 rounded-xs opacity-70 transition-opacity hover:opacity-100 focus:ring-2 focus:ring-offset-2 focus:outline-hidden disabled:pointer-events-none">
					<XIcon className="size-4" />
					<span className="sr-only">Close</span>
				</SheetPrimitive.Close>
			</SheetPrimitive.Content>
		</SheetPortal>
	);
}

function SheetHeader({ className, ...props }: React.ComponentProps<"div">) {
	return (
		<div
			data-slot="sheet-header"
			className={cn("flex flex-col gap-1.5 p-4", className)}
			{...props}
		/>
	);
}

function SheetFooter({ className, ...props }: React.ComponentProps<"div">) {
	return (
		<div
			data-slot="sheet-footer"
			className={cn("mt-auto flex flex-col gap-2 p-4", className)}
			{...props}
		/>
	);
}

function SheetTitle({
	className,
	...props
}: React.ComponentProps<typeof SheetPrimitive.Title>) {
	return (
		<SheetPrimitive.Title
			data-slot="sheet-title"
			className={cn("text-foreground font-semibold", className)}
			{...props}
		/>
	);
}

function SheetDescription({
	className,
	...props
}: React.ComponentProps<typeof SheetPrimitive.Description>) {
	return (
		<SheetPrimitive.Description
			data-slot="sheet-description"
			className={cn("text-muted-foreground text-sm", className)}
			{...props}
		/>
	);
}

export {
	Sheet,
	SheetTrigger,
	SheetClose,
	SheetContent,
	SheetHeader,
	SheetFooter,
	SheetTitle,
	SheetDescription,
};
</file>

<file path="apps/web/app/components/ui/sidebar.tsx">
"use client";

import { Slot } from "@radix-ui/react-slot";
import { type VariantProps, cva } from "class-variance-authority";
import { PanelLeftIcon } from "lucide-react";
import * as React from "react";

import { Button } from "~/components/ui/button";
import { Input } from "~/components/ui/input";
import { Separator } from "~/components/ui/separator";
import {
  Sheet,
  SheetContent,
  SheetDescription,
  SheetHeader,
  SheetTitle,
} from "~/components/ui/sheet";
import { Skeleton } from "~/components/ui/skeleton";
import {
  Tooltip,
  TooltipContent,
  TooltipProvider,
  TooltipTrigger,
} from "~/components/ui/tooltip";
import { useIsMobile } from "~/lib/use-mobile";
import { cn } from "~/lib/utils";

const SIDEBAR_COOKIE_NAME = "sidebar_state";
const SIDEBAR_COOKIE_MAX_AGE = 60 * 60 * 24 * 7;
const SIDEBAR_WIDTH = "16rem";
const SIDEBAR_WIDTH_MOBILE = "18rem";
const SIDEBAR_WIDTH_ICON = "3rem";
const SIDEBAR_KEYBOARD_SHORTCUT = "b";

type SidebarContextProps = {
  state: "expanded" | "collapsed";
  open: boolean;
  setOpen: (open: boolean) => void;
  openMobile: boolean;
  setOpenMobile: (open: boolean) => void;
  isMobile: boolean;
  toggleSidebar: () => void;
};

const SidebarContext = React.createContext<SidebarContextProps | null>(null);

function useSidebar() {
  const context = React.useContext(SidebarContext);
  if (!context) {
    throw new Error("useSidebar must be used within a SidebarProvider.");
  }

  return context;
}

function SidebarProvider({
  defaultOpen = true,
  open: openProp,
  onOpenChange: setOpenProp,
  className,
  style,
  children,
  ...props
}: React.ComponentProps<"div"> & {
  defaultOpen?: boolean;
  open?: boolean;
  onOpenChange?: (open: boolean) => void;
}) {
  const isMobile = useIsMobile();
  const [openMobile, setOpenMobile] = React.useState(false);

  // This is the internal state of the sidebar.
  // We use openProp and setOpenProp for control from outside the component.
  const [_open, _setOpen] = React.useState(defaultOpen);
  const open = openProp ?? _open;
  const setOpen = React.useCallback(
    (value: boolean | ((value: boolean) => boolean)) => {
      const openState = typeof value === "function" ? value(open) : value;
      if (setOpenProp) {
        setOpenProp(openState);
      } else {
        _setOpen(openState);
      }

      // This sets the cookie to keep the sidebar state.
      document.cookie = `${SIDEBAR_COOKIE_NAME}=${openState}; path=/; max-age=${SIDEBAR_COOKIE_MAX_AGE}`;
    },
    [setOpenProp, open],
  );

  // Helper to toggle the sidebar.
  const toggleSidebar = React.useCallback(() => {
    return isMobile ? setOpenMobile((open) => !open) : setOpen((open) => !open);
  }, [isMobile, setOpen, setOpenMobile]);

  // Adds a keyboard shortcut to toggle the sidebar.
  React.useEffect(() => {
    const handleKeyDown = (event: KeyboardEvent) => {
      if (
        event.key === SIDEBAR_KEYBOARD_SHORTCUT &&
        (event.metaKey || event.ctrlKey)
      ) {
        event.preventDefault();
        toggleSidebar();
      }
    };

    window.addEventListener("keydown", handleKeyDown);
    return () => window.removeEventListener("keydown", handleKeyDown);
  }, [toggleSidebar]);

  // We add a state so that we can do data-state="expanded" or "collapsed".
  // This makes it easier to style the sidebar with Tailwind classes.
  const state = open ? "expanded" : "collapsed";

  const contextValue = React.useMemo<SidebarContextProps>(
    () => ({
      state,
      open,
      setOpen,
      isMobile,
      openMobile,
      setOpenMobile,
      toggleSidebar,
    }),
    [state, open, setOpen, isMobile, openMobile, setOpenMobile, toggleSidebar],
  );

  return (
    <SidebarContext.Provider value={contextValue}>
      <TooltipProvider delayDuration={0}>
        <div
          data-slot="sidebar-wrapper"
          style={
            {
              "--sidebar-width": SIDEBAR_WIDTH,
              "--sidebar-width-icon": SIDEBAR_WIDTH_ICON,
              ...style,
            } as React.CSSProperties
          }
          className={cn(
            "group/sidebar-wrapper has-data-[variant=inset]:bg-sidebar flex min-h-svh w-full",
            className,
          )}
          {...props}
        >
          {children}
        </div>
      </TooltipProvider>
    </SidebarContext.Provider>
  );
}

function Sidebar({
  side = "left",
  variant = "sidebar",
  collapsible = "offcanvas",
  className,
  children,
  ...props
}: React.ComponentProps<"div"> & {
  side?: "left" | "right";
  variant?: "sidebar" | "floating" | "inset";
  collapsible?: "offcanvas" | "icon" | "none";
}) {
  const { isMobile, state, openMobile, setOpenMobile } = useSidebar();

  if (collapsible === "none") {
    return (
      <div
        data-slot="sidebar"
        className={cn(
          "bg-sidebar text-sidebar-foreground flex h-full w-(--sidebar-width) flex-col",
          className,
        )}
        {...props}
      >
        {children}
      </div>
    );
  }

  if (isMobile) {
    return (
      <Sheet open={openMobile} onOpenChange={setOpenMobile} {...props}>
        <SheetContent
          data-sidebar="sidebar"
          data-slot="sidebar"
          data-mobile="true"
          className="bg-sidebar text-sidebar-foreground w-(--sidebar-width) p-0 [&>button]:hidden"
          style={
            {
              "--sidebar-width": SIDEBAR_WIDTH_MOBILE,
            } as React.CSSProperties
          }
          side={side}
        >
          <SheetHeader className="sr-only">
            <SheetTitle>Sidebar</SheetTitle>
            <SheetDescription>Displays the mobile sidebar.</SheetDescription>
          </SheetHeader>
          <div className="flex h-full w-full flex-col">{children}</div>
        </SheetContent>
      </Sheet>
    );
  }

  return (
    <div
      className="group peer text-sidebar-foreground hidden md:block"
      data-state={state}
      data-collapsible={state === "collapsed" ? collapsible : ""}
      data-variant={variant}
      data-side={side}
      data-slot="sidebar"
    >
      {/* This is what handles the sidebar gap on desktop */}
      <div
        data-slot="sidebar-gap"
        className={cn(
          "relative w-(--sidebar-width) bg-transparent transition-[width] duration-200 ease-linear",
          "group-data-[collapsible=offcanvas]:w-0",
          "group-data-[side=right]:rotate-180",
          variant === "floating" || variant === "inset"
            ? "group-data-[collapsible=icon]:w-[calc(var(--sidebar-width-icon)+(--spacing(4)))]"
            : "group-data-[collapsible=icon]:w-(--sidebar-width-icon)",
        )}
      />
      <div
        data-slot="sidebar-container"
        className={cn(
          "fixed inset-y-0 z-10 hidden h-svh w-(--sidebar-width) transition-[left,right,width] duration-200 ease-linear md:flex",
          side === "left"
            ? "left-0 group-data-[collapsible=offcanvas]:left-[calc(var(--sidebar-width)*-1)]"
            : "right-0 group-data-[collapsible=offcanvas]:right-[calc(var(--sidebar-width)*-1)]",
          // Adjust the padding for floating and inset variants.
          variant === "floating" || variant === "inset"
            ? "p-2 group-data-[collapsible=icon]:w-[calc(var(--sidebar-width-icon)+(--spacing(4))+2px)]"
            : "group-data-[collapsible=icon]:w-(--sidebar-width-icon) group-data-[side=left]:border-r group-data-[side=right]:border-l",
          className,
        )}
        {...props}
      >
        <div
          data-sidebar="sidebar"
          data-slot="sidebar-inner"
          className="bg-sidebar group-data-[variant=floating]:border-sidebar-border flex h-full w-full flex-col group-data-[variant=floating]:rounded-lg group-data-[variant=floating]:border group-data-[variant=floating]:shadow-sm"
        >
          {children}
        </div>
      </div>
    </div>
  );
}

function SidebarTrigger({
  className,
  onClick,
  ...props
}: React.ComponentProps<typeof Button>) {
  const { toggleSidebar } = useSidebar();

  return (
    <Button
      data-sidebar="trigger"
      data-slot="sidebar-trigger"
      variant="ghost"
      size="icon"
      className={cn("size-7", className)}
      onClick={(event) => {
        onClick?.(event);
        toggleSidebar();
      }}
      {...props}
    >
      <PanelLeftIcon />
      <span className="sr-only">Toggle Sidebar</span>
    </Button>
  );
}

function SidebarRail({ className, ...props }: React.ComponentProps<"button">) {
  const { toggleSidebar } = useSidebar();

  return (
    <button
      data-sidebar="rail"
      data-slot="sidebar-rail"
      aria-label="Toggle Sidebar"
      tabIndex={-1}
      onClick={toggleSidebar}
      title="Toggle Sidebar"
      className={cn(
        "hover:after:bg-sidebar-border absolute inset-y-0 z-20 hidden w-4 -translate-x-1/2 transition-all ease-linear group-data-[side=left]:-right-4 group-data-[side=right]:left-0 after:absolute after:inset-y-0 after:left-1/2 after:w-[2px] sm:flex",
        "in-data-[side=left]:cursor-w-resize in-data-[side=right]:cursor-e-resize",
        "[[data-side=left][data-state=collapsed]_&]:cursor-e-resize [[data-side=right][data-state=collapsed]_&]:cursor-w-resize",
        "hover:group-data-[collapsible=offcanvas]:bg-sidebar group-data-[collapsible=offcanvas]:translate-x-0 group-data-[collapsible=offcanvas]:after:left-full",
        "[[data-side=left][data-collapsible=offcanvas]_&]:-right-2",
        "[[data-side=right][data-collapsible=offcanvas]_&]:-left-2",
        className,
      )}
      {...props}
    />
  );
}

function SidebarInset({ className, ...props }: React.ComponentProps<"main">) {
  return (
    <main
      data-slot="sidebar-inset"
      className={cn(
        "bg-background relative flex w-full flex-1 flex-col",
        "md:peer-data-[variant=inset]:m-2 md:peer-data-[variant=inset]:ml-0 md:peer-data-[variant=inset]:rounded-xl md:peer-data-[variant=inset]:shadow-sm md:peer-data-[variant=inset]:peer-data-[state=collapsed]:ml-2",
        className,
      )}
      {...props}
    />
  );
}

function SidebarInput({
  className,
  ...props
}: React.ComponentProps<typeof Input>) {
  return (
    <Input
      data-slot="sidebar-input"
      data-sidebar="input"
      className={cn("bg-background h-8 w-full shadow-none", className)}
      {...props}
    />
  );
}

function SidebarHeader({ className, ...props }: React.ComponentProps<"div">) {
  return (
    <div
      data-slot="sidebar-header"
      data-sidebar="header"
      className={cn("flex flex-col gap-2 p-2", className)}
      {...props}
    />
  );
}

function SidebarFooter({ className, ...props }: React.ComponentProps<"div">) {
  return (
    <div
      data-slot="sidebar-footer"
      data-sidebar="footer"
      className={cn("flex flex-col gap-2 p-2", className)}
      {...props}
    />
  );
}

function SidebarSeparator({
  className,
  ...props
}: React.ComponentProps<typeof Separator>) {
  return (
    <Separator
      data-slot="sidebar-separator"
      data-sidebar="separator"
      className={cn("bg-sidebar-border mx-2 w-auto", className)}
      {...props}
    />
  );
}

function SidebarContent({ className, ...props }: React.ComponentProps<"div">) {
  return (
    <div
      data-slot="sidebar-content"
      data-sidebar="content"
      className={cn(
        "flex min-h-0 flex-1 flex-col gap-2 overflow-auto group-data-[collapsible=icon]:overflow-hidden",
        className,
      )}
      {...props}
    />
  );
}

function SidebarGroup({ className, ...props }: React.ComponentProps<"div">) {
  return (
    <div
      data-slot="sidebar-group"
      data-sidebar="group"
      className={cn("relative flex w-full min-w-0 flex-col p-2", className)}
      {...props}
    />
  );
}

function SidebarGroupLabel({
  className,
  asChild = false,
  ...props
}: React.ComponentProps<"div"> & { asChild?: boolean }) {
  const Comp = asChild ? Slot : "div";

  return (
    <Comp
      data-slot="sidebar-group-label"
      data-sidebar="group-label"
      className={cn(
        "text-sidebar-foreground/70 ring-sidebar-ring flex h-8 shrink-0 items-center rounded-md px-2 text-xs font-medium outline-hidden transition-[margin,opacity] duration-200 ease-linear focus-visible:ring-2 [&>svg]:size-4 [&>svg]:shrink-0",
        "group-data-[collapsible=icon]:-mt-8 group-data-[collapsible=icon]:opacity-0",
        className,
      )}
      {...props}
    />
  );
}

function SidebarGroupAction({
  className,
  asChild = false,
  ...props
}: React.ComponentProps<"button"> & { asChild?: boolean }) {
  const Comp = asChild ? Slot : "button";

  return (
    <Comp
      data-slot="sidebar-group-action"
      data-sidebar="group-action"
      className={cn(
        "text-sidebar-foreground ring-sidebar-ring hover:bg-sidebar-accent hover:text-sidebar-accent-foreground absolute top-3.5 right-3 flex aspect-square w-5 items-center justify-center rounded-md p-0 outline-hidden transition-transform focus-visible:ring-2 [&>svg]:size-4 [&>svg]:shrink-0",
        // Increases the hit area of the button on mobile.
        "after:absolute after:-inset-2 md:after:hidden",
        "group-data-[collapsible=icon]:hidden",
        className,
      )}
      {...props}
    />
  );
}

function SidebarGroupContent({
  className,
  ...props
}: React.ComponentProps<"div">) {
  return (
    <div
      data-slot="sidebar-group-content"
      data-sidebar="group-content"
      className={cn("w-full text-sm", className)}
      {...props}
    />
  );
}

function SidebarMenu({ className, ...props }: React.ComponentProps<"ul">) {
  return (
    <ul
      data-slot="sidebar-menu"
      data-sidebar="menu"
      className={cn("flex w-full min-w-0 flex-col gap-1", className)}
      {...props}
    />
  );
}

function SidebarMenuItem({ className, ...props }: React.ComponentProps<"li">) {
  return (
    <li
      data-slot="sidebar-menu-item"
      data-sidebar="menu-item"
      className={cn("group/menu-item relative", className)}
      {...props}
    />
  );
}

const sidebarMenuButtonVariants = cva(
  "peer/menu-button flex w-full items-center gap-2 overflow-hidden rounded-md p-2 text-left text-sm outline-hidden ring-sidebar-ring transition-[width,height,padding] hover:bg-sidebar-accent hover:text-sidebar-accent-foreground focus-visible:ring-2 active:bg-sidebar-accent active:text-sidebar-accent-foreground disabled:pointer-events-none disabled:opacity-50 group-has-data-[sidebar=menu-action]/menu-item:pr-8 aria-disabled:pointer-events-none aria-disabled:opacity-50 data-[active=true]:bg-sidebar-accent data-[active=true]:font-medium data-[active=true]:text-sidebar-accent-foreground data-[state=open]:hover:bg-sidebar-accent data-[state=open]:hover:text-sidebar-accent-foreground group-data-[collapsible=icon]:size-8! group-data-[collapsible=icon]:p-2! [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0",
  {
    variants: {
      variant: {
        default: "hover:bg-sidebar-accent hover:text-sidebar-accent-foreground",
        outline:
          "bg-background shadow-[0_0_0_1px_hsl(var(--sidebar-border))] hover:bg-sidebar-accent hover:text-sidebar-accent-foreground hover:shadow-[0_0_0_1px_hsl(var(--sidebar-accent))]",
      },
      size: {
        default: "h-8 text-sm",
        sm: "h-7 text-xs",
        lg: "h-12 text-sm group-data-[collapsible=icon]:p-0!",
      },
    },
    defaultVariants: {
      variant: "default",
      size: "default",
    },
  },
);

function SidebarMenuButton({
  asChild = false,
  isActive = false,
  variant = "default",
  size = "default",
  tooltip,
  className,
  ...props
}: React.ComponentProps<"button"> & {
  asChild?: boolean;
  isActive?: boolean;
  tooltip?: string | React.ComponentProps<typeof TooltipContent>;
} & VariantProps<typeof sidebarMenuButtonVariants>) {
  const Comp = asChild ? Slot : "button";
  const { isMobile, state } = useSidebar();

  const button = (
    <Comp
      data-slot="sidebar-menu-button"
      data-sidebar="menu-button"
      data-size={size}
      data-active={isActive}
      className={cn(sidebarMenuButtonVariants({ variant, size }), className)}
      {...props}
    />
  );

  if (!tooltip) {
    return button;
  }

  if (typeof tooltip === "string") {
    tooltip = {
      children: tooltip,
    };
  }

  return (
    <Tooltip>
      <TooltipTrigger asChild>{button}</TooltipTrigger>
      <TooltipContent
        side="right"
        align="center"
        hidden={state !== "collapsed" || isMobile}
        {...tooltip}
      />
    </Tooltip>
  );
}

function SidebarMenuAction({
  className,
  asChild = false,
  showOnHover = false,
  ...props
}: React.ComponentProps<"button"> & {
  asChild?: boolean;
  showOnHover?: boolean;
}) {
  const Comp = asChild ? Slot : "button";

  return (
    <Comp
      data-slot="sidebar-menu-action"
      data-sidebar="menu-action"
      className={cn(
        "text-sidebar-foreground ring-sidebar-ring hover:bg-sidebar-accent hover:text-sidebar-accent-foreground peer-hover/menu-button:text-sidebar-accent-foreground absolute top-1.5 right-1 flex aspect-square w-5 items-center justify-center rounded-md p-0 outline-hidden transition-transform focus-visible:ring-2 [&>svg]:size-4 [&>svg]:shrink-0",
        // Increases the hit area of the button on mobile.
        "after:absolute after:-inset-2 md:after:hidden",
        "peer-data-[size=sm]/menu-button:top-1",
        "peer-data-[size=default]/menu-button:top-1.5",
        "peer-data-[size=lg]/menu-button:top-2.5",
        "group-data-[collapsible=icon]:hidden",
        showOnHover &&
          "peer-data-[active=true]/menu-button:text-sidebar-accent-foreground group-focus-within/menu-item:opacity-100 group-hover/menu-item:opacity-100 data-[state=open]:opacity-100 md:opacity-0",
        className,
      )}
      {...props}
    />
  );
}

function SidebarMenuBadge({
  className,
  ...props
}: React.ComponentProps<"div">) {
  return (
    <div
      data-slot="sidebar-menu-badge"
      data-sidebar="menu-badge"
      className={cn(
        "text-sidebar-foreground pointer-events-none absolute right-1 flex h-5 min-w-5 items-center justify-center rounded-md px-1 text-xs font-medium tabular-nums select-none",
        "peer-hover/menu-button:text-sidebar-accent-foreground peer-data-[active=true]/menu-button:text-sidebar-accent-foreground",
        "peer-data-[size=sm]/menu-button:top-1",
        "peer-data-[size=default]/menu-button:top-1.5",
        "peer-data-[size=lg]/menu-button:top-2.5",
        "group-data-[collapsible=icon]:hidden",
        className,
      )}
      {...props}
    />
  );
}

function SidebarMenuSkeleton({
  className,
  showIcon = false,
  ...props
}: React.ComponentProps<"div"> & {
  showIcon?: boolean;
}) {
  // Random width between 50 to 90%.
  const width = React.useMemo(() => {
    return `${Math.floor(Math.random() * 40) + 50}%`;
  }, []);

  return (
    <div
      data-slot="sidebar-menu-skeleton"
      data-sidebar="menu-skeleton"
      className={cn("flex h-8 items-center gap-2 rounded-md px-2", className)}
      {...props}
    >
      {showIcon && (
        <Skeleton
          className="size-4 rounded-md"
          data-sidebar="menu-skeleton-icon"
        />
      )}
      <Skeleton
        className="h-4 max-w-(--skeleton-width) flex-1"
        data-sidebar="menu-skeleton-text"
        style={
          {
            "--skeleton-width": width,
          } as React.CSSProperties
        }
      />
    </div>
  );
}

function SidebarMenuSub({ className, ...props }: React.ComponentProps<"ul">) {
  return (
    <ul
      data-slot="sidebar-menu-sub"
      data-sidebar="menu-sub"
      className={cn(
        "border-sidebar-border mx-3.5 flex min-w-0 translate-x-px flex-col gap-1 border-l px-2.5 py-0.5",
        "group-data-[collapsible=icon]:hidden",
        className,
      )}
      {...props}
    />
  );
}

function SidebarMenuSubItem({
  className,
  ...props
}: React.ComponentProps<"li">) {
  return (
    <li
      data-slot="sidebar-menu-sub-item"
      data-sidebar="menu-sub-item"
      className={cn("group/menu-sub-item relative", className)}
      {...props}
    />
  );
}

function SidebarMenuSubButton({
  asChild = false,
  size = "md",
  isActive = false,
  className,
  ...props
}: React.ComponentProps<"a"> & {
  asChild?: boolean;
  size?: "sm" | "md";
  isActive?: boolean;
}) {
  const Comp = asChild ? Slot : "a";

  return (
    <Comp
      data-slot="sidebar-menu-sub-button"
      data-sidebar="menu-sub-button"
      data-size={size}
      data-active={isActive}
      className={cn(
        "text-sidebar-foreground ring-sidebar-ring hover:bg-sidebar-accent hover:text-sidebar-accent-foreground active:bg-sidebar-accent active:text-sidebar-accent-foreground [&>svg]:text-sidebar-accent-foreground flex h-7 min-w-0 -translate-x-px items-center gap-2 overflow-hidden rounded-md px-2 outline-hidden focus-visible:ring-2 disabled:pointer-events-none disabled:opacity-50 aria-disabled:pointer-events-none aria-disabled:opacity-50 [&>span:last-child]:truncate [&>svg]:size-4 [&>svg]:shrink-0",
        "data-[active=true]:bg-sidebar-accent data-[active=true]:text-sidebar-accent-foreground",
        size === "sm" && "text-xs",
        size === "md" && "text-sm",
        "group-data-[collapsible=icon]:hidden",
        className,
      )}
      {...props}
    />
  );
}

export {
  Sidebar,
  SidebarContent,
  SidebarFooter,
  SidebarGroup,
  SidebarGroupAction,
  SidebarGroupContent,
  SidebarGroupLabel,
  SidebarHeader,
  SidebarInput,
  SidebarInset,
  SidebarMenu,
  SidebarMenuAction,
  SidebarMenuBadge,
  SidebarMenuButton,
  SidebarMenuItem,
  SidebarMenuSkeleton,
  SidebarMenuSub,
  SidebarMenuSubButton,
  SidebarMenuSubItem,
  SidebarProvider,
  SidebarRail,
  SidebarSeparator,
  SidebarTrigger,
  useSidebar,
};
</file>

<file path="apps/web/app/components/ui/skeleton.tsx">
import { cn } from "~/lib/utils";

function Skeleton({ className, ...props }: React.ComponentProps<"div">) {
  return (
    <div
      data-slot="skeleton"
      className={cn("bg-accent animate-pulse rounded-md", className)}
      {...props}
    />
  );
}

export { Skeleton };
</file>

<file path="apps/web/app/components/ui/slider.tsx">
"use client";

import * as SliderPrimitive from "@radix-ui/react-slider";
import * as React from "react";

import { cn } from "~/lib/utils";

function Slider({
  className,
  defaultValue,
  value,
  min = 0,
  max = 100,
  ...props
}: React.ComponentProps<typeof SliderPrimitive.Root>) {
  const _values = React.useMemo(
    () =>
      Array.isArray(value)
        ? value
        : Array.isArray(defaultValue)
          ? defaultValue
          : [min, max],
    [value, defaultValue, min, max],
  );

  return (
    <SliderPrimitive.Root
      data-slot="slider"
      defaultValue={defaultValue}
      value={value}
      min={min}
      max={max}
      className={cn(
        "relative flex w-full touch-none items-center select-none data-[disabled]:opacity-50 data-[orientation=vertical]:h-full data-[orientation=vertical]:min-h-44 data-[orientation=vertical]:w-auto data-[orientation=vertical]:flex-col",
        className,
      )}
      {...props}
    >
      <SliderPrimitive.Track
        data-slot="slider-track"
        className={cn(
          "bg-muted relative grow overflow-hidden rounded-full data-[orientation=horizontal]:h-1.5 data-[orientation=horizontal]:w-full data-[orientation=vertical]:h-full data-[orientation=vertical]:w-1.5",
        )}
      >
        <SliderPrimitive.Range
          data-slot="slider-range"
          className={cn(
            "bg-primary absolute data-[orientation=horizontal]:h-full data-[orientation=vertical]:w-full",
          )}
        />
      </SliderPrimitive.Track>
      {Array.from({ length: _values.length }, (_, index) => (
        <SliderPrimitive.Thumb
          data-slot="slider-thumb"
          key={index}
          className="border-primary bg-background ring-ring/50 block size-4 shrink-0 rounded-full border shadow-sm transition-[color,box-shadow] hover:ring-4 focus-visible:ring-4 focus-visible:outline-hidden disabled:pointer-events-none disabled:opacity-50"
        />
      ))}
    </SliderPrimitive.Root>
  );
}

export { Slider };
</file>

<file path="apps/web/app/components/ui/sonner.tsx">
import { useTheme } from "next-themes";
import { Toaster as Sonner, type ToasterProps } from "sonner";

const Toaster = ({ ...props }: ToasterProps) => {
	const { theme = "system" } = useTheme();

	return (
		<Sonner
			theme={theme as ToasterProps["theme"]}
			className="toaster group"
			style={
				{
					"--normal-bg": "var(--popover)",
					"--normal-text": "var(--popover-foreground)",
					"--normal-border": "var(--border)",
				} as React.CSSProperties
			}
			{...props}
		/>
	);
};

export { Toaster };
</file>

<file path="apps/web/app/components/ui/switch.tsx">
"use client";

import * as SwitchPrimitive from "@radix-ui/react-switch";
import type * as React from "react";

import { cn } from "~/lib/utils";

function Switch({
  className,
  ...props
}: React.ComponentProps<typeof SwitchPrimitive.Root>) {
  return (
    <SwitchPrimitive.Root
      data-slot="switch"
      className={cn(
        "peer data-[state=checked]:bg-primary data-[state=unchecked]:bg-input focus-visible:border-ring focus-visible:ring-ring/50 dark:data-[state=unchecked]:bg-input/80 inline-flex h-[1.15rem] w-8 shrink-0 items-center rounded-full border border-transparent shadow-xs transition-all outline-none focus-visible:ring-[3px] disabled:cursor-not-allowed disabled:opacity-50",
        className,
      )}
      {...props}
    >
      <SwitchPrimitive.Thumb
        data-slot="switch-thumb"
        className={cn(
          "bg-background dark:data-[state=unchecked]:bg-foreground dark:data-[state=checked]:bg-primary-foreground pointer-events-none block size-4 rounded-full ring-0 transition-transform data-[state=checked]:translate-x-[calc(100%-2px)] data-[state=unchecked]:translate-x-0",
        )}
      />
    </SwitchPrimitive.Root>
  );
}

export { Switch };
</file>

<file path="apps/web/app/components/ui/table.tsx">
import type * as React from "react";

import { cn } from "~/lib/utils";

function Table({ className, ...props }: React.ComponentProps<"table">) {
  return (
    <div
      data-slot="table-container"
      className="relative w-full overflow-x-auto"
    >
      <table
        data-slot="table"
        className={cn("w-full caption-bottom text-sm", className)}
        {...props}
      />
    </div>
  );
}

function TableHeader({ className, ...props }: React.ComponentProps<"thead">) {
  return (
    <thead
      data-slot="table-header"
      className={cn("[&_tr]:border-b", className)}
      {...props}
    />
  );
}

function TableBody({ className, ...props }: React.ComponentProps<"tbody">) {
  return (
    <tbody
      data-slot="table-body"
      className={cn("[&_tr:last-child]:border-0", className)}
      {...props}
    />
  );
}

function TableFooter({ className, ...props }: React.ComponentProps<"tfoot">) {
  return (
    <tfoot
      data-slot="table-footer"
      className={cn(
        "bg-muted/50 border-t font-medium [&>tr]:last:border-b-0",
        className,
      )}
      {...props}
    />
  );
}

function TableRow({ className, ...props }: React.ComponentProps<"tr">) {
  return (
    <tr
      data-slot="table-row"
      className={cn(
        "hover:bg-muted/50 data-[state=selected]:bg-muted border-b transition-colors",
        className,
      )}
      {...props}
    />
  );
}

function TableHead({ className, ...props }: React.ComponentProps<"th">) {
  return (
    <th
      data-slot="table-head"
      className={cn(
        "text-foreground h-10 px-2 text-left align-middle font-medium whitespace-nowrap [&:has([role=checkbox])]:pr-0 [&>[role=checkbox]]:translate-y-[2px]",
        className,
      )}
      {...props}
    />
  );
}

function TableCell({ className, ...props }: React.ComponentProps<"td">) {
  return (
    <td
      data-slot="table-cell"
      className={cn(
        "p-2 align-middle whitespace-nowrap [&:has([role=checkbox])]:pr-0 [&>[role=checkbox]]:translate-y-[2px]",
        className,
      )}
      {...props}
    />
  );
}

function TableCaption({
  className,
  ...props
}: React.ComponentProps<"caption">) {
  return (
    <caption
      data-slot="table-caption"
      className={cn("text-muted-foreground mt-4 text-sm", className)}
      {...props}
    />
  );
}

export {
  Table,
  TableHeader,
  TableBody,
  TableFooter,
  TableHead,
  TableRow,
  TableCell,
  TableCaption,
};
</file>

<file path="apps/web/app/components/ui/tabs.tsx">
"use client";

import * as TabsPrimitive from "@radix-ui/react-tabs";
import type * as React from "react";

import { cn } from "~/lib/utils";

function Tabs({
  className,
  ...props
}: React.ComponentProps<typeof TabsPrimitive.Root>) {
  return (
    <TabsPrimitive.Root
      data-slot="tabs"
      className={cn("flex flex-col gap-2", className)}
      {...props}
    />
  );
}

function TabsList({
  className,
  ...props
}: React.ComponentProps<typeof TabsPrimitive.List>) {
  return (
    <TabsPrimitive.List
      data-slot="tabs-list"
      className={cn(
        "bg-muted text-muted-foreground inline-flex h-9 w-fit items-center justify-center rounded-lg p-[3px]",
        className,
      )}
      {...props}
    />
  );
}

function TabsTrigger({
  className,
  ...props
}: React.ComponentProps<typeof TabsPrimitive.Trigger>) {
  return (
    <TabsPrimitive.Trigger
      data-slot="tabs-trigger"
      className={cn(
        "data-[state=active]:bg-background dark:data-[state=active]:text-foreground focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:outline-ring dark:data-[state=active]:border-input dark:data-[state=active]:bg-input/30 text-foreground dark:text-muted-foreground inline-flex h-[calc(100%-1px)] flex-1 items-center justify-center gap-1.5 rounded-md border border-transparent px-2 py-1 text-sm font-medium whitespace-nowrap transition-[color,box-shadow] focus-visible:ring-[3px] focus-visible:outline-1 disabled:pointer-events-none disabled:opacity-50 data-[state=active]:shadow-sm [&_svg]:pointer-events-none [&_svg]:shrink-0 [&_svg:not([class*='size-'])]:size-4",
        className,
      )}
      {...props}
    />
  );
}

function TabsContent({
  className,
  ...props
}: React.ComponentProps<typeof TabsPrimitive.Content>) {
  return (
    <TabsPrimitive.Content
      data-slot="tabs-content"
      className={cn("flex-1 outline-none", className)}
      {...props}
    />
  );
}

export { Tabs, TabsList, TabsTrigger, TabsContent };
</file>

<file path="apps/web/app/components/ui/textarea.tsx">
import type * as React from "react";

import { cn } from "~/lib/utils";

function Textarea({ className, ...props }: React.ComponentProps<"textarea">) {
  return (
    <textarea
      data-slot="textarea"
      className={cn(
        "border-input placeholder:text-muted-foreground focus-visible:border-ring focus-visible:ring-ring/50 aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive dark:bg-input/30 flex field-sizing-content min-h-16 w-full rounded-md border bg-transparent px-3 py-2 text-base shadow-xs transition-[color,box-shadow] outline-none focus-visible:ring-[3px] disabled:cursor-not-allowed disabled:opacity-50 md:text-sm",
        className,
      )}
      {...props}
    />
  );
}

export { Textarea };
</file>

<file path="apps/web/app/components/ui/toast.tsx">
"use client";

import * as ToastPrimitives from "@radix-ui/react-toast";
import { type VariantProps, cva } from "class-variance-authority";
import { X } from "lucide-react";
import * as React from "react";

import { cn } from "../../lib/utils";

const ToastProvider = ToastPrimitives.Provider;

const ToastViewport = React.forwardRef<
	React.ElementRef<typeof ToastPrimitives.Viewport>,
	React.ComponentPropsWithoutRef<typeof ToastPrimitives.Viewport>
>(({ className, ...props }, ref) => (
	<ToastPrimitives.Viewport
		ref={ref}
		className={cn(
			"fixed top-0 z-[100] flex max-h-screen w-full flex-col-reverse p-4 sm:bottom-0 sm:right-0 sm:top-auto sm:flex-col md:max-w-[420px]",
			className,
		)}
		{...props}
	/>
));
ToastViewport.displayName = ToastPrimitives.Viewport.displayName;

const toastVariants = cva(
	"group pointer-events-auto relative flex w-full items-center justify-between space-x-2 overflow-hidden rounded-md border p-4 pr-6 shadow-lg transition-all data-[swipe=cancel]:translate-x-0 data-[swipe=end]:translate-x-[var(--radix-toast-swipe-end-x)] data-[swipe=move]:translate-x-[var(--radix-toast-swipe-move-x)] data-[swipe=move]:transition-none data-[state=open]:animate-in data-[state=closed]:animate-out data-[swipe=end]:animate-out data-[state=closed]:fade-out-80 data-[state=closed]:slide-out-to-right-full data-[state=open]:slide-in-from-top-full data-[state=open]:sm:slide-in-from-bottom-full",
	{
		variants: {
			variant: {
				default: "border bg-background text-foreground",
				destructive:
					"destructive group border-destructive bg-destructive text-destructive-foreground",
			},
		},
		defaultVariants: {
			variant: "default",
		},
	},
);

const Toast = React.forwardRef<
	React.ElementRef<typeof ToastPrimitives.Root>,
	React.ComponentPropsWithoutRef<typeof ToastPrimitives.Root> &
		VariantProps<typeof toastVariants>
>(({ className, variant, ...props }, ref) => {
	return (
		<ToastPrimitives.Root
			ref={ref}
			className={cn(toastVariants({ variant }), className)}
			{...props}
		/>
	);
});
Toast.displayName = ToastPrimitives.Root.displayName;

const ToastAction = React.forwardRef<
	React.ElementRef<typeof ToastPrimitives.Action>,
	React.ComponentPropsWithoutRef<typeof ToastPrimitives.Action>
>(({ className, ...props }, ref) => (
	<ToastPrimitives.Action
		ref={ref}
		className={cn(
			"inline-flex h-8 shrink-0 items-center justify-center rounded-md border bg-transparent px-3 text-sm font-medium transition-colors hover:bg-secondary focus:outline-none focus:ring-1 focus:ring-ring disabled:pointer-events-none disabled:opacity-50 group-[.destructive]:border-muted/40 group-[.destructive]:hover:border-destructive/30 group-[.destructive]:hover:bg-destructive group-[.destructive]:hover:text-destructive-foreground group-[.destructive]:focus:ring-destructive",
			className,
		)}
		{...props}
	/>
));
ToastAction.displayName = ToastPrimitives.Action.displayName;

const ToastClose = React.forwardRef<
	React.ElementRef<typeof ToastPrimitives.Close>,
	React.ComponentPropsWithoutRef<typeof ToastPrimitives.Close>
>(({ className, ...props }, ref) => (
	<ToastPrimitives.Close
		ref={ref}
		className={cn(
			"absolute right-1 top-1 rounded-md p-1 text-foreground/50 opacity-0 transition-opacity hover:text-foreground focus:opacity-100 focus:outline-none focus:ring-1 group-hover:opacity-100 group-[.destructive]:text-red-300 group-[.destructive]:hover:text-red-50 group-[.destructive]:focus:ring-red-400 group-[.destructive]:focus:ring-offset-red-600",
			className,
		)}
		toast-close=""
		{...props}
	>
		<X className="h-4 w-4" />
	</ToastPrimitives.Close>
));
ToastClose.displayName = ToastPrimitives.Close.displayName;

const ToastTitle = React.forwardRef<
	React.ElementRef<typeof ToastPrimitives.Title>,
	React.ComponentPropsWithoutRef<typeof ToastPrimitives.Title>
>(({ className, ...props }, ref) => (
	<ToastPrimitives.Title
		ref={ref}
		className={cn("text-sm font-semibold [&+div]:text-xs", className)}
		{...props}
	/>
));
ToastTitle.displayName = ToastPrimitives.Title.displayName;

const ToastDescription = React.forwardRef<
	React.ElementRef<typeof ToastPrimitives.Description>,
	React.ComponentPropsWithoutRef<typeof ToastPrimitives.Description>
>(({ className, ...props }, ref) => (
	<ToastPrimitives.Description
		ref={ref}
		className={cn("text-sm opacity-90", className)}
		{...props}
	/>
));
ToastDescription.displayName = ToastPrimitives.Description.displayName;

type ToastProps = React.ComponentPropsWithoutRef<typeof Toast>;

type ToastActionElement = React.ReactElement<typeof ToastAction>;

export {
	type ToastProps,
	type ToastActionElement,
	ToastProvider,
	ToastViewport,
	Toast,
	ToastTitle,
	ToastDescription,
	ToastClose,
	ToastAction,
};
</file>

<file path="apps/web/app/components/ui/toaster.tsx">
"use client";

import * as ToastPrimitives from "@radix-ui/react-toast";
import { type VariantProps, cva } from "class-variance-authority";
import { X } from "lucide-react";
import * as React from "react";

import { cn } from "../../lib/utils";

const ToastProvider = ToastPrimitives.Provider;

const ToastViewport = React.forwardRef<
	React.ElementRef<typeof ToastPrimitives.Viewport>,
	React.ComponentPropsWithoutRef<typeof ToastPrimitives.Viewport>
>(({ className, ...props }, ref) => (
	<ToastPrimitives.Viewport
		ref={ref}
		className={cn(
			"fixed top-0 z-[100] flex max-h-screen w-full flex-col-reverse p-4 sm:bottom-0 sm:right-0 sm:top-auto sm:flex-col md:max-w-[420px]",
			className,
		)}
		{...props}
	/>
));
ToastViewport.displayName = ToastPrimitives.Viewport.displayName;

const toastVariants = cva(
	"group pointer-events-auto relative flex w-full items-center justify-between space-x-2 overflow-hidden rounded-md border p-4 pr-6 shadow-lg transition-all data-[swipe=cancel]:translate-x-0 data-[swipe=end]:translate-x-[var(--radix-toast-swipe-end-x)] data-[swipe=move]:translate-x-[var(--radix-toast-swipe-move-x)] data-[swipe=move]:transition-none data-[state=open]:animate-in data-[state=closed]:animate-out data-[swipe=end]:animate-out data-[state=closed]:fade-out-80 data-[state=closed]:slide-out-to-right-full data-[state=open]:slide-in-from-top-full data-[state=open]:sm:slide-in-from-bottom-full",
	{
		variants: {
			variant: {
				default: "border bg-background text-foreground",
				destructive:
					"destructive group border-destructive bg-destructive text-destructive-foreground",
			},
		},
		defaultVariants: {
			variant: "default",
		},
	},
);

const Toast = React.forwardRef<
	React.ElementRef<typeof ToastPrimitives.Root>,
	React.ComponentPropsWithoutRef<typeof ToastPrimitives.Root> &
		VariantProps<typeof toastVariants>
>(({ className, variant, ...props }, ref) => {
	return (
		<ToastPrimitives.Root
			ref={ref}
			className={cn(toastVariants({ variant }), className)}
			{...props}
		/>
	);
});
Toast.displayName = ToastPrimitives.Root.displayName;

const ToastAction = React.forwardRef<
	React.ElementRef<typeof ToastPrimitives.Action>,
	React.ComponentPropsWithoutRef<typeof ToastPrimitives.Action>
>(({ className, ...props }, ref) => (
	<ToastPrimitives.Action
		ref={ref}
		className={cn(
			"inline-flex h-8 shrink-0 items-center justify-center rounded-md border bg-transparent px-3 text-sm font-medium transition-colors hover:bg-secondary focus:outline-none focus:ring-1 focus:ring-ring disabled:pointer-events-none disabled:opacity-50 group-[.destructive]:border-muted/40 group-[.destructive]:hover:border-destructive/30 group-[.destructive]:hover:bg-destructive group-[.destructive]:hover:text-destructive-foreground group-[.destructive]:focus:ring-destructive",
			className,
		)}
		{...props}
	/>
));
ToastAction.displayName = ToastPrimitives.Action.displayName;

const ToastClose = React.forwardRef<
	React.ElementRef<typeof ToastPrimitives.Close>,
	React.ComponentPropsWithoutRef<typeof ToastPrimitives.Close>
>(({ className, ...props }, ref) => (
	<ToastPrimitives.Close
		ref={ref}
		className={cn(
			"absolute right-1 top-1 rounded-md p-1 text-foreground/50 opacity-0 transition-opacity hover:text-foreground focus:opacity-100 focus:outline-none focus:ring-1 group-hover:opacity-100 group-[.destructive]:text-red-300 group-[.destructive]:hover:text-red-50 group-[.destructive]:focus:ring-red-400 group-[.destructive]:focus:ring-offset-red-600",
			className,
		)}
		toast-close=""
		{...props}
	>
		<X className="h-4 w-4" />
	</ToastPrimitives.Close>
));
ToastClose.displayName = ToastPrimitives.Close.displayName;

const ToastTitle = React.forwardRef<
	React.ElementRef<typeof ToastPrimitives.Title>,
	React.ComponentPropsWithoutRef<typeof ToastPrimitives.Title>
>(({ className, ...props }, ref) => (
	<ToastPrimitives.Title
		ref={ref}
		className={cn("text-sm font-semibold [&+div]:text-xs", className)}
		{...props}
	/>
));
ToastTitle.displayName = ToastPrimitives.Title.displayName;

const ToastDescription = React.forwardRef<
	React.ElementRef<typeof ToastPrimitives.Description>,
	React.ComponentPropsWithoutRef<typeof ToastPrimitives.Description>
>(({ className, ...props }, ref) => (
	<ToastPrimitives.Description
		ref={ref}
		className={cn("text-sm opacity-90", className)}
		{...props}
	/>
));
ToastDescription.displayName = ToastPrimitives.Description.displayName;

type ToastProps = React.ComponentPropsWithoutRef<typeof Toast>;

type ToastActionElement = React.ReactElement<typeof ToastAction>;

export {
	type ToastProps,
	type ToastActionElement,
	ToastProvider,
	ToastViewport,
	Toast,
	ToastTitle,
	ToastDescription,
	ToastClose,
	ToastAction,
};
</file>

<file path="apps/web/app/components/ui/toggle-group.tsx">
"use client";

import * as ToggleGroupPrimitive from "@radix-ui/react-toggle-group";
import type { VariantProps } from "class-variance-authority";
import * as React from "react";

import { toggleVariants } from "~/components/ui/toggle";
import { cn } from "~/lib/utils";

const ToggleGroupContext = React.createContext<
  VariantProps<typeof toggleVariants>
>({
  size: "default",
  variant: "default",
});

function ToggleGroup({
  className,
  variant,
  size,
  children,
  ...props
}: React.ComponentProps<typeof ToggleGroupPrimitive.Root> &
  VariantProps<typeof toggleVariants>) {
  return (
    <ToggleGroupPrimitive.Root
      data-slot="toggle-group"
      data-variant={variant}
      data-size={size}
      className={cn(
        "group/toggle-group flex w-fit items-center rounded-md data-[variant=outline]:shadow-xs",
        className,
      )}
      {...props}
    >
      <ToggleGroupContext.Provider value={{ variant, size }}>
        {children}
      </ToggleGroupContext.Provider>
    </ToggleGroupPrimitive.Root>
  );
}

function ToggleGroupItem({
  className,
  children,
  variant,
  size,
  ...props
}: React.ComponentProps<typeof ToggleGroupPrimitive.Item> &
  VariantProps<typeof toggleVariants>) {
  const context = React.useContext(ToggleGroupContext);

  return (
    <ToggleGroupPrimitive.Item
      data-slot="toggle-group-item"
      data-variant={context.variant || variant}
      data-size={context.size || size}
      className={cn(
        toggleVariants({
          variant: context.variant || variant,
          size: context.size || size,
        }),
        "min-w-0 flex-1 shrink-0 rounded-none shadow-none first:rounded-l-md last:rounded-r-md focus:z-10 focus-visible:z-10 data-[variant=outline]:border-l-0 data-[variant=outline]:first:border-l",
        className,
      )}
      {...props}
    >
      {children}
    </ToggleGroupPrimitive.Item>
  );
}

export { ToggleGroup, ToggleGroupItem };
</file>

<file path="apps/web/app/components/ui/toggle.tsx">
import * as TogglePrimitive from "@radix-ui/react-toggle";
import { type VariantProps, cva } from "class-variance-authority";
import type * as React from "react";

import { cn } from "~/lib/utils";

const toggleVariants = cva(
  "inline-flex items-center justify-center gap-2 rounded-md text-sm font-medium hover:bg-muted hover:text-muted-foreground disabled:pointer-events-none disabled:opacity-50 data-[state=on]:bg-accent data-[state=on]:text-accent-foreground [&_svg]:pointer-events-none [&_svg:not([class*='size-'])]:size-4 [&_svg]:shrink-0 focus-visible:border-ring focus-visible:ring-ring/50 focus-visible:ring-[3px] outline-none transition-[color,box-shadow] aria-invalid:ring-destructive/20 dark:aria-invalid:ring-destructive/40 aria-invalid:border-destructive whitespace-nowrap",
  {
    variants: {
      variant: {
        default: "bg-transparent",
        outline:
          "border border-input bg-transparent shadow-xs hover:bg-accent hover:text-accent-foreground",
      },
      size: {
        default: "h-9 px-2 min-w-9",
        sm: "h-8 px-1.5 min-w-8",
        lg: "h-10 px-2.5 min-w-10",
      },
    },
    defaultVariants: {
      variant: "default",
      size: "default",
    },
  },
);

function Toggle({
  className,
  variant,
  size,
  ...props
}: React.ComponentProps<typeof TogglePrimitive.Root> &
  VariantProps<typeof toggleVariants>) {
  return (
    <TogglePrimitive.Root
      data-slot="toggle"
      className={cn(toggleVariants({ variant, size, className }))}
      {...props}
    />
  );
}

export { Toggle, toggleVariants };
</file>

<file path="apps/web/app/components/ui/tooltip.tsx">
import * as TooltipPrimitive from "@radix-ui/react-tooltip";
import type * as React from "react";

import { cn } from "~/lib/utils";

function TooltipProvider({
  delayDuration = 0,
  ...props
}: React.ComponentProps<typeof TooltipPrimitive.Provider>) {
  return (
    <TooltipPrimitive.Provider
      data-slot="tooltip-provider"
      delayDuration={delayDuration}
      {...props}
    />
  );
}

function Tooltip({
  ...props
}: React.ComponentProps<typeof TooltipPrimitive.Root>) {
  return (
    <TooltipProvider>
      <TooltipPrimitive.Root data-slot="tooltip" {...props} />
    </TooltipProvider>
  );
}

function TooltipTrigger({
  ...props
}: React.ComponentProps<typeof TooltipPrimitive.Trigger>) {
  return <TooltipPrimitive.Trigger data-slot="tooltip-trigger" {...props} />;
}

function TooltipContent({
  className,
  sideOffset = 0,
  children,
  ...props
}: React.ComponentProps<typeof TooltipPrimitive.Content>) {
  return (
    <TooltipPrimitive.Portal>
      <TooltipPrimitive.Content
        data-slot="tooltip-content"
        sideOffset={sideOffset}
        className={cn(
          "bg-primary text-primary-foreground animate-in fade-in-0 zoom-in-95 data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=closed]:zoom-out-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2 z-50 w-fit origin-(--radix-tooltip-content-transform-origin) rounded-md px-3 py-1.5 text-xs text-balance",
          className,
        )}
        {...props}
      >
        {children}
        <TooltipPrimitive.Arrow className="bg-primary fill-primary z-50 size-2.5 translate-y-[calc(-50%_-_2px)] rotate-45 rounded-[2px]" />
      </TooltipPrimitive.Content>
    </TooltipPrimitive.Portal>
  );
}

export { Tooltip, TooltipTrigger, TooltipContent, TooltipProvider };
</file>

<file path="apps/web/app/components/ui/use-toast.tsx">
"use client";

import * as ToastPrimitives from "@radix-ui/react-toast";
import { type VariantProps, cva } from "class-variance-authority";
import { X } from "lucide-react";
import * as React from "react";

import { cn } from "../../lib/utils";

const ToastProvider = ToastPrimitives.Provider;

const ToastViewport = React.forwardRef<
	React.ElementRef<typeof ToastPrimitives.Viewport>,
	React.ComponentPropsWithoutRef<typeof ToastPrimitives.Viewport>
>(({ className, ...props }, ref) => (
	<ToastPrimitives.Viewport
		ref={ref}
		className={cn(
			"fixed top-0 z-[100] flex max-h-screen w-full flex-col-reverse p-4 sm:bottom-0 sm:right-0 sm:top-auto sm:flex-col md:max-w-[420px]",
			className,
		)}
		{...props}
	/>
));
ToastViewport.displayName = ToastPrimitives.Viewport.displayName;

const toastVariants = cva(
	"group pointer-events-auto relative flex w-full items-center justify-between space-x-2 overflow-hidden rounded-md border p-4 pr-6 shadow-lg transition-all data-[swipe=cancel]:translate-x-0 data-[swipe=end]:translate-x-[var(--radix-toast-swipe-end-x)] data-[swipe=move]:translate-x-[var(--radix-toast-swipe-move-x)] data-[swipe=move]:transition-none data-[state=open]:animate-in data-[state=closed]:animate-out data-[swipe=end]:animate-out data-[state=closed]:fade-out-80 data-[state=closed]:slide-out-to-right-full data-[state=open]:slide-in-from-top-full data-[state=open]:sm:slide-in-from-bottom-full",
	{
		variants: {
			variant: {
				default: "border bg-background text-foreground",
				destructive:
					"destructive group border-destructive bg-destructive text-destructive-foreground",
			},
		},
		defaultVariants: {
			variant: "default",
		},
	},
);

const Toast = React.forwardRef<
	React.ElementRef<typeof ToastPrimitives.Root>,
	React.ComponentPropsWithoutRef<typeof ToastPrimitives.Root> &
		VariantProps<typeof toastVariants>
>(({ className, variant, ...props }, ref) => {
	return (
		<ToastPrimitives.Root
			ref={ref}
			className={cn(toastVariants({ variant }), className)}
			{...props}
		/>
	);
});
Toast.displayName = ToastPrimitives.Root.displayName;

const ToastAction = React.forwardRef<
	React.ElementRef<typeof ToastPrimitives.Action>,
	React.ComponentPropsWithoutRef<typeof ToastPrimitives.Action>
>(({ className, ...props }, ref) => (
	<ToastPrimitives.Action
		ref={ref}
		className={cn(
			"inline-flex h-8 shrink-0 items-center justify-center rounded-md border bg-transparent px-3 text-sm font-medium transition-colors hover:bg-secondary focus:outline-none focus:ring-1 focus:ring-ring disabled:pointer-events-none disabled:opacity-50 group-[.destructive]:border-muted/40 group-[.destructive]:hover:border-destructive/30 group-[.destructive]:hover:bg-destructive group-[.destructive]:hover:text-destructive-foreground group-[.destructive]:focus:ring-destructive",
			className,
		)}
		{...props}
	/>
));
ToastAction.displayName = ToastPrimitives.Action.displayName;

const ToastClose = React.forwardRef<
	React.ElementRef<typeof ToastPrimitives.Close>,
	React.ComponentPropsWithoutRef<typeof ToastPrimitives.Close>
>(({ className, ...props }, ref) => (
	<ToastPrimitives.Close
		ref={ref}
		className={cn(
			"absolute right-1 top-1 rounded-md p-1 text-foreground/50 opacity-0 transition-opacity hover:text-foreground focus:opacity-100 focus:outline-none focus:ring-1 group-hover:opacity-100 group-[.destructive]:text-red-300 group-[.destructive]:hover:text-red-50 group-[.destructive]:focus:ring-red-400 group-[.destructive]:focus:ring-offset-red-600",
			className,
		)}
		toast-close=""
		{...props}
	>
		<X className="h-4 w-4" />
	</ToastPrimitives.Close>
));
ToastClose.displayName = ToastPrimitives.Close.displayName;

const ToastTitle = React.forwardRef<
	React.ElementRef<typeof ToastPrimitives.Title>,
	React.ComponentPropsWithoutRef<typeof ToastPrimitives.Title>
>(({ className, ...props }, ref) => (
	<ToastPrimitives.Title
		ref={ref}
		className={cn("text-sm font-semibold [&+div]:text-xs", className)}
		{...props}
	/>
));
ToastTitle.displayName = ToastPrimitives.Title.displayName;

const ToastDescription = React.forwardRef<
	React.ElementRef<typeof ToastPrimitives.Description>,
	React.ComponentPropsWithoutRef<typeof ToastPrimitives.Description>
>(({ className, ...props }, ref) => (
	<ToastPrimitives.Description
		ref={ref}
		className={cn("text-sm opacity-90", className)}
		{...props}
	/>
));
ToastDescription.displayName = ToastPrimitives.Description.displayName;

type ToastProps = React.ComponentPropsWithoutRef<typeof Toast>;

type ToastActionElement = React.ReactElement<typeof ToastAction>;

export {
	type ToastProps,
	type ToastActionElement,
	ToastProvider,
	ToastViewport,
	Toast,
	ToastTitle,
	ToastDescription,
	ToastClose,
	ToastAction,
};
</file>

<file path="apps/web/app/components/video/content-editor.tsx">
import { Button } from "~/components/ui/button";
import { Textarea } from "~/components/ui/textarea";
import { Loader2, Pencil, Save, X } from "lucide-react";
import { useEffect, useState } from "react";

type ContentEditorProps = {
  content: string;
  isLoading?: boolean;
  errorMessage?: string;
  onSave?: (content: string) => Promise<void>;
  className?: string;
  readOnly?: boolean;
  placeholder?: string;
  maxHeight?: string;
};

export function ContentEditor({
  content,
  isLoading = false,
  errorMessage,
  onSave,
  className = "",
  readOnly = false,
  placeholder = "Content not available yet",
  maxHeight = "400px",
}: ContentEditorProps) {
  const [isEditing, setIsEditing] = useState(false);
  const [editedContent, setEditedContent] = useState(content);
  const [isSaving, setIsSaving] = useState(false);
  const [saveError, setSaveError] = useState<string | null>(null);

  // Update edited content when the source content changes
  useEffect(() => {
    setEditedContent(content);
  }, [content]);

  const handleEdit = () => {
    setIsEditing(true);
    setSaveError(null);
  };

  const handleCancel = () => {
    setIsEditing(false);
    setEditedContent(content);
    setSaveError(null);
  };

  const handleSave = async () => {
    if (!onSave) return;
    setIsSaving(true);
    setSaveError(null);

    try {
      await onSave(editedContent);
      setIsEditing(false);
    } catch (error) {
      setSaveError(
        error instanceof Error ? error.message : "Error saving content",
      );
    } finally {
      setIsSaving(false);
    }
  };

  if (isLoading) {
    return (
      <div className="flex justify-center items-center p-8">
        <Loader2 className="h-6 w-6 animate-spin mr-2" />
        <span>Loading content...</span>
      </div>
    );
  }

  if (errorMessage) {
    return (
      <div className="p-4 border border-red-200 rounded-md bg-red-50 text-red-600">
        <p className="font-medium">Error loading content</p>
        <p className="text-sm mt-1">{errorMessage}</p>
      </div>
    );
  }

  if (!content.trim() && !isEditing) {
    return (
      <div className="flex flex-col items-center justify-center p-8 text-center text-muted-foreground">
        <p>{placeholder}</p>
        {!readOnly && onSave && (
          <Button
            variant="outline"
            size="sm"
            onClick={handleEdit}
            className="mt-4"
          >
            <Pencil className="h-4 w-4 mr-2" />
            Create Content
          </Button>
        )}
      </div>
    );
  }

  return (
    <div className={`relative ${className}`}>
      {isEditing ? (
        <>
          <Textarea
            value={editedContent}
            onChange={(e) => setEditedContent(e.target.value)}
            className={`min-h-[200px] font-mono text-sm p-4 ${saveError ? "border-red-300" : ""}`}
            placeholder="Enter content here..."
            disabled={isSaving}
          />

          {saveError && (
            <div className="mt-2 p-2 text-sm text-red-600 bg-red-50 rounded-md">
              {saveError}
            </div>
          )}

          <div className="flex justify-end gap-2 mt-4">
            <Button
              variant="outline"
              size="sm"
              onClick={handleCancel}
              disabled={isSaving}
            >
              <X className="h-4 w-4 mr-1" />
              Cancel
            </Button>
            <Button size="sm" onClick={handleSave} disabled={isSaving}>
              {isSaving ? (
                <>
                  <Loader2 className="h-4 w-4 mr-2 animate-spin" />
                  Saving...
                </>
              ) : (
                <>
                  <Save className="h-4 w-4 mr-1" />
                  Save Changes
                </>
              )}
            </Button>
          </div>
        </>
      ) : (
        <>
          <div
            className={`overflow-y-auto p-4 font-mono text-sm whitespace-pre-wrap border rounded-md ${
              !readOnly
                ? "hover:border-primary hover:bg-accent/10 transition-colors"
                : ""
            }`}
            style={{ maxHeight }}
          >
            {content}
          </div>

          {!readOnly && onSave && (
            <Button
              variant="ghost"
              size="sm"
              onClick={handleEdit}
              className="absolute top-2 right-2"
            >
              <Pencil className="h-4 w-4" />
            </Button>
          )}
        </>
      )}
    </div>
  );
}
</file>

<file path="apps/web/app/components/video/processing-dashboard.tsx">
import { useQuery, useQueryClient } from "@tanstack/react-query";
import { PlusIcon } from "lucide-react";
import { useEffect, useRef, useState } from "react";
import { toast } from "sonner";
import { Alert, AlertDescription, AlertTitle } from "~/components/ui/alert";
import { Button } from "~/components/ui/button";
import {
  Card,
  CardContent,
  CardFooter,
  CardHeader,
} from "~/components/ui/card";
import type { Step } from "~/components/ui/progress-steps";
import { Skeleton } from "~/components/ui/skeleton";
import {
  getProcessingJobs,
  getSignedUploadUrl,
  notifyUploadComplete,
} from "~/lib/api";
import { useJobStatusManager } from "~/lib/useJobStatusManager";
import type {
  SignedUploadUrlRequest,
  SignedUploadUrlResponse,
  UploadCompleteRequest,
  VideoJobSchema,
} from "~/types/api";
import { VideoProgressCard } from "./video-progress-card";

// Map backend processing stages to frontend steps
const stageToStepMap: Record<string, number> = {
  uploaded: 0,
  audio_extraction: 1,
  transcript_generation: 2,
  subtitle_generation: 3,
  shownote_generation: 4,
  chapter_generation: 5,
  title_generation: 6,
  youtube_upload: 7,
  completed: 8,
};

// Helper to determine the current step index based on backend stage
function getCurrentStepIndex(
  jobStatus: VideoJobSchema["status"],
  stages?: VideoJobSchema["processing_stages"],
): number {
  if (jobStatus === "COMPLETED") return 8; // Max steps
  if (jobStatus === "FAILED") return 0; // Or a specific error step
  if (typeof stages === "object" && stages !== null && !Array.isArray(stages)) {
    return Object.keys(stages).length;
  }
  if (Array.isArray(stages)) {
    return stages.length;
  }
  return 0;
}

function getProgressCardStatus(
  jobStatus: VideoJobSchema["status"],
): "processing" | "completed" | "error" | "paused" {
  switch (jobStatus) {
    case "COMPLETED":
      return "completed";
    case "FAILED":
      return "error";
    case "PENDING":
      return "processing"; // Or a specific "pending" visual state if desired
    case "PROCESSING":
      return "processing";
    default:
      return "processing"; // Fallback
  }
}

type ProcessingDashboardProps = {
  className?: string;
};

export function ProcessingDashboard({ className }: ProcessingDashboardProps) {
  useJobStatusManager();
  const queryClient = useQueryClient();
  const inputRef = useRef<HTMLInputElement>(null);
  const [isUploading, setIsUploading] = useState(false);

  const {
    data: processingJobs,
    isLoading,
    error: fetchError,
  } = useQuery<VideoJobSchema[], Error>({
    queryKey: ["processingJobs"],
    queryFn: () => getProcessingJobs(),
  });

  const handleUploadButtonClick = () => {
    if (isUploading) return;
    inputRef.current?.click();
  };

  const handleFileChange = async (
    event: React.ChangeEvent<HTMLInputElement>,
  ) => {
    if (event.target.files && event.target.files.length > 0) {
      const file = event.target.files[0];
      if (inputRef.current) {
        inputRef.current.value = "";
      }

      setIsUploading(true);
      const uploadPromise = async () => {
        let signedUrlResponse: SignedUploadUrlResponse;
        try {
          const requestData: SignedUploadUrlRequest = {
            filename: file.name,
            content_type: file.type,
          };
          signedUrlResponse = await getSignedUploadUrl(requestData);
          if (!signedUrlResponse.upload_url || !signedUrlResponse.video_id) {
            throw new Error("Invalid response from signed URL endpoint");
          }
        } catch (err: any) {
          console.error("Failed to get upload URL:", err);
          throw new Error(err.message || "Failed to get upload URL");
        }

        const { upload_url: uploadUrl, video_id: videoId } = signedUrlResponse;

        try {
          await new Promise<void>((resolve, reject) => {
            const xhr = new XMLHttpRequest();
            xhr.open("PUT", uploadUrl);
            xhr.setRequestHeader("Content-Type", file.type);
            xhr.onload = () => {
              if (xhr.status >= 200 && xhr.status < 300) {
                resolve();
              } else {
                reject(
                  new Error(
                    `Upload failed with status ${xhr.status}: ${xhr.statusText}`,
                  ),
                );
              }
            };
            xhr.onerror = () =>
              reject(new Error("Upload failed due to network error"));
            xhr.send(file);
          });
        } catch (err: any) {
          console.error("Upload failed:", err);
          throw new Error(err.message || "Upload to storage failed");
        }

        try {
          const completeRequestData: UploadCompleteRequest = {
            video_id: String(videoId),
            original_filename: file.name,
            content_type: file.type,
            size_bytes: file.size,
          };
          await notifyUploadComplete(completeRequestData);
        } catch (err: any) {
          console.error("Failed to finalize upload:", err);
          throw new Error(
            err.message || "Failed to finalize upload with backend",
          );
        }
        return videoId;
      };

      toast.promise(uploadPromise(), {
        loading: "Uploading video...",
        success: (videoId) => {
          queryClient.invalidateQueries({ queryKey: ["processingJobs"] });
          queryClient.invalidateQueries({ queryKey: ["myVideos"] });
          return `Video "${file.name}" uploaded successfully! (ID: ${videoId})`;
        },
        error: (err) => `Upload failed: ${err.message}`,
        finally: () => {
          setIsUploading(false);
        },
      });
    }
  };

  const handlePauseResume = (videoId: string) => {
    console.log(
      "Pause/resume functionality is not currently supported by the backend.",
      videoId,
    );
  };

  return (
    <div className={className}>
      <div className="flex items-center justify-between mb-8">
        <div>
          <h1 className="text-2xl font-bold tracking-tight">
            Video Processing
          </h1>
          <p className="text-muted-foreground text-sm mt-1">
            Track the status of your video processing tasks
          </p>
        </div>
        <Button onClick={handleUploadButtonClick} disabled={isUploading}>
          <PlusIcon className="h-4 w-4 mr-2" />
          {isUploading ? "Uploading..." : "Upload New Video"}
        </Button>
      </div>

      <input
        type="file"
        ref={inputRef}
        onChange={handleFileChange}
        style={{ display: "none" }}
        accept="video/*"
        disabled={isUploading}
      />

      {fetchError && (
        <div className="py-10">
          <Alert variant="destructive" className="max-w-lg mx-auto">
            <AlertTitle>Error Fetching Processing Videos</AlertTitle>
            <AlertDescription>{fetchError.message}</AlertDescription>
          </Alert>
        </div>
      )}

      {isLoading && !fetchError ? (
        <div className="grid gap-6 sm:grid-cols-1 lg:grid-cols-2 xl:grid-cols-3">
          {[...Array(3)].map((_, index) => (
            <Card key={index} className="animate-pulse">
              <CardHeader className="pb-2">
                <div className="flex items-start justify-between">
                  <div className="space-y-1 flex-grow pr-2">
                    <Skeleton className="h-5 w-3/4" />
                    <Skeleton className="h-4 w-1/2" />
                  </div>
                  <Skeleton className="h-14 w-24 shrink-0 rounded-md" />
                </div>
              </CardHeader>
              <CardContent>
                <Skeleton className="h-6 w-full mb-2" />
                <Skeleton className="h-4 w-1/2" />
              </CardContent>
              <CardFooter className="flex justify-between pt-0">
                <Skeleton className="h-8 w-20" />
                <Skeleton className="h-8 w-24" />
              </CardFooter>
            </Card>
          ))}
        </div>
      ) : !fetchError && processingJobs && processingJobs.length === 0 ? (
        <div className="flex flex-col items-center justify-center py-20 text-center">
          <p className="text-muted-foreground mb-4">
            No videos currently processing
          </p>
          <Button
            variant="outline"
            onClick={handleUploadButtonClick}
            disabled={isUploading}
          >
            {isUploading ? "Uploading..." : "Upload a new video"}
          </Button>
        </div>
      ) : !fetchError && processingJobs ? (
        <div className="grid gap-6 sm:grid-cols-1 lg:grid-cols-2 xl:grid-cols-3">
          {processingJobs.map((job) => {
            const cardStatus = getProgressCardStatus(job.status);

            const simplifiedSteps: Step[] = [];
            const currentDisplayStepId: string | undefined = undefined;

            if (cardStatus === "processing" && job.processing_stages) {
              if (Array.isArray(job.processing_stages)) {
              } else if (
                typeof job.processing_stages === "object" &&
                job.processing_stages !== null
              ) {
              }
            } else if (cardStatus === "completed") {
            }

            return (
              <VideoProgressCard
                key={job.id}
                videoId={String(job.id)}
                videoTitle={
                  job.metadata?.title ||
                  job.video?.original_filename ||
                  "Untitled Video"
                }
                thumbnailUrl={job.metadata?.thumbnail_file_url || undefined}
                uploadedAt={
                  job.created_at ? new Date(job.created_at) : new Date()
                }
                status={cardStatus}
                processingSteps={simplifiedSteps}
                currentStepId={currentDisplayStepId}
                onPauseResume={() => handlePauseResume(String(job.id))}
              />
            );
          })}
        </div>
      ) : null}
    </div>
  );
}
</file>

<file path="apps/web/app/components/video/processing-steps.ts">
import type { Step } from "~/components/ui/progress-steps";

// Define the IDs for our processing steps
export enum ProcessingStepId {
  UPLOAD = "upload",
  AUDIO_EXTRACTION = "audio_extraction",
  TRANSCRIPT = "transcript",
  SUBTITLES = "subtitles",
  SHOWNOTES = "shownotes",
  CHAPTERS = "chapters",
  TITLE = "title",
  YOUTUBE_UPLOAD = "youtube_upload",
}

// Define static step metadata
export const PROCESSING_STEPS_META = {
  [ProcessingStepId.UPLOAD]: {
    label: "Video Upload",
    description: "Uploading video file to secure storage",
    progressPercentage: 10,
  },
  [ProcessingStepId.AUDIO_EXTRACTION]: {
    label: "Audio Extraction",
    description: "Extracting audio track for transcription",
    progressPercentage: 15,
  },
  [ProcessingStepId.TRANSCRIPT]: {
    label: "Transcript Generation",
    description: "Creating full text transcript from audio",
    progressPercentage: 15,
  },
  [ProcessingStepId.SUBTITLES]: {
    label: "Subtitles Generation",
    description: "Creating timestamped VTT subtitles",
    progressPercentage: 15,
  },
  [ProcessingStepId.SHOWNOTES]: {
    label: "Shownotes Generation",
    description: "Creating detailed show notes and summary",
    progressPercentage: 15,
  },
  [ProcessingStepId.CHAPTERS]: {
    label: "Chapters Generation",
    description: "Creating timestamped chapters",
    progressPercentage: 15,
  },
  [ProcessingStepId.TITLE]: {
    label: "Title & Keywords",
    description: "Creating optimized title and keywords",
    progressPercentage: 5,
  },
  [ProcessingStepId.YOUTUBE_UPLOAD]: {
    label: "YouTube Upload",
    description: "Uploading to YouTube with metadata",
    progressPercentage: 10,
  },
};

// Create the processing steps in the proper order
export const ORDERED_PROCESSING_STEPS = Object.keys(PROCESSING_STEPS_META).map(
  (id) => ({
    id,
    ...PROCESSING_STEPS_META[id as ProcessingStepId],
  }),
);

// Initialize all steps to pending
export function initializeProcessingSteps(): Step[] {
  return Object.entries(PROCESSING_STEPS_META).map(([id, meta]) => ({
    id,
    label: meta.label,
    description: meta.description,
    status: "pending" as const,
  }));
}

// Update step status in the array
export function updateStepStatus(
  steps: Step[],
  stepId: ProcessingStepId,
  status: Step["status"],
  options?: { progress?: number; errorMessage?: string },
): Step[] {
  return steps.map((step) => {
    if (step.id === stepId) {
      return {
        ...step,
        status,
        progress: options?.progress,
        errorMessage: options?.errorMessage,
      };
    }
    return step;
  });
}

// Calculate the overall progress percentage
export function calculateOverallProgress(steps: Step[]): number {
  // If all steps are completed, return 100%
  if (steps.every((step) => step.status === "completed")) {
    return 100;
  }

  let totalProgress = 0;
  let completedProgress = 0;

  steps.forEach((step) => {
    const stepMeta = PROCESSING_STEPS_META[step.id as ProcessingStepId];
    const weight = stepMeta.progressPercentage;

    totalProgress += weight;

    if (step.status === "completed") {
      completedProgress += weight;
    } else if (step.status === "in_progress" && step.progress !== undefined) {
      // For in-progress steps, add a portion based on its progress
      completedProgress += (weight * step.progress) / 100;
    }
  });

  return Math.round((completedProgress / totalProgress) * 100);
}

// Mock step progress for UI development/testing
export function createMockProcessingSteps(currentStepIndex: number): Step[] {
  const orderedStepIds = Object.keys(PROCESSING_STEPS_META);

  return orderedStepIds.map((id, index) => {
    const meta = PROCESSING_STEPS_META[id as ProcessingStepId];

    let status: Step["status"] = "pending";
    let progress: number | undefined = undefined;

    if (index < currentStepIndex) {
      status = "completed";
    } else if (index === currentStepIndex) {
      status = "in_progress";
      progress = Math.floor(Math.random() * 100);
    }

    return {
      id,
      label: meta.label,
      description: meta.description,
      status,
      progress,
    };
  });
}
</file>

<file path="apps/web/app/components/video/thumbnail-gallery.tsx">
import { Button } from "../ui/button";
import {
  Card,
  CardContent,
  CardDescription,
  CardFooter,
  CardHeader,
  CardTitle,
} from "../ui/card";
import { Input } from "../ui/input";
import { Label } from "../ui/label";
import { Tabs, TabsContent, TabsList, TabsTrigger } from "../ui/tabs";
import { Textarea } from "../ui/textarea";
import { cn } from "../../lib/utils";
import {
  Check,
  Edit2,
  Image,
  Loader2,
  RefreshCw,
  Sparkles,
} from "lucide-react";
import { useState } from "react";

export type Thumbnail = {
  id: string;
  url: string;
  prompt: string;
  isSelected?: boolean;
  status: "ready" | "generating" | "failed";
  error?: string;
};

type ThumbnailGalleryProps = {
  videoId: string;
  thumbnails: Thumbnail[];
  onSelect: (thumbnailId: string) => void;
  onRegenerateAll: () => void;
  onRegenerateSingle: (thumbnailId: string, newPrompt: string) => void;
  onApply: (thumbnailId: string) => void;
  onCustomUpload?: (file: File) => void;
  className?: string;
  isGenerating?: boolean;
};

export function ThumbnailGallery({
  videoId,
  thumbnails,
  onSelect,
  onRegenerateAll,
  onRegenerateSingle,
  onApply,
  onCustomUpload,
  className,
  isGenerating = false,
}: ThumbnailGalleryProps) {
  const [editingThumbnailId, setEditingThumbnailId] = useState<string | null>(
    null,
  );
  const [editPrompt, setEditPrompt] = useState("");
  const [customUploadFile, setCustomUploadFile] = useState<File | null>(null);

  const selectedThumbnail = thumbnails.find((thumb) => thumb.isSelected);

  const handleEditStart = (thumbnail: Thumbnail) => {
    setEditingThumbnailId(thumbnail.id);
    setEditPrompt(thumbnail.prompt);
  };

  const handleEditSave = (thumbnailId: string) => {
    if (editPrompt.trim()) {
      onRegenerateSingle(thumbnailId, editPrompt.trim());
      setEditingThumbnailId(null);
    }
  };

  const handleFileChange = (e: React.ChangeEvent<HTMLInputElement>) => {
    if (e.target.files && e.target.files.length > 0) {
      setCustomUploadFile(e.target.files[0]);
    }
  };

  const handleCustomUpload = () => {
    if (customUploadFile && onCustomUpload) {
      onCustomUpload(customUploadFile);
      setCustomUploadFile(null);
    }
  };

  return (
    <Card className={className}>
      <CardHeader>
        <CardTitle className="flex justify-between items-center">
          <span>Thumbnail Options</span>
          <Button
            size="sm"
            variant="outline"
            onClick={onRegenerateAll}
            disabled={isGenerating}
            className="gap-1"
          >
            {isGenerating ? (
              <>
                <Loader2 className="h-3.5 w-3.5 animate-spin" />
                Generating...
              </>
            ) : (
              <>
                <Sparkles className="h-3.5 w-3.5" />
                Generate New Set
              </>
            )}
          </Button>
        </CardTitle>
        <CardDescription>
          Select or customize the thumbnail for your video
        </CardDescription>
      </CardHeader>

      <CardContent>
        <Tabs defaultValue="gallery">
          <TabsList className="grid w-full grid-cols-2 mb-4">
            <TabsTrigger value="gallery">AI Generated</TabsTrigger>
            <TabsTrigger value="custom">Custom Upload</TabsTrigger>
          </TabsList>

          <TabsContent value="gallery" className="space-y-4">
            {/* Selected Thumbnail Preview */}
            {selectedThumbnail && (
              <div className="space-y-2">
                <Label className="text-xs text-muted-foreground">
                  Selected Thumbnail
                </Label>
                <div className="aspect-video bg-muted rounded-md overflow-hidden relative">
                  <img
                    src={selectedThumbnail.url}
                    alt="Selected thumbnail"
                    className="w-full h-full object-cover"
                  />
                  <div className="absolute inset-0 bg-black/40 flex items-center justify-center opacity-0 hover:opacity-100 transition-opacity">
                    <Button
                      variant="secondary"
                      size="sm"
                      onClick={() => handleEditStart(selectedThumbnail)}
                    >
                      Edit Prompt
                    </Button>
                  </div>
                </div>
              </div>
            )}

            {/* Thumbnail Grid */}
            <div className="grid grid-cols-2 gap-3">
              {thumbnails.map((thumbnail) => (
                <div
                  key={thumbnail.id}
                  className={cn(
                    "relative group rounded-md overflow-hidden border-2 aspect-video",
                    thumbnail.isSelected
                      ? "border-primary"
                      : "border-transparent",
                  )}
                >
                  {/* Thumbnail Image */}
                  {thumbnail.status === "generating" ? (
                    <div className="w-full h-full bg-muted flex items-center justify-center">
                      <Loader2 className="h-6 w-6 animate-spin text-muted-foreground" />
                    </div>
                  ) : thumbnail.status === "failed" ? (
                    <div className="w-full h-full bg-destructive/10 flex flex-col items-center justify-center p-2">
                      <span className="text-xs text-destructive font-medium">
                        Generation Failed
                      </span>
                      {thumbnail.error && (
                        <span className="text-[10px] text-muted-foreground text-center mt-1">
                          {thumbnail.error}
                        </span>
                      )}
                    </div>
                  ) : (
                    <img
                      src={thumbnail.url}
                      alt={`Thumbnail option ${thumbnail.id}`}
                      className="w-full h-full object-cover"
                    />
                  )}

                  {/* Overlay with Actions */}
                  {thumbnail.status === "ready" && (
                    <div className="absolute inset-0 bg-black/60 opacity-0 group-hover:opacity-100 transition-opacity flex flex-col items-center justify-center gap-2">
                      <div className="flex gap-1">
                        <Button
                          size="sm"
                          variant="secondary"
                          className="h-8"
                          onClick={() => handleEditStart(thumbnail)}
                        >
                          <Edit2 className="h-3.5 w-3.5 mr-1" />
                          Edit
                        </Button>
                        <Button
                          size="sm"
                          variant={thumbnail.isSelected ? "default" : "outline"}
                          className="h-8"
                          onClick={() => onSelect(thumbnail.id)}
                        >
                          <Check className="h-3.5 w-3.5 mr-1" />
                          {thumbnail.isSelected ? "Selected" : "Select"}
                        </Button>
                      </div>
                      <p className="text-[10px] text-white/70 px-2 text-center line-clamp-2 mt-1">
                        {thumbnail.prompt}
                      </p>
                    </div>
                  )}
                </div>
              ))}
            </div>

            {/* Edit Prompt Dialog */}
            {editingThumbnailId && (
              <div className="mt-4 border rounded-md p-3 space-y-3">
                <Label htmlFor="thumbnail-prompt">Edit Thumbnail Prompt</Label>
                <Textarea
                  id="thumbnail-prompt"
                  value={editPrompt}
                  onChange={(e) => setEditPrompt(e.target.value)}
                  placeholder="Describe what you want in this thumbnail..."
                  className="resize-none min-h-[100px]"
                />
                <div className="flex justify-end gap-2">
                  <Button
                    variant="outline"
                    size="sm"
                    onClick={() => setEditingThumbnailId(null)}
                  >
                    Cancel
                  </Button>
                  <Button
                    size="sm"
                    onClick={() => handleEditSave(editingThumbnailId)}
                    disabled={!editPrompt.trim()}
                  >
                    Regenerate
                  </Button>
                </div>
              </div>
            )}
          </TabsContent>

          <TabsContent value="custom" className="space-y-4">
            <div className="border-2 border-dashed rounded-md p-4 text-center">
              <div className="flex flex-col items-center justify-center gap-2">
                <Image className="h-8 w-8 text-muted-foreground" />
                <div className="space-y-1">
                  <p className="text-sm font-medium">Upload Custom Thumbnail</p>
                  <p className="text-xs text-muted-foreground">
                    PNG, JPG, or WEBP up to 2MB
                  </p>
                </div>

                <Input
                  type="file"
                  accept="image/png,image/jpeg,image/webp"
                  className="max-w-xs mt-2"
                  onChange={handleFileChange}
                />

                {customUploadFile && (
                  <div className="mt-2 w-full max-w-xs">
                    <p className="text-xs text-muted-foreground truncate">
                      {customUploadFile.name} (
                      {Math.round(customUploadFile.size / 1024)} KB)
                    </p>
                    <Button
                      className="w-full mt-2"
                      size="sm"
                      onClick={handleCustomUpload}
                    >
                      Upload & Use This Thumbnail
                    </Button>
                  </div>
                )}
              </div>
            </div>

            <div className="text-xs text-muted-foreground">
              <p>Image requirements:</p>
              <ul className="list-disc pl-5 space-y-1 mt-1">
                <li>1280x720 pixels (16:9 aspect ratio)</li>
                <li>Less than 2MB in size</li>
                <li>PNG, JPG, or WEBP format</li>
                <li>High-contrast images work best</li>
              </ul>
            </div>
          </TabsContent>
        </Tabs>
      </CardContent>

      <CardFooter>
        <Button
          className="w-full"
          disabled={!selectedThumbnail}
          onClick={() => selectedThumbnail && onApply(selectedThumbnail.id)}
        >
          Apply Selected Thumbnail
        </Button>
      </CardFooter>
    </Card>
  );
}
</file>

<file path="apps/web/app/components/video/title-selector.tsx">
import { Button } from "~/components/ui/button";
import {
  Card,
  CardContent,
  CardDescription,
  CardFooter,
  CardHeader,
  CardTitle,
} from "~/components/ui/card";
import { Input } from "~/components/ui/input";
import { cn } from "~/lib/utils";
import { Check, Edit2, RefreshCw, Sparkles, ThumbsUp } from "lucide-react";
import { useState } from "react";

export type TitleOption = {
  id: string;
  text: string;
  votes?: number;
  isSelected?: boolean;
};

type TitleSelectorProps = {
  videoId: string;
  titleOptions: TitleOption[];
  onSelect: (titleId: string) => void;
  onEdit: (titleId: string, newText: string) => void;
  onVote: (titleId: string) => void;
  onGenerateMore: () => void;
  onApply: (titleId: string) => void;
  className?: string;
  maxDisplayedOptions?: number;
};

export function TitleSelector({
  videoId,
  titleOptions,
  onSelect,
  onEdit,
  onVote,
  onGenerateMore,
  onApply,
  className,
  maxDisplayedOptions = 5,
}: TitleSelectorProps) {
  const [editingTitleId, setEditingTitleId] = useState<string | null>(null);
  const [editText, setEditText] = useState("");
  const [showAllOptions, setShowAllOptions] = useState(false);

  const sortedOptions = [...titleOptions].sort(
    (a, b) => (b.votes || 0) - (a.votes || 0),
  );

  const displayedOptions = showAllOptions
    ? sortedOptions
    : sortedOptions.slice(0, maxDisplayedOptions);

  const selectedTitle = sortedOptions.find((title) => title.isSelected);

  const handleEditStart = (title: TitleOption) => {
    setEditingTitleId(title.id);
    setEditText(title.text);
  };

  const handleEditSave = () => {
    if (editingTitleId && editText.trim()) {
      onEdit(editingTitleId, editText.trim());
      setEditingTitleId(null);
    }
  };

  const handleEditCancel = () => {
    setEditingTitleId(null);
  };

  return (
    <Card className={className}>
      <CardHeader>
        <CardTitle className="flex justify-between items-center">
          <span>Video Title Options</span>
          <Button
            size="sm"
            variant="outline"
            onClick={onGenerateMore}
            className="gap-1"
          >
            <Sparkles className="h-3.5 w-3.5" />
            Generate More
          </Button>
        </CardTitle>
        <CardDescription>
          Select the best title for your video or create your own
        </CardDescription>
      </CardHeader>

      <CardContent className="space-y-4">
        {/* Selected Title Preview */}
        {selectedTitle && (
          <div className="p-3 border rounded-md bg-muted/50">
            <div className="text-xs text-muted-foreground mb-1">
              Selected Title
            </div>
            <div className="font-medium">{selectedTitle.text}</div>
          </div>
        )}

        {/* Title Options */}
        <div className="space-y-3">
          {displayedOptions.map((title) => (
            <div
              key={title.id}
              className={cn(
                "p-3 border rounded-md relative transition",
                title.isSelected
                  ? "border-primary/50 bg-primary/5"
                  : "hover:border-border/80",
              )}
            >
              {editingTitleId === title.id ? (
                <div className="space-y-2">
                  <Input
                    value={editText}
                    onChange={(e) => setEditText(e.target.value)}
                    className="w-full"
                    autoFocus
                  />
                  <div className="flex space-x-2 justify-end">
                    <Button
                      size="sm"
                      variant="ghost"
                      onClick={handleEditCancel}
                    >
                      Cancel
                    </Button>
                    <Button size="sm" onClick={handleEditSave}>
                      Save
                    </Button>
                  </div>
                </div>
              ) : (
                <>
                  <div className="mr-16 text-sm">{title.text}</div>
                  <div className="absolute right-3 top-3 flex items-center space-x-2">
                    <Button
                      size="icon"
                      variant="ghost"
                      className="h-7 w-7"
                      onClick={() => onVote(title.id)}
                    >
                      <ThumbsUp className="h-3.5 w-3.5" />
                      {title.votes && title.votes > 0 && (
                        <span className="absolute -top-0.5 -right-0.5 bg-primary text-[10px] text-primary-foreground w-4 h-4 flex items-center justify-center rounded-full">
                          {title.votes}
                        </span>
                      )}
                    </Button>
                    <Button
                      size="icon"
                      variant="ghost"
                      className="h-7 w-7"
                      onClick={() => handleEditStart(title)}
                    >
                      <Edit2 className="h-3.5 w-3.5" />
                    </Button>
                    <Button
                      size="icon"
                      variant="ghost"
                      className={cn(
                        "h-7 w-7",
                        title.isSelected && "text-primary",
                      )}
                      onClick={() => onSelect(title.id)}
                    >
                      <Check className="h-3.5 w-3.5" />
                    </Button>
                  </div>
                </>
              )}
            </div>
          ))}

          {titleOptions.length > maxDisplayedOptions && (
            <Button
              variant="ghost"
              size="sm"
              className="w-full text-xs"
              onClick={() => setShowAllOptions(!showAllOptions)}
            >
              {showAllOptions
                ? "Show Less"
                : `Show ${titleOptions.length - maxDisplayedOptions} More Options`}
            </Button>
          )}
        </div>
      </CardContent>

      <CardFooter>
        <Button
          className="w-full"
          disabled={!selectedTitle}
          onClick={() => selectedTitle && onApply(selectedTitle.id)}
        >
          Apply Selected Title
        </Button>
      </CardFooter>
    </Card>
  );
}
</file>

<file path="apps/web/app/components/video/video-detail.tsx">
import { Button } from "../ui/button";
import {
  Card,
  CardContent,
  CardDescription,
  CardHeader,
  CardTitle,
} from "../ui/card";
import { ProgressSteps, type Step } from "../ui/progress-steps";
import { Tabs, TabsContent, TabsList, TabsTrigger } from "../ui/tabs";
import { tryFetchContent } from "../../services/gcs-content";
import { Link } from "@tanstack/react-router";
import {
  ArrowLeft,
  CheckCircle,
  Download,
  ExternalLink,
  Loader2,
  type LucideIcon,
} from "lucide-react";
import { useEffect, useState } from "react";
import { ContentEditor } from "./content-editor";
import { calculateOverallProgress } from "./processing-steps";

type VideoAsset = {
  type: string;
  label: string;
  url: string;
  icon: LucideIcon;
  sizeKB?: number;
};

type VideoDetailProps = {
  videoId: string;
  videoTitle: string;
  videoUrl: string;
  thumbnailUrl?: string;
  processingSteps: Step[];
  currentStepId?: string;
  youtubeUrl?: string;
  status: "processing" | "completed" | "error" | "paused";
  assets?: VideoAsset[];
  className?: string;
  // Content related props
  output_files?: Record<string, string>;
  bucket_name?: string;
  onSaveContent?: (contentType: string, content: string) => Promise<void>;
};

export function VideoDetail({
  videoId,
  videoTitle,
  videoUrl,
  thumbnailUrl,
  processingSteps,
  currentStepId,
  youtubeUrl,
  status,
  assets = [],
  className,
  output_files = {},
  bucket_name,
  onSaveContent,
}: VideoDetailProps) {
  const overallProgress = calculateOverallProgress(processingSteps);
  const isCompleted = status === "completed";

  // State for content
  const [transcript, setTranscript] = useState<string>("");
  const [subtitles, setSubtitles] = useState<string>("");
  const [chapters, setChapters] = useState<string>("");
  const [shownotes, setShownotes] = useState<string>("");

  // Loading states
  const [loadingTranscript, setLoadingTranscript] = useState<boolean>(false);
  const [loadingSubtitles, setLoadingSubtitles] = useState<boolean>(false);
  const [loadingChapters, setLoadingChapters] = useState<boolean>(false);
  const [loadingShownotes, setLoadingShownotes] = useState<boolean>(false);

  // Error states
  const [transcriptError, setTranscriptError] = useState<string | null>(null);
  const [subtitlesError, setSubtitlesError] = useState<string | null>(null);
  const [chaptersError, setChaptersError] = useState<string | null>(null);
  const [shownotesError, setShownotesError] = useState<string | null>(null);

  // Active tab
  const [activeContentTab, setActiveContentTab] =
    useState<string>("transcript");

  // Effect to load content based on active tab
  useEffect(() => {
    if (!bucket_name || status !== "completed") return;

    const fetchContent = async () => {
      // Only fetch content for the active tab to save bandwidth
      switch (activeContentTab) {
        case "transcript":
          if (transcript || loadingTranscript) return;
          setLoadingTranscript(true);
          setTranscriptError(null);
          try {
            const content = await tryFetchContent(
              bucket_name,
              output_files,
              "transcript",
            );
            setTranscript(content || "");
          } catch (error) {
            setTranscriptError(
              error instanceof Error
                ? error.message
                : "Failed to load transcript",
            );
          } finally {
            setLoadingTranscript(false);
          }
          break;

        case "subtitles":
          if (subtitles || loadingSubtitles) return;
          setLoadingSubtitles(true);
          setSubtitlesError(null);
          try {
            const content = await tryFetchContent(
              bucket_name,
              output_files,
              "subtitles",
            );
            setSubtitles(content || "");
          } catch (error) {
            setSubtitlesError(
              error instanceof Error
                ? error.message
                : "Failed to load subtitles",
            );
          } finally {
            setLoadingSubtitles(false);
          }
          break;

        case "chapters":
          if (chapters || loadingChapters) return;
          setLoadingChapters(true);
          setChaptersError(null);
          try {
            const content = await tryFetchContent(
              bucket_name,
              output_files,
              "chapters",
            );
            setChapters(content || "");
          } catch (error) {
            setChaptersError(
              error instanceof Error
                ? error.message
                : "Failed to load chapters",
            );
          } finally {
            setLoadingChapters(false);
          }
          break;

        case "shownotes":
          if (shownotes || loadingShownotes) return;
          setLoadingShownotes(true);
          setShownotesError(null);
          try {
            const content = await tryFetchContent(
              bucket_name,
              output_files,
              "shownotes",
            );
            setShownotes(content || "");
          } catch (error) {
            setShownotesError(
              error instanceof Error
                ? error.message
                : "Failed to load shownotes",
            );
          } finally {
            setLoadingShownotes(false);
          }
          break;
      }
    };

    fetchContent();
  }, [
    activeContentTab,
    bucket_name,
    output_files,
    status,
    transcript,
    subtitles,
    chapters,
    shownotes,
    loadingTranscript,
    loadingSubtitles,
    loadingChapters,
    loadingShownotes,
  ]);

  // Handle save operations for different content types
  const handleSaveTranscript = async (content: string) => {
    if (!onSaveContent) throw new Error("Save function not provided");
    await onSaveContent("transcript", content);
    setTranscript(content);
  };

  const handleSaveSubtitles = async (content: string) => {
    if (!onSaveContent) throw new Error("Save function not provided");
    await onSaveContent("subtitles", content);
    setSubtitles(content);
  };

  const handleSaveChapters = async (content: string) => {
    if (!onSaveContent) throw new Error("Save function not provided");
    await onSaveContent("chapters", content);
    setChapters(content);
  };

  const handleSaveShownotes = async (content: string) => {
    if (!onSaveContent) throw new Error("Save function not provided");
    await onSaveContent("shownotes", content);
    setShownotes(content);
  };

  return (
    <div className={className}>
      <div className="mb-6">
        <Link
          to="/dashboard"
          className="inline-flex items-center text-sm text-muted-foreground hover:text-foreground mb-4"
        >
          <ArrowLeft className="mr-2 h-4 w-4" />
          Back to dashboard
        </Link>

        <div className="flex items-center justify-between">
          <h1 className="text-2xl font-bold tracking-tight line-clamp-1">
            {videoTitle}
          </h1>
          {youtubeUrl && (
            <Button variant="outline" size="sm" asChild>
              <a href={youtubeUrl} target="_blank" rel="noopener noreferrer">
                <ExternalLink className="mr-2 h-4 w-4" />
                View on YouTube
              </a>
            </Button>
          )}
        </div>

        <div className="text-sm text-muted-foreground mt-1">ID: {videoId}</div>
      </div>

      <div className="grid gap-6 md:grid-cols-2">
        <div className="md:col-span-1 space-y-6">
          {/* Video Preview */}
          <Card>
            <CardHeader className="pb-2">
              <CardTitle className="text-base">Video Preview</CardTitle>
            </CardHeader>
            <CardContent>
              <div className="aspect-video bg-muted rounded-md overflow-hidden">
                {status === "completed" ? (
                  <video
                    src={videoUrl}
                    poster={thumbnailUrl}
                    controls
                    className="w-full h-full object-cover"
                  />
                ) : thumbnailUrl ? (
                  <img
                    src={thumbnailUrl}
                    alt={videoTitle}
                    className="w-full h-full object-cover"
                  />
                ) : (
                  <div className="w-full h-full flex items-center justify-center text-muted-foreground">
                    Processing video...
                  </div>
                )}
              </div>
            </CardContent>
          </Card>

          {/* Status Card */}
          <Card>
            <CardHeader className="pb-2">
              <div className="flex items-center justify-between">
                <CardTitle className="text-base">Processing Status</CardTitle>
                {isCompleted && (
                  <div className="flex items-center text-xs font-medium text-primary">
                    <CheckCircle className="mr-1 h-3 w-3" />
                    Complete
                  </div>
                )}
                {!isCompleted && (
                  <div className="text-xs font-medium text-muted-foreground">
                    {overallProgress}% complete
                  </div>
                )}
              </div>
            </CardHeader>
            <CardContent>
              <ProgressSteps
                steps={processingSteps}
                currentStepId={currentStepId}
              />
            </CardContent>
          </Card>
        </div>

        <div className="md:col-span-1 space-y-6">
          {/* Generated Content */}
          <Card>
            <CardHeader>
              <CardTitle className="text-base">Generated Content</CardTitle>
              <CardDescription>
                Assets created during video processing
              </CardDescription>
            </CardHeader>
            <CardContent>
              <Tabs
                value={activeContentTab}
                onValueChange={setActiveContentTab}
              >
                <TabsList className="grid grid-cols-4 mb-4">
                  <TabsTrigger value="transcript">Transcript</TabsTrigger>
                  <TabsTrigger value="subtitles">Subtitles</TabsTrigger>
                  <TabsTrigger value="chapters">Chapters</TabsTrigger>
                  <TabsTrigger value="shownotes">Shownotes</TabsTrigger>
                </TabsList>

                <TabsContent value="transcript" className="space-y-4">
                  {isCompleted ? (
                    <ContentEditor
                      content={transcript}
                      isLoading={loadingTranscript}
                      errorMessage={transcriptError || undefined}
                      onSave={onSaveContent ? handleSaveTranscript : undefined}
                      readOnly={!onSaveContent}
                      placeholder="Transcript not available"
                      maxHeight="400px"
                    />
                  ) : (
                    <div className="flex flex-col items-center justify-center py-8 text-center text-muted-foreground">
                      <p>Transcript not yet generated</p>
                      <p className="text-xs mt-1">
                        This will be available once processing is complete
                      </p>
                    </div>
                  )}
                </TabsContent>

                <TabsContent value="subtitles" className="space-y-4">
                  {isCompleted ? (
                    <ContentEditor
                      content={subtitles}
                      isLoading={loadingSubtitles}
                      errorMessage={subtitlesError || undefined}
                      onSave={onSaveContent ? handleSaveSubtitles : undefined}
                      readOnly={!onSaveContent}
                      placeholder="Subtitles not available"
                      maxHeight="400px"
                    />
                  ) : (
                    <div className="flex flex-col items-center justify-center py-8 text-center text-muted-foreground">
                      <p>Subtitles not yet generated</p>
                      <p className="text-xs mt-1">
                        This will be available once processing is complete
                      </p>
                    </div>
                  )}
                </TabsContent>

                <TabsContent value="chapters" className="space-y-4">
                  {isCompleted ? (
                    <ContentEditor
                      content={chapters}
                      isLoading={loadingChapters}
                      errorMessage={chaptersError || undefined}
                      onSave={onSaveContent ? handleSaveChapters : undefined}
                      readOnly={!onSaveContent}
                      placeholder="Chapters not available"
                      maxHeight="400px"
                    />
                  ) : (
                    <div className="flex flex-col items-center justify-center py-8 text-center text-muted-foreground">
                      <p>Chapters not yet generated</p>
                      <p className="text-xs mt-1">
                        This will be available once processing is complete
                      </p>
                    </div>
                  )}
                </TabsContent>

                <TabsContent value="shownotes" className="space-y-4">
                  {isCompleted ? (
                    <ContentEditor
                      content={shownotes}
                      isLoading={loadingShownotes}
                      errorMessage={shownotesError || undefined}
                      onSave={onSaveContent ? handleSaveShownotes : undefined}
                      readOnly={!onSaveContent}
                      placeholder="Show notes not available"
                      maxHeight="400px"
                    />
                  ) : (
                    <div className="flex flex-col items-center justify-center py-8 text-center text-muted-foreground">
                      <p>Show notes not yet generated</p>
                      <p className="text-xs mt-1">
                        This will be available once processing is complete
                      </p>
                    </div>
                  )}
                </TabsContent>
              </Tabs>
            </CardContent>
          </Card>

          {/* Download Assets */}
          {isCompleted && assets.length > 0 && (
            <Card>
              <CardHeader className="pb-2">
                <CardTitle className="text-base">Download Assets</CardTitle>
              </CardHeader>
              <CardContent>
                <ul className="divide-y">
                  {assets.map((asset, index) => (
                    <li key={index} className="py-2 first:pt-0 last:pb-0">
                      <div className="flex items-center justify-between">
                        <div className="flex items-center">
                          <asset.icon className="h-4 w-4 text-muted-foreground mr-2" />
                          <span className="text-sm">{asset.label}</span>
                          {asset.sizeKB && (
                            <span className="text-xs text-muted-foreground ml-2">
                              ({asset.sizeKB} KB)
                            </span>
                          )}
                        </div>
                        <Button variant="ghost" size="sm" asChild>
                          <a href={asset.url} download>
                            <Download className="h-4 w-4" />
                          </a>
                        </Button>
                      </div>
                    </li>
                  ))}
                </ul>
              </CardContent>
            </Card>
          )}
        </div>
      </div>
    </div>
  );
}
</file>

<file path="apps/web/app/components/video/video-progress-card.tsx">
import { Button } from "../ui/button";
import {
  Card,
  CardContent,
  CardFooter,
  CardHeader,
  CardTitle,
} from "../ui/card";
import { ProgressSteps, type Step } from "../ui/progress-steps";
import { ExternalLink, PauseIcon, PlayIcon } from "lucide-react";
import { useState } from "react";

type VideoProgressCardProps = {
  videoId: string;
  videoTitle: string;
  thumbnailUrl?: string;
  uploadedAt: Date;
  status: "processing" | "completed" | "error" | "paused";
  processingSteps: Step[];
  currentStepId?: string;
  youtubeUrl?: string;
  onPauseResume?: () => void;
  className?: string;
};

export function VideoProgressCard({
  videoId,
  videoTitle,
  thumbnailUrl,
  uploadedAt,
  status,
  processingSteps,
  currentStepId,
  youtubeUrl,
  onPauseResume,
  className,
}: VideoProgressCardProps) {
  const [isPaused, setIsPaused] = useState(status === "paused");

  const handlePauseResume = () => {
    setIsPaused(!isPaused);
    onPauseResume?.();
  };

  const formatDate = (date: Date) => {
    return new Intl.DateTimeFormat("en-US", {
      month: "short",
      day: "numeric",
      hour: "numeric",
      minute: "numeric",
    }).format(date);
  };

  return (
    <Card className={className}>
      <CardHeader className="pb-2">
        <div className="flex items-start justify-between">
          <div className="space-y-1">
            <CardTitle className="line-clamp-1 text-base">
              {videoTitle}
            </CardTitle>
            <div className="flex items-center gap-2 text-xs text-muted-foreground">
              <span>Uploaded {formatDate(uploadedAt)}</span>
              <span>•</span>
              <span>ID: {videoId.slice(0, 8)}</span>
            </div>
          </div>

          {thumbnailUrl && (
            <div className="relative h-14 w-24 overflow-hidden rounded-md shrink-0">
              <img
                src={thumbnailUrl}
                alt={videoTitle}
                className="h-full w-full object-cover"
              />
            </div>
          )}
        </div>
      </CardHeader>

      <CardContent>
        <ProgressSteps steps={processingSteps} currentStepId={currentStepId} />
      </CardContent>

      <CardFooter className="flex justify-between pt-0">
        {(status === "processing" || status === "paused") && (
          <Button variant="outline" size="sm" onClick={handlePauseResume}>
            {isPaused ? (
              <>
                <PlayIcon className="mr-1.5 h-3.5 w-3.5" />
                Resume
              </>
            ) : (
              <>
                <PauseIcon className="mr-1.5 h-3.5 w-3.5" />
                Pause
              </>
            )}
          </Button>
        )}

        {status === "completed" && youtubeUrl && (
          <Button variant="outline" size="sm" asChild>
            <a href={youtubeUrl} target="_blank" rel="noopener noreferrer">
              <ExternalLink className="mr-1.5 h-3.5 w-3.5" />
              View on YouTube
            </a>
          </Button>
        )}

        <Button variant="ghost" size="sm" asChild>
          <a href={`/video/${videoId}`}>View Details</a>
        </Button>
      </CardFooter>
    </Card>
  );
}
</file>

<file path="apps/web/app/components/video/VideoList.tsx">
import type { VideoSummary } from "~/types/api";
import { VideoListItem } from "./VideoListItem";
import { Button } from "~/components/ui/button";
import { Skeleton } from "~/components/ui/skeleton"; // For loading state
import { Alert, AlertDescription, AlertTitle } from "~/components/ui/alert"; // Added for error display

interface VideoListProps {
  videos: VideoSummary[];
  isLoading: boolean;
  error?: Error | null;
  hasNextPage?: boolean;
  isFetchingNextPage?: boolean;
  fetchNextPage?: () => void;
  showUploadButton?: boolean; // Optional: if the empty state upload button is handled here
  onTriggerUpload?: () => void; // Callback to open upload dialog
}

export function VideoList({
  videos,
  isLoading,
  error,
  hasNextPage,
  isFetchingNextPage,
  fetchNextPage,
  showUploadButton = false, // Default to false, dashboard can control its own dialog trigger
  onTriggerUpload,
}: VideoListProps) {
  if (isLoading && videos.length === 0) {
    // Initial loading state
    return (
      <div className="grid gap-6 sm:grid-cols-1 lg:grid-cols-2 xl:grid-cols-3">
        {[...Array(6)].map((_, index) => (
          <div
            key={index}
            className="rounded-lg border border-border p-4 space-y-3"
          >
            <Skeleton className="h-6 w-3/4" />
            <Skeleton className="aspect-video w-full rounded-md" />
            <Skeleton className="h-4 w-1/2" />
            <div className="flex space-x-2">
              <Skeleton className="h-8 w-24" />
            </div>
          </div>
        ))}
      </div>
    );
  }

  if (error) {
    return (
      <div className="text-center py-10">
        <Alert variant="destructive" className="max-w-md mx-auto">
          <AlertTitle>Error Loading Videos</AlertTitle>
          <AlertDescription>{error.message}</AlertDescription>
        </Alert>
      </div>
    );
  }

  if (videos.length === 0) {
    return (
      <div className="flex flex-col items-center justify-center py-20 text-center">
        <p className="text-muted-foreground mb-4">
          No videos found in your library.
        </p>
        {showUploadButton && onTriggerUpload && (
          <Button variant="outline" onClick={onTriggerUpload}>
            Upload your first video
          </Button>
        )}
      </div>
    );
  }

  return (
    <>
      <div className="grid gap-6 sm:grid-cols-1 lg:grid-cols-2 xl:grid-cols-3">
        {videos.map((video) => (
          <VideoListItem key={video.id} video={video} />
        ))}
      </div>
      {hasNextPage && fetchNextPage && (
        <div className="flex justify-center mt-6">
          <Button
            onClick={fetchNextPage}
            disabled={isFetchingNextPage || isLoading}
          >
            {isFetchingNextPage ? "Loading more..." : "Load More"}
          </Button>
        </div>
      )}
    </>
  );
}
</file>

<file path="apps/web/app/components/video/VideoListItem.tsx">
import { Link } from "@tanstack/react-router";
import type { VideoSummary } from "../../types/api";
import { Button } from "../ui/button";

interface VideoListItemProps {
  video: VideoSummary;
}

export function VideoListItem({ video }: VideoListItemProps) {
  return (
    <div
      key={video.id} // Key should be on the top-level element returned by map in VideoList
      className="group relative rounded-lg border border-border p-4 hover:border-primary transition-colors"
    >
      <div className="flex justify-between items-start mb-3">
        <h3 className="font-semibold line-clamp-1 group-hover:text-primary transition-colors">
          {video.title || "Untitled Video"}
        </h3>
        {/* TODO: Add status badge or icon here based on video.status */}
      </div>
      {video.thumbnail_file_url && (
        <Link
          to="/video/$videoId"
          params={{ videoId: String(video.id) }}
          className="block aspect-video w-full overflow-hidden rounded-md mb-3"
        >
          <img
            src={video.thumbnail_file_url}
            alt={video.title || "Video thumbnail"}
            className="w-full h-full object-cover transition-transform group-hover:scale-105"
          />
        </Link>
      )}
      <div className="mt-2 space-y-1 text-sm text-muted-foreground">
        <p>Status: {video.status || "N/A"}</p>
        {/* Can add more details like created_at, duration etc. if needed */}
      </div>
      <div className="mt-3 flex space-x-2">
        <Button variant="outline" size="sm" asChild>
          <Link to="/video/$videoId" params={{ videoId: String(video.id) }}>
            View Details
          </Link>
        </Button>
        {/* TODO: Add other actions like Edit, Delete if applicable */}
      </div>
    </div>
  );
}
</file>

<file path="apps/web/app/components/video/VideoUploadDropzone.tsx">
import React, { useRef, useState } from "react";
import {
  getSignedUploadUrl,
  notifyUploadComplete,
} from "../../lib/api"; // Import new API functions
import type {
  SignedUploadUrlRequest,
  SignedUploadUrlResponse,
  UploadCompleteRequest,
} from "../../types/api"; // Import types
import { toast } from "sonner"; // Import toast

type UploadStatus = "idle" | "requesting" | "uploading" | "finalizing" | "done" | "error";

export function VideoUploadDropzone({
  onUploadComplete: onUploadSuccess, // Renamed prop for clarity
}: {
  onUploadComplete?: (videoId: string) => void; // Pass videoId back
}) {
  const [status, setStatus] = useState<UploadStatus>("idle");
  const [error, setError] = useState<string | null>(null);
  const [progress, setProgress] = useState<number>(0);
  const inputRef = useRef<HTMLInputElement>(null);

  async function handleFile(file: File) {
    setError(null);
    setStatus("requesting");
    setProgress(0);

    let signedUrlResponse: SignedUploadUrlResponse;
    try {
      const requestData: SignedUploadUrlRequest = {
        filename: file.name,
        content_type: file.type,
      };
      signedUrlResponse = await getSignedUploadUrl(requestData);
      if (!signedUrlResponse.upload_url || !signedUrlResponse.video_id) {
        throw new Error("Invalid response from signed URL endpoint");
      }
    } catch (err: any) {
      const errorMsg = err.message || "Failed to get upload URL";
      setError(errorMsg);
      toast.error(errorMsg);
      setStatus("error");
      return;
    }

    const { upload_url: uploadUrl, video_id: videoId } = signedUrlResponse;

    // 2. Upload file to signed URL
    setStatus("uploading");
    try {
      await new Promise<void>((resolve, reject) => {
        const xhr = new XMLHttpRequest();
        xhr.open("PUT", uploadUrl);
        xhr.setRequestHeader("Content-Type", file.type);
        xhr.upload.onprogress = (e) => {
          if (e.lengthComputable) {
            setProgress(Math.round((e.loaded / e.total) * 100));
          }
        };
        xhr.onload = () => {
          if (xhr.status >= 200 && xhr.status < 300) {
            resolve();
          } else {
            reject(new Error(`Upload failed with status ${xhr.status}: ${xhr.statusText}`));
          }
        };
        xhr.onerror = () => reject(new Error("Upload failed due to network error"));
        xhr.send(file);
      });
    } catch (err: any) {
      const errorMsg = err.message || "Upload failed";
      setError(errorMsg);
      toast.error(errorMsg);
      setStatus("error");
      return;
    }

    // 3. Notify backend upload is complete
    setStatus("finalizing");
    try {
      const completeRequestData: UploadCompleteRequest = {
        video_id: videoId,
        original_filename: file.name,
        content_type: file.type,
        size_bytes: file.size,
        // storage_path can be omitted if backend infers it
      };
      await notifyUploadComplete(completeRequestData);
    } catch (err: any) {
      const errorMsg = err.message || "Failed to finalize upload";
      setError(errorMsg);
      toast.error(errorMsg);
      setStatus("error");
      return;
    }

    setStatus("done");
    setProgress(100);
    if (onUploadSuccess) onUploadSuccess(videoId); // Pass videoId on success
  }

  function onDrop(e: React.DragEvent<HTMLDivElement>) {
    e.preventDefault();
    if (status === "uploading" || status === "finalizing" || status === "requesting") return;
    if (e.dataTransfer.files && e.dataTransfer.files.length > 0) {
      handleFile(e.dataTransfer.files[0]);
    }
  }

  function onFileChange(e: React.ChangeEvent<HTMLInputElement>) {
    if (status === "uploading" || status === "finalizing" || status === "requesting") return;
    if (e.target.files && e.target.files.length > 0) {
      handleFile(e.target.files[0]);
      // Reset file input to allow uploading the same file again
      if (inputRef.current) {
        inputRef.current.value = "";
      }
    }
  }

  const isUploading = status === "requesting" || status === "uploading" || status === "finalizing";

  return (
    <div
      onDrop={onDrop}
      onDragOver={(e) => e.preventDefault()}
      style={{
        border: "2px dashed #888",
        borderRadius: 8,
        padding: 32,
        textAlign: "center",
        background: isUploading ? "#f0f0f0" : "#fafbfc",
        cursor: isUploading ? "default" : "pointer",
        opacity: isUploading ? 0.7 : 1,
        margin: "16px 0",
      }}
      onClick={() => !isUploading && inputRef.current?.click()}
      tabIndex={0}
      role="button"
      aria-label="Upload video"
      aria-disabled={isUploading}
    >
      <input
        ref={inputRef}
        type="file"
        accept="video/*"
        style={{ display: "none" }}
        onChange={onFileChange}
        disabled={isUploading}
      />
      {status === "idle" && <span>Drag & drop a video file here, or click to select</span>}
      {status === "requesting" && <span>Requesting upload permissions…</span>}
      {status === "uploading" && (
        <div>
          <span>Uploading… {progress}%</span>
          <progress
            value={progress}
            max={100}
            style={{ width: "100%", marginTop: "8px" }}
          />
        </div>
      )}
      {status === "finalizing" && <span>Finalizing upload…</span>}
      {status === "done" && <span style={{ color: "green" }}>Upload complete! Ready for processing.</span>}
      {status === "error" && (
        <span style={{ color: "red" }}>
          Error: {error}
        </span>
      )}
    </div>
  );
}

export default VideoUploadDropzone;
</file>

<file path="apps/web/app/components/auth.tsx">
export function Auth({
	actionText,
	onSubmit,
	status,
	afterSubmit,
}: {
	actionText: string;
	onSubmit: (e: React.FormEvent<HTMLFormElement>) => void;
	status: "pending" | "idle" | "success" | "error";
	afterSubmit?: React.ReactNode;
}) {
	return (
		<div className="fixed inset-0 bg-white dark:bg-black flex items-start justify-center p-8">
			<div className="bg-white dark:bg-gray-900 p-8 rounded-lg shadow-lg">
				<h1 className="text-2xl font-bold mb-4">{actionText}</h1>
				<form
					onSubmit={(e) => {
						e.preventDefault();
						onSubmit(e);
					}}
					className="space-y-4"
				>
					<div>
						<label htmlFor="email" className="block text-xs">
							Username
						</label>
						<input
							type="email"
							name="email"
							id="email"
							className="px-2 py-1 w-full rounded border border-gray-500/20 bg-white dark:bg-gray-800"
						/>
					</div>
					<div>
						<label htmlFor="password" className="block text-xs">
							Password
						</label>
						<input
							type="password"
							name="password"
							id="password"
							className="px-2 py-1 w-full rounded border border-gray-500/20 bg-white dark:bg-gray-800"
						/>
					</div>
					<button
						type="submit"
						className="w-full bg-cyan-600 text-white rounded py-2 font-black uppercase"
						disabled={status === "pending"}
					>
						{status === "pending" ? "..." : actionText}
					</button>
					{afterSubmit ? afterSubmit : null}
				</form>
			</div>
		</div>
	);
}
</file>

<file path="apps/web/app/components/button-link.tsx">
import { createLink } from "@tanstack/react-router";
import { Button } from "./ui/button";

export const ButtonLink = createLink(Button);
</file>

<file path="apps/web/app/components/default-catch-boundary.tsx">
import {
	ErrorComponent,
	Link,
	rootRouteId,
	useMatch,
	useRouter,
} from "@tanstack/react-router";
import type { ErrorComponentProps } from "@tanstack/react-router";
import * as React from "react";

export function DefaultCatchBoundary({ error }: ErrorComponentProps) {
	const router = useRouter();
	const isRoot = useMatch({
		strict: false,
		select: (state) => state.id === rootRouteId,
	});

	console.error(error);

	return (
		<div className="min-w-0 flex-1 p-4 flex flex-col items-center justify-center gap-6">
			<ErrorComponent error={error} />
			<div className="flex gap-2 items-center flex-wrap">
				<button
					onClick={() => {
						router.invalidate();
					}}
					className={
						"px-2 py-1 bg-gray-600 dark:bg-gray-700 rounded text-white uppercase font-extrabold"
					}
				>
					Try Again
				</button>
				{isRoot ? (
					<Link
						to="/"
						className={
							"px-2 py-1 bg-gray-600 dark:bg-gray-700 rounded text-white uppercase font-extrabold"
						}
					>
						Home
					</Link>
				) : (
					<Link
						to="/"
						className={
							"px-2 py-1 bg-gray-600 dark:bg-gray-700 rounded text-white uppercase font-extrabold"
						}
						onClick={(e) => {
							e.preventDefault();
							window.history.back();
						}}
					>
						Go Back
					</Link>
				)}
			</div>
		</div>
	);
}
</file>

<file path="apps/web/app/components/GoogleLoginButton.tsx">
import { Button } from "~/components/ui/button"; // Assuming shadcn/ui Button is available
import { useAuth } from "~/lib/useAuth"; // Adjusted path assuming hooks are in ../hooks

export function GoogleLoginButton() {
  const { signInWithGoogle, isLoading, error } = useAuth();

  const handleLogin = async () => {
    const result = await signInWithGoogle();
    // signInWithGoogle from useAuth already handles redirection or returns error.
    // Error will be in the `error` state from useAuth if it occurs before redirect.
    if (result.error) {
      // Optionally, display a specific toast or alert here if not handled globally
      console.error("Google Sign-In error:", result.error.message);
    }
    // If successful, navigation to Google occurs, then to callback.
  };

  return (
    <Button
      type="button"
      onClick={handleLogin}
      className="w-full bg-red-600 hover:bg-red-700 text-white font-bold uppercase flex items-center justify-center gap-2"
      aria-label="Sign in with Google"
      disabled={isLoading}
    >
      {isLoading ? (
        <>
          <svg
            className="animate-spin -ml-1 mr-3 h-5 w-5 text-white"
            xmlns="http://www.w3.org/2000/svg"
            fill="none"
            viewBox="0 0 24 24"
          >
            <circle
              className="opacity-25"
              cx="12"
              cy="12"
              r="10"
              stroke="currentColor"
              strokeWidth="4"
            ></circle>
            <path
              className="opacity-75"
              fill="currentColor"
              d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"
            ></path>
          </svg>
          Signing in...
        </>
      ) : (
        <>
          <svg
            width="20"
            height="20"
            viewBox="0 0 48 48"
            fill="none"
            xmlns="http://www.w3.org/2000/svg"
            className="mr-2"
          >
            <g>
              <path
                d="M44.5 20H24V28.5H36.9C35.5 33.1 31.2 36 24 36C16.3 36 10 29.7 10 22C10 14.3 16.3 8 24 8C27.3 8 30.1 9.1 32.3 11L38.1 5.2C34.5 2.1 29.6 0 24 0C10.7 0 0 10.7 0 24C0 37.3 10.7 48 24 48C37.3 48 48 37.3 48 24C48 22.3 47.8 20.7 47.5 19.1L44.5 20Z"
                fill="#FFC107"
              />
              <path
                d="M6.3 14.7L13.7 20.1C15.7 15.7 19.5 12.5 24 12.5C26.5 12.5 28.7 13.4 30.4 14.8L36.2 9C33.1 6.3 28.8 4.5 24 4.5C15.9 4.5 8.8 10.1 6.3 14.7Z"
                fill="#FF3D00"
              />
              <path
                d="M24 43.5C31.1 43.5 37.1 39.1 39.6 33.1L32.7 27.7C31.1 30.7 27.8 32.5 24 32.5C19.5 32.5 15.7 29.3 13.7 24.9L6.3 30.3C8.8 34.9 15.9 43.5 24 43.5Z"
                fill="#4CAF50"
              />
              <path
                d="M47.5 19.1H44.5V20H24V28.5H36.9C36.2 31 34.5 33.1 32.7 34.7L39.6 40.1C43.1 36.9 45.5 31.9 45.5 24C45.5 22.3 45.3 20.7 44.5 19.1Z"
                fill="#1976D2"
              />
            </g>
          </svg>
          Sign in with Google
        </>
      )}
      {/* Display error from useAuth if needed, though might be better handled by a global toast */}
      {/* {error && <p className="text-xs text-red-500 mt-1">Error: {error.message}</p>} */}
    </Button>
  );
}
</file>

<file path="apps/web/app/components/layout.tsx">
export const Layout = ({
  children,
  className,
}: {
  className?: string
  children: React.ReactNode
}) => {
  return (
    <main className={`flex flex-col max-w-6xl mx-auto p-4 ${className}`}>
      {children}
    </main>
  )
}
</file>

<file path="apps/web/app/components/login.tsx">
import { zodResolver } from "@hookform/resolvers/zod";
import { Link, useRouter } from "@tanstack/react-router";
import { useForm } from "react-hook-form";
import { toast } from "sonner"; // Assuming sonner is used for toasts as per Phase 5
import * as z from "zod";
import { Button } from "~/components/ui/button";
import {
  Form,
  FormControl,
  FormField,
  FormItem,
  FormLabel,
  FormMessage,
} from "~/components/ui/form";
import { Input } from "~/components/ui/input";
import { useAuth } from "../lib/useAuth";
import { GoogleLoginButton } from "./GoogleLoginButton";

const loginSchema = z.object({
  email: z.string().email({ message: "Invalid email address." }),
  password: z.string().min(1, { message: "Password is required." }),
});

type LoginFormValues = z.infer<typeof loginSchema>;

export function Login() {
  const router = useRouter();
  const {
    loginWithPassword,
    isLoading,
    error: authError,
    isInitialized,
  } = useAuth(); // `error` from useAuth renamed to `authError` to avoid conflict

  const form = useForm<LoginFormValues>({
    resolver: zodResolver(loginSchema),
    defaultValues: {
      email: "",
      password: "",
    },
  });

  const onSubmit = async (values: LoginFormValues) => {
    const { error } = await loginWithPassword({
      email: values.email,
      password: values.password,
    });

    if (error) {
      // Error is already set in `authError` state by `useAuth`
      // Optionally, show a toast for more immediate feedback if authError isn't displayed directly
      toast.error(
        error.message || "Login failed. Please check your credentials.",
      );
    } else {
      toast.success("Login successful!");
      // router.invalidate() might be needed if loader data depends on auth state
      await router.invalidate();
      router.navigate({ to: "/dashboard" }); // Navigate to dashboard as per task
    }
  };

  // Redirect if already logged in and initialized
  // This logic might be better placed in the route component or a layout
  // useEffect(() => {
  //   if (isInitialized && session) {
  //     router.navigate({ to: '/dashboard' });
  //   }
  // }, [isInitialized, session, router]);

  return (
    <div className="max-w-md mx-auto mt-8 p-6 border rounded-lg shadow-md">
      <h2 className="text-2xl font-semibold text-center mb-6">Login</h2>

      <GoogleLoginButton />

      <div className="my-4 flex items-center">
        <hr className="flex-grow border-gray-300" />
        <span className="mx-2 text-gray-500 text-xs uppercase">or</span>
        <hr className="flex-grow border-gray-300" />
      </div>

      <Form {...form}>
        <form onSubmit={form.handleSubmit(onSubmit)} className="space-y-4">
          <FormField
            control={form.control}
            name="email"
            render={({ field }) => (
              <FormItem>
                <FormLabel>Email</FormLabel>
                <FormControl>
                  <Input placeholder="your@email.com" {...field} />
                </FormControl>
                <FormMessage />
              </FormItem>
            )}
          />
          <FormField
            control={form.control}
            name="password"
            render={({ field }) => (
              <FormItem>
                <FormLabel>Password</FormLabel>
                <FormControl>
                  <Input type="password" placeholder="••••••••" {...field} />
                </FormControl>
                <FormMessage />
              </FormItem>
            )}
          />

          {authError && (
            <p className="text-sm text-red-500 text-center">
              {authError.message}
            </p>
          )}

          <Button type="submit" className="w-full" disabled={isLoading}>
            {isLoading ? (
              <>
                <svg
                  className="animate-spin -ml-1 mr-3 h-5 w-5 text-white"
                  xmlns="http://www.w3.org/2000/svg"
                  fill="none"
                  viewBox="0 0 24 24"
                >
                  <circle
                    className="opacity-25"
                    cx="12"
                    cy="12"
                    r="10"
                    stroke="currentColor"
                    strokeWidth="4"
                  ></circle>
                  <path
                    className="opacity-75"
                    fill="currentColor"
                    d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"
                  ></path>
                </svg>
                Logging in...
              </>
            ) : (
              "Login"
            )}
          </Button>
        </form>
      </Form>
      <p className="mt-6 text-center text-sm">
        Don't have an account?{" "}
        <Link to="/signup" className="font-medium text-primary hover:underline">
          Sign up
        </Link>
      </p>
    </div>
  );
}
</file>

<file path="apps/web/app/components/navigation.tsx">
import React from "react";
import { cn } from "~/lib/utils";
import {
  NavigationMenu,
  NavigationMenuContent,
  NavigationMenuItem,
  NavigationMenuLink,
  NavigationMenuList,
  NavigationMenuTrigger,
  navigationMenuTriggerStyle,
} from "./ui/navigation-menu";

export const Navigation = () => {
  return (
    <NavigationMenu>
      <NavigationMenuList>
        <NavigationMenuItem>
          <NavigationMenuLink
            className={navigationMenuTriggerStyle()}
            to="/dashboard"
          >
            Dashboard
          </NavigationMenuLink>
        </NavigationMenuItem>
        <NavigationMenuItem>
          <NavigationMenuTrigger>Account</NavigationMenuTrigger>
          <NavigationMenuContent>
            <ul className="flex flex-col gap-2 p-4 w-[350px]">
              <NavigationMenuLink to="/settings">
                <ListItem title="Settings">Manage your account settings.</ListItem>
              </NavigationMenuLink>
              <NavigationMenuLink to="/_authed/video">
                <ListItem title="Videos">
                  Access your video content.
                </ListItem>
              </NavigationMenuLink>
              <NavigationMenuLink to="/logout">
                <ListItem title="Logout">Sign out of your account.</ListItem>
              </NavigationMenuLink>
            </ul>
          </NavigationMenuContent>
        </NavigationMenuItem>
        <NavigationMenuItem>
          <NavigationMenuLink
            className={navigationMenuTriggerStyle()}
            to="/login"
          >
            Login
          </NavigationMenuLink>
        </NavigationMenuItem>
      </NavigationMenuList>
    </NavigationMenu>
  );
};

const ListItem = React.forwardRef<
  React.ElementRef<"li">,
  React.ComponentPropsWithoutRef<"li">
>(({ className, title, children, ...props }, ref) => {
  return (
    <li
      className={cn(
        "block select-none space-y-1 rounded-md p-3 leading-none no-underline outline-none transition-colors hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground",
        className,
      )}
      {...props}
    >
      <div className="text-sm font-medium leading-none">{title}</div>
      <p className="line-clamp-2 text-sm leading-snug text-muted-foreground">
        {children}
      </p>
    </li>
  );
});
ListItem.displayName = "ListItem";
</file>

<file path="apps/web/app/components/not-found.tsx">
import { Link } from '@tanstack/react-router'

export function NotFound({ children }: { children?: any }) {
  return (
    <div className="space-y-2 p-2">
      <div className="text-gray-600 dark:text-gray-400">
        {children || <p>The page you are looking for does not exist.</p>}
      </div>
      <p className="flex items-center gap-2 flex-wrap">
        <button
          onClick={() => window.history.back()}
          className="bg-emerald-500 text-white px-2 py-1 rounded uppercase font-black text-sm"
        >
          Go back
        </button>
        <Link
          to="/"
          className="bg-cyan-600 text-white px-2 py-1 rounded uppercase font-black text-sm"
        >
          Start Over
        </Link>
      </p>
    </div>
  )
}
</file>

<file path="apps/web/app/components/post-error.tsx">
import { ErrorComponent, ErrorComponentProps } from '@tanstack/react-router'

export function PostErrorComponent({ error }: ErrorComponentProps) {
  return <ErrorComponent error={error} />
}
</file>

<file path="apps/web/app/components/ProtectedLayout.tsx">
import React, { useEffect, useState } from "react";
import { useNavigate } from "@tanstack/react-router";

type ProtectedLayoutProps = {
  children: React.ReactNode;
};

export function ProtectedLayout({ children }: ProtectedLayoutProps) {
  const [loading, setLoading] = useState(true);
  const [authenticated, setAuthenticated] = useState(false);
  const navigate = useNavigate();

  useEffect(() => {
    async function checkAuth() {
      try {
        const res = await fetch("/auth/me", {
          credentials: "include",
        });
        if (res.ok) {
          setAuthenticated(true);
        } else {
          setAuthenticated(false);
          navigate({ to: "/login" });
        }
      } catch (err) {
        setAuthenticated(false);
        navigate({ to: "/login" });
      } finally {
        setLoading(false);
      }
    }
    checkAuth();
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, []);

  if (loading) {
    return <div>Loading...</div>;
  }

  if (!authenticated) {
    return null;
  }

  return <>{children}</>;
}

export default ProtectedLayout;
</file>

<file path="apps/web/app/components/user-error.tsx">
import { ErrorComponent, ErrorComponentProps } from '@tanstack/react-router'

export function UserErrorComponent({ error }: ErrorComponentProps) {
  return <ErrorComponent error={error} />
}
</file>

<file path="apps/web/app/components/user-menu.tsx">
import { useQueryClient } from "@tanstack/react-query";
import { createLink, useRouter } from "@tanstack/react-router";
import { LogOut, User } from "lucide-react";
import { useState } from "react";
import { signOut } from "~/services/auth.api";
import { useAuthenticatedUser } from "~/services/queries";
import { Avatar, AvatarFallback, AvatarImage } from "./ui/avatar";
import { Button } from "./ui/button";
import {
  DropdownMenu,
  DropdownMenuContent,
  DropdownMenuItem,
  DropdownMenuLabel,
  DropdownMenuSeparator,
  DropdownMenuTrigger,
} from "./ui/dropdown-menu";
import { Switch } from "./ui/switch";

const ItemLink = createLink(DropdownMenuItem);

export function UserMenu() {
  const router = useRouter();
  const queryClient = useQueryClient();
  const {
    data: { user },
  } = useAuthenticatedUser();
  const [open, setOpen] = useState(false);

  const handleLogout = async () => {
    await signOut();
    queryClient.resetQueries();
    router.invalidate();
  };

  return (
    <DropdownMenu open={open} onOpenChange={setOpen}>
      <DropdownMenuTrigger asChild>
        <Button variant="ghost" className="relative h-8 w-8 rounded-full">
          <Avatar className="h-8 w-8">
            <AvatarImage
              src="/placeholder.svg?height=32&width=32"
              alt="User avatar"
            />
            <AvatarFallback>
              <User className="h-4 w-4" />
            </AvatarFallback>
          </Avatar>
        </Button>
      </DropdownMenuTrigger>
      <DropdownMenuContent className="w-56" align="end" forceMount>
        <DropdownMenuLabel className="font-normal">
          <div className="flex flex-col space-y-1">
            <p className="text-sm font-medium leading-none">
              {user.meta.username ?? "User"}
            </p>
            <p className="text-xs leading-none text-muted-foreground">
              {user.email}
            </p>
          </div>
        </DropdownMenuLabel>
        <DropdownMenuSeparator />
        <ItemLink
          className="cursor-pointer"
          to="/profile"
          onClick={() => setOpen(false)}
        >
          Profile
        </ItemLink>
        <DropdownMenuSeparator />
        <DropdownMenuItem>
          <div className="flex items-center justify-between w-full">
            Dark Mode
            <Switch
              // checked={theme === "dark"}
              disabled
              //   onCheckedChange={() =>
              //     setTheme(theme === "light" ? "dark" : "light")
              //   }
            />
          </div>
        </DropdownMenuItem>
        <DropdownMenuSeparator />
        <DropdownMenuItem
          className="text-red-600 cursor-pointer"
          onSelect={handleLogout}
        >
          <LogOut className="mr-2 h-4 w-4" />
          <span>Log out</span>
        </DropdownMenuItem>
      </DropdownMenuContent>
    </DropdownMenu>
  );
}
</file>

<file path="apps/web/app/lib/api.ts">
// API fetchers for the web app

import type {
  VideoSummary,
  SignedUploadUrlRequest,
  SignedUploadUrlResponse,
  UploadCompleteRequest,
  VideoDetailsResponse,
  VideoMetadataUpdateRequest,
  ApiErrorResponse,
} from '../types/api';
import { supabase } from '@echo/db/clients/browser'; // Import Supabase client

const API_BASE_URL = import.meta.env.VITE_API_URL || "http://localhost:8000";
const API_V1_PREFIX = "/api/v1";

// Helper to get Supabase token
async function getAuthHeaders(): Promise<HeadersInit> {
  const { data: { session } } = await supabase.auth.getSession();
  const headers: HeadersInit = {
    'Content-Type': 'application/json',
  };
  if (session?.access_token) {
    headers['Authorization'] = `Bearer ${session.access_token}`;
  }
  return headers;
}

async function handleApiResponse<T>(response: Response): Promise<T> {
  if (!response.ok) {
    let errorPayload: ApiErrorResponse | string;
    try {
      errorPayload = await response.json();
    } catch (e) {
      errorPayload = await response.text();
    }
    const errorMessage = typeof errorPayload === 'string' ? errorPayload : (errorPayload as ApiErrorResponse).detail || `HTTP error ${response.status}`;
    throw new Error(`API Error: ${response.status} - ${errorMessage}`);
  }
  if (response.status === 204) { // No Content
    return undefined as T; // Or handle as appropriate for your use case
  }
  return response.json() as Promise<T>;
}

// Define PaginationParams interface
export interface PaginationParams {
  limit?: number;
  offset?: number;
  // page?: number; // Alternative, if backend uses page numbers
}

// Fetches the current user's videos from the backend API.
export async function fetchMyVideos(params?: PaginationParams): Promise<VideoSummary[]> {
  const queryParams = new URLSearchParams();
  if (params?.limit) queryParams.append('limit', String(params.limit));
  if (params?.offset) queryParams.append('offset', String(params.offset));
  // if (params?.page) queryParams.append('page', String(params.page));

  const endpoint = `${API_BASE_URL}${API_V1_PREFIX}/users/me/videos${queryParams.toString() ? '?' + queryParams.toString() : ''}`;
  const headers = await getAuthHeaders();

  const res = await fetch(endpoint, {
    method: "GET",
    headers: headers,
  });

  return handleApiResponse<VideoSummary[]>(res);
}

// Requests a pre-signed URL to upload a video directly to cloud storage.
export async function getSignedUploadUrl(
  data: SignedUploadUrlRequest
): Promise<SignedUploadUrlResponse> {
  const endpoint = `${API_BASE_URL}${API_V1_PREFIX}/videos/signed-upload-url`;
  const headers = await getAuthHeaders(); // Assuming this might need auth too
  const res = await fetch(endpoint, {
    method: "POST",
    headers: headers,
    body: JSON.stringify(data),
  });
  return handleApiResponse<SignedUploadUrlResponse>(res);
}

// Notifies the backend that a direct video upload is complete.
export async function notifyUploadComplete(
  data: UploadCompleteRequest
): Promise<void> {
  const endpoint = `${API_BASE_URL}${API_V1_PREFIX}/videos/upload-complete`;
  const headers = await getAuthHeaders();
  const res = await fetch(endpoint, {
    method: "POST",
    headers: headers,
    body: JSON.stringify(data),
  });
  return handleApiResponse<void>(res);
}

// Fetches comprehensive details for a specific video.
export async function getVideoDetails(
  videoId: string
): Promise<VideoDetailsResponse> {
  const endpoint = `${API_BASE_URL}${API_V1_PREFIX}/videos/${videoId}/details`;
  const headers = await getAuthHeaders();
  const res = await fetch(endpoint, {
    method: "GET",
    headers: headers,
  });
  return handleApiResponse<VideoDetailsResponse>(res);
}

// Updates metadata for a specific video.
export async function updateVideoMetadata(
  videoId: string,
  metadata: VideoMetadataUpdateRequest
): Promise<void> {
  const endpoint = `${API_BASE_URL}${API_V1_PREFIX}/videos/${videoId}/metadata`;
  const headers = await getAuthHeaders();
  const res = await fetch(endpoint, {
    method: "PUT",
    headers: headers,
    body: JSON.stringify(metadata),
  });
  return handleApiResponse<void>(res);
}

// Fetches the status and results of a specific processing job.
// Note: WebSocket is preferred for real-time updates, but this can be a fallback.
// Assuming VideoJob type would be defined in types/api.ts similar to VideoDetailsResponse
// For now, let's assume it returns a similar structure to VideoJob from types/api.ts
import type { VideoJobSchema as VideoJob } from '../types/api';
export async function getJobDetails(jobId: string): Promise<VideoJob> {
  const endpoint = `${API_BASE_URL}${API_V1_PREFIX}/videos/jobs/${jobId}`;
  const headers = await getAuthHeaders();
  const res = await fetch(endpoint, {
    method: "GET",
    headers: headers,
  });
  return handleApiResponse<VideoJob>(res);
}

// Fetches processing jobs for the authenticated user, optionally filtered by status.
export async function getProcessingJobs(statuses?: string[]): Promise<VideoJob[]> {
  const queryParams = new URLSearchParams();
  if (statuses && statuses.length > 0) {
    statuses.forEach(status => queryParams.append('status', status));
  }
  
  const endpoint = `${API_BASE_URL}${API_V1_PREFIX}/users/me/jobs${queryParams.toString() ? '?' + queryParams.toString() : ''}`;
  const headers = await getAuthHeaders();
  const res = await fetch(endpoint, {
    method: "GET",
    headers: headers,
  });
  return handleApiResponse<VideoJob[]>(res);
}
</file>

<file path="apps/web/app/lib/date.ts">
import { format } from "date-fns";

export const formatDateTime = (date: Date) => {
  return format(date, "yyyy-MM-dd HH:mm");
};

export const formatDate = (date: Date) => {
  return format(date, "yyyy-MM-dd");
};
</file>

<file path="apps/web/app/lib/form.ts">
import { createFormHook, createFormHookContexts } from "@tanstack/react-form";
import { SelectField } from "~/components/form/select-field";
import { SubmitButton } from "~/components/form/submit-button";
import { TextField } from "~/components/form/text-field";

export const { fieldContext, useFieldContext, formContext, useFormContext } =
  createFormHookContexts();

export const { useAppForm, withForm } = createFormHook({
  fieldComponents: {
    TextField,
    SelectField,
  },
  formComponents: {
    SubmitButton,
  },
  fieldContext,
  formContext,
});
</file>

<file path="apps/web/app/lib/types.gen.ts">
export type Json =
  | string
  | number
  | boolean
  | null
  | { [key: string]: Json | undefined }
  | Json[];

export type Database = {
  public: {
    Tables: {
      categories: {
        Row: {
          color: string | null;
          id: number;
          name: string;
        };
        Insert: {
          color?: string | null;
          id?: number;
          name: string;
        };
        Update: {
          color?: string | null;
          id?: number;
          name?: string;
        };
        Relationships: [];
      };
      communities: {
        Row: {
          created_at: string;
          homeUrl: string | null;
          id: number;
          location: string | null;
          logoUrl: string | null;
          name: string;
        };
        Insert: {
          created_at?: string;
          homeUrl?: string | null;
          id?: number;
          location?: string | null;
          logoUrl?: string | null;
          name: string;
        };
        Update: {
          created_at?: string;
          homeUrl?: string | null;
          id?: number;
          location?: string | null;
          logoUrl?: string | null;
          name?: string;
        };
        Relationships: [];
      };
      event_tag: {
        Row: {
          event: number;
          id: number;
          tag: number;
        };
        Insert: {
          event: number;
          id?: number;
          tag: number;
        };
        Update: {
          event?: number;
          id?: number;
          tag?: number;
        };
        Relationships: [
          {
            foreignKeyName: "event_tag_event_fkey";
            columns: ["event"];
            isOneToOne: false;
            referencedRelation: "events";
            referencedColumns: ["id"];
          },
          {
            foreignKeyName: "event_tag_tag_fkey";
            columns: ["tag"];
            isOneToOne: false;
            referencedRelation: "tags";
            referencedColumns: ["id"];
          },
        ];
      };
      events: {
        Row: {
          cfpClosingDate: string | null;
          cfpUrl: string | null;
          city: string | null;
          communityDraft: boolean | null;
          communityId: number | null;
          country: string | null;
          date: string | null;
          dateEnd: string | null;
          description: string | null;
          eventUrl: string | null;
          id: number;
          mode: Database["public"]["Enums"]["eventMode"] | null;
          name: string;
        };
        Insert: {
          cfpClosingDate?: string | null;
          cfpUrl?: string | null;
          city?: string | null;
          communityDraft?: boolean | null;
          communityId?: number | null;
          country?: string | null;
          date?: string | null;
          dateEnd?: string | null;
          description?: string | null;
          eventUrl?: string | null;
          id?: number;
          mode?: Database["public"]["Enums"]["eventMode"] | null;
          name: string;
        };
        Update: {
          cfpClosingDate?: string | null;
          cfpUrl?: string | null;
          city?: string | null;
          communityDraft?: boolean | null;
          communityId?: number | null;
          country?: string | null;
          date?: string | null;
          dateEnd?: string | null;
          description?: string | null;
          eventUrl?: string | null;
          id?: number;
          mode?: Database["public"]["Enums"]["eventMode"] | null;
          name?: string;
        };
        Relationships: [
          {
            foreignKeyName: "events_communityId_fkey";
            columns: ["communityId"];
            isOneToOne: false;
            referencedRelation: "communities";
            referencedColumns: ["id"];
          },
        ];
      };
      tags: {
        Row: {
          category: number;
          id: number;
          name: string;
        };
        Insert: {
          category: number;
          id?: number;
          name: string;
        };
        Update: {
          category?: number;
          id?: number;
          name?: string;
        };
        Relationships: [
          {
            foreignKeyName: "tags_category_fkey";
            columns: ["category"];
            isOneToOne: false;
            referencedRelation: "categories";
            referencedColumns: ["id"];
          },
        ];
      };
      user_community: {
        Row: {
          communityId: number;
          created_at: string;
          id: number;
          userId: string;
        };
        Insert: {
          communityId: number;
          created_at?: string;
          id?: number;
          userId: string;
        };
        Update: {
          communityId?: number;
          created_at?: string;
          id?: number;
          userId?: string;
        };
        Relationships: [
          {
            foreignKeyName: "user_community_communityId_fkey";
            columns: ["communityId"];
            isOneToOne: false;
            referencedRelation: "communities";
            referencedColumns: ["id"];
          },
        ];
      };
    };
    Views: {
      [_ in never]: never;
    };
    Functions: {
      [_ in never]: never;
    };
    Enums: {
      eventMode: "In person" | "Hybrid" | "Remote";
    };
    CompositeTypes: {
      [_ in never]: never;
    };
  };
};

type PublicSchema = Database[Extract<keyof Database, "public">];

export type Tables<
  PublicTableNameOrOptions extends
    | keyof (PublicSchema["Tables"] & PublicSchema["Views"])
    | { schema: keyof Database },
  TableName extends PublicTableNameOrOptions extends { schema: keyof Database }
    ? keyof (Database[PublicTableNameOrOptions["schema"]]["Tables"] &
        Database[PublicTableNameOrOptions["schema"]]["Views"])
    : never = never,
> = PublicTableNameOrOptions extends { schema: keyof Database }
  ? (Database[PublicTableNameOrOptions["schema"]]["Tables"] &
      Database[PublicTableNameOrOptions["schema"]]["Views"])[TableName] extends {
      Row: infer R;
    }
    ? R
    : never
  : PublicTableNameOrOptions extends keyof (PublicSchema["Tables"] &
        PublicSchema["Views"])
    ? (PublicSchema["Tables"] &
        PublicSchema["Views"])[PublicTableNameOrOptions] extends {
        Row: infer R;
      }
      ? R
      : never
    : never;

export type TablesInsert<
  PublicTableNameOrOptions extends
    | keyof PublicSchema["Tables"]
    | { schema: keyof Database },
  TableName extends PublicTableNameOrOptions extends { schema: keyof Database }
    ? keyof Database[PublicTableNameOrOptions["schema"]]["Tables"]
    : never = never,
> = PublicTableNameOrOptions extends { schema: keyof Database }
  ? Database[PublicTableNameOrOptions["schema"]]["Tables"][TableName] extends {
      Insert: infer I;
    }
    ? I
    : never
  : PublicTableNameOrOptions extends keyof PublicSchema["Tables"]
    ? PublicSchema["Tables"][PublicTableNameOrOptions] extends {
        Insert: infer I;
      }
      ? I
      : never
    : never;

export type TablesUpdate<
  PublicTableNameOrOptions extends
    | keyof PublicSchema["Tables"]
    | { schema: keyof Database },
  TableName extends PublicTableNameOrOptions extends { schema: keyof Database }
    ? keyof Database[PublicTableNameOrOptions["schema"]]["Tables"]
    : never = never,
> = PublicTableNameOrOptions extends { schema: keyof Database }
  ? Database[PublicTableNameOrOptions["schema"]]["Tables"][TableName] extends {
      Update: infer U;
    }
    ? U
    : never
  : PublicTableNameOrOptions extends keyof PublicSchema["Tables"]
    ? PublicSchema["Tables"][PublicTableNameOrOptions] extends {
        Update: infer U;
      }
      ? U
      : never
    : never;

export type Enums<
  PublicEnumNameOrOptions extends
    | keyof PublicSchema["Enums"]
    | { schema: keyof Database },
  EnumName extends PublicEnumNameOrOptions extends { schema: keyof Database }
    ? keyof Database[PublicEnumNameOrOptions["schema"]]["Enums"]
    : never = never,
> = PublicEnumNameOrOptions extends { schema: keyof Database }
  ? Database[PublicEnumNameOrOptions["schema"]]["Enums"][EnumName]
  : PublicEnumNameOrOptions extends keyof PublicSchema["Enums"]
    ? PublicSchema["Enums"][PublicEnumNameOrOptions]
    : never;

export type CompositeTypes<
  PublicCompositeTypeNameOrOptions extends
    | keyof PublicSchema["CompositeTypes"]
    | { schema: keyof Database },
  CompositeTypeName extends PublicCompositeTypeNameOrOptions extends {
    schema: keyof Database;
  }
    ? keyof Database[PublicCompositeTypeNameOrOptions["schema"]]["CompositeTypes"]
    : never = never,
> = PublicCompositeTypeNameOrOptions extends { schema: keyof Database }
  ? Database[PublicCompositeTypeNameOrOptions["schema"]]["CompositeTypes"][CompositeTypeName]
  : PublicCompositeTypeNameOrOptions extends keyof PublicSchema["CompositeTypes"]
    ? PublicSchema["CompositeTypes"][PublicCompositeTypeNameOrOptions]
    : never;
</file>

<file path="apps/web/app/lib/types.ts">
export type ObjectKeysByValueType<T, U> = {
  [K in keyof T as Required<T>[K] extends U ? K : never]: T[K];
};
</file>

<file path="apps/web/app/lib/use-mobile.ts">
import * as React from "react";

const MOBILE_BREAKPOINT = 768;

export function useIsMobile() {
	const [isMobile, setIsMobile] = React.useState<boolean | undefined>(
		undefined,
	);

	React.useEffect(() => {
		const mql = window.matchMedia(`(max-width: ${MOBILE_BREAKPOINT - 1}px)`);
		const onChange = () => {
			setIsMobile(window.innerWidth < MOBILE_BREAKPOINT);
		};
		mql.addEventListener("change", onChange);
		setIsMobile(window.innerWidth < MOBILE_BREAKPOINT);
		return () => mql.removeEventListener("change", onChange);
	}, []);

	return !!isMobile;
}
</file>

<file path="apps/web/app/lib/useAppWebSocket.ts">
import { useState, useEffect, useRef, useCallback } from 'react';
// Assuming your job status updates will have a structure.
// This should align with what the backend sends over WebSocket.
// Let's use the VideoJob type from our API types for now, or a subset.
import type { VideoJobSchema as VideoJob, ProcessingStatus } from '../types/api';
import { useAuth } from './useAuth'; // Assuming useAuth provides user and session

export interface WebSocketJobUpdate extends Partial<VideoJob> {
  job_id: number; // Ensure job_id is always present for identification
  // any other specific fields expected in a WebSocket message for job updates
  // e.g., status, progress_percentage, error_message
}

const WS_BASE_URL = import.meta.env.VITE_WS_BASE_URL || 'ws://localhost:8000'; // Example, ensure this is in your .env

export type WebSocketStatus = 'connecting' | 'open' | 'closing' | 'closed' | 'uninstantiated';

interface UseAppWebSocketOptions {
  onOpen?: (event: Event) => void;
  onMessage?: (event: MessageEvent) => void;
  onError?: (event: Event) => void;
  onClose?: (event: CloseEvent) => void;
  reconnectLimit?: number;
  reconnectIntervalMs?: number;
  // Path to append after WS_BASE_URL, e.g., /ws/jobs/status/
  // If it needs dynamic parts like user_id, the hook will append it.
  path?: string;
}

interface UseAppWebSocketReturn {
  sendJsonMessage: (data: any) => void;
  lastJsonMessage: any | null;
  connectionStatus: WebSocketStatus;
  isConnected: boolean;
  socketRef: React.MutableRefObject<WebSocket | null>;
}

export function useAppWebSocket(options?: UseAppWebSocketOptions): UseAppWebSocketReturn {
  const { session, user } = useAuth();
  const [lastJsonMessage, setLastJsonMessage] = useState<any | null>(null);
  const [connectionStatus, setConnectionStatus] = useState<WebSocketStatus>('uninstantiated');
  const socketRef = useRef<WebSocket | null>(null);
  const reconnectAttemptsRef = useRef<number>(0);

  const {
    onOpen,
    onMessage,
    onError,
    onClose,
    reconnectLimit = 5,
    reconnectIntervalMs = 3000,
    path = '/ws/jobs/status/' // Default path, user_id will be appended
  } = options || {};

  const connect = useCallback(async () => {
    if (socketRef.current && socketRef.current.readyState === WebSocket.OPEN) {
      return; // Already connected
    }
    if (!session?.access_token || !user?.id) {
      console.log('WebSocket: No session or user ID, not connecting.');
      setConnectionStatus('closed'); // Or some other appropriate status
      return;
    }

    setConnectionStatus('connecting');

    const wsUrl = `${WS_BASE_URL.replace(/^http/, 'ws')}${path}${user.id}?token=${session.access_token}`;

    try {
      const socket = new WebSocket(wsUrl);
      socketRef.current = socket;

      socket.onopen = (event) => {
        console.log('WebSocket: Connection opened');
        setConnectionStatus('open');
        reconnectAttemptsRef.current = 0; // Reset reconnect attempts on successful open
        if (onOpen) onOpen(event);
      };

      socket.onmessage = (event) => {
        try {
          const message = JSON.parse(event.data);
          setLastJsonMessage(message);
          if (onMessage) onMessage(event); // Pass the raw event too
        } catch (e) {
          console.error('WebSocket: Error parsing JSON message', e);
          // Handle non-JSON messages or pass raw data if needed
          if (onMessage) onMessage(event);
        }
      };

      socket.onerror = (event) => {
        console.error('WebSocket: Error', event);
        setConnectionStatus('closed'); // Or a specific error status
        if (onError) onError(event);
        // Reconnect logic will be triggered by onclose
      };

      socket.onclose = (event) => {
        console.log(`WebSocket: Connection closed (code: ${event.code}, reason: ${event.reason})`);
        setConnectionStatus('closed');
        if (onClose) onClose(event);

        // Reconnect logic
        if (reconnectAttemptsRef.current < reconnectLimit) {
          reconnectAttemptsRef.current++;
          console.log(`WebSocket: Attempting to reconnect (${reconnectAttemptsRef.current}/${reconnectLimit})...`);
          setTimeout(connect, reconnectIntervalMs);
        } else {
          console.log('WebSocket: Reconnect limit reached.');
        }
      };
    } catch (err) {
      console.error('WebSocket: Instantiation failed', err);
      setConnectionStatus('closed'); // Or a specific error status
    }
  }, [session, user, onOpen, onMessage, onError, onClose, reconnectLimit, reconnectIntervalMs, path]);

  useEffect(() => {
    if (session?.access_token && user?.id) {
      connect();
    } else {
      // If no session, ensure any existing socket is closed
      if (socketRef.current) {
        socketRef.current.close(1000, 'User logged out or session expired');
        socketRef.current = null;
      }
      setConnectionStatus('closed');
    }

    return () => {
      if (socketRef.current) {
        console.log('WebSocket: Cleaning up connection.');
        // Prevent reconnect attempts on component unmount
        reconnectAttemptsRef.current = reconnectLimit + 1;
        socketRef.current.close(1000, 'Component unmounted');
        socketRef.current = null;
      }
    };
  }, [session, user, connect, reconnectLimit]); // connect is stable due to useCallback with its own deps

  const sendJsonMessage = useCallback((data: any) => {
    if (socketRef.current && socketRef.current.readyState === WebSocket.OPEN) {
      try {
        socketRef.current.send(JSON.stringify(data));
      } catch (e) {
        console.error("WebSocket: Error sending JSON message", e);
      }
    } else {
      console.warn("WebSocket: Connection not open. Message not sent.", data);
    }
  }, []);

  return {
    sendJsonMessage,
    lastJsonMessage,
    connectionStatus,
    isConnected: connectionStatus === 'open',
    socketRef,
  };
}
</file>

<file path="apps/web/app/lib/useAuth.ts">
import { useState, useEffect, useCallback } from 'react';
import { supabase } from '@echo/db/clients/browser';
import type { AuthError, Session, User, SignInWithPasswordCredentials, SignUpWithPasswordCredentials, AuthChangeEvent, OAuthResponse, UserResponse } from '@supabase/supabase-js';

interface UseAuthState {
  user: User | null;
  session: Session | null;
  isLoading: boolean;
  error: AuthError | null;
  isInitialized: boolean; // To track if the initial auth state has been loaded
}

interface UseAuthActions {
  loginWithPassword: (credentials: SignInWithPasswordCredentials) => Promise<{ error: AuthError | null }>;
  signUpWithEmailPassword: (credentials: SignUpWithPasswordCredentials) => Promise<{ error: AuthError | null }>;
  signOut: () => Promise<{ error: AuthError | null }>;
  signInWithGoogle: () => Promise<OAuthResponse>;
}

export function useAuth(): UseAuthState & UseAuthActions {
  const [user, setUser] = useState<User | null>(null);
  const [session, setSession] = useState<Session | null>(null);
  const [isLoading, setIsLoading] = useState<boolean>(false); // For active operations like login/signup
  const [error, setError] = useState<AuthError | null>(null);
  const [isInitialized, setIsInitialized] = useState<boolean>(false); // Tracks initial auth state check

  useEffect(() => {
    setIsLoading(true);
    supabase.auth.getSession().then(({ data, error }: { data: { session: Session | null }, error: AuthError | null }) => {
      if (error) {
        console.error('Error getting initial session:', error);
        setError(error);
      }
      setSession(data.session);
      setUser(data.session?.user ?? null);
      setIsInitialized(true);
      setIsLoading(false);
    });

    const { data: authListenerData } = supabase.auth.onAuthStateChange(
      async (event: AuthChangeEvent, newSession: Session | null) => {
        setSession(newSession);
        setUser(newSession?.user ?? null);
        setError(null);
        setIsInitialized(true);
        setIsLoading(false);
      }
    );

    return () => {
      authListenerData.subscription.unsubscribe();
    };
  }, []);

  const handleAuthOperation = useCallback(
    async (authPromiseFactory: () => Promise<{ data?: any; error: AuthError | null }>) => {
      setIsLoading(true);
      setError(null);
      try {
        const { error: opError } = await authPromiseFactory();
        if (opError) {
          setError(opError);
          return { error: opError };
        }
        // Session and user state will be updated by onAuthStateChange listener
        return { error: null };
      } catch (e: any) {
        const err = { name: 'AuthOperationError', message: e.message || 'An unknown error occurred' } as AuthError;
        setError(err);
        return { error: err };
      } finally {
        setIsLoading(false);
      }
    },
    []
  );

  const loginWithPassword = useCallback(
    async (credentials: SignInWithPasswordCredentials) => {
      return handleAuthOperation(() => supabase.auth.signInWithPassword(credentials));
    },
    [handleAuthOperation]
  );

  const signUpWithEmailPassword = useCallback(
    async (credentials: SignUpWithPasswordCredentials) => {
      return handleAuthOperation(() => supabase.auth.signUp(credentials));
    },
    [handleAuthOperation]
  );

  const signOut = useCallback(async () => {
    return handleAuthOperation(() => supabase.auth.signOut());
  }, [handleAuthOperation]);

  const signInWithGoogle = useCallback(async (): Promise<OAuthResponse> => {
    setIsLoading(true);
    setError(null);
    const result = await supabase.auth.signInWithOAuth({
        provider: 'google',
        options: {
            redirectTo: `${window.location.origin}/auth/callback`,
        },
    });
    
    if (result.error) {
        setError(result.error);
        setIsLoading(false);
    }
    return result; 
  }, []);


  return { user, session, isLoading, error, isInitialized, loginWithPassword, signUpWithEmailPassword, signOut, signInWithGoogle };
}
</file>

<file path="apps/web/app/lib/useDebounce.ts">
import { useEffect, useState } from "react";

export const useDebounce = (value: any, time: number = 200) => {
  const [debouncedValue, setDebouncedValue] = useState(value);

  useEffect(() => {
    const handler = setTimeout(() => {
      setDebouncedValue(value);
    }, time);

    return () => {
      clearTimeout(handler);
    };
  }, [value, time]);

  return debouncedValue;
};
</file>

<file path="apps/web/app/lib/useJobStatus.ts">
import { useState, useEffect, useRef } from 'react';
import { useQueryClient } from '@tanstack/react-query';
import { useAppWebSocket } from './useAppWebSocket';
import { supabase } from '@echo/db';
import type { Session, AuthChangeEvent } from '@supabase/supabase-js';
import type { VideoJobSchema as VideoJob, ProcessingStatus, VideoSummary, WebSocketJobUpdate } from '../types/api';

export function useJobStatusManager() {
  const queryClient = useQueryClient();
  const [currentSession, setCurrentSession] = useState<Session | null>(null);
  const prevUserIdRef = useRef<string | null>(null);

  useEffect(() => {
    supabase.auth.getSession().then(({ data }: { data: { session: Session | null } }) => {
      setCurrentSession(data.session);
      const currentUserId = data.session?.user?.id ?? null;
      if (currentUserId) {
        console.log("JobStatusManager: Initial session found, user ID:", currentUserId);
      } else {
        console.log("JobStatusManager: No initial session found.");
      }
      prevUserIdRef.current = currentUserId;
    });

    const { data: authListenerData } = supabase.auth.onAuthStateChange(
      (_event: AuthChangeEvent, session: Session | null) => {
        setCurrentSession(session);
        const newUserId = session?.user?.id ?? null;
        if (newUserId) {
          console.log("JobStatusManager: Auth state changed, new user ID:", newUserId);
        } else {
          console.log("JobStatusManager: Auth state changed, user logged out or no session.");
        }
        prevUserIdRef.current = newUserId;
      }
    );

    return () => {
      authListenerData.subscription.unsubscribe();
    };
  }, []);

  const handleTypedWebSocketMessage = (wsUpdateData: WebSocketJobUpdate) => {
    console.log("JobStatusManager: Received parsed job update via WebSocket", wsUpdateData);

    if (!wsUpdateData.job_id) {
        console.warn("JobStatusManager: WebSocket update missing job_id, skipping cache update.", wsUpdateData);
        return;
    }

    const jobDetailsQueryKey = ['jobDetails', String(wsUpdateData.job_id)];
    queryClient.setQueryData<VideoJob | undefined>(
      jobDetailsQueryKey,
      (oldData) => {
        if (oldData) {
          const updatedData = { ...oldData, ...wsUpdateData };
          return updatedData as VideoJob;
        }
        return oldData;
      }
    );

    const myVideosQueryKey = ['myVideos'];
    queryClient.setQueryData<VideoSummary[] | undefined>(
      myVideosQueryKey,
      (oldVideoList) => {
        if (!oldVideoList) return undefined;
        return oldVideoList.map(videoSummary => {
          if (wsUpdateData.video_id && videoSummary.id === wsUpdateData.video_id) {
            const newStatus = wsUpdateData.status as ProcessingStatus | undefined;
            return {
              ...videoSummary,
              status: newStatus || videoSummary.status,
              title: wsUpdateData.title ?? videoSummary.title,
            };
          }
          return videoSummary;
        });
      }
    );
    console.log(`JobStatusManager: Updated cache for job ${wsUpdateData.job_id} and potentially related lists.`);
  };

  const { isConnected, lastJsonMessage } = useAppWebSocket({
    onOpen: () => console.log("JobStatusManager: WebSocket connection established."),
    onClose: (event) => console.log("JobStatusManager: WebSocket connection closed.", event),
    onError: (event) => console.error("JobStatusManager: WebSocket error.", event),
  });

  useEffect(() => {
    if (lastJsonMessage) {
        if (typeof lastJsonMessage === 'object' && lastJsonMessage !== null && ('job_id' in lastJsonMessage || 'video_id' in lastJsonMessage)) {
            const updateData = lastJsonMessage as WebSocketJobUpdate; 
            handleTypedWebSocketMessage(updateData);
        } else {
            console.warn("JobStatusManager: Received WebSocket message of unexpected shape:", lastJsonMessage);
        }
    }
  }, [lastJsonMessage]);

  useEffect(() => {
    const currentUserId = prevUserIdRef.current;
    if (currentUserId) {
      console.log(`JobStatusManager: Active for user ${currentUserId}. WebSocket connected: ${isConnected}`);
    } else {
      console.log("JobStatusManager: Waiting for user ID to be determined. WebSocket connected: ${isConnected}");
    }
  }, [isConnected]);

  return { isWebSocketConnected: isConnected, currentUserId: prevUserIdRef.current, session: currentSession };
}
</file>

<file path="apps/web/app/lib/useJobStatusManager.ts">
import { useState, useEffect, useRef } from 'react';
import { useQueryClient } from '@tanstack/react-query';
import { useAppWebSocket } from './useAppWebSocket';
import { supabase } from '@echo/db';
import type { Session, AuthChangeEvent } from '@supabase/supabase-js';
// VideoSummary was re-added, VideoJobSchema aliased to VideoJob, WebSocketJobUpdate removed from this import
import type { VideoJobSchema as VideoJob, ProcessingStatus, VideoSummary } from '../types/api'; 

// Define WebSocketJobUpdate locally
// It represents the expected shape of job update messages from the WebSocket.
// Ensures job_id is present for targeting cache updates, video_id for lists.
export type WebSocketJobUpdate = Partial<VideoJob> & { 
  job_id: number; 
  video_id?: number; 
  // Include any other fields that are guaranteed or essential in a WS message for job updates.
  // For example, if status is always sent for an update:
  // status?: ProcessingStatus;
};

export function useJobStatusManager() {
  const queryClient = useQueryClient();
  const [currentSession, setCurrentSession] = useState<Session | null>(null);
  const prevUserIdRef = useRef<string | null>(null);

  useEffect(() => {
    supabase.auth.getSession().then(({ data }: { data: { session: Session | null } }) => {
      setCurrentSession(data.session);
      const currentUserId = data.session?.user?.id ?? null;
      if (currentUserId) {
        console.log("JobStatusManager: Initial session found, user ID:", currentUserId);
      } else {
        console.log("JobStatusManager: No initial session found.");
      }
      prevUserIdRef.current = currentUserId;
    });

    const { data: authListenerData } = supabase.auth.onAuthStateChange(
      (_event: AuthChangeEvent, session: Session | null) => {
        setCurrentSession(session);
        const newUserId = session?.user?.id ?? null;
        if (newUserId) {
          console.log("JobStatusManager: Auth state changed, new user ID:", newUserId);
        } else {
          console.log("JobStatusManager: Auth state changed, user logged out or no session.");
        }
        prevUserIdRef.current = newUserId;
      }
    );

    return () => {
      authListenerData.subscription.unsubscribe();
    };
  }, []);

  const handleTypedWebSocketMessage = (wsUpdateData: WebSocketJobUpdate) => {
    console.log("JobStatusManager: Received parsed job update via WebSocket", wsUpdateData);

    if (!wsUpdateData.job_id) {
        console.warn("JobStatusManager: WebSocket update missing job_id, skipping cache update.", wsUpdateData);
        return;
    }

    const jobDetailsQueryKey = ['jobDetails', String(wsUpdateData.job_id)];
    queryClient.setQueryData<VideoJob | undefined>(
      jobDetailsQueryKey,
      (oldData) => {
        if (oldData) {
          const updatedData = { ...oldData, ...wsUpdateData };
          // Ensure all fields from VideoJob are potentially present if wsUpdateData is partial
          // This is a bit simplistic; a more robust merge might be needed depending on data structure
          return updatedData as VideoJob;
        }
        // If the job details were not already cached, we might not want to create it here,
        // or we might want to fetch it if it's a new job we should know about.
        // For now, only update if existing.
        return oldData; 
      }
    );

    const myVideosQueryKey = ['myVideos'];
    queryClient.setQueryData<VideoSummary[] | undefined>(
      myVideosQueryKey,
      (oldVideoList) => {
        if (!oldVideoList) return undefined;
        return oldVideoList.map(videoSummary => {
          // Assuming video_id is present in wsUpdateData if it's relevant to a video entry
          if (wsUpdateData.video_id && videoSummary.id === wsUpdateData.video_id) {
            const newStatus = wsUpdateData.status as ProcessingStatus | undefined; // Type assertion
            return {
              ...videoSummary,
              // Only update fields that are present in the WebSocket update
              ...(wsUpdateData.metadata?.title && { title: wsUpdateData.metadata.title }),
              ...(newStatus && { status: newStatus }),
              // Add other relevant fields from VideoSummary that might be updated
            };
          }
          return videoSummary;
        });
      }
    );

    const processingJobsQueryKey = ['processingJobs'];
    queryClient.setQueryData<VideoJob[] | undefined>(
      processingJobsQueryKey,
      (oldData) => {
        if (!oldData) return undefined; // If no cache exists, do nothing or consider fetching

        const jobExists = oldData.some(job => job.id === wsUpdateData.job_id);
        
        if (jobExists) {
          return oldData.map(job => {
            if (job.id === wsUpdateData.job_id) {
              // Merge existing job data with update
              // Ensure status is correctly typed if present in wsUpdateData
              const updatedJob = { ...job, ...wsUpdateData };
              if (wsUpdateData.status) {
                updatedJob.status = wsUpdateData.status as ProcessingStatus;
              }
              return updatedJob;
            }
            return job;
          });
        } else {
          // If the job is new and its status implies it should be on the processing dashboard
          // (e.g., PENDING, PROCESSING), add it to the list.
          // This requires wsUpdateData to be a more complete representation of a VideoJob.
          // For now, we'll assume if it's a new job_id, we might want to add it if it's a full object.
          // This might need refinement based on what data the WS sends for "new" jobs.
          if (wsUpdateData.status && (wsUpdateData.status === "PENDING" || wsUpdateData.status === "PROCESSING")) {
             // We need to be careful about partial updates vs full new job objects.
             // Let's assume wsUpdateData could be a full new job if it's not in oldData.
             // The type WebSocketJobUpdate is Partial<VideoJob>, so we need to ensure
             // that if we add it, it has all necessary fields for a VideoJob.
             // This part is tricky without knowing the exact WS message contents for new jobs.
             // A safer approach for "new" jobs might be to invalidate the query and let it refetch,
             // or ensure the WS sends the full job object.
             // For now, let's try to add it if it has a status.
             // This cast might be unsafe if wsUpdateData is truly partial.
            return [...oldData, wsUpdateData as VideoJob];
          }
        }
        return oldData;
      }
    );

    console.log(`JobStatusManager: Updated cache for job ${wsUpdateData.job_id} and relevant lists (processingJobs, myVideos).`);
  };

  const { isConnected, lastJsonMessage } = useAppWebSocket({
    onOpen: () => console.log("JobStatusManager: WebSocket connection established."),
    onClose: (event) => console.log("JobStatusManager: WebSocket connection closed.", event),
    onError: (event) => console.error("JobStatusManager: WebSocket error.", event),
  });

  useEffect(() => {
    if (lastJsonMessage) {
        // Validate the structure of the message more carefully
        if (typeof lastJsonMessage === 'object' && 
            lastJsonMessage !== null && 
            'job_id' in lastJsonMessage &&
            typeof (lastJsonMessage as any).job_id === 'number' // Ensure job_id is a number
            // Potentially add more checks if other fields are critical for routing/typing
            ) {
            const updateData = lastJsonMessage as WebSocketJobUpdate; 
            handleTypedWebSocketMessage(updateData);
        } else {
            console.warn("JobStatusManager: Received WebSocket message of unexpected shape or missing/invalid job_id:", lastJsonMessage);
        }
    }
  }, [lastJsonMessage, queryClient]); // Added queryClient to dependencies of useEffect if it's used in handleTypedWebSocketMessage through closure

  useEffect(() => {
    const currentUserId = prevUserIdRef.current;
    if (currentUserId) {
      console.log(`JobStatusManager: Active for user ${currentUserId}. WebSocket connected: ${isConnected}`);
    } else {
      console.log(`JobStatusManager: Waiting for user ID to be determined. WebSocket connected: ${isConnected}`);
    }
  }, [isConnected]); // Removed prevUserIdRef.current from deps as it's a ref.

  return { isWebSocketConnected: isConnected, currentUserId: prevUserIdRef.current, session: currentSession };
}
</file>

<file path="apps/web/app/lib/useMutation.ts">
import * as React from "react";

export function useMutation<TVariables, TData, TError = Error>(opts: {
	fn: (variables: TVariables) => Promise<TData>;
	onSuccess?: (ctx: { data: TData }) => void | Promise<void>;
}) {
	const [submittedAt, setSubmittedAt] = React.useState<number | undefined>();
	const [variables, setVariables] = React.useState<TVariables | undefined>();
	const [error, setError] = React.useState<TError | undefined>();
	const [data, setData] = React.useState<TData | undefined>();
	const [status, setStatus] = React.useState<
		"idle" | "pending" | "success" | "error"
	>("idle");

	const mutate = React.useCallback(
		async (variables: TVariables): Promise<TData | undefined> => {
			setStatus("pending");
			setSubmittedAt(Date.now());
			setVariables(variables);
			//
			try {
				const data = await opts.fn(variables);
				await opts.onSuccess?.({ data });
				setStatus("success");
				setError(undefined);
				setData(data);
				return data;
			} catch (err: any) {
				setStatus("error");
				setError(err);
			}
		},
		[opts.fn],
	);

	return {
		status,
		variables,
		submittedAt,
		mutate,
		error,
		data,
	};
}
</file>

<file path="apps/web/app/lib/utils.ts">
import { clsx, type ClassValue } from "clsx";
import { twMerge } from "tailwind-merge";

export function cn(...inputs: ClassValue[]) {
  return twMerge(clsx(inputs));
}

export async function sleep(ms: number) {
  return new Promise((resolve) => setTimeout(resolve, ms));
}

export function getColorFromName(name: string) {
  const colors = [
    "bg-red-400",
    "bg-orange-400",
    "bg-yellow-400",
    "bg-green-400",
    "bg-teal-400",
    "bg-blue-400",
    "bg-indigo-400",
    "bg-purple-400",
    "bg-pink-400",
    "bg-lime-400",
    "bg-emerald-400",
    "bg-cyan-400",
    "bg-sky-400",
    "bg-violet-400",
    "bg-fuchsia-400",
    "bg-rose-400",
    "bg-amber-400",
    "bg-green-300",
    "bg-blue-300",
    "bg-purple-300",
  ];

  let index = 0;
  if (name.length > 0) {
    let code = 0;
    for (let i = 0; i < 3 && i < name.length; i++) {
      code += name.charCodeAt(i) + name.charCodeAt(name.length - 1 - i);
    }

    index = code + name.length;
  }

  return colors[index % colors.length];
}

export function getFirstSunday(year: number, month: number): Date {
  const firstDayOfMonth = new Date(year, month - 1, 1);
  const dayOfWeek = firstDayOfMonth.getDay(); // 0 (Sunday) to 6 (Saturday)

  let diff = 0;
  if (dayOfWeek !== 0) {
    diff = -dayOfWeek;
  }

  const firstSunday = new Date(year, month - 1, 1 + diff);
  return firstSunday;
}

export function getLastSaturday(year: number, month: number): Date {
  const lastDayOfMonth = new Date(year, month, 0);
  const dayOfWeek = lastDayOfMonth.getDay(); // 0 (Sunday) to 6 (Saturday)

  let diff = 6 - dayOfWeek;

  const lastSaturday = new Date(
    year,
    month - 1,
    lastDayOfMonth.getDate() + diff,
  );
  return lastSaturday;
}

export function getFirstAndLast(
  year: number,
  month: number,
): { firstSunday: Date; lastSaturday: Date } {
  const firstSunday = getFirstSunday(year, month);
  const lastSaturday = getLastSaturday(year, month);

  return { firstSunday, lastSaturday };
}
</file>

<file path="apps/web/app/routes/auth/callback.tsx">
import { createFileRoute, useNavigate } from "@tanstack/react-router";
import { useEffect } from "react";
import { toast } from "sonner";
import { useAuth } from "~/lib/useAuth"; // Assuming path to useAuth hook

export const Route = createFileRoute("/auth/callback")({
  component: AuthCallbackComponent,
});

function AuthCallbackComponent() {
  const navigate = useNavigate();
  const { session, error: authError, isLoading, isInitialized } = useAuth();

  useEffect(() => {
    if (!isInitialized) {
      // Still waiting for useAuth to initialize and process the auth state
      return;
    }

    if (authError) {
      toast.error(
        authError.message || "Authentication failed. Please try again.",
      );
      navigate({ to: "/login", replace: true });
    } else if (session) {
      toast.success("Successfully signed in!");
      navigate({ to: "/dashboard", replace: true });
    } else {
      // This case might occur if the callback was invalid or already processed,
      // and no session was established, and no explicit error was thrown by useAuth from the callback processing.
      toast.error("Could not establish a session. Please log in.");
      navigate({ to: "/login", replace: true });
    }
  }, [session, authError, isLoading, isInitialized, navigate]);

  // Display a user-friendly loading message
  return (
    <div className="flex flex-col items-center justify-center min-h-screen p-4 text-center">
      <svg
        className="animate-spin h-12 w-12 text-primary mb-4"
        xmlns="http://www.w3.org/2000/svg"
        fill="none"
        viewBox="0 0 24 24"
      >
        <circle
          className="opacity-25"
          cx="12"
          cy="12"
          r="10"
          stroke="currentColor"
          strokeWidth="4"
        ></circle>
        <path
          className="opacity-75"
          fill="currentColor"
          d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"
        ></path>
      </svg>
      <h2 className="text-2xl font-semibold mb-2">
        Processing Authentication...
      </h2>
      <p className="text-gray-600">
        Please wait while we securely sign you in. You will be redirected
        shortly.
      </p>
    </div>
  );
}
</file>

<file path="apps/web/app/routes/__root.tsx">
import type { QueryClient } from "@tanstack/react-query"
import {
  HeadContent,
  Outlet,
  Scripts,
  createRootRouteWithContext,
} from "@tanstack/react-router"
import * as React from "react"
import { Header } from "~/components/header"
import { Toaster } from "~/components/ui/sonner"
// @ts-expect-error
import css from "~/globals.css?url"
import { authQueries } from "~/services/queries"

export const Route = createRootRouteWithContext<{
  queryClient: QueryClient
}>()({
  beforeLoad: async ({ context }) => {
    const authState = await context.queryClient.ensureQueryData(
      authQueries.user(),
    )

    return { authState }
  },
  head: () => ({
    meta: [
      {
        charSet: "utf-8",
      },
      {
        name: "viewport",
        content: "width=device-width, initial-scale=1",
      },
      {
        title: "ConfHub!",
      },
    ],
    links: [
      {
        rel: "stylesheet",
        href: css,
      },
      {
        rel: "icon",
        type: "image/png",
        href: "/favicon.png",
      },
    ],
  }),
  component: RootComponent,
})

function RootComponent() {
  return (
    <RootDocument>
      <Outlet />
    </RootDocument>
  )
}

const TanStackRouterDevtools =
  process.env.NODE_ENV === "production"
    ? () => null
    : React.lazy(() =>
      import("@tanstack/router-devtools").then((res) => ({
        default: res.TanStackRouterDevtools,
      })),
    )

function RootDocument({ children }: { children: React.ReactNode }) {
  return (
    <html>
      <head>
        <HeadContent />
      </head>
      <body>
        <Header />
        <hr />
        {children}
        <Scripts />
        <Toaster />
        <React.Suspense>
          <TanStackRouterDevtools />
        </React.Suspense>
      </body>
    </html>
  )
}
</file>

<file path="apps/web/app/routes/_authed.jobs.$jobId.tsx">
import { createFileRoute, useParams } from "@tanstack/react-router";
import { useQuery } from "@tanstack/react-query";
import { getJobDetails } from "~/lib/api"; // Corrected: Import specific function
import { Badge } from "~/components/ui/badge";
import {
  Card,
  CardContent,
  CardHeader,
  CardTitle,
  CardDescription,
} from "~/components/ui/card";
import { Alert, AlertDescription, AlertTitle } from "~/components/ui/alert";
import { Skeleton } from "~/components/ui/skeleton";
import { formatDistanceToNow } from "date-fns";

export const Route = createFileRoute("/_authed/jobs/$jobId")({
  component: JobDetailsPage,
});

function JobDetailsPage() {
  const { jobId } = useParams({ from: Route.id });

  const {
    data: jobDetails,
    isLoading,
    error,
    isError,
  } = useQuery({
    queryKey: ["jobDetails", jobId],
    queryFn: () => getJobDetails(jobId), // Corrected: Use imported function directly
    // ... (rest of useQuery options)
  });

  if (isLoading) {
    return (
      <div className="container mx-auto p-4">
        <Card>
          <CardHeader>
            <div className="flex justify-between items-center mb-2">
              <Skeleton className="h-8 w-1/2" /> {/* Job ID Title */}
              <Skeleton className="h-6 w-24" /> {/* Status Badge */}
            </div>
            <Skeleton className="h-4 w-3/4" /> {/* Description */}
          </CardHeader>
          <CardContent className="space-y-6">
            {/* Video Information Section Skeleton */}
            <div>
              <Skeleton className="h-6 w-1/3 mb-2" /> {/* Section Title */}
              <Skeleton className="h-4 w-full mb-1" /> {/* Video ID line */}
              <Skeleton className="h-4 w-3/4" /> {/* Filename line */}
            </div>
            {/* Job Progress/Stages Section Skeleton */}
            <div>
              <Skeleton className="h-6 w-1/3 mb-2" /> {/* Section Title */}
              <Skeleton className="h-16 w-full" />{" "}
              {/* Placeholder for stages/status text */}
            </div>
            {/* Timestamps Section Skeleton */}
            <div>
              <Skeleton className="h-6 w-1/3 mb-2" /> {/* Section Title */}
              <Skeleton className="h-4 w-full mb-1" /> {/* Created at line */}
              <Skeleton className="h-4 w-3/4" /> {/* Updated at line */}
            </div>
            {/* Potential Error Details Section Skeleton (optional, shows if error part visible) */}
            {/* No explicit skeleton for error_message as it only appears if there is an error,
                which wouldn't be the case during isLoading. But if it were a default visible section:
            <div>
              <Skeleton className="h-6 w-1/3 mb-2 text-destructive" />
              <Skeleton className="h-10 w-full" />
            </div>
            */}
          </CardContent>
        </Card>
      </div>
    );
  }

  if (isError || !jobDetails) {
    return (
      <div className="container mx-auto p-4">
        <Alert variant="destructive">
          <AlertTitle>Error</AlertTitle>
          <AlertDescription>
            {error?.message ||
              "Failed to load job details. The job may not exist or an error occurred."}
          </AlertDescription>
        </Alert>
      </div>
    );
  }

  const {
    id,
    video_id,
    status,
    processing_stages,
    created_at,
    updated_at,
    error_message,
    video, // Assuming 'video' object is part of VideoJobSchema and contains original_filename
  } = jobDetails;

  const getStatusVariant = (currentStatus: string) => {
    switch (currentStatus.toUpperCase()) {
      case "COMPLETED":
        return "default"; // Corrected: Use 'default' for success, can be styled green via CSS
      case "FAILED":
        return "destructive";
      case "PROCESSING":
        return "default"; // Or 'secondary' if 'default' is used for COMPLETED with specific styling
      case "PENDING":
        return "secondary";
      default:
        return "outline";
    }
  };

  const videoFilename = video?.original_filename || "N/A";
  const lastUpdatedText = updated_at
    ? formatDistanceToNow(new Date(updated_at), { addSuffix: true })
    : "N/A";
  const createdAtText = created_at
    ? new Date(created_at).toLocaleString()
    : "N/A";

  return (
    <div className="container mx-auto p-4">
      <Card>
        <CardHeader>
          <CardTitle className="flex justify-between items-center">
            <span>Job ID: {id}</span>
            <Badge variant={getStatusVariant(status)}>{status}</Badge>
          </CardTitle>
          <CardDescription>
            Details for video processing job. Last updated: {lastUpdatedText}.
          </CardDescription>
        </CardHeader>
        <CardContent className="space-y-6">
          <div>
            <h3 className="text-lg font-semibold mb-1">Video Information</h3>
            <p>
              <strong>Video ID:</strong> {video_id || "N/A"}
            </p>
            <p>
              <strong>Original Filename:</strong> {videoFilename}
            </p>
          </div>

          <div>
            <h3 className="text-lg font-semibold mb-1">Job Progress/Stages</h3>
            {/* Display processing_stages if available and meaningful */}
            {processing_stages && (
              <pre className="text-xs bg-muted p-2 rounded-md overflow-x-auto">
                {JSON.stringify(processing_stages, null, 2)}
              </pre>
            )}
            {status === "PENDING" && !processing_stages && (
              <p>Waiting to be processed...</p>
            )}
            {status === "PROCESSING" && !processing_stages && (
              <p>Processing...</p>
            )}
            {status === "COMPLETED" && <p>Processing complete.</p>}
          </div>

          <div>
            <h3 className="text-lg font-semibold mb-1">Timestamps</h3>
            <p>
              <strong>Created:</strong> {createdAtText}
            </p>
            <p>
              <strong>Last Updated:</strong>{" "}
              {updated_at ? new Date(updated_at).toLocaleString() : "N/A"}
            </p>
          </div>

          {error_message && (
            <div>
              <h3 className="text-lg font-semibold mb-1 text-destructive">
                Error Details
              </h3>
              <Alert variant="destructive">
                <AlertDescription>{error_message}</AlertDescription>
              </Alert>
            </div>
          )}

          {/* TODO: Add link to the video page if processing is complete */}
          {/* {status === 'COMPLETED' && video_id && (
            <Button asChild>
              <Link to={`/video/${video_id}`}>View Video</Link>
            </Button>
          )} */}
        </CardContent>
      </Card>
    </div>
  );
}
</file>

<file path="apps/web/app/routes/_authed.tsx">
import { createFileRoute, Outlet, redirect } from "@tanstack/react-router";
import { supabase } from "@echo/db/clients/browser";
import React from "react";

// Define a simple loading component to be used as the pendingComponent
function AuthedLayoutPendingComponent() {
	return (
		<div className="flex items-center justify-center h-screen">
			<svg className="animate-spin h-10 w-10 text-primary" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
				<circle className="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" strokeWidth="4"></circle>
				<path className="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
			</svg>
			<span className="ml-3 text-xl">Loading authenticated session...</span>
		</div>
	);
}

export const Route = createFileRoute("/_authed")({
	beforeLoad: async ({ location }) => {
		const { data: { session }, error } = await supabase.auth.getSession();

		if (error) {
			console.error("Error getting session in _authed beforeLoad:", error);
			// Handle error appropriately, perhaps redirect to an error page or login
			throw redirect({
				to: "/login",
				search: {
					redirect: location.pathname, // Pass the original intended path
				},
			});
		}

		if (!session) {
			throw redirect({
				to: "/login",
				search: {
					// Store the attempted URL to redirect back after login
					redirect: location.pathname,
				},
			});
		}
		// If session exists, proceed to load the route component.
		// Optionally, you can pass user/session to context if needed by child routes directly from loader
		// return { user: session.user }; // Example: if you want to put user in context
		return {}; // Or an empty object if not passing anything specific to context here
	},
	component: AuthedLayoutComponent,
	pendingComponent: AuthedLayoutPendingComponent,
	// Removing the old errorComponent that rendered <Login />
	// Error handling for auth failure is now a redirect in beforeLoad.
	// Other errors can be handled by a more generic error component higher up or per-route.
});

function AuthedLayoutComponent() {
	// This component will render if beforeLoad successfully finds a session.
	// It should provide the Outlet for nested authenticated routes.
	// You could also include a shared layout for authenticated pages here (e.g., a navbar with user info).
	// const { user } = Route.useRouteContext(); // Example if context was populated in beforeLoad
	
	// For now, a simple Outlet.
	// Components within this layout can use the useAuth() hook to get user/session details.
	return (
		<>
			{/* Example: <AuthenticatedNavbar /> */}
			<Outlet />
		</>
	);
}
</file>

<file path="apps/web/app/routes/_pathlessLayout.tsx">
import { Outlet, createFileRoute } from '@tanstack/react-router'

export const Route = createFileRoute('/_pathlessLayout')({
  component: LayoutComponent,
})

function LayoutComponent() {
  return (
    <div className="p-2">
      <div className="border-b">I'm a layout</div>
      <div>
        <Outlet />
      </div>
    </div>
  )
}
</file>

<file path="apps/web/app/routes/$videoId.tsx">
import { zodResolver } from "@hookform/resolvers/zod";
import { useMutation, useQuery } from "@tanstack/react-query";
import { Link, createFileRoute, useParams } from "@tanstack/react-router";
import { useEffect } from "react";
import { type ControllerRenderProps, FieldValues, useForm } from "react-hook-form";
import { toast } from "sonner";
import * as z from "zod";
import { Alert, AlertDescription, AlertTitle } from "~/components/ui/alert";
import { Button } from "~/components/ui/button";
import {
  Card,
  CardContent,
  CardDescription,
  CardHeader,
  CardTitle,
} from "~/components/ui/card";
import {
  Form,
  FormControl,
  FormField,
  FormItem,
  FormLabel,
  FormMessage,
} from "~/components/ui/form";
import { Input } from "~/components/ui/input";
import { Skeleton } from "~/components/ui/skeleton";
import { Textarea } from "~/components/ui/textarea";
import type {
  VideoDetailsResponse,
  VideoMetadataUpdateRequest,
} from "~/types/api";
import { getVideoDetails, updateVideoMetadata } from "../lib/api";

// Placeholder for MediaPlayer component - to be created later
const MediaPlayer = ({
  src,
  title,
  subtitleFilesUrls,
}: {
  src: string;
  title?: string;
  subtitleFilesUrls?: { [key: string]: string } | null;
}) => {
  return (
    <div className="aspect-video bg-slate-900 flex items-center justify-center text-slate-100 rounded-lg overflow-hidden">
      {src ? (
        <video
          controls
          src={src}
          title={title || "Video player"}
          className="w-full h-full"
          crossOrigin="anonymous"
        >
          Your browser does not support the video tag.
          {subtitleFilesUrls &&
            Object.entries(subtitleFilesUrls).map(
              ([lang, subtitleSrc], index) => (
                <track
                  key={lang}
                  kind="subtitles"
                  srcLang={lang}
                  src={subtitleSrc}
                  label={lang.toUpperCase()} // Simple label, could be more descriptive
                  default={index === 0} // Set the first subtitle track as default
                />
              ),
            )}
        </video>
      ) : (
        <p>
          Video playback URL not available. Please ensure backend provides it.
        </p>
      )}
    </div>
  );
};

const metadataFormSchema = z.object({
  title: z.string().min(1, "Title is required.").max(255),
  description: z.string().max(5000).optional(),
  tags: z.string().optional(), // Represent tags as a comma-separated string for simplicity in form
});
type MetadataFormValues = z.infer<typeof metadataFormSchema>;

export const Route = createFileRoute("/_authed/video/$videoId")({
  component: VideoDetailPage,
});

function VideoDetailPage() {
  const { videoId } = useParams({ from: Route.id });
  const {
    data: videoDetails,
    isLoading,
    error,
    isError,
    refetch,
  } = useQuery<VideoDetailsResponse, Error>({
    queryKey: ["videoDetails", videoId],
    queryFn: () => getVideoDetails(videoId),
  });

  const form = useForm<MetadataFormValues>({
    resolver: zodResolver(metadataFormSchema),
    // Default values will be set in useEffect when videoDetails load
  });

  useEffect(() => {
    if (videoDetails?.metadata) {
      form.reset({
        title: videoDetails.metadata.title || "",
        description: videoDetails.metadata.description || "",
        tags: videoDetails.metadata.tags?.join(", ") || "",
      });
    }
  }, [videoDetails, form.reset]);

  const { mutate: submitMetadata, isPending: isUpdatingMetadata } = useMutation(
    {
      mutationFn: async (data: VideoMetadataUpdateRequest) =>
        updateVideoMetadata(videoId, data),
      onSuccess: () => {
        toast.success("Metadata updated successfully!");
        refetch(); // Refetch video details to show updated data
      },
      onError: (err: Error) => {
        toast.error(`Failed to update metadata: ${err.message}`);
      },
    },
  );

  const onSubmitMetadata = (values: MetadataFormValues) => {
    const updateRequest: VideoMetadataUpdateRequest = {
      title: values.title,
      description: values.description || null,
      tags: values.tags
        ? values.tags
            .split(",")
            .map((tag) => tag.trim())
            .filter((tag) => tag)
        : [],
    };
    submitMetadata(updateRequest);
  };

  if (isLoading) {
    return <VideoDetailSkeleton />;
  }

  if (isError || !videoDetails) {
    return (
      <div className="container mx-auto p-4">
        <Alert variant="destructive">
          <AlertTitle>Error Loading Video</AlertTitle>
          <AlertDescription>
            {error?.message ||
              "Failed to load video details. The video may not exist or an error occurred."}
          </AlertDescription>
        </Alert>
      </div>
    );
  }

  // Playback URL needs to be provided by the backend in VideoDetailsResponse, ideally as a direct field
  // like `video.playback_url` (e.g., a GCS signed URL).
  // The `storage_path` (e.g., gs://bucket/path) is generally not directly playable.
  // Waiting for backend to add a dedicated playback URL field to VideoSchema or VideoDetailsResponse.
  const playbackUrl =
    (videoDetails.video as any)?.playback_url ||
    videoDetails.video?.storage_path ||
    "";
  const videoTitle =
    videoDetails.metadata?.title ||
    videoDetails.video?.original_filename ||
    "Video";
  const subtitles = videoDetails.metadata?.subtitle_files_urls as
    | { [key: string]: string }
    | undefined;

  return (
    <div className="container mx-auto p-4 space-y-6">
      <Card>
        <CardHeader>
          <CardTitle>{videoTitle}</CardTitle>
          {videoDetails.video?.original_filename && (
            <CardDescription>
              Original file: {videoDetails.video.original_filename}
            </CardDescription>
          )}
        </CardHeader>
        <CardContent>
          <MediaPlayer
            src={playbackUrl}
            title={videoTitle}
            subtitleFilesUrls={subtitles}
          />
        </CardContent>
      </Card>

      <div className="grid md:grid-cols-3 gap-6">
        <div className="md:col-span-2 space-y-4">
          <Card>
            <CardHeader>
              <CardTitle>Details & Metadata</CardTitle>
            </CardHeader>
            <CardContent className="space-y-2">
              <p>
                <strong>Status:</strong> {videoDetails.status}
              </p>
              <p>
                <strong>Uploaded:</strong>{" "}
                {videoDetails.video?.created_at
                  ? new Date(videoDetails.video.created_at).toLocaleString()
                  : "N/A"}
              </p>
              <p>
                <strong>Last Updated:</strong>{" "}
                {videoDetails.updated_at
                  ? new Date(videoDetails.updated_at).toLocaleString()
                  : "N/A"}
              </p>
              {videoDetails.metadata?.description && (
                <p>
                  <strong>Description:</strong>{" "}
                  {videoDetails.metadata.description}
                </p>
              )}
              {videoDetails.metadata?.tags &&
                videoDetails.metadata.tags.length > 0 && (
                  <p>
                    <strong>Tags:</strong>{" "}
                    {videoDetails.metadata.tags.join(", ")}
                  </p>
                )}
            </CardContent>
          </Card>

          {videoDetails.metadata?.transcript_text && (
            <Card>
              <CardHeader>
                <CardTitle>Transcript</CardTitle>
              </CardHeader>
              <CardContent>
                <Textarea
                  readOnly
                  value={videoDetails.metadata.transcript_text}
                  rows={10}
                  className="font-mono text-sm"
                />
              </CardContent>
            </Card>
          )}
        </div>

        <div className="md:col-span-1">
          <Card>
            <CardHeader>
              <CardTitle>Edit Metadata</CardTitle>
            </CardHeader>
            <CardContent>
              <Form {...form}>
                <form
                  onSubmit={form.handleSubmit(onSubmitMetadata)}
                  className="space-y-4"
                >
                  <FormField
                    control={form.control}
                    name="title"
                    render={({
                      field,
                    }: {
                      field: ControllerRenderProps<MetadataFormValues, "title">;
                    }) => (
                      <FormItem>
                        <FormLabel>Title</FormLabel>
                        <FormControl>
                          <Input {...field} />
                        </FormControl>
                        <FormMessage />
                      </FormItem>
                    )}
                  />
                  <FormField
                    control={form.control}
                    name="description"
                    render={({
                      field,
                    }: {
                      field: ControllerRenderProps<
                        MetadataFormValues,
                        "description"
                      >;
                    }) => (
                      <FormItem>
                        <FormLabel>Description</FormLabel>
                        <FormControl>
                          <Textarea {...field} rows={4} />
                        </FormControl>
                        <FormMessage />
                      </FormItem>
                    )}
                  />
                  <FormField
                    control={form.control}
                    name="tags"
                    render={({
                      field,
                    }: {
                      field: ControllerRenderProps<MetadataFormValues, "tags">;
                    }) => (
                      <FormItem>
                        <FormLabel>Tags (comma-separated)</FormLabel>
                        <FormControl>
                          <Input {...field} />
                        </FormControl>
                        <FormMessage />
                      </FormItem>
                    )}
                  />
                  <Button
                    type="submit"
                    disabled={isUpdatingMetadata}
                    className="w-full"
                  >
                    {isUpdatingMetadata ? "Updating..." : "Save Metadata"}
                  </Button>
                </form>
              </Form>
            </CardContent>
          </Card>
        </div>
      </div>
    </div>
  );
}

const VideoDetailSkeleton = () => (
  <div className="container mx-auto p-4 space-y-6">
    <Card>
      <CardHeader>
        <Skeleton className="h-8 w-3/4 mb-2" />
        <Skeleton className="h-4 w-1/2" />
      </CardHeader>
      <CardContent>
        <Skeleton className="aspect-video w-full" />
      </CardContent>
    </Card>
    <div className="grid md:grid-cols-3 gap-6">
      <div className="md:col-span-2 space-y-4">
        <Card>
          <CardHeader>
            <Skeleton className="h-7 w-1/3" />
          </CardHeader>
          <CardContent className="space-y-3">
            <Skeleton className="h-4 w-full" />
            <Skeleton className="h-4 w-full" />
            <Skeleton className="h-4 w-3/4" />
            <Skeleton className="h-4 w-full" />
            <Skeleton className="h-4 w-2/3" />
          </CardContent>
        </Card>
        <Card>
          <CardHeader>
            <Skeleton className="h-7 w-1/3" />
          </CardHeader>
          <CardContent>
            <Skeleton className="h-24 w-full" />
          </CardContent>
        </Card>
      </div>
      <div className="md:col-span-1">
        <Card>
          <CardHeader>
            <Skeleton className="h-7 w-1/2" />
          </CardHeader>
          <CardContent className="space-y-4">
            <Skeleton className="h-10 w-full" />
            <Skeleton className="h-20 w-full" />
            <Skeleton className="h-10 w-full" />
            <Skeleton className="h-10 w-full" />
          </CardContent>
        </Card>
      </div>
    </div>
  </div>
);
</file>

<file path="apps/web/app/routes/dashboard.tsx">
import { Button } from "~/components/ui/button";
import { VideoUploadDropzone } from "~/components/video/VideoUploadDropzone";
import { Tabs, TabsContent, TabsList, TabsTrigger } from "~/components/ui/tabs";
import { ProcessingDashboard } from "~/components/video/processing-dashboard";
import { Link, createFileRoute, useNavigate } from "@tanstack/react-router";
import { fetchMyVideos, type PaginationParams } from "~/lib/api";
import type { VideoSummary } from "~/types/api";
import {
  useInfiniteQuery,
  type InfiniteData,
  type QueryKey,
} from "@tanstack/react-query";
import { ExternalLink, UploadIcon } from "lucide-react";
import { useEffect, useState, Fragment } from "react";
import {
  Dialog,
  DialogContent,
  DialogHeader,
  DialogTitle,
  DialogTrigger,
} from "~/components/ui/dialog";
import { VideoList } from "~/components/video/VideoList";

function DashboardComponent() {
  const [activeTab, setActiveTab] = useState("library");
  const [uploadDialogOpen, setUploadDialogOpen] = useState(false);

  const navigate = useNavigate();

  const {
    data,
    fetchNextPage,
    hasNextPage,
    isFetchingNextPage,
    isLoading: videosLoading,
    error: videosError,
  } = useInfiniteQuery<
    VideoSummary[],
    Error,
    InfiniteData<VideoSummary[], PaginationParams | undefined>,
    QueryKey,
    PaginationParams | undefined
  >({
    queryKey: ["myVideos"],
    queryFn: ({ pageParam = { offset: 0, limit: 10 } }) =>
      fetchMyVideos(pageParam),
    initialPageParam: { offset: 0, limit: 10 } as PaginationParams | undefined,
    getNextPageParam: (
      lastPage: VideoSummary[],
      allPages: VideoSummary[][],
      lastPageParam: PaginationParams | undefined,
    ) => {
      if (!lastPageParam || lastPage.length < (lastPageParam.limit ?? 10)) {
        return undefined;
      }
      const currentTotal = allPages.reduce((acc, page) => acc + page.length, 0);
      return { offset: currentTotal, limit: lastPageParam.limit ?? 10 };
    },
  });

  const videos: VideoSummary[] =
    data?.pages.flatMap((page: VideoSummary[]) => page) ?? [];

  return (
    <div className="container py-10">
      <div className="flex flex-col sm:flex-row sm:items-center sm:justify-between mb-8 gap-4">
        <div>
          <h1 className="text-xl sm:text-2xl font-bold tracking-tight">
            Video Dashboard
          </h1>
          <p className="text-muted-foreground text-sm mt-1">
            Manage and monitor your video processing status
          </p>
        </div>
        <Dialog open={uploadDialogOpen} onOpenChange={setUploadDialogOpen}>
          <DialogTrigger asChild>
            <Button>
              <UploadIcon className="h-4 w-4 md:mr-2" />
              <span className="hidden md:inline">Upload New Video</span>
              <span className="sr-only md:hidden">Upload New Video</span>
            </Button>
          </DialogTrigger>
          <DialogContent className="sm:max-w-md">
            <DialogHeader>
              <DialogTitle>Upload Video</DialogTitle>
            </DialogHeader>
            <div className="py-4">
              <VideoUploadDropzone
                onUploadComplete={() => setUploadDialogOpen(false)}
              />
            </div>
          </DialogContent>
        </Dialog>
      </div>

      <Tabs value={activeTab} onValueChange={setActiveTab}>
        <TabsList className="w-full grid grid-cols-2 max-w-md mb-6">
          <TabsTrigger value="processing" className="flex-1">
            Processing Status
          </TabsTrigger>
          <TabsTrigger value="library" className="flex-1">
            Video Library
          </TabsTrigger>
        </TabsList>

        <TabsContent value="processing" className="space-y-4 animate-in">
          <ProcessingDashboard />
        </TabsContent>

        <TabsContent value="library" className="space-y-4 animate-in">
          <VideoList
            videos={videos}
            isLoading={videosLoading && !data}
            error={videosError}
            hasNextPage={hasNextPage}
            isFetchingNextPage={isFetchingNextPage}
            fetchNextPage={fetchNextPage}
            showUploadButton={true}
            onTriggerUpload={() => setUploadDialogOpen(true)}
          />
        </TabsContent>
      </Tabs>
    </div>
  );
}

export const Route = createFileRoute("/dashboard")({
  component: DashboardComponent,
});
</file>

<file path="apps/web/app/routes/index.tsx">
import {
  ErrorComponent,
  createFileRoute,
  useNavigate,
} from "@tanstack/react-router"
import React from "react"
import { ErrorBoundary } from "react-error-boundary"
import { Layout } from "~/components/layout"

export const Route = createFileRoute("/")({
  component: Home,
})

const skeletons = Array.from({ length: 2 })

function Home() {
  const filters = Route.useSearch()
  const navigate = useNavigate()

  return (
    <Layout>
      <div className="mb-9 text-center">
        <h1 className="text-4xl font-bold tracking-tight mb-3">
          Tech Events & Conferences
        </h1>
        <p className="text-lg text-muted-foreground max-w-2xl mx-auto">
          Discover the best tech conferences, meetups, and workshops happening
          around the world.
        </p>
      </div>
      <div className="flex flex-col gap-4 w-full">
        <ErrorBoundary
          fallbackRender={(props) => <ErrorComponent error={props.error} />}
        >
        </ErrorBoundary>
        <div className="flex flex-col gap-4">
          <ErrorBoundary
            fallbackRender={(props) => <ErrorComponent error={props.error} />}
          >
 
          </ErrorBoundary>
        </div>
      </div>
    </Layout>
  )
}
</file>

<file path="apps/web/app/routes/login.tsx">
import { createFileRoute, redirect } from "@tanstack/react-router";
import { Login } from "~/components/login";
import { supabase } from "@echo/db/clients/browser"; // Import supabase client

export const Route = createFileRoute("/login")({
  beforeLoad: async ({ cause }) => {
    // Redirect to dashboard if user is already logged in and tries to enter the login page.
    if (cause === "enter") {
      const {
        data: { session },
      } = await supabase.auth.getSession();
      if (session) {
        throw redirect({
          to: "/dashboard",
          replace: true,
        });
      }
    }
  },
  component: LoginComp,
});

function LoginComp() {
  return <Login />;
}
</file>

<file path="apps/web/app/routes/logout.tsx">
import { createFileRoute, redirect } from "@tanstack/react-router";
import { createServerFn } from "@tanstack/start";
import { getSupabaseServerClient } from "@echo/db/clients/ssr";

const logoutFn = createServerFn().handler(async () => {
  const supabase = await getSupabaseServerClient();
  const { error } = await supabase.auth.signOut();

  if (error) {
    return {
      error: true,
      message: error.message,
    };
  }

  throw redirect({
    href: "/",
  });
});

export const Route = createFileRoute("/logout")({
  preload: false,
  loader: () => logoutFn(),
});
</file>

<file path="apps/web/app/routes/profile.tsx">
import { createFileRoute, redirect } from "@tanstack/react-router"
import { ProfileCard } from "~/components/profile-card"

export const Route = createFileRoute("/profile")({
  component: RouteComponent,
  beforeLoad: async ({ context }) => {
    if (!context.authState.isAuthenticated) {
      throw redirect({ to: "/" })
    }
  },
})

function RouteComponent() {
  return <ProfileCard />
}
</file>

<file path="apps/web/app/routes/settings.tsx">
import { createFileRoute } from "@tanstack/react-router";

import { Button } from "~/components/ui/button";
import { Card, CardContent, CardHeader, CardTitle } from "~/components/ui/card";
import { Input } from "~/components/ui/input";
import { Label } from "~/components/ui/label";
import { Separator } from "~/components/ui/separator";
import { Switch } from "~/components/ui/switch";
// import { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from "~/components/ui/select"; // Placeholder for future use

function SettingsComponent() {
  return (
    <div className="container mx-auto py-8 max-w-4xl space-y-8">
      <h1 className="text-3xl font-bold">Settings</h1>

      {/* Profile & Preferences Section */}
      <Card>
        <CardHeader>
          <CardTitle>Profile & Preferences</CardTitle>
        </CardHeader>
        <CardContent className="space-y-4">
          <div className="space-y-2">
            <Label htmlFor="displayName">Display Name</Label>
            <Input
              id="displayName"
              placeholder="Your Name (coming soon)"
              disabled
            />
          </div>
          <div className="space-y-2">
            <Label htmlFor="email">Email</Label>
            <Input
              id="email"
              type="email"
              placeholder="your.email@example.com (coming soon)"
              disabled
            />
          </div>
          <div className="flex items-center justify-between space-x-2 pt-2">
            <Label htmlFor="darkMode" className="flex flex-col space-y-1">
              <span>Dark Mode</span>
              <span className="font-normal leading-snug text-muted-foreground">
                Adjust the appearance to reduce eye strain.
              </span>
            </Label>
            <Switch id="darkMode" disabled />
          </div>
        </CardContent>
      </Card>

      {/* YouTube Integration Section */}
      <Card>
        <CardHeader>
          <CardTitle>YouTube Integration</CardTitle>
        </CardHeader>
        <CardContent className="space-y-4">
          <div className="space-y-2">
            <Label>Connected Account</Label>
            <div className="flex items-center justify-between">
              <p className="text-sm text-muted-foreground">
                youtube-channel-name (coming soon)
              </p>
              <Button variant="outline" size="sm" disabled>
                Reconnect
              </Button>
            </div>
          </div>
          <Separator />
          <div className="space-y-2">
            <Label htmlFor="defaultPrivacy">Default Upload Privacy</Label>
            {/* Placeholder for Select component */}
            <Input
              id="defaultPrivacy"
              placeholder="Private (coming soon)"
              disabled
            />
            {/* <Select disabled>
              <SelectTrigger id="defaultPrivacy">
                <SelectValue placeholder="Select default privacy" />
              </SelectTrigger>
              <SelectContent>
                <SelectItem value="private">Private</SelectItem>
                <SelectItem value="unlisted">Unlisted</SelectItem>
                <SelectItem value="public">Public</SelectItem>
              </SelectContent>
            </Select> */}
          </div>
          <div className="space-y-2">
            <Label htmlFor="defaultCategory">Default Video Category</Label>
            {/* Placeholder for Select component */}
            <Input
              id="defaultCategory"
              placeholder="Science & Technology (coming soon)"
              disabled
            />
          </div>
        </CardContent>
      </Card>

      {/* AI Configuration Section */}
      <Card>
        <CardHeader>
          <CardTitle>AI Configuration</CardTitle>
        </CardHeader>
        <CardContent className="space-y-4">
          <div className="space-y-2">
            <Label>AI Model</Label>
            <p className="text-sm text-muted-foreground">
              Gemini Pro (Current Model - read-only)
            </p>
          </div>
          <Separator />
          <div className="space-y-2">
            <Label htmlFor="titleSuggestions">
              Number of Title Suggestions
            </Label>
            <Input
              id="titleSuggestions"
              type="number"
              placeholder="3 (coming soon)"
              disabled
            />
          </div>
          <div className="space-y-2">
            <Label htmlFor="thumbnailStyles">Thumbnail Generation Style</Label>
            {/* Placeholder for Select component */}
            <Input
              id="thumbnailStyles"
              placeholder="Default (coming soon)"
              disabled
            />
          </div>
        </CardContent>
      </Card>

      {/* Notification Settings Section */}
      <Card>
        <CardHeader>
          <CardTitle>Notifications</CardTitle>
        </CardHeader>
        <CardContent className="space-y-4">
          <div className="flex items-center justify-between space-x-2">
            <Label
              htmlFor="emailNotifications"
              className="flex flex-col space-y-1"
            >
              <span>Email Notifications</span>
              <span className="font-normal leading-snug text-muted-foreground">
                Receive email updates for processing events.
              </span>
            </Label>
            <Switch id="emailNotifications" disabled />
          </div>
          <Separator />
          <p className="text-sm font-medium text-muted-foreground">
            Notify me when:
          </p>
          <div className="flex items-center justify-between space-x-2 pl-4">
            <Label htmlFor="notifyUploadComplete">Upload Complete</Label>
            <Switch id="notifyUploadComplete" disabled />
          </div>
          <div className="flex items-center justify-between space-x-2 pl-4">
            <Label htmlFor="notifyProcessingComplete">
              Processing Complete
            </Label>
            <Switch id="notifyProcessingComplete" disabled />
          </div>
          <div className="flex items-center justify-between space-x-2 pl-4">
            <Label htmlFor="notifyProcessingError">Processing Error</Label>
            <Switch id="notifyProcessingError" disabled />
          </div>
        </CardContent>
      </Card>

      {/* Storage & Credentials Section */}
      <Card>
        <CardHeader>
          <CardTitle>Storage & Credentials</CardTitle>
        </CardHeader>
        <CardContent className="space-y-4">
          <div className="space-y-2">
            <Label>Google Cloud Storage</Label>
            <p className="text-sm text-muted-foreground">
              Input Bucket: `your-input-bucket` (read-only)
            </p>
            <p className="text-sm text-muted-foreground">
              Output Bucket: `your-output-bucket` (read-only)
            </p>
          </div>
          <Separator />
          <div className="space-y-2">
            <Label>Credential Status</Label>
            <p className="text-sm text-muted-foreground">
              Google Cloud: Connected ✅
            </p>
            <p className="text-sm text-muted-foreground">
              YouTube API: Connected ✅
            </p>
          </div>
        </CardContent>
      </Card>
    </div>
  );
}

export const Route = createFileRoute("/settings")({
  component: SettingsComponent,
});
</file>

<file path="apps/web/app/routes/sign-in.tsx">
import { Link, createFileRoute, redirect } from "@tanstack/react-router"
import { SignInForm } from "~/components/auth/sign-in-form"
import { Layout } from "~/components/layout"

export const Route = createFileRoute("/sign-in")({
  component: RouteComponent,
  beforeLoad: async ({ context }) => {
    if (context.authState.isAuthenticated) {
      throw redirect({ to: "/" })
    }
  },
})

function RouteComponent() {
  return (
    <Layout className="items-center gap-2 max-w-md">
      <SignInForm />
      <small>
        <Link to="/sign-up" className="group">
          Do you want to create an account instead?{" "}
          <span className="underline group-hover:no-underline">Sign Up</span>
        </Link>
      </small>
    </Layout>
  )
}
</file>

<file path="apps/web/app/routes/signup.tsx">
import { createFileRoute, Link, redirect } from "@tanstack/react-router"
import { Layout } from "~/components/layout"
import { SignUpForm } from "~/components/auth/sign-up-form"

export const Route = createFileRoute("/sign-up")({
  component: RouteComponent,
  beforeLoad: async ({ context }) => {
    if (context.authState.isAuthenticated) {
      throw redirect({ to: "/" })
    }
  },
})

function RouteComponent() {
  return (
    <Layout className="items-center gap-2 max-w-md">
      <SignUpForm />
      <small>
        <Link to="/sign-in" className="group">
          Do you already have an account?{" "}
          <span className="underline group-hover:no-underline">Sign In</span>
        </Link>
      </small>
    </Layout>
  )
}
</file>

<file path="apps/web/app/services/auth.api.ts">
import { createMiddleware, createServerFn, json } from "@tanstack/react-start"
import { getSupabaseServerClient } from "~/lib/supabase"
import {
  type AuthState,
  SignInSchema,
  SignUpSchema,
  UserMetaSchema,
} from "./auth.schema"

export const userMiddleware = createMiddleware({ type: "function" }).server(
  async ({ next }) => {
    const supabase = getSupabaseServerClient()

    const { data } = await supabase.auth.getUser()

    return next({
      context: {
        user: data.user,
        supabase,
      },
    })
  },
)
export const userRequiredMiddleware = createMiddleware({ type: "function" })
  .middleware([userMiddleware])
  .server(async ({ next, context }) => {
    if (!context.user) {
      throw json(
        { message: "You must be logged in to access this resource!" },
        { status: 401 },
      )
    }

    return next({
      context: {
        user: context.user,
      },
    })
  })

export const signUp = createServerFn()
  .validator(SignUpSchema)
  .handler(async ({ data }) => {
    const { data: userData, error } =
      await getSupabaseServerClient().auth.signUp({
        email: data.email,
        password: data.password,
      })

    if (error) {
      switch (error.code) {
        case "email_exists":
          throw new Error("Email already exists")
        case "weak_password":
          throw new Error("Your password is too weak")
        default:
          throw new Error(error.message)
      }
    }

    if (userData.user) {
      return userData.user.id
    }

    throw new Error("Something went wrong")
  })

export const signIn = createServerFn()
  .validator(SignInSchema)
  .handler(async ({ data }) => {
    const { error } = await getSupabaseServerClient().auth.signInWithPassword({
      email: data.email,
      password: data.password,
    })

    if (error) {
      return { error: error.message }
    }
  })

export const signOut = createServerFn().handler(async () => {
  await getSupabaseServerClient().auth.signOut()
})

export const getUser = createServerFn()
  .middleware([userMiddleware])
  .handler<AuthState>(async ({ context: { user } }) => {
    if (!user) {
      return { isAuthenticated: false }
    }

    return {
      isAuthenticated: true,
      user: {
        email: user.email,
        meta: { username: user.user_metadata.username },
      },
    }
  })

export const updateUser = createServerFn()
  .validator(UserMetaSchema)
  .handler(async ({ data }) => {
    const supabase = getSupabaseServerClient()

    const { error } = await supabase.auth.updateUser({
      data: { username: data.username },
    })

    if (error) {
      throw new Error(error.message)
    }
  })
</file>

<file path="apps/web/app/services/auth.schema.ts">
import { z } from "zod"

export const UserMetaSchema = z.object({
  username: z.string().min(3).max(20),
})

export type UserMeta = z.infer<typeof UserMetaSchema>

// TODO: Refine password === confirmPassword
export const SignUpSchema = z.object({
  username: UserMetaSchema.shape.username,
  email: z.string().email(),
  password: z.string().min(6),
  confirmPassword: z.string(),
})

export type SignUpSchema = z.infer<typeof SignUpSchema>

export const SignInSchema = z.object({
  email: z.string().email(),
  password: z.string(),
})

export type SignInSchema = z.infer<typeof SignInSchema>

export type AuthState =
  | {
      isAuthenticated: false
    }
  | {
      isAuthenticated: true
      user: User
    }

export type User = { email?: string; meta: UserMeta }
</file>

<file path="apps/web/app/services/gcs-content.ts">
/**
 * Service to handle fetching content from Google Cloud Storage
 */

// Utility to fetch content from GCS using a publicly accessible URL
export async function fetchGCSContent(url: string): Promise<string> {
	try {
		const response = await fetch(url);

		if (!response.ok) {
			throw new Error(
				`Failed to fetch content: ${response.status} ${response.statusText}`,
			);
		}

		return await response.text();
	} catch (error) {
		console.error("Error fetching GCS content:", error);
		throw error;
	}
}

// Generate a publicly accessible URL for a GCS file (if permission allows)
export function getGCSPublicUrl(bucketName: string, filePath: string): string {
	return `https://storage.googleapis.com/${bucketName}/${filePath}`;
}

// Process the output_files paths from Firestore to generate usable URLs
export function getContentUrls(
	bucketName: string,
	outputFiles: Record<string, string> = {},
) {
	const urls: Record<string, string> = {};

	Object.entries(outputFiles).forEach(([key, path]) => {
		if (path) {
			urls[key] = getGCSPublicUrl(bucketName, path);
		}
	});

	return urls;
}

// Try to fetch content, returns null if not available
export async function tryFetchContent(
	bucketName: string | undefined,
	outputFiles: Record<string, string>,
	contentType: string,
): Promise<string | null> {
	if (!bucketName || !outputFiles[contentType]) {
		return null;
	}

	try {
		const url = getGCSPublicUrl(bucketName, outputFiles[contentType]);
		const content = await fetchGCSContent(url);
		return content;
	} catch (error) {
		console.error(`Error fetching ${contentType}:`, error);
		return null;
	}
}
</file>

<file path="apps/web/app/services/queries.ts">
import {
    type UseSuspenseQueryResult,
    queryOptions,
    useMutation,
    useQueryClient,
    useSuspenseQuery,
  } from "@tanstack/react-query"
  import { getUser } from "./auth.api"
  
  export const eventQueries = {
    all: ["events"],
    list: (filters: EventFilters) =>
      queryOptions({
        queryKey: [...eventQueries.all, "list", filters],
        queryFn: () => getEvents({ data: filters }),
      }),
    detail: (eventId: number) =>
      queryOptions({
        queryKey: [...eventQueries.all, "detail", eventId],
        queryFn: () => getEvent({ data: { id: eventId } }),
        enabled: !Number.isNaN(eventId) && !!eventId,
      }),
  }
  
  export const useUpsertEventMutation = () => {
    const queryClient = useQueryClient()
    return useMutation({
      mutationFn: (data: Parameters<typeof upsertEvent>[0]) => upsertEvent(data),
      onSuccess: () => {
        queryClient.invalidateQueries({ queryKey: eventQueries.all })
      },
    })
  }
  

  
  export const authQueries = {
    all: ["auth"],
    user: () =>
      queryOptions({
        queryKey: [...authQueries.all, "user"],
        queryFn: () => getUser(),
      }),
  }
  
  export const useAuthentication = () => {
    return useSuspenseQuery(authQueries.user())
  }
  
  export const useAuthenticatedUser = () => {
    const authQuery = useAuthentication()
  
    if (authQuery.data.isAuthenticated === false) {
      throw new Error("User is not authenticated!")
    }
  
    return authQuery as UseSuspenseQueryResult<typeof authQuery.data>
  }
</file>

<file path="apps/web/app/api.ts">
import {
  createStartAPIHandler,
  defaultAPIFileRouteHandler,
} from "@tanstack/react-start/api"

export default createStartAPIHandler(defaultAPIFileRouteHandler)
</file>

<file path="apps/web/app/client.tsx">
import { StartClient } from "@tanstack/react-start"
import { hydrateRoot } from "react-dom/client"
import { createRouter } from "./router"

const router = createRouter()

hydrateRoot(document, <StartClient router={router} />)
</file>

<file path="apps/web/app/env.ts">
// TODO: Check with zod
interface ImportMeta {
  env: {
    VITE_SUPABASE_URL: string;
    VITE_API_URL: string;
    VITE_SUPABASE_ANON_KEY: string;
    VITE_DEFAULT_USER_EMAIL: string;
    VITE_DEFAULT_USER_PASSWORD: string;
  };
}
</file>

<file path="apps/web/app/globals.css">
@tailwind base;
@tailwind components;
@tailwind utilities;

@layer base {
  :root {
    --background: 0 0% 100%;
    --foreground: 222.2 47.4% 11.2%;

    --muted: 210 40% 96.1%;
    --muted-foreground: 215.4 16.3% 46.9%;

    --popover: 0 0% 100%;
    --popover-foreground: 222.2 47.4% 11.2%;

    --border: 214.3 31.8% 91.4%;
    --input: 214.3 31.8% 91.4%;

    --card: 0 0% 100%;
    --card-foreground: 222.2 47.4% 11.2%;

    --primary: 222.2 47.4% 11.2%;
    --primary-foreground: 210 40% 98%;

    --secondary: 210 40% 96.1%;
    --secondary-foreground: 222.2 47.4% 11.2%;

    --accent: 210 40% 96.1%;
    --accent-foreground: 222.2 47.4% 11.2%;

    --destructive: 0 100% 50%;
    --destructive-foreground: 210 40% 98%;

    --ring: 215 20.2% 65.1%;

    --radius: 0.5rem;
  }

  .dark {
    --background: 224 71% 4%;
    --foreground: 213 31% 91%;

    --muted: 223 47% 11%;
    --muted-foreground: 215.4 16.3% 56.9%;

    --accent: 216 34% 17%;
    --accent-foreground: 210 40% 98%;

    --popover: 224 71% 4%;
    --popover-foreground: 215 20.2% 65.1%;

    --border: 216 34% 17%;
    --input: 216 34% 17%;

    --card: 224 71% 4%;
    --card-foreground: 213 31% 91%;

    --primary: 210 40% 98%;
    --primary-foreground: 222.2 47.4% 1.2%;

    --secondary: 222.2 47.4% 11.2%;
    --secondary-foreground: 210 40% 98%;

    --destructive: 0 63% 31%;
    --destructive-foreground: 210 40% 98%;

    --ring: 216 34% 17%;

    --radius: 0.5rem;
  }
}

@layer base {
  * {
    @apply border-border outline-ring/50;
  }
  body {
    @apply bg-background text-foreground;
    font-feature-settings:
      "rlig" 1,
      "calt" 1;
  }
}
</file>

<file path="apps/web/app/router.tsx">
import { MutationCache, QueryClient } from "@tanstack/react-query"
import {
  ErrorComponent,
  createRouter as createTanStackRouter,
} from "@tanstack/react-router"
import { routerWithQueryClient } from "@tanstack/react-router-with-query"
import { toast } from "sonner"
import { ZodError } from "zod"
import { fromError } from "zod-validation-error"
import { routeTree } from "./routeTree.gen"

function parseZodError(error: Error) {
  try {
    return new ZodError(JSON.parse(error.message))
  } catch {}
}

export function createRouter() {
  const queryClient: QueryClient = new QueryClient({
    defaultOptions: {
      queries: {
        staleTime: 1000 * 60 * 5,
        retry: 0,
        refetchOnWindowFocus: false,
      },
    },
    mutationCache: new MutationCache({
      onError: (error: unknown) => {
        if (error instanceof Error) {
          const zodError = parseZodError(error)
          if (zodError) {
            toast.error(fromError(zodError, { maxIssuesInMessage: 2 }).message)
            return
          }

          toast.error(error.message)
        } else if (typeof error === "string") {
          toast.error(error)
        }
      },
    }),
  })

  const router = routerWithQueryClient(
    createTanStackRouter({
      routeTree,
      defaultPreload: false,
      defaultErrorComponent: ErrorComponent,
      defaultNotFoundComponent: () => "Not found!",
      context: { queryClient },
    }),
    queryClient,
  )

  return router
}

declare module "@tanstack/react-router" {
  interface Register {
    router: ReturnType<typeof createRouter>
  }
}
</file>

<file path="apps/web/app/routeTree.gen.ts">
/* eslint-disable */

// @ts-nocheck

// noinspection JSUnusedGlobalSymbols

// This file was automatically generated by TanStack Router.
// You should NOT make any changes in this file as it will be overwritten.
// Additionally, you should also exclude this file from your linter and/or formatter to prevent it from being checked or modified.

// Import Routes

import { Route as AuthedVideoVideoIdImport } from './routes/$videoId'
import { Route as rootRoute } from './routes/__root'
import { Route as AuthedImport } from './routes/_authed'
import { Route as AuthedJobsJobIdImport } from './routes/_authed.jobs.$jobId'
import { Route as PathlessLayoutImport } from './routes/_pathlessLayout'
import { Route as AuthCallbackImport } from './routes/auth/callback'
import { Route as DashboardImport } from './routes/dashboard'
import { Route as IndexImport } from './routes/index'
import { Route as LoginImport } from './routes/login'
import { Route as LogoutImport } from './routes/logout'
import { Route as SettingsImport } from './routes/settings'
import { Route as SignupImport } from './routes/signup'

// Create/Update Routes

const SignupRoute = SignupImport.update({
  id: '/signup',
  path: '/signup',
  getParentRoute: () => rootRoute,
} as any)

const SettingsRoute = SettingsImport.update({
  id: '/settings',
  path: '/settings',
  getParentRoute: () => rootRoute,
} as any)

const LogoutRoute = LogoutImport.update({
  id: '/logout',
  path: '/logout',
  getParentRoute: () => rootRoute,
} as any)

const LoginRoute = LoginImport.update({
  id: '/login',
  path: '/login',
  getParentRoute: () => rootRoute,
} as any)

const DashboardRoute = DashboardImport.update({
  id: '/dashboard',
  path: '/dashboard',
  getParentRoute: () => rootRoute,
} as any)

const PathlessLayoutRoute = PathlessLayoutImport.update({
  id: '/_pathlessLayout',
  getParentRoute: () => rootRoute,
} as any)

const AuthedRoute = AuthedImport.update({
  id: '/_authed',
  getParentRoute: () => rootRoute,
} as any)

const IndexRoute = IndexImport.update({
  id: '/',
  path: '/',
  getParentRoute: () => rootRoute,
} as any)

const AuthCallbackRoute = AuthCallbackImport.update({
  id: '/auth/callback',
  path: '/auth/callback',
  getParentRoute: () => rootRoute,
} as any)

const AuthedVideoVideoIdRoute = AuthedVideoVideoIdImport.update({
  id: '/video/$videoId',
  path: '/video/$videoId',
  getParentRoute: () => AuthedRoute,
} as any)

const AuthedJobsJobIdRoute = AuthedJobsJobIdImport.update({
  id: '/jobs/$jobId',
  path: '/jobs/$jobId',
  getParentRoute: () => AuthedRoute,
} as any)

// Populate the FileRoutesByPath interface

declare module '@tanstack/react-router' {
  interface FileRoutesByPath {
    '/': {
      id: '/'
      path: '/'
      fullPath: '/'
      preLoaderRoute: typeof IndexImport
      parentRoute: typeof rootRoute
    }
    '/_authed': {
      id: '/_authed'
      path: ''
      fullPath: ''
      preLoaderRoute: typeof AuthedImport
      parentRoute: typeof rootRoute
    }
    '/_pathlessLayout': {
      id: '/_pathlessLayout'
      path: ''
      fullPath: ''
      preLoaderRoute: typeof PathlessLayoutImport
      parentRoute: typeof rootRoute
    }
    '/dashboard': {
      id: '/dashboard'
      path: '/dashboard'
      fullPath: '/dashboard'
      preLoaderRoute: typeof DashboardImport
      parentRoute: typeof rootRoute
    }
    '/login': {
      id: '/login'
      path: '/login'
      fullPath: '/login'
      preLoaderRoute: typeof LoginImport
      parentRoute: typeof rootRoute
    }
    '/logout': {
      id: '/logout'
      path: '/logout'
      fullPath: '/logout'
      preLoaderRoute: typeof LogoutImport
      parentRoute: typeof rootRoute
    }
    '/settings': {
      id: '/settings'
      path: '/settings'
      fullPath: '/settings'
      preLoaderRoute: typeof SettingsImport
      parentRoute: typeof rootRoute
    }
    '/signup': {
      id: '/signup'
      path: '/signup'
      fullPath: '/signup'
      preLoaderRoute: typeof SignupImport
      parentRoute: typeof rootRoute
    }
    '/auth/callback': {
      id: '/auth/callback'
      path: '/auth/callback'
      fullPath: '/auth/callback'
      preLoaderRoute: typeof AuthCallbackImport
      parentRoute: typeof rootRoute
    }
    '/_authed/jobs/$jobId': {
      id: '/_authed/jobs/$jobId'
      path: '/jobs/$jobId'
      fullPath: '/jobs/$jobId'
      preLoaderRoute: typeof AuthedJobsJobIdImport
      parentRoute: typeof AuthedImport
    }
    '/_authed/video/$videoId': {
      id: '/_authed/video/$videoId'
      path: '/video/$videoId'
      fullPath: '/video/$videoId'
      preLoaderRoute: typeof AuthedVideoVideoIdImport
      parentRoute: typeof AuthedImport
    }
  }
}

// Create and export the route tree

interface AuthedRouteChildren {
  AuthedJobsJobIdRoute: typeof AuthedJobsJobIdRoute
  AuthedVideoVideoIdRoute: typeof AuthedVideoVideoIdRoute
}

const AuthedRouteChildren: AuthedRouteChildren = {
  AuthedJobsJobIdRoute: AuthedJobsJobIdRoute,
  AuthedVideoVideoIdRoute: AuthedVideoVideoIdRoute,
}

const AuthedRouteWithChildren =
  AuthedRoute._addFileChildren(AuthedRouteChildren)

export interface FileRoutesByFullPath {
  '/': typeof IndexRoute
  '': typeof PathlessLayoutRoute
  '/dashboard': typeof DashboardRoute
  '/login': typeof LoginRoute
  '/logout': typeof LogoutRoute
  '/settings': typeof SettingsRoute
  '/signup': typeof SignupRoute
  '/auth/callback': typeof AuthCallbackRoute
  '/jobs/$jobId': typeof AuthedJobsJobIdRoute
  '/video/$videoId': typeof AuthedVideoVideoIdRoute
}

export interface FileRoutesByTo {
  '/': typeof IndexRoute
  '': typeof PathlessLayoutRoute
  '/dashboard': typeof DashboardRoute
  '/login': typeof LoginRoute
  '/logout': typeof LogoutRoute
  '/settings': typeof SettingsRoute
  '/signup': typeof SignupRoute
  '/auth/callback': typeof AuthCallbackRoute
  '/jobs/$jobId': typeof AuthedJobsJobIdRoute
  '/video/$videoId': typeof AuthedVideoVideoIdRoute
}

export interface FileRoutesById {
  __root__: typeof rootRoute
  '/': typeof IndexRoute
  '/_authed': typeof AuthedRouteWithChildren
  '/_pathlessLayout': typeof PathlessLayoutRoute
  '/dashboard': typeof DashboardRoute
  '/login': typeof LoginRoute
  '/logout': typeof LogoutRoute
  '/settings': typeof SettingsRoute
  '/signup': typeof SignupRoute
  '/auth/callback': typeof AuthCallbackRoute
  '/_authed/jobs/$jobId': typeof AuthedJobsJobIdRoute
  '/_authed/video/$videoId': typeof AuthedVideoVideoIdRoute
}

export interface FileRouteTypes {
  fileRoutesByFullPath: FileRoutesByFullPath
  fullPaths:
    | '/'
    | ''
    | '/dashboard'
    | '/login'
    | '/logout'
    | '/settings'
    | '/signup'
    | '/auth/callback'
    | '/jobs/$jobId'
    | '/video/$videoId'
  fileRoutesByTo: FileRoutesByTo
  to:
    | '/'
    | ''
    | '/dashboard'
    | '/login'
    | '/logout'
    | '/settings'
    | '/signup'
    | '/auth/callback'
    | '/jobs/$jobId'
    | '/video/$videoId'
  id:
    | '__root__'
    | '/'
    | '/_authed'
    | '/_pathlessLayout'
    | '/dashboard'
    | '/login'
    | '/logout'
    | '/settings'
    | '/signup'
    | '/auth/callback'
    | '/_authed/jobs/$jobId'
    | '/_authed/video/$videoId'
  fileRoutesById: FileRoutesById
}

export interface RootRouteChildren {
  IndexRoute: typeof IndexRoute
  AuthedRoute: typeof AuthedRouteWithChildren
  PathlessLayoutRoute: typeof PathlessLayoutRoute
  DashboardRoute: typeof DashboardRoute
  LoginRoute: typeof LoginRoute
  LogoutRoute: typeof LogoutRoute
  SettingsRoute: typeof SettingsRoute
  SignupRoute: typeof SignupRoute
  AuthCallbackRoute: typeof AuthCallbackRoute
}

const rootRouteChildren: RootRouteChildren = {
  IndexRoute: IndexRoute,
  AuthedRoute: AuthedRouteWithChildren,
  PathlessLayoutRoute: PathlessLayoutRoute,
  DashboardRoute: DashboardRoute,
  LoginRoute: LoginRoute,
  LogoutRoute: LogoutRoute,
  SettingsRoute: SettingsRoute,
  SignupRoute: SignupRoute,
  AuthCallbackRoute: AuthCallbackRoute,
}

export const routeTree = rootRoute
  ._addFileChildren(rootRouteChildren)
  ._addFileTypes<FileRouteTypes>()

/* ROUTE_MANIFEST_START
{
  "routes": {
    "__root__": {
      "filePath": "__root.tsx",
      "children": [
        "/",
        "/_authed",
        "/_pathlessLayout",
        "/dashboard",
        "/login",
        "/logout",
        "/settings",
        "/signup",
        "/auth/callback"
      ]
    },
    "/": {
      "filePath": "index.tsx"
    },
    "/_authed": {
      "filePath": "_authed.tsx",
      "children": [
        "/_authed/jobs/$jobId",
        "/_authed/video/$videoId"
      ]
    },
    "/_pathlessLayout": {
      "filePath": "_pathlessLayout.tsx"
    },
    "/dashboard": {
      "filePath": "dashboard.tsx"
    },
    "/login": {
      "filePath": "login.tsx"
    },
    "/logout": {
      "filePath": "logout.tsx"
    },
    "/settings": {
      "filePath": "settings.tsx"
    },
    "/signup": {
      "filePath": "signup.tsx"
    },
    "/auth/callback": {
      "filePath": "auth/callback.tsx"
    },
    "/_authed/jobs/$jobId": {
      "filePath": "_authed.jobs.$jobId.tsx",
      "parent": "/_authed"
    },
    "/_authed/video/$videoId": {
      "filePath": "_authed/video/$videoId.tsx",
      "parent": "/_authed"
    }
  }
}
ROUTE_MANIFEST_END */
</file>

<file path="apps/web/app/ssr.tsx">
import { getRouterManifest } from "@tanstack/react-start/router-manifest"
import {
  createStartHandler,
  defaultStreamHandler,
} from "@tanstack/react-start/server"

import { createRouter } from "./router"

export default createStartHandler({
  createRouter,
  getRouterManifest,
})(defaultStreamHandler)
</file>

<file path="apps/web/app/types.ts">
import type { Tables } from "./lib/types.gen"

export type Event = Tables<"events">
</file>

<file path="apps/web/.env.development">
# apps/web/.env.development
VITE_BASE_URL=http://localhost:5173          # TanStack / Vite default

VITE_SUPABASE_URL=http://localhost:54321
VITE_SUPABASE_ANON_KEY=eyJhbGciOiJIUzI1NiIs...

VITE_API_BASE_URL=http://localhost:8000      # FastAPI

VITE_APP_URL=http://localhost:5173           # OAuth callback origin

GOOGLE_CLIENT_ID=
GOOGLE_CLIENT_SECRET=
</file>

<file path="apps/web/.env.production">
VITE_BASE_URL=https://app.my-domain.com
VITE_SUPABASE_URL=https://xyz.supabase.co
VITE_SUPABASE_ANON_KEY=public-anon-key
VITE_API_BASE_URL=https://api.my-domain.com
VITE_APP_URL=https://app.my-domain.com

GOOGLE_CLIENT_ID=
GOOGLE_CLIENT_SECRET=
</file>

<file path="apps/web/.gitignore">
node_modules
# Logs
logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*
lerna-debug.log*
.pnpm-debug.log*

# Diagnostic reports (https://nodejs.org/api/report.html)
report.[0-9]*.[0-9]*.[0-9]*.[0-9]*.json

# Runtime data
pids
*.pid
*.seed
*.pid.lock

# Directory for instrumented libs generated by jscoverage/JSCover
lib-cov

# Coverage directory used by tools like istanbul
coverage
*.lcov

# nyc test coverage
.nyc_output

# Grunt intermediate storage (https://gruntjs.com/creating-plugins#storing-task-files)
.grunt

# Bower dependency directory (https://bower.io/)
bower_components

# node-waf configuration
.lock-wscript

# Compiled binary addons (https://nodejs.org/api/addons.html)
build/Release

# Dependency directories
node_modules/
jspm_packages/

# Snowpack dependency directory (https://snowpack.dev/)
web_modules/

# TypeScript cache
*.tsbuildinfo

# Optional npm cache directory
.npm

# Optional eslint cache
.eslintcache

# Optional stylelint cache
.stylelintcache

# Microbundle cache
.rpt2_cache/
.rts2_cache_cjs/
.rts2_cache_es/
.rts2_cache_umd/

# Optional REPL history
.node_repl_history

# Output of 'npm pack'
*.tgz

# Yarn Integrity file
.yarn-integrity

# dotenv environment variable files
.env
.env.development.local
.env.test.local
.env.production.local
.env.local

# parcel-bundler cache (https://parceljs.org/)
.cache
.parcel-cache

# Next.js build output
.next
out

# Nuxt.js build / generate output
.nuxt
dist

# Gatsby files
.cache/
# Comment in the public line in if your project uses Gatsby and not Next.js
# https://nextjs.org/blog/next-9-1#public-directory-support
# public

# vuepress build output
.vuepress/dist

# vuepress v2.x temp and cache directory
.temp
.cache

# Docusaurus cache and generated files
.docusaurus

# Serverless directories
.serverless/

# FuseBox cache
.fusebox/

# DynamoDB Local files
.dynamodb/

# TernJS port file
.tern-port

# Stores VSCode versions used for testing VSCode extensions
.vscode-test

# yarn v2
.yarn/cache
.yarn/unplugged
.yarn/build-state.yml
.yarn/install-state.gz
.pnp.*

.vinxi
.netlify
</file>

<file path="apps/web/app.config.ts">
import { defineConfig } from "@tanstack/start/config";
import tsConfigPaths from "vite-tsconfig-paths";

export default defineConfig({
  vite: {
    plugins: [
      tsConfigPaths({
        projects: ["./tsconfig.json"],
      }),
    ],
  },
  server: {
    preset: "netlify",
    compatibilityDate: "2025-01-02",
  },
});
</file>

<file path="apps/web/biome.json">
{
	"$schema": "https://biomejs.dev/schemas/1.9.4/schema.json",
	"vcs": {
		"enabled": false,
		"clientKind": "git",
		"useIgnoreFile": false
	},
	"files": {
		"ignoreUnknown": false,
		"ignore": []
	},
	"formatter": {
		"enabled": true,
		"indentStyle": "tab",
		"indentWidth": 2,
		"lineWidth": 80
	},
	"organizeImports": {
		"enabled": true
	},
	"linter": {
		"enabled": true,
		"rules": {
			"recommended": true,
			"a11y": {
				"useSemanticElements": "off"
			}
		}
	},
	"javascript": {
		"formatter": {
			"quoteStyle": "double",
			"trailingCommas": "all"
		}
	}
}
</file>

<file path="apps/web/components.json">
{
  "$schema": "https://ui.shadcn.com/schema.json",
  "style": "default",
  "rsc": false,
  "tsx": true,
  "tailwind": {
    "config": "tailwind.config.ts",
    "css": "app/globals.css",
    "baseColor": "slate",
    "cssVariables": true,
    "prefix": ""
  },
  "aliases": {
    "components": "~/components",
    "utils": "~/lib/utils",
    "ui": "~/components/ui",
    "lib": "~/lib",
    "hooks": "~/hooks"
  }
}
</file>

<file path="apps/web/package.json">
{
  "name": "@echo/web",
  "version": "1.0.0",
  "main": "index.js",
  "type": "module",
  "scripts": {
    "dev": "vinxi dev",
    "build": "vinxi build",
    "start": "vinxi start",
    "lint": "biome check --write --unsafe",
    "format": "biome format --write --unsafe",
    "check": "biome check --write",
    "supabase:types-gen": "supabase gen types typescript --project-id atvyovuiqftrksyetnjw > app/lib/types.gen.ts"
  },
  "keywords": [],
  "author": "",
  "license": "ISC",
  "description": "",
  "dependencies": {
    "@echo/db": "workspace:*",
    "@hookform/resolvers": "^5.0.1",
    "@radix-ui/react-accordion": "^1.2.8",
    "@radix-ui/react-alert-dialog": "^1.1.11",
    "@radix-ui/react-aspect-ratio": "^1.1.4",
    "@radix-ui/react-avatar": "^1.1.7",
    "@radix-ui/react-checkbox": "^1.2.3",
    "@radix-ui/react-collapsible": "^1.1.8",
    "@radix-ui/react-context-menu": "^2.2.12",
    "@radix-ui/react-dialog": "^1.1.11",
    "@radix-ui/react-dropdown-menu": "^2.1.12",
    "@radix-ui/react-hover-card": "^1.1.11",
    "@radix-ui/react-label": "^2.1.2",
    "@radix-ui/react-menubar": "^1.1.12",
    "@radix-ui/react-navigation-menu": "^1.2.10",
    "@radix-ui/react-popover": "^1.1.11",
    "@radix-ui/react-progress": "^1.1.4",
    "@radix-ui/react-radio-group": "^1.3.4",
    "@radix-ui/react-scroll-area": "^1.2.6",
    "@radix-ui/react-select": "^2.1.6",
    "@radix-ui/react-separator": "^1.1.4",
    "@radix-ui/react-slider": "^1.2.3",
    "@radix-ui/react-slot": "^1.1.2",
    "@radix-ui/react-switch": "^1.1.3",
    "@radix-ui/react-tabs": "^1.1.8",
    "@radix-ui/react-toast": "^1.2.11",
    "@radix-ui/react-toggle": "^1.1.6",
    "@radix-ui/react-toggle-group": "^1.1.7",
    "@radix-ui/react-tooltip": "^1.2.4",
    "@supabase/ssr": "^0.5.2",
    "@supabase/supabase-js": "^2.48.1",
    "@tanstack/react-form": "^1.0.0",
    "@tanstack/react-query": "^5.66.9",
    "@tanstack/react-router": "^1.111.7",
    "@tanstack/react-router-with-query": "^1.111.7",
    "@tanstack/start": "^1.111.7",
    "@tanstack/react-table": "^8.21.3",
    "@tanstack/router-plugin": "^1.114.3",
    "@vitejs/plugin-react": "^4.3.4",
    "boxen": "^8.0.1",
    "chalk": "^4.1.2",
    "class-variance-authority": "^0.7.1",
    "clsx": "^2.1.1",
    "cmdk": "^1.1.1",
    "commander": "^11.1.0",
    "cors": "^2.8.5",
    "date-fns": "^4.1.0",
    "dotenv": "^16.5.0",
    "embla-carousel-react": "^8.6.0",
    "express": "^4.21.2",
    "fastmcp": "^1.23.2",
    "figlet": "^1.8.1",
    "fuse.js": "^7.1.0",
    "googleapis": "^148.0.0",
    "gradient-string": "^3.0.0",
    "helmet": "^8.1.0",
    "input-otp": "^1.4.2",
    "inquirer": "^12.6.0",
    "jsonwebtoken": "^9.0.2",
    "lru-cache": "^10.4.3",
    "lucide-react": "^0.488.0",
    "next-themes": "^0.4.6",
    "openai": "^4.96.2",
    "ora": "^8.2.0",
    "react-day-picker": "8.10.1",
    "react": "^19.0.0",
    "react-dom": "^19.0.0",
    "react-error-boundary": "^5.0.0",
    "react-hook-form": "^7.56.1",
    "react-resizable-panels": "^3.0.0",
    "recharts": "^2.15.3",
    "sonner": "^2.0.3",
    "tailwind-merge": "2.6.0",
    "tailwindcss-animate": "^1.0.7",
    "vaul": "^1.1.2",
    "vinxi": "^0.4.3",
    "zod": "^3.24.1",
    "zod-validation-error": "^3.4.0"
  },
  "devDependencies": {
    "@biomejs/biome": "1.9.4",
    "@tanstack/router-devtools": "^1.111.7",
    "@types/react": "^18.3.18",
    "@types/react-dom": "^18.3.5",
    "autoprefixer": "^10.4.20",
    "jsdom": "^26.1.0",
    "json-schema-to-typescript": "^15.0.4",
    "postcss": "^8.5.1",
    "tailwindcss": "^3.4.17",
    "typescript": "^5.7.3",
    "vite-tsconfig-paths": "^5.1.4",
    "web-vitals": "^4.2.4"
  },
  "overrides": {
    "react-is": "^19.0.0-rc-69d4b800-20241021"
  }
}
</file>

<file path="apps/web/postcss.config.mjs">
export default {
  plugins: {
    tailwindcss: {},
    autoprefixer: {},
  },
};
</file>

<file path="apps/web/README.md">
Fix Auth 
Generate types
</file>

<file path="apps/web/tailwind.config.ts">
/** @type {import('tailwindcss').Config} */
module.exports = {
  darkMode: ["class"],
  content: ["app/**/*.{ts,tsx}", "components/**/*.{ts,tsx}"],
  theme: {
    container: {
      center: true,
      padding: "2rem",
      screens: {
        "2xl": "1400px",
      },
    },
    fontFamily: {
      sans: ["ui-sans-serif", "system-ui"],
      serif: ["ui-serif", "Georgia"],
      mono: ["ui-monospace", "SFMono-Regular"],
    },
    extend: {
      colors: {
        border: "hsl(var(--border))",
        input: "hsl(var(--input))",
        ring: "hsl(var(--ring))",
        background: "hsl(var(--background))",
        foreground: "hsl(var(--foreground))",
        primary: {
          DEFAULT: "hsl(var(--primary))",
          foreground: "hsl(var(--primary-foreground))",
        },
        secondary: {
          DEFAULT: "hsl(var(--secondary))",
          foreground: "hsl(var(--secondary-foreground))",
        },
        destructive: {
          DEFAULT: "hsl(var(--destructive))",
          foreground: "hsl(var(--destructive-foreground))",
        },
        muted: {
          DEFAULT: "hsl(var(--muted))",
          foreground: "hsl(var(--muted-foreground))",
        },
        accent: {
          DEFAULT: "hsl(var(--accent))",
          foreground: "hsl(var(--accent-foreground))",
        },
        popover: {
          DEFAULT: "hsl(var(--popover))",
          foreground: "hsl(var(--popover-foreground))",
        },
        card: {
          DEFAULT: "hsl(var(--card))",
          foreground: "hsl(var(--card-foreground))",
        },
      },
      borderRadius: {
        lg: "var(--radius)",
        md: "calc(var(--radius) - 2px)",
        sm: "calc(var(--radius) - 4px)",
      },
      keyframes: {
        "accordion-down": {
          from: {
            height: "0",
          },
          to: {
            height: "var(--radix-accordion-content-height)",
          },
        },
        "accordion-up": {
          from: {
            height: "var(--radix-accordion-content-height)",
          },
          to: {
            height: "0",
          },
        },
      },
      animation: {
        "accordion-down": "accordion-down 0.2s ease-out",
        "accordion-up": "accordion-up 0.2s ease-out",
      },
    },
  },
  plugins: [require("tailwindcss-animate")],
};
</file>

<file path="apps/web/tsconfig.json">
{
  "include": [
    "**/*.ts",
    "**/*.tsx",
    "../../supabase/**/*.ts"
  ],
  "compilerOptions": {
    "strict": true,
    "esModuleInterop": true,
    "jsx": "react-jsx",
    "module": "ESNext",
    "moduleResolution": "Bundler",
    "lib": [
      "DOM",
      "DOM.Iterable",
      "ES2022"
    ],
    "isolatedModules": true,
    "resolveJsonModule": true,
    "skipLibCheck": true,
    "target": "ES2022",
    "allowJs": true,
    "forceConsistentCasingInFileNames": true,
    "baseUrl": ".",
    "paths": {
      "~/*": [
        "./app/*"
      ],
      "@echo/db": [
        "../../packages/supabase"
      ],
      "@echo/db/*": [
        "../../packages/supabase/*"
      ]
    }
  }
}
</file>

<file path="packages/supabase/clients/browser.ts">
import { createBrowserClient } from "@supabase/ssr";
import type { Database } from "../types/generated";

export const supabase = createBrowserClient<Database>(
  import.meta.env.VITE_SUPABASE_URL!,
  import.meta.env.VITE_SUPABASE_ANON_KEY!
);
</file>

<file path="packages/supabase/clients/ssr.ts">
import { createServerClient } from "@supabase/ssr";
import type { Cookies } from "@tanstack/react-start";
import type { Database } from "../types/generated";

export const getSupabase = (cookies: Cookies) =>
  createServerClient<Database>(
    process.env.SUPABASE_URL!,
    process.env.SUPABASE_ANON_KEY!,
    { cookies }
  );
</file>

<file path="packages/supabase/migrations/20250514044259_create_videos_table.sql">
-- Migration: Setup video processing tables (videos, video_jobs, video_metadata)
-- Original Timestamp: 20250514044259 (retained for filename consistency if modifying)
-- Purpose: Defines the core data structure for the video processing pipeline,
-- including tables for video uploads, processing jobs, and generated metadata,
-- along with appropriate RLS policies for user data isolation and an enum for job status.
BEGIN;
-- 0. Create ENUM type for processing_status if it doesn't exist
-- This ensures the type is available before being used in table definitions.
DO $$ BEGIN IF NOT EXISTS (
  SELECT 1
  FROM pg_type
  WHERE typname = 'processing_status_enum'
) THEN CREATE TYPE public.processing_status_enum AS ENUM ('PENDING', 'PROCESSING', 'COMPLETED', 'FAILED');
END IF;
END $$;
-- 1. Create the 'videos' table
-- Stores core information about uploaded video files.
CREATE TABLE IF NOT EXISTS public.videos (
  id SERIAL PRIMARY KEY,
  uploader_user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE NOT NULL,
  original_filename TEXT NOT NULL,
  storage_path TEXT NOT NULL UNIQUE,
  content_type TEXT NOT NULL,
  size_bytes BIGINT NOT NULL,
  created_at TIMESTAMPTZ DEFAULT timezone('utc'::text, now()) NOT NULL,
  updated_at TIMESTAMPTZ DEFAULT timezone('utc'::text, now()) NOT NULL
);
COMMENT ON TABLE public.videos IS 'Stores information about originally uploaded video files.';
COMMENT ON COLUMN public.videos.id IS 'Unique identifier for the video entry.';
COMMENT ON COLUMN public.videos.uploader_user_id IS 'Foreign key to auth.users, identifying the uploader.';
COMMENT ON COLUMN public.videos.original_filename IS 'The original name of the uploaded video file.';
COMMENT ON COLUMN public.videos.storage_path IS 'Unique path where the original video is stored (e.g., GCS path).';
COMMENT ON COLUMN public.videos.content_type IS 'MIME type of the video (e.g., video/mp4).';
COMMENT ON COLUMN public.videos.size_bytes IS 'Size of the original video file in bytes.';
COMMENT ON COLUMN public.videos.created_at IS 'Timestamp of when the video record was created.';
COMMENT ON COLUMN public.videos.updated_at IS 'Timestamp of when the video record was last updated.';
-- Generic Trigger function for updated_at columns
-- This function can be reused for multiple tables.
CREATE OR REPLACE FUNCTION public.update_updated_at_column() RETURNS TRIGGER LANGUAGE plpgsql SECURITY INVOKER
SET search_path = '' AS $$ BEGIN NEW.updated_at = timezone('utc'::text, now());
RETURN NEW;
END;
$$;
-- Trigger for 'videos' table to automatically update 'updated_at'
DROP TRIGGER IF EXISTS trig_update_videos_updated_at ON public.videos;
CREATE TRIGGER trig_update_videos_updated_at BEFORE
UPDATE ON public.videos FOR EACH ROW EXECUTE FUNCTION public.update_updated_at_column();
-- RLS for 'videos' table
ALTER TABLE public.videos ENABLE ROW LEVEL SECURITY;
-- Policy: Users can select their own videos.
DROP POLICY IF EXISTS "Users can select their own videos" ON public.videos;
CREATE POLICY "Users can select their own videos" ON public.videos FOR
SELECT TO authenticated USING (
    (
      SELECT auth.uid()
    ) = uploader_user_id
  );
-- Policy: Users can insert videos for themselves.
DROP POLICY IF EXISTS "Users can insert their own videos" ON public.videos;
CREATE POLICY "Users can insert their own videos" ON public.videos FOR
INSERT TO authenticated WITH CHECK (
    (
      SELECT auth.uid()
    ) = uploader_user_id
  );
-- Policy: Users can update their own videos.
DROP POLICY IF EXISTS "Users can update their own videos" ON public.videos;
CREATE POLICY "Users can update their own videos" ON public.videos FOR
UPDATE TO authenticated USING (
    (
      SELECT auth.uid()
    ) = uploader_user_id
  ) WITH CHECK (
    (
      SELECT auth.uid()
    ) = uploader_user_id
  );
-- Policy: Users can delete their own videos.
DROP POLICY IF EXISTS "Users can delete their own videos" ON public.videos;
CREATE POLICY "Users can delete their own videos" ON public.videos FOR DELETE TO authenticated USING (
  (
    SELECT auth.uid()
  ) = uploader_user_id
);
-- Index for faster RLS checks and queries on uploader_user_id
CREATE INDEX IF NOT EXISTS idx_videos_uploader_user_id ON public.videos(uploader_user_id);
-- 2. Create the 'video_jobs' table
-- Tracks the status and progress of video processing tasks.
CREATE TABLE IF NOT EXISTS public.video_jobs (
  id SERIAL PRIMARY KEY,
  video_id INTEGER REFERENCES public.videos(id) ON DELETE CASCADE NOT NULL,
  status public.processing_status_enum NOT NULL DEFAULT 'PENDING',
  processing_stages JSONB NULL,
  error_message TEXT NULL,
  created_at TIMESTAMPTZ DEFAULT timezone('utc'::text, now()) NOT NULL,
  updated_at TIMESTAMPTZ DEFAULT timezone('utc'::text, now()) NOT NULL
);
COMMENT ON TABLE public.video_jobs IS 'Tracks each processing attempt or workflow for a video.';
COMMENT ON COLUMN public.video_jobs.id IS 'Unique identifier for the video processing job.';
COMMENT ON COLUMN public.video_jobs.video_id IS 'Foreign key referencing the associated video in public.videos.';
COMMENT ON COLUMN public.video_jobs.status IS 'Current status of the job using the processing_status_enum type.';
COMMENT ON COLUMN public.video_jobs.processing_stages IS 'JSONB field to store detailed progress of various processing stages.';
COMMENT ON COLUMN public.video_jobs.error_message IS 'Stores any error message if the job failed.';
COMMENT ON COLUMN public.video_jobs.created_at IS 'Timestamp of when the job record was created.';
COMMENT ON COLUMN public.video_jobs.updated_at IS 'Timestamp of when the job record was last updated.';
-- Trigger for 'video_jobs' table
DROP TRIGGER IF EXISTS trig_update_video_jobs_updated_at ON public.video_jobs;
CREATE TRIGGER trig_update_video_jobs_updated_at BEFORE
UPDATE ON public.video_jobs FOR EACH ROW EXECUTE FUNCTION public.update_updated_at_column();
-- RLS for 'video_jobs' table
ALTER TABLE public.video_jobs ENABLE ROW LEVEL SECURITY;
-- Policy: Users can select jobs related to their own videos.
DROP POLICY IF EXISTS "Users can select jobs for their videos" ON public.video_jobs;
CREATE POLICY "Users can select jobs for their videos" ON public.video_jobs FOR
SELECT TO authenticated USING (
    EXISTS (
      SELECT 1
      FROM public.videos v
      WHERE v.id = video_jobs.video_id
        AND v.uploader_user_id = (
          SELECT auth.uid()
        )
    )
  );
-- Policy: Users can insert jobs for their own videos.
DROP POLICY IF EXISTS "Users can insert jobs for their videos" ON public.video_jobs;
CREATE POLICY "Users can insert jobs for their videos" ON public.video_jobs FOR
INSERT TO authenticated WITH CHECK (
    EXISTS (
      SELECT 1
      FROM public.videos v
      WHERE v.id = video_jobs.video_id
        AND v.uploader_user_id = (
          SELECT auth.uid()
        )
    )
  );
-- Policy: Users can update jobs related to their own videos.
DROP POLICY IF EXISTS "Users can update jobs for their videos" ON public.video_jobs;
CREATE POLICY "Users can update jobs for their videos" ON public.video_jobs FOR
UPDATE TO authenticated USING (
    EXISTS (
      SELECT 1
      FROM public.videos v
      WHERE v.id = video_jobs.video_id
        AND v.uploader_user_id = (
          SELECT auth.uid()
        )
    )
  ) WITH CHECK (
    EXISTS (
      SELECT 1
      FROM public.videos v
      WHERE v.id = video_jobs.video_id
        AND v.uploader_user_id = (
          SELECT auth.uid()
        )
    )
  );
-- Policy: Users can delete jobs related to their own videos.
DROP POLICY IF EXISTS "Users can delete jobs for their videos" ON public.video_jobs;
CREATE POLICY "Users can delete jobs for their videos" ON public.video_jobs FOR DELETE TO authenticated USING (
  EXISTS (
    SELECT 1
    FROM public.videos v
    WHERE v.id = video_jobs.video_id
      AND v.uploader_user_id = (
        SELECT auth.uid()
      )
  )
);
-- Indexes for foreign keys and frequently queried columns
CREATE INDEX IF NOT EXISTS idx_video_jobs_video_id ON public.video_jobs(video_id);
CREATE INDEX IF NOT EXISTS idx_video_jobs_status ON public.video_jobs(status);
-- 3. Create the 'video_metadata' table
-- Stores metadata extracted or generated during video processing.
CREATE TABLE IF NOT EXISTS public.video_metadata (
  id SERIAL PRIMARY KEY,
  job_id INTEGER REFERENCES public.video_jobs(id) ON DELETE CASCADE NOT NULL UNIQUE,
  title TEXT NULL,
  description TEXT NULL,
  tags TEXT [] NULL,
  transcript_text TEXT NULL,
  transcript_file_url TEXT NULL,
  subtitle_files_urls JSONB NULL,
  thumbnail_file_url TEXT NULL,
  extracted_video_duration_seconds FLOAT NULL,
  extracted_video_resolution TEXT NULL,
  extracted_video_format TEXT NULL,
  show_notes_text TEXT NULL,
  created_at TIMESTAMPTZ DEFAULT timezone('utc'::text, now()) NOT NULL,
  updated_at TIMESTAMPTZ DEFAULT timezone('utc'::text, now()) NOT NULL
);
COMMENT ON TABLE public.video_metadata IS 'Stores metadata extracted or generated from a successfully completed video job.';
COMMENT ON COLUMN public.video_metadata.id IS 'Unique identifier for the video metadata entry.';
COMMENT ON COLUMN public.video_metadata.job_id IS 'Foreign key referencing the video_jobs table (one-to-one relationship).';
COMMENT ON COLUMN public.video_metadata.title IS 'Generated or user-provided title of the video.';
COMMENT ON COLUMN public.video_metadata.description IS 'Generated or user-provided description of the video.';
COMMENT ON COLUMN public.video_metadata.tags IS 'Array of tags associated with the video.';
COMMENT ON COLUMN public.video_metadata.transcript_text IS 'Full text transcript of the video.';
COMMENT ON COLUMN public.video_metadata.transcript_file_url IS 'URL to the stored transcript file (e.g., in GCS).';
COMMENT ON COLUMN public.video_metadata.subtitle_files_urls IS 'JSONB object storing URLs to various subtitle formats (e.g., {"vtt": "url", "srt": "url"}).';
COMMENT ON COLUMN public.video_metadata.thumbnail_file_url IS 'URL to the stored thumbnail image.';
COMMENT ON COLUMN public.video_metadata.extracted_video_duration_seconds IS 'Duration of the video in seconds, extracted by FFmpeg.';
COMMENT ON COLUMN public.video_metadata.extracted_video_resolution IS 'Resolution of the video (e.g., "1920x1080").';
COMMENT ON COLUMN public.video_metadata.extracted_video_format IS 'Format of the video (e.g., "mp4").';
COMMENT ON COLUMN public.video_metadata.show_notes_text IS 'Generated or user-provided show notes or detailed summary.';
COMMENT ON COLUMN public.video_metadata.created_at IS 'Timestamp of when the metadata record was created.';
COMMENT ON COLUMN public.video_metadata.updated_at IS 'Timestamp of when the metadata record was last updated.';
-- Trigger for 'video_metadata' table
DROP TRIGGER IF EXISTS trig_update_video_metadata_updated_at ON public.video_metadata;
CREATE TRIGGER trig_update_video_metadata_updated_at BEFORE
UPDATE ON public.video_metadata FOR EACH ROW EXECUTE FUNCTION public.update_updated_at_column();
-- RLS for 'video_metadata' table
ALTER TABLE public.video_metadata ENABLE ROW LEVEL SECURITY;
-- Policy: Users can select metadata for jobs related to their own videos.
DROP POLICY IF EXISTS "Users can select metadata for their video jobs" ON public.video_metadata;
CREATE POLICY "Users can select metadata for their video jobs" ON public.video_metadata FOR
SELECT TO authenticated USING (
    EXISTS (
      SELECT 1
      FROM public.video_jobs vj
        JOIN public.videos v ON vj.video_id = v.id
      WHERE vj.id = video_metadata.job_id
        AND v.uploader_user_id = (
          SELECT auth.uid()
        )
    )
  );
-- Policy: Users can insert metadata for jobs related to their own videos.
DROP POLICY IF EXISTS "Users can insert metadata for their video jobs" ON public.video_metadata;
CREATE POLICY "Users can insert metadata for their video jobs" ON public.video_metadata FOR
INSERT TO authenticated WITH CHECK (
    EXISTS (
      SELECT 1
      FROM public.video_jobs vj
        JOIN public.videos v ON vj.video_id = v.id
      WHERE vj.id = video_metadata.job_id
        AND v.uploader_user_id = (
          SELECT auth.uid()
        )
    )
  );
-- Policy: Users can update metadata for jobs related to their own videos.
DROP POLICY IF EXISTS "Users can update metadata for their video jobs" ON public.video_metadata;
CREATE POLICY "Users can update metadata for their video jobs" ON public.video_metadata FOR
UPDATE TO authenticated USING (
    EXISTS (
      SELECT 1
      FROM public.video_jobs vj
        JOIN public.videos v ON vj.video_id = v.id
      WHERE vj.id = video_metadata.job_id
        AND v.uploader_user_id = (
          SELECT auth.uid()
        )
    )
  ) WITH CHECK (
    EXISTS (
      SELECT 1
      FROM public.video_jobs vj
        JOIN public.videos v ON vj.video_id = v.id
      WHERE vj.id = video_metadata.job_id
        AND v.uploader_user_id = (
          SELECT auth.uid()
        )
    )
  );
-- Policy: Users can delete metadata for jobs related to their own videos.
DROP POLICY IF EXISTS "Users can delete metadata for their video jobs" ON public.video_metadata;
CREATE POLICY "Users can delete metadata for their video jobs" ON public.video_metadata FOR DELETE TO authenticated USING (
  EXISTS (
    SELECT 1
    FROM public.video_jobs vj
      JOIN public.videos v ON vj.video_id = v.id
    WHERE vj.id = video_metadata.job_id
      AND v.uploader_user_id = (
        SELECT auth.uid()
      )
  )
);
-- Index for the foreign key job_id
CREATE INDEX IF NOT EXISTS idx_video_metadata_job_id ON public.video_metadata(job_id);
COMMIT;
</file>

<file path="packages/supabase/migrations/README.md">
{
  "name": "echo",
  "version": "1.0.0",
  "scripts": {
    "start": "node index.js",
    "test": "jest",
    "db:migrate": "pnpm dlx supabase db push",
    "db:codegen": "sqlacodegen $DATABASE_URL --generator asyncpg --outfile apps/core/app/db/models.py",
    "db:refresh": "pnpm run db:migrate && pnpm run db:codegen"
  },
  "dependencies": {
    "express": "^4.17.1"
  }
}
</file>

<file path="packages/supabase/mutations/index.ts">
// This is where the mutations will when working with the db
</file>

<file path="packages/supabase/.gitignore">
# Supabase
.branches
.temp

# dotenvx
.env.keys
.env.local
.env.*.local
</file>

<file path="packages/supabase/config.toml">
# For detailed configuration reference documentation, visit:
# https://supabase.com/docs/guides/local-development/cli/config
# A string used to distinguish different Supabase projects on the same host. Defaults to the
# working directory name when running `supabase init`.
project_id = "echo"

[api]
enabled = true
# Port to use for the API URL.
port = 54321
# Schemas to expose in your API. Tables, views and stored procedures in this schema will get API
# endpoints. `public` and `graphql_public` schemas are included by default.
schemas = ["public", "graphql_public"]
# Extra schemas to add to the search_path of every request.
extra_search_path = ["public", "extensions"]
# The maximum number of rows returns from a view, table, or stored procedure. Limits payload size
# for accidental or malicious requests.
max_rows = 1000

[api.tls]
# Enable HTTPS endpoints locally using a self-signed certificate.
enabled = false

[db]
# Port to use for the local database URL.
port = 54322
# Port used by db diff command to initialize the shadow database.
shadow_port = 54320
# The database major version to use. This has to be the same as your remote database's. Run `SHOW
# server_version;` on the remote database to check.
major_version = 15

[db.pooler]
enabled = false
# Port to use for the local connection pooler.
port = 54329
# Specifies when a server connection can be reused by other clients.
# Configure one of the supported pooler modes: `transaction`, `session`.
pool_mode = "transaction"
# How many server connections to allow per user/database pair.
default_pool_size = 20
# Maximum number of client connections allowed.
max_client_conn = 100

# [db.vault]
# secret_key = "env(SECRET_VALUE)"

[db.migrations]
# Specifies an ordered list of schema files that describe your database.
# Supports glob patterns relative to supabase directory: "./schemas/*.sql"
schema_paths = []

[db.seed]
# If enabled, seeds the database after migrations during a db reset.
enabled = true
# Specifies an ordered list of seed files to load during db reset.
# Supports glob patterns relative to supabase directory: "./seeds/*.sql"
sql_paths = ["./seed.sql"]

[realtime]
enabled = true
# Bind realtime via either IPv4 or IPv6. (default: IPv4)
# ip_version = "IPv6"
# The maximum length in bytes of HTTP request headers. (default: 4096)
# max_header_length = 4096

[studio]
enabled = true
# Port to use for Supabase Studio.
port = 54323
# External URL of the API server that frontend connects to.
api_url = "http://127.0.0.1"
# OpenAI API Key to use for Supabase AI in the Supabase Studio.
openai_api_key = "env(OPENAI_API_KEY)"

# Email testing server. Emails sent with the local dev setup are not actually sent - rather, they
# are monitored, and you can view the emails that would have been sent from the web interface.
[inbucket]
enabled = true
# Port to use for the email testing server web interface.
port = 54324
# Uncomment to expose additional ports for testing user applications that send emails.
# smtp_port = 54325
# pop3_port = 54326
# admin_email = "admin@email.com"
# sender_name = "Admin"

[storage]
enabled = true
# The maximum file size allowed (e.g. "5MB", "500KB").
file_size_limit = "50MiB"

# Image transformation API is available to Supabase Pro plan.
# [storage.image_transformation]
# enabled = true

# Uncomment to configure local storage buckets
# [storage.buckets.images]
# public = false
# file_size_limit = "50MiB"
# allowed_mime_types = ["image/png", "image/jpeg"]
# objects_path = "./images"

[auth]
enabled = true
# The base URL of your website. Used as an allow-list for redirects and for constructing URLs used
# in emails.
site_url = "http://127.0.0.1:3000"
# A list of *exact* URLs that auth providers are permitted to redirect to post authentication.
additional_redirect_urls = ["https://127.0.0.1:3000"]
# How long tokens are valid for, in seconds. Defaults to 3600 (1 hour), maximum 604,800 (1 week).
jwt_expiry = 3600
# If disabled, the refresh token will never expire.
enable_refresh_token_rotation = true
# Allows refresh tokens to be reused after expiry, up to the specified interval in seconds.
# Requires enable_refresh_token_rotation = true.
refresh_token_reuse_interval = 10
# Allow/disallow new user signups to your project.
enable_signup = true
# Allow/disallow anonymous sign-ins to your project.
enable_anonymous_sign_ins = false
# Allow/disallow testing manual linking of accounts
enable_manual_linking = false
# Passwords shorter than this value will be rejected as weak. Minimum 6, recommended 8 or more.
minimum_password_length = 6
# Passwords that do not meet the following requirements will be rejected as weak. Supported values
# are: `letters_digits`, `lower_upper_letters_digits`, `lower_upper_letters_digits_symbols`
password_requirements = ""

[auth.rate_limit]
# Number of emails that can be sent per hour. Requires auth.email.smtp to be enabled.
email_sent = 2
# Number of SMS messages that can be sent per hour. Requires auth.sms to be enabled.
sms_sent = 30
# Number of anonymous sign-ins that can be made per hour per IP address. Requires enable_anonymous_sign_ins = true.
anonymous_users = 30
# Number of sessions that can be refreshed in a 5 minute interval per IP address.
token_refresh = 150
# Number of sign up and sign-in requests that can be made in a 5 minute interval per IP address (excludes anonymous users).
sign_in_sign_ups = 30
# Number of OTP / Magic link verifications that can be made in a 5 minute interval per IP address.
token_verifications = 30

# Configure one of the supported captcha providers: `hcaptcha`, `turnstile`.
# [auth.captcha]
# enabled = true
# provider = "hcaptcha"
# secret = ""

[auth.email]
# Allow/disallow new user signups via email to your project.
enable_signup = true
# If enabled, a user will be required to confirm any email change on both the old, and new email
# addresses. If disabled, only the new email is required to confirm.
double_confirm_changes = true
# If enabled, users need to confirm their email address before signing in.
enable_confirmations = false
# If enabled, users will need to reauthenticate or have logged in recently to change their password.
secure_password_change = false
# Controls the minimum amount of time that must pass before sending another signup confirmation or password reset email.
max_frequency = "1s"
# Number of characters used in the email OTP.
otp_length = 6
# Number of seconds before the email OTP expires (defaults to 1 hour).
otp_expiry = 3600

# Use a production-ready SMTP server
# [auth.email.smtp]
# enabled = true
# host = "smtp.sendgrid.net"
# port = 587
# user = "apikey"
# pass = "env(SENDGRID_API_KEY)"
# admin_email = "admin@email.com"
# sender_name = "Admin"

# Uncomment to customize email template
# [auth.email.template.invite]
# subject = "You have been invited"
# content_path = "./supabase/templates/invite.html"

[auth.sms]
# Allow/disallow new user signups via SMS to your project.
enable_signup = false
# If enabled, users need to confirm their phone number before signing in.
enable_confirmations = false
# Template for sending OTP to users
template = "Your code is {{ .Code }}"
# Controls the minimum amount of time that must pass before sending another sms otp.
max_frequency = "5s"

# Use pre-defined map of phone number to OTP for testing.
# [auth.sms.test_otp]
# 4152127777 = "123456"

# Configure logged in session timeouts.
# [auth.sessions]
# Force log out after the specified duration.
# timebox = "24h"
# Force log out if the user has been inactive longer than the specified duration.
# inactivity_timeout = "8h"

# This hook runs before a token is issued and allows you to add additional claims based on the authentication method used.
# [auth.hook.custom_access_token]
# enabled = true
# uri = "pg-functions://<database>/<schema>/<hook_name>"

# Configure one of the supported SMS providers: `twilio`, `twilio_verify`, `messagebird`, `textlocal`, `vonage`.
[auth.sms.twilio]
enabled = false
account_sid = ""
message_service_sid = ""
# DO NOT commit your Twilio auth token to git. Use environment variable substitution instead:
auth_token = "env(SUPABASE_AUTH_SMS_TWILIO_AUTH_TOKEN)"

# Multi-factor-authentication is available to Supabase Pro plan.
[auth.mfa]
# Control how many MFA factors can be enrolled at once per user.
max_enrolled_factors = 10

# Control MFA via App Authenticator (TOTP)
[auth.mfa.totp]
enroll_enabled = false
verify_enabled = false

# Configure MFA via Phone Messaging
[auth.mfa.phone]
enroll_enabled = false
verify_enabled = false
otp_length = 6
template = "Your code is {{ .Code }}"
max_frequency = "5s"

# Configure MFA via WebAuthn
# [auth.mfa.web_authn]
# enroll_enabled = true
# verify_enabled = true

# Use an external OAuth provider. The full list of providers are: `apple`, `azure`, `bitbucket`,
# `discord`, `facebook`, `github`, `gitlab`, `google`, `keycloak`, `linkedin_oidc`, `notion`, `twitch`,
# `twitter`, `slack`, `spotify`, `workos`, `zoom`.
[auth.external.google]
enabled = true 
client_id = "env(GOOGLE_CLIENT_ID)"
# DO NOT commit your OAuth provider secret to git. Use environment variable substitution instead:
secret = "env(GOOGLE_CLIENT_SECRET)"
# Overrides the default auth redirectUrl.
redirect_uri = "http://localhost:5173/auth/callback"
# Overrides the default auth provider URL. Used to support self-hosted gitlab, single-tenant Azure,
# or any other third-party OIDC providers.
url = ""
# If enabled, the nonce check will be skipped. Required for local sign in with Google auth.
skip_nonce_check = false

# Use Firebase Auth as a third-party provider alongside Supabase Auth.
[auth.third_party.firebase]
enabled = false
# project_id = "my-firebase-project"

# Use Auth0 as a third-party provider alongside Supabase Auth.
[auth.third_party.auth0]
enabled = false
# tenant = "my-auth0-tenant"
# tenant_region = "us"

# Use AWS Cognito (Amplify) as a third-party provider alongside Supabase Auth.
[auth.third_party.aws_cognito]
enabled = false
# user_pool_id = "my-user-pool-id"
# user_pool_region = "us-east-1"

# Use Clerk as a third-party provider alongside Supabase Auth.
[auth.third_party.clerk]
enabled = false
# Obtain from https://clerk.com/setup/supabase
# domain = "example.clerk.accounts.dev"

[edge_runtime]
enabled = true
# Configure one of the supported request policies: `oneshot`, `per_worker`.
# Use `oneshot` for hot reload, or `per_worker` for load testing.
policy = "oneshot"
# Port to attach the Chrome inspector for debugging edge functions.
inspector_port = 8083
# The Deno major version to use.
deno_version = 1

# [edge_runtime.secrets]
# secret_key = "env(SECRET_VALUE)"

[analytics]
enabled = true
port = 54327
# Configure one of the supported backends: `postgres`, `bigquery`.
backend = "postgres"

# Experimental features may be deprecated any time
[experimental]
# Configures Postgres storage engine to use OrioleDB (S3)
orioledb_version = ""
# Configures S3 bucket URL, eg. <bucket_name>.s3-<region>.amazonaws.com
s3_host = "env(S3_HOST)"
# Configures S3 bucket region, eg. us-east-1
s3_region = "env(S3_REGION)"
# Configures AWS_ACCESS_KEY_ID for S3 bucket
s3_access_key = "env(S3_ACCESS_KEY)"
# Configures AWS_SECRET_ACCESS_KEY for S3 bucket
s3_secret_key = "env(S3_SECRET_KEY)"
</file>

<file path="packages/supabase/index.ts">
export * from "./clients/browser";
export * from "./clients/ssr";
export * from "./types/generated";
</file>

<file path="packages/supabase/package.json">
{
  "name": "@echo/db",
  "version": "1.0.0",
  "type": "module",
  "main": "./index.ts",
  "exports": {
    ".": "./index.ts",
    "./clients/browser": "./clients/browser.ts",
    "./clients/ssr": "./clients/ssr.ts",
    "./types/generated": "./types/generated.ts"
  },
  "scripts": {
    "lint": "eslint ."
  },
  "keywords": [],
  "author": "",
  "license": "ISC",
  "description": "",
  "dependencies": {
    "@supabase/ssr": "0.6.1",
    "@supabase/supabase-js": "^2.49.4",
    "@tanstack/react-start": "^1.120.5"
  },
  "devDependencies": {
    "typescript": "^5.5.3"
  }
}
</file>

<file path=".cursorignore">
# Add directories or file patterns to ignore during indexing (e.g. foo/ or *.csv)
</file>

<file path=".dockerignore">
# Git
.git
.gitignore

# Node
node_modules
.next
npm-debug.log*
yarn-error.log*
pnpm-debug.log*
.pnpm-store/
.env*
!.env.example
*.tsbuildinfo

# Python
venv/
.venv/
__pycache__/
*.py[cod]
*$py.class
.pytest_cache/
.mypy_cache/
.ruff_cache/

# IDE/OS specific
.vscode/
.idea/
*.swp
.DS_Store
</file>

<file path=".gitignore">
# See https://help.github.com/articles/ignoring-files/ for more about ignoring files.

# dependencies
**/node_modules/**
# Additions for monorepo structure
/apps/web/node_modules
/.pnp
.pnp.js

# testing
/coverage
.pytest_cache

# next.js
/.next/
/out/
# Additions for monorepo structure
/apps/web/.next/
/apps/web/out/

# python
venv/
.venv/
.env
__pycache__

# production
/build

# misc
.DS_Store
*.pem

# debug
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# local env files
.env*.local

# typescript
*.tsbuildinfo
next-env.d.ts
# Additions for monorepo structure
/apps/web/next-env.d.ts
*.swp


api/tests/requests/

# Sensitive test files
api/src/tests/sensitive/*
api/src/tests/requests/*

# playwright
playwright-report/
test-results/

# docker
docker*.log

# Added by Claude Task Master
# Logs
logs
*.log
dev-debug.log
# Dependency directories
node_modules/
# Environment variables
# Editor directories and files
.idea
.vscode
*.suo
*.ntvs*
*.njsproj
*.sln
*.sw?
# OS specific
# Task files
tasks.json
tasks/ 
api/.env
apps/web/.env
api/config/secrets/*.json
</file>

<file path=".python-version">
3.13.0
</file>

<file path=".repomixignore">
# JS
node_modules/
**/node_modules/
package-lock.json
yarn.lock

# Python
venv/
.venv/
**/venv/
**/.venv/
__pycache__/
**/__pycache__/
*.pyc
uv.lock

# Build artifacts
dist/
build/

# macOS system file
.DS_Store
</file>

<file path="echo.code-workspace">
{
    "folders": [
        {
            "path": "."
        }
    ]
}
</file>

<file path="package.json">
{
  "name": "echo",
  "version": "0.1.0",
  "private": true,
  "scripts": {
    "db:start": "cd packages/supabase && supabase start",
    "db:stop": "cd packages/supabase && supabase stop --no-backup",
    "db:reset": "cd packages/supabase && supabase db reset",
    "db:push": "cd packages/supabase && supabase db push",
    "db:generate-migration": "echo 'Run: cd packages/supabase && supabase migration new <migration_name>'",

    "codegen:db-orm-models": "bash apps/core/bin/codegen_models.sh",
    "codegen:db-pydantic-models": "bash apps/core/bin/codegen_pydantic_supabase.sh",
    "codegen:db-types": "cd packages/supabase && supabase gen types typescript --project-id atvyovuiqftrksyetnjw --schema public > types/generated.ts",
    "codegen:api-types": "cd apps/core && uv run pydantic-to-typescript --module apps.core.app.db_pydantic_models.supabase_models --output ../../apps/web/app/types/api.ts --json2ts-cmd ../../apps_web/node_modules/.bin/json2ts && cd ../..",
    "codegen:all": "pnpm codegen:db-orm-models && pnpm codegen:db-pydantic-models && pnpm codegen:db-types && pnpm codegen:api-types",

    "setup:python-env": "cd apps/core && uv venv && source .venv/bin/activate && uv pip install -e \".[dev]\" && echo 'Python env setup complete. Remember to activate it in new terminals: source apps/core/.venv/bin/activate' && cd ../..",
    "db:setup-local": "pnpm db:start && echo 'Waiting for Supabase to start...' && sleep 10 && pnpm db:push && pnpm codegen:db-orm-models && pnpm codegen:db-pydantic-models && pnpm codegen:db-types",
    "db:refresh-local-schema": "pnpm db:push && pnpm codegen:db-orm-models && pnpm codegen:db-pydantic-models && pnpm codegen:db-types",

    "dev:web": "pnpm --filter @echo/web dev",
    "dev:api": "bash apps/core/bin/dev.sh",
    "dev": "concurrently --kill-others-on-fail --names \"WEB,API\" -c \"bgBlue.bold,bgMagenta.bold\" \"pnpm dev:web\" \"pnpm dev:api\"",

    "api:lint": "bash apps/core/bin/lint.sh",
    "api:format": "bash apps/core/bin/format.sh",
    "api:typecheck": "bash apps/core/bin/typecheck.sh",
    "api:test": "bash apps/core/bin/test.sh",

    "build": "echo 'Build script needs to be defined'",
    "clean": "echo 'Clean script needs to be defined'"
  },
  "dependencies": {},
  "devDependencies": {
    "concurrently": "^9.1.2",
    "npm-run-all": "^4.1.5"
  }
}
</file>

<file path="pnpm-workspace.yaml">
packages:
  - "apps/*"
  - "packages/*"
  - "supabase"
</file>

<file path="README.md">
# AI YouTube Video Metadata Generator — PRD

## ✨ Overview

This app helps users automatically generate metadata for YouTube videos (titles, subtitles, chapters, descriptions) using Google Gemini.

It uses a polyglot monorepo architecture with:

* Supabase for auth, database, and real-time features
* FastAPI for AI workflows and video processing
* GCS for video storage
* React + TanStack for frontend UI and routing

---

## 🛠️ Stack Architecture

```mermaid
graph TD
  A[React + TanStack Router] -->|calls| B(Supabase Auth)
  A -->|calls| C[FastAPI Backend]
  A -->|calls| D[Supabase DB]
  C -->|generates| E[Google Cloud Storage Signed URLs]
  C -->|processes with| F[Gemini (via Vertex AI)]
  C -->|writes metadata to| D
  A -->|fetches metadata from| D
```
 
---

## 📖 Key Use Cases

### 1. User Onboarding

* Login/signup via Supabase
* Connect YouTube account (OAuth)

### 2. Upload Video

* Get signed GCS upload URL from FastAPI
* Upload video directly to GCS
* Trigger FastAPI to process video

### 3. Generate Metadata

* FastAPI extracts audio
* Sends audio to Gemini
* Saves results (transcript, title, description, chapters) to Supabase

### 4. View Results

* React frontend fetches metadata via Supabase
* User sees structured AI-generated content

---

## 📝 API Endpoints

| Endpoint         | Method   | Description                               |
| ---------------- | -------- | ----------------------------------------- |
| `/auth/login`    | POST     | Custom auth endpoint if needed            |
| `/upload-url`    | POST     | Returns signed GCS upload URL             |
| `/videos`        | POST     | Logs video metadata + triggers processing |
| `/videos/:id`    | GET      | Returns generated metadata                |
| `/youtube/oauth` | GET/POST | Handles YouTube OAuth                     |

---

## 📊 Data Models

### `users`

* `id`
* `email`
* `youtube_access_token`
* `created_at`

### `videos`

* `id`
* `user_id`
* `gcs_path`
* `processing_status`
* `created_at`

### `video_metadata`

* `id`
* `video_id`
* `title`
* `description`
* `transcript`
* `chapters`
* `updated_at`

---

## 👌 Frontend Responsibilities

* Supabase SDK handles auth and session
* React fetches signed URLs from FastAPI
* Video uploaded directly to GCS
* API call to FastAPI to trigger metadata processing
* Polls FastAPI for metadata or queries Supabase

---

## ⚖️ Backend Responsibilities

* FastAPI routes for file handling, auth, AI logic
* Generates signed URLs
* Integrates with Gemini via Vertex AI
* Persists results in Supabase
* Background jobs for long-running tasks (via asyncio or Celery)

---

## 🚀 DevOps

* Docker Compose for local dev + prod
* Traefik reverse proxy for HTTPS
* GitHub Actions for CI/CD

---

## 🔒 Security

* Supabase handles RLS and auth
* GCS uploads via signed URLs
* JWT auth between frontend and FastAPI
* OAuth token refresh support

---

## 📊 Testing

* Pytest for FastAPI endpoints
* Playwright for frontend E2E tests
* Supabase seeding for test environments

---

## 🔄 Workflow Diagram

```mermaid
sequenceDiagram
  participant U as User
  participant W as Web App
  participant F as FastAPI
  participant S as Supabase
  participant G as GCS
  participant M as Gemini

  U->>W: Logs in via Supabase
  W->>S: Validates session
  W->>F: GET /upload-url
  F->>G: Generate signed GCS URL
  F-->>W: Return URL
  W->>G: Upload .mp4
  W->>F: POST /videos
  F->>G: Fetch video
  F->>M: Send audio to Gemini
  M-->>F: Metadata
  F->>S: Store results
  W->>S: Fetch metadata
  W->>U: Show content
```

---

## 💻 Development Setup

### Local DB workflow
pnpm run db:migrate   # apply SQL
pnpm run db:codegen   # regenerate ORM
pnpm run dev          # boot FastAPI

### Writing migrations
For guidelines on writing and managing database migrations, please see the [migrations README](./packages/supabase/migrations/README.md).

### Generating API Types

To ensure type consistency between the Python backend (`apps/core`) Pydantic models and the TypeScript frontend (`apps/web`), we use `pydantic-to-typescript`.

-   **Pydantic Models Location**: `apps/core/api/schemas/video_processing_schemas.py`
-   **Generated TypeScript Types Location**: `apps/web/src/types/api.ts`

To regenerate the TypeScript types after making changes to the Pydantic models, run the following command from the `apps/web` directory:

```bash
pnpm run generate:api-types
```

This script executes `pydantic2ts` using the `uv` environment from `apps/core`.

Make sure you have installed the necessary dependencies:
-   In `apps/core` (Python environment, managed by `uv`):
    ```bash
    # If not already installed (should be via pyproject.toml or uv.lock)
    # cd apps/core && uv add "pydantic-to-typescript>=2"
    ```
-   In `apps/web` (Node.js environment, managed by `pnpm`):
    ```bash
    # If not already installed (should be via package.json)
    # pnpm --filter @echo/web add -D json-schema-to-typescript 
    ```

---

This structure lets you move fast, use Supabase where it shines, and lean into Python where AI or Google SDKs are best. Let me know if you want to split this PRD into feature cards or set up tracking in Linear/Notion.
</file>

<file path="repomix.config.json">
{
  "output": {
    "filePath": "repomix-output.xml",
    "style": "xml",
    "parsableStyle": false,
    "fileSummary": true,
    "directoryStructure": true,
    "removeComments": false,
    "removeEmptyLines": false,
    "topFilesLength": 5,
    "showLineNumbers": false,
    "copyToClipboard": false
  },
  "include": [],
  "ignore": {
    "useGitignore": true,
    "useDefaultPatterns": true,
    "customPatterns": []
  },
  "security": {
    "enableSecurityCheck": true
  },
  "tokenCount": {
    "encoding": "o200k_base"
  }
}
</file>

</files>
