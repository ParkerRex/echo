# Overview
This document outlines the requirements for a containerized service to automate YouTube thumbnail creation. It solves the problem of time-consuming manual thumbnail design by orchestrating AI tools (Google Imagen3 for image generation/editing, Google Gemini 2.5 Flash for text generation) and image processing (Pillow) to produce consistent, branded thumbnails. The primary user is a content creator or developer needing an automated way to generate 1280x720px thumbnails via an HTTP API, deployable on Google Cloud Run. The value lies in significantly reducing manual effort, ensuring brand consistency, and potentially improving click-through rates via AI-optimized titles and backgrounds.

# Core Features
-   **AI Background Generation:**
    -   *What:* Generates a 1280x720px background image using Imagen3 based on a user-provided video title combined with a configurable base prompt.
    -   *Why:* Automates the creation of relevant and visually appealing backgrounds tailored to the video's topic.
    -   *How:* Accepts a `title` via API, calls the Imagen3 API, and returns a reference to the generated image.
-   **AI Title Rewriting:**
    -   *What:* Generates multiple alternative YouTube titles based on an original video title using Gemini 2.5 Flash.
    -   *Why:* Provides optimized, click-worthy title options to improve video discovery and engagement.
    -   *How:* Accepts a `title` via API, calls the Gemini API with a specific prompt, and returns an array of suggested titles.
-   **Automated Face Cutout & Processing:**
    -   *What:* Takes a path to a face photograph, automatically removes the background, optionally refines the cutout using Imagen3 for style consistency, and prepares it for composition.
    -   *Why:* Allows easy inclusion of a consistent personal brand element (the user's face) without manual editing.
    -   *How:* Accepts a `facePhotoPath` via API, uses image processing libraries (and potentially Imagen3 edit features) to isolate the face/shoulders with a transparent background, returns a reference to the processed cutout.
-   **Template-Based Composition:**
    -   *What:* Assembles the generated background, chosen title text, and processed face cutout into a final 1280x720px PNG image based on fixed positional templates.
    -   *Why:* Ensures brand consistency across all thumbnails with predefined placements for key elements.
    -   *How:* Uses the Pillow library to layer the background, render text (scaled to fit) in a specific top-left box, and paste the face cutout (centered) into a specific bottom-right box. Saves the result as a PNG.
-   **HTTP API Interface:**
    -   *What:* Exposes the core features and the end-to-end workflow via distinct HTTP endpoints.
    -   *Why:* Enables programmatic integration with other scripts or automation pipelines.
    -   *How:* Provides endpoints like `/generate` (full workflow), `/rewrite` (titles), `/face-process`, `/compose`, and `/preview`. Requires Bearer token authentication.
-   **Configurable Output:**
    -   *What:* Allows configuration of the output directory and filename pattern for the final thumbnail.
    -   *Why:* Provides flexibility for integrating the generated thumbnail into different file management workflows.
    -   *How:* Uses environment variables to define the output path and filename structure (e.g., `<video-slug>_thumbnail.png`).

# User Experience
-   **Primary User:** A developer or technically-inclined content creator interacting with the service programmatically via its HTTP API.
-   **Key User Flows:**
    1.  **Full Generation:** POST to `/generate` with `title` and `facePhotoPath` -> Receive reference to final PNG thumbnail.
    2.  **Step-by-Step Generation:**
        a. POST to `/rewrite` with `title` -> Get title options.
        b. POST to `/generate` (or similar) with `title` -> Get background reference.
        c. POST to `/face-process` with `facePhotoPath` -> Get face cutout reference.
        d. POST to `/compose` with background ref, chosen title, face ref -> Get final PNG reference.
    3.  **Preview:** GET `/preview` with `slug` -> Receive small JPEG/GIF preview.
-   **UI/UX Considerations:** The service is primarily API-driven, so the "UI" is the API contract (OpenAPI spec). Error handling should return clear JSON messages and appropriate HTTP status codes (e.g., 401 for auth errors, 502 for external API failures). The `/preview` endpoint provides a minimal visual feedback mechanism.

# Technical Architecture
-   **System Components:**
    -   **Web Service:** Python application using Flask/Gunicorn (or similar framework) handling HTTP requests.
    -   **Image Processor:** Python module using Pillow for image manipulation, text rendering, and composition.
    -   **AI Clients:** Python modules interacting with Google Cloud Client Libraries for Imagen3 and Gemini APIs.
    -   **Authentication Middleware:** Component to validate incoming Bearer tokens (potentially using Google Auth libraries).
-   **Data Models:** Primarily transient data related to requests (titles, file paths). No persistent database is required for core functionality. Configuration managed via environment variables. State implicitly managed by file references (background, cutout, final image).
-   **APIs and Integrations:**
    -   **Inbound:** RESTful HTTP API defined by OpenAPI spec (endpoints: `/generate`, `/rewrite`, `/face-process`, `/compose`, `/preview`).
    -   **Outbound:** Google Cloud Imagen3 API, Google Cloud Gemini 2.5 Flash API, Google Cloud Secret Manager (optional, for API key retrieval).
-   **Infrastructure Requirements:**
    -   **Compute:** Google Cloud Run service (configured for ~512MiB RAM, 1 vCPU, auto-scaling).
    -   **Containerization:** Docker image containing the Python application, libraries, font file, and potentially the base face photo.
    -   **Networking:** Standard Cloud Run ingress/egress.
    -   **Authentication:** Mechanism for validating Bearer tokens (e.g., IAM integration).
    -   **Storage:** Local container filesystem for transient processing; potentially GCS for persistent storage of generated assets if needed beyond local scope. Requires access to a font file and the base face photo (via volume mount or baked into image).

# Development Roadmap (Phased Scope)
-   **Phase 1: Core Image Generation & Composition (MVP Foundation)**
    -   Implement basic HTTP server (Flask/Gunicorn).
    -   Integrate Pillow for image loading, saving, and basic composition.
    -   Implement composition logic with hardcoded text/face positioning based on template coordinates (TBD).
    -   Integrate Imagen3 API client for background generation (using base prompt + title).
    -   Implement `/compose` endpoint logic (taking existing background ref, text string, face ref).
    -   Setup Dockerfile and basic Cloud Run deployment.
    -   *Goal: Prove core image creation and layering works.*
-   **Phase 2: AI Text & Face Processing Integration**
    -   Integrate Gemini API client for title rewriting (`/rewrite` endpoint).
    -   Implement text rendering logic within the composition step, including dynamic font scaling to fit the box.
    -   Implement face processing: background removal (using a library like `rembg` or similar) and optional Imagen3 refinement (`/face-process` endpoint).
    -   Update composition logic to use the processed face cutout.
    -   *Goal: Integrate all AI components and automated processing steps.*
-   **Phase 3: End-to-End Workflow & API Polish**
    -   Implement the main `/generate` endpoint orchestrating the full workflow (background -> titles -> face -> compose -> save).
    -   Implement the `/preview` endpoint.
    -   Add Bearer token authentication middleware to all endpoints.
    -   Implement robust error handling (retries for external APIs, proper HTTP status codes, JSON error responses).
    -   Refine configuration via environment variables (API keys, paths, template coordinates).
    -   Add basic logging (Cloud Logging integration).
    -   *Goal: Deliver a fully functional, secured, and robust service.*
-   **Future Enhancements (Post-MVP):**
    -   Batch processing endpoint.
    -   More sophisticated template options (multiple layouts).
    -   User-configurable base prompts for Imagen3/Gemini.
    -   Integration with GCS for input/output instead of local paths.
    -   More advanced error reporting/monitoring (Stackdriver alerts).
    -   Caching mechanisms for API calls or generated assets.

# Logical Dependency Chain
1.  **Basic Server & Image Handling:** Setup Flask/Gunicorn, Docker, Cloud Run deployment. Implement basic Pillow functions (load, save, create canvas). *Provides the execution environment.*
2.  **Composition Logic:** Implement the core `compose` function using Pillow to layer a background, text (initially hardcoded), and a face image (initially a placeholder/pre-cutout) based on template coordinates. *Establishes the core visual assembly.*
3.  **Imagen3 Background:** Integrate the Imagen3 API call to generate the background image based on a title. Wire this into a basic endpoint. *Provides the first dynamic visual element.*
4.  **Text Rendering:** Implement dynamic text rendering (font loading, scaling to fit the text box) within the composition logic. *Makes the text dynamic.*
5.  **Face Processing:** Implement the automated background removal for the face photo. Integrate this into a `/face-process` endpoint or directly into the main flow. *Automates a key input preparation step.*
6.  **Gemini Titles:** Integrate the Gemini API call for title rewriting (`/rewrite` endpoint). *Adds the text generation feature.*
7.  **End-to-End Orchestration (`/generate`):** Combine all previous steps into the main workflow endpoint. *Connects all pieces for the primary use case.*
8.  **Authentication & Preview:** Add Bearer token validation and the `/preview` endpoint. *Secures the API and adds utility.*
9.  **Error Handling & Configuration:** Implement retries, detailed error responses, and make parameters configurable via environment variables. *Increases robustness and flexibility.*

*Prioritization aims to get a visible, composed image output (even with placeholders) quickly, then progressively replace placeholders with dynamic/AI-generated content and finally add production-readiness features.*

# Risks and Mitigations
-   **Technical Challenge: Face Background Removal:** Reliably removing backgrounds from diverse face photos can be difficult.
    -   *Mitigation:* Start with a robust library (e.g., `rembg`). If insufficient, explore using Imagen3's editing/masking features or accept lower reliability for complex backgrounds. Clearly document limitations.
-   **Technical Challenge: Text Fitting:** Dynamically scaling text to perfectly fit a bounding box can be tricky with varying text lengths and fonts.
    -   *Mitigation:* Implement an iterative scaling approach (start large, shrink until fits) or calculate based on font metrics. Allow for minor imperfections or define strict character limits for titles if necessary.
-   **Dependency Risk: AI API Reliability/Cost:** Imagen3 and Gemini APIs might have downtime, rate limits, or unexpected costs.
    -   *Mitigation:* Implement robust retry logic with exponential backoff. Add circuit breakers for persistent failures. Monitor usage and costs closely via Google Cloud Billing/Monitoring. Have fallback logic (e.g., return error, skip step) if APIs are critical.
-   **Scope Creep: Defining MVP:** Difficulty in deciding the minimal feature set to launch quickly.
    -   *Mitigation:* Strictly follow the phased roadmap (Phase 1 -> 2 -> 3). Prioritize the core composition and AI integrations that deliver the main value proposition first. Defer non-essential features (e.g., batch processing, GCS integration) to 'Future Enhancements'.
-   **Resource Constraints (Solo Developer):** Balancing development speed with quality and testing.
    -   *Mitigation:* Focus on automated testing for core logic (Pillow composition, API client interactions). Leverage Cloud Run's managed nature to reduce infrastructure overhead. Prioritize features ruthlessly based on the MVP definition. Accept that certain non-functional requirements (e.g., >80% test coverage) might be achieved progressively.

# Appendix
-   **Template Coordinates (Preliminary - Needs Finalization):**
    -   Canvas: 1280x720 px
    -   Text Box: (x1: 50, y1: 50) -> (x2: 650, y2: 350)
    -   Face Box: (x1: 1070, y1: 520) -> (x2: 1280, y2: 720)
-   **API Authentication:** OAuth 2.0 Bearer Token required for all endpoints.
-   **Key Libraries:** Pillow, google-cloud-aiplatform, Flask/Gunicorn, google-auth.
-   **Configuration:** Via environment variables (e.g., `GOOGLE_API_KEY`, `PROJECT_ID`, `FONT_PATH`, `FACE_PHOTO_PATH`, `OUTPUT_DIR`, `TEXT_BOX_COORDS`, `FACE_BOX_COORDS`, `IMAGEN_BASE_PROMPT`, `GEMINI_TITLE_PROMPT`).
